 Bueno, buen día. El lunes llegamos ahí, hablábamos de errores. Bueno, primero definimos error absoluto, que la idea simplemente es, tengo una magnitud o un numerito de X, lo quiero aproximar, lo aproximo por un numerito x barra, que obtengo por, anda a saber qué procedimiento, y bueno, me puedo definir el error absoluto, esto es lo que llamamos el error absoluto, que es simplemente por cuánto le estoy errando y el error relativo que es normalizar por la magnitud o por el número que estoy aproximando. Esa definición nada más la tiramos ahí, no la usamos mucho. Hoy justamente quiero que empecemos a avanzar en entender qué pasa con estos errores, en particular con el error relativo, cuando hacemos operaciones. Primero que nada, asumiendo que podemos hacer nuestras operaciones exactamente. Si nos da el tiempo, ya nos vamos a meter después en el mundo computadora, en el mundo encima, no puedo representar mis números exactamente. Podemos tener algunos errores y nos empezamos a ver cómo nos puede afectar un mal algoritmo, cómo nos podemos ver percutido en que estos errores aumenten de magnitud. Entonces, hoy la clase va a ir básicamente de esto, propagación de errores. Día. Y lo primero que quiero que hagamos es a evaluar una función. El color este se llega a ver todavía, ¿no? Está todo bien, ¿sabes, chico? ¿La cámara está bien? ¿El color? Sí, está perfecto. Avíseme si me quedo sin tinta y si ya se deja de ver, avíseme. Entonces, la idea es esta, tengo una función f, no importa, definida en un dominio en R, ¿de acuerdo? ¿La de R, de R? Da una función real y la puedo derivar. Da una función razonable. Y nosotros tenemos la suerte de que esta f la podemos computar exactamente. Exactamente. Y queremos, queremos hallar, no sé, vamos a llamar así, y igual f de x para un cierto x. O sea, nada, quiero evaluar una función. Y puedo computar f, la f la puedo calcular exactamente. O sea, si me das la entrada, yo la calculo exacta. Detalle, la trampa está en que el x viene sucio. El x viene mal. Entonces, pero no tenemos x, sino una aproximación. ¿Se entiende cómo es el problema? O sea, tengo un error en la entrada, pero mi algoritmo es perfecto. No le falla la f. La pregunta obvia es, yo voy a computar, obviamente, voy a computar f en este x barra. Esto no va a ser y, esto va a ser una aproximación de y. Y la pregunta es, ¿cómo se relacionan? ¿Cómo se relacionan? El error que tengo en mi nueva aproximación de y, o sea, el error en mi salida con el error en la entrada. ¿Se entiende la pregunta? O sea, tengo una máquina perfecta, pero le entró algo mal, algo con un errorcito. La pregunta es, ¿qué pasa con el errorcito a la salida? Vale. Lo que podemos hacer nosotros es usar la definición que tengo allá. Y acordadme, damos que y es f de x y que y barra es f de x barra. Y bueno, buen día. Y acordadme ahora de que, bueno, pará, si, yo qué sé, no está mal, no es descabellado pensar, bueno, yo qué sé, si este x barra es una aproximación razonable de x, si x barra no está muy lejos de x, y bueno, f de x barra menos f de x, le puedo hacer un desarrollo de Taylor para comparar esa diferencia. Entonces, si yo hago un Taylor de primer orden, acá, Taylor me diría, bueno, f en x barra es, hago un Taylor alrededor del punto x para estimar f x barra. Si hago un Taylor de primer orden, estoy reemplazando, acá escribí, hay algo mal acá, es x barra menos x. Esto no es una igualdad, esto es una aproximación, estoy aproximando mi función f por un polinomio de grado 1 como una función de n x barra, perdón que capaz que la notación es confusa. No me importa que no conozca x, Taylor vale igual por más que no conozcas el punto, eso lo digo porque alguien lo preguntaba el otro día en el foro. Y reemplazo entonces, más que una igualdad, esto va a ser un cuchuflo de se parece, y cuando reemplazo f x barra por esto, f x barra menos f de x me queda aproximadamente f prima de x. Y ahora lo que hago simplemente es hacerme aparecer, yo quiero relacionar el y con el x, y fíjense que yo tengo x barra menos x, esto está bueno, mejor a favor. Y para tener epsilon x me falta dividir por x, así que voy a multiplicar y dividir por x. Y si aparece epsilon x, esto me queda igual a f prima de x por x sobre f de x por epsilon x. Igualdad en el estado centrado. ¿Está muy bien? Cuentitas sencillas, cuentas amigables, pero ya son significativas. Fíjense que tenemos que el error relativo en y es más o menos, a menos de aproximación, la primer orden que hicimos acá, es igual al error relativo en x multiplicado por algo. Esto de vuelta estoy asumiendo que la f la puedo concluir exactamente. Simplemente esto es una medida, o sea, lo que estoy haciendo con este numerito es cuantificar cuanto aumenta el error relativo de la salida respecto a la entrada, por el solo hecho de que tenga una función. Por el solo hecho de que le arrupe un poquito a la entrada. Pero asumiendo que estoy haciendo todo exactamente. Este numerito, le vamos a llamar el número de condición de f. No es una k, es una kappa. Les digo porque va a haber k's dentro de un ratito. Esto es una kappa. Yo trato de que las kappas, yo sé que totalmente imperceptible, mis kappas tienen como una curruita ahí. Las kappas son mucho más derechas. Les aclaro por las dudas. Kappa sub f en x. Voy a agarrar ese numerito que tenía ahí. Y los números de condición generalmente, como no lo vamos a usar para hacer cuentas en el medio, sino al final, ya le voy a poner el valor absoluto. También me va a interesar la magnitud de esto y ya le voy a poner el valor absoluto de 1. O sea, si yo quisiera escribir esta igualdad usando el número de condición, por ejemplo, yo no me voy a poner el valor de la kappa. Pero es que yo lo así, ¿no? El error relativo en i en magnitud es aproximadamente el número de condición de f. Ya metí una k, me dio una kappa. Acertó el cuentito de la curva. Número de condición en la salida, perdón, error relativo en la salida es número de condición, que es un factor que te dice cuánto aumenta por error relativo en la entrada. Es un factor de magnificación. Es como un indicador del nivel de dificultad de evaluar tu f. Es como, ¿qué tan sensible es la f? ¿Cuánto te puede perdonar la f si te equivocas un poquito en la entrada o no? Entonces, en general, medio así en el aire, si el número de condición de una función está cerquita de 1, decimos que evaluar el problema de evaluar la f en x es un problema bien condicionado. Y si es mucho más grande que 1, decimos que el problema de evaluar la f en x está mal condicionado. ¿Qué es cerquita de 1 y qué es mucho más grande de 1? ¿Ni idea? Depende de tu problema. Yo qué sé, para mí moralmente más de 100 ya es mucho, alrededor de 10 está bien. Entre 10 y 100 puede estar subjetivo. Pero totalmente depende de tu problema. ¿Puedo decir que si te convieras en una función por ejemplo de x cuadrado de seno de 0 a 0, que va 0 a 0 y no se puede estar cerrado, que va a ganar que no tiene error? Voy a repetir tu pregunta por un tema de micrófono. A usted suena raro que pongamos la derivada en x porque podrá una función medio patológica como x cuadrado por seno de 1 sobre x que la derivada en 0 da 0. ¿Y afuera no tienes nada? ¿Qué pasa con esa función? En 0 vale 0 también. Acá tienes un pequeñísimo problema la definición de menor condición. Si a esa función yo le pego un tiquiñazo y la levanto, está re bien condicionada porque no me importa que haga una basura así, si esta basura la hace alrededor del 4. Porque todos estos errorcitos son errorcitos alrededor del 4. Entonces como error relativos son chiquitos. Es esa sutileza que está escondida ahí. Esto es todo. Lo presentamos, muy lindo. Es un parámetro que nos va a hablar de sensibilidad de la evaluada función. Lo dejamos reposo un ratito. Volvemos a esto seguramente más tarde. O bueno, o capaz que ya la semana que viene. Simplemente mensaje acá es esto. El número de condición me dice cuánto se magnifica el error si pudiese computar mi F exactamente. El error en la entrada y la salida si pudiese computar la F exactamente. Segunda cosa, segunda forma de ver cómo se puede poner el error si hacemos las operaciones aritméticas. ¿Qué es lo que se puede poner? O sea, sumar dos números, restar dos números, multiplicarlos, dividirlos. Quiero hacer la suma sí o sí y la multiplicación de división hago una de las dos. ¿Cuál? Multiplicación de división. Es un penal. Hay que presión. ¿Multiplicación o división? ¿Qué te gusta más? Multiplicación. Perfecto. Multiplicación. Lo que les digo, la división está ahí en las notas. Es esencialmente la misma cuentita. Entonces yo ahora tengo dos números, X y. En vez de tener X e Y, lo que tengo es X barra y barra. Y si yo tengo la capacidad de multiplicar exactamente, lo mejor que puedo hacer es, a ver si entendemos el juego de las barritas, tomar como aproximación a X por Y al producto de la aproximación en X por la aproximación en Y. ¿Se entiende? Tengo mi número que aproxima X, mi número que aproxima Y, tengo la capacidad de multiplicar exactamente, los multiplico y lo que me queda es una aproximación al producto. Bien. Entonces, repetimos el jueguito de preguntarnos cómo se relaciona el error relativo en este producto respecto al error relativo en las entradas. Entonces, lo voy a hacer, creo que era vos que me habías preguntado en el foro. Lo voy a hacer como vos decías, total. En las notas lo hago de otra forma, pero da lo mismo. Uso la definición nomás. Entonces, el error en este producto es... Bueno, debería poner esto, pero ya estoy usando que es el producto de las aproximaciones, menos X por Y sobre X por Y. ¿Sí? La definición. Bueno, algo que uno puede sacar de aquella igualdad que puse, de la definición del error relativo, que también la habíamos escrito la clase pasada, era que de acá uno puede despejar la aproximación en función del error relativo y el número que quiere aproximar. ¿Sí? O sea, que podría acá reemplazar X barlita por 1 más épsilon X por X e Y barlita lo puede aproximar por 1 más épsilon Y por Y. Está palmando. ¿Tenés alguna pregunta? ¿Ahí? Pregúntenme. No sé quién está escuchando algo de la aproximación. Dale, pregúntenme. No hay miedo. Sí, esa última. Dale. Dale. ¿Marcáme a qué? ¿Esto? ¿Aga? Esta es la definición, ¿no? Esta es la definición. El error relativo en el producto es, en realidad, hago dos pasos acá en el pizarrón de una, pero lo correcto sería decir esto, ¿no? Es, el error relativo al aproximar algo es lo que obtuve de aproximarlo... Perdona, este barlita no va, ¿no? Este barlita no va, capaz que se confundiera. Lo que... Mi aproximación, menos el número, digo el número, uso esta propiedad. Y ahora, sigo yo. Bien, me voy a comer esa barlita nuevo. Bien. Bueno, simplifico un montón de cosas ahí, ¿no? Los X por Y se van todos. Ni que hablar estoy asumiendo que X e Y son distintos de 0. Si X e Y fueran 0, ya está. Ya está. Para empezar, no podría hablar del error relativo o en X o en Y, ni mucho menos podré hablar del error relativo en el producto, ni tampoco tendría sentido porque estoy multiplicando por 0. Me va a dar 0. Entonces, puedo simplificar acá X por Y. Y esto me queda 1 más epsilon X, 1 más epsilon Y, menos 1, y se tachó el X por Y. Buenas. ¿No? Distributivo a todo, esto me queda epsilon X más epsilon Y más epsilon X, epsilon Y. Bien. ¿Sí? Si tus aproximaciones son más o menos buenas en el sentido de que epsilon X y epsilon Y son chiquitas, entonces uno espera que el producto sea en magnitud más chiquito que alguno de los dos, ¿no? O sea, esto va a ser comparable con la suma. Bien. ¿Cuál es la moraleja de este cuento? Moraleja, multiplicar es seguro. Muy... Lo que me cuesta escribir la palabra multiplicar en el pizarro, no saben lo que es. Tengo que pensarlo 7 veces. Multiplicar es seguro. ¿En qué sentido? En el sentido de que el error relativo en la salida, si yo lo puedo hacer exactamente, no va a ser mucho peor que los errores que tiene la entrada. ¿Sí? Sí. ¿Sí? Sí. No va a ser mucho peor que los errores que tiene la entrada. ¿Sí? Incluso, incluso, fíjense esto que interesante y también que intuitivo, yo a los épsilons los dejaba que fueran positivos o negativos, ¿no? Entonces, claro, fíjense, si vos tenés el épsilon X que es negativo, quiere decir que tu aproximación de X es un poquito más chica que X. Si tu épsilon Y es positivo, quiere decir que tu aproximación de Y es un poquito más grande que Y. Capaz que cuando los multiplicás, eso se compensa un poco. O sea, si épsilon X y épsilon Y tienen signos distintos, capaz que esto se compensa y hasta te queda mejor. Podría pasar. Que es como decir, si agarro un número un poquito más chico que lo que quiero y uno más grande de lo que quiero y los multiplico, capaz que justo se arregla todo. No importa. Lo importante acá es, multiplico número 2, estoy tranquilo. No va a pasar nada grave. Fíjense que acá sí podía pasar. Si el número de condiciones es grande, si mi f está mal condicionada, puedo tener un problema. Acá no voy a tener ningún problema. La división no la vamos a hacer. Pueden hacer ustedes la misma cuenta. Lo que van a llegar es a esto. Misma cuenta. No tiene nada misterioso. Y tampoco tiene nada de así, de estrambótico. El épsilon Y puede ser positivo o negativo. O sea que este signo de menos no dice nada en especial. Lo que importa es, de vuelta, si yo quiero ver qué magnitud tiene este error relativo, esta magnitud es comparable con el signo de la división de la división de la cantidad de los dos. Bueno, bien. Entonces, multiplicar o dividir, estamos tranquilos. Los errores no se van a propagar mucho. ¿Qué pasa cuando sumas o restas? Cada sumar y restar, el número de condiciones que tiene el error relativo es el número de condiciones que tiene el error relativo. Y el número de condiciones que tiene el error relativo es el número de condiciones que tiene el error relativo. La sumar y restar, o sea, la vez de multiplicar y dividir, podría haber pensado también que es más o menos lo mismo. Pero yo qué sé, tendría que haber entendido cómo es el número de condiciones de hacer 1 sobre i. Podría haberlo hecho con aquella función. Pero bueno, prefería hacerlo separado. Bueno, sumo o resto de números. ¿Está bien? Entonces, de vuelta, si puedo hacer la suma exactamente, mi aproximación a la suma va a ser la suma de las aproximaciones. Y con la resta lo mismo, ¿no? Para fijar ideas, ¿vindríamos la suma? ¿Sí, no tengo que poner más menos todos lados? ¿Me dejan? Me tienes que decir que sí. ¿Me dejan? Gracias. Listo. Igual i puede ser negativo. O sea que en realidad hay como una resta camuflada. Bueno, a ver. ¿Cómo sería entonces el error en esta suma? ¿Día? Y bueno. Mismo razonamiento, ¿no? Mi aproximación menos el número de condiciones de la suma. ¿Verdad? ¿Verdad? ¿Verdad? ¿Verdad? ¿Verdad? ¿Verdad? Mi aproximación menos el número que quiero aproximar dividido el número que quiero aproximar. Hago el jueguito ese de escribir x barlita como x por 1 más epsilon x y barlita como y por 1 más epsilon y menos x menos y sobre x más y. Acá se tachan un par de cosas y ordeno y me queda algo así. Si no me equivoco. A ver. x por 1 se va con este. Me queda epsilon x por x dividido x más y. Y por simetría tiene que ser así entonces. ¿Sí? Bueno, la pregunta es, ¿eso es bueno o es malo? ¿Es bueno o es malo? O sea, ¿es bueno que me haya parecido x sobre x más y por epsilon x o y sobre x más y por epsilon y? ¿Este término es chico o es grande? Depende, ¿no? Depende. Vamos a mirar. Si x e y tienen el mismo signo, le pongo así rapidito, x por y mayor a 0 quiere decir que tienen el mismo signo, entonces es fácil ver x más y tiene el mismo signo que x, ¿no? Tiene el mismo signo. Este número va a estar atrapado entre 0 y 1. Sí, decime. ¿Dónde? ¿Acá? Falta un menos uno, ¿deciés? No, pero fíjate, x por 1, x menos x se van. Sí, o sea, queda ahí. ¿Están de acuerdo con esto? Es hacer una cuentita nomás, ¿no? Pero... Está ahí. Lo mismo puedo decir obviamente para el otro. Para y sobre x más y. Sale al toque. ¿Y esto qué quiere decir? Quiere decir que estos factores que están acá multiplicando están entre 0 y 1. O sea que estas cosas realmente no son muy grandes, ¿no? Entonces, lo que pasa en este caso es que si miro, le pongo barlita, le pongo barro absoluto a este error relativo, me queda algo así. Estos números están entre 0 y 1. De hecho, incluso podría haber hecho las cosas un poco mejores y decir, suman 1 entre sí, ¿no? Si sumo estos dos me da 1 la suma. Pero está, no importa. No calienta. No calienta. Por ejemplo, lo puedo escribir así. O sea, el error relativo en la suma no es peor que la suma de los errores relativos en valor absoluto. O no es peor que el peor de los dos. Estamos tranquilazos. Sumar números del mismo signo es seguro. Y repito, es seguro en el sentido de que el error relativo en magnitud no aumenta mucho. Está controlado, el error relativo en la salida está controlado por el error relativo en la entrada. De forma así, estable. ¿Se entiende? Bueno, ¿qué pasa si tienen signo distinto? En las notas, la cuenta está hecha de una forma muy distinta. Así no me tratan de vender humo. Y que hablar que si x o y son 0 no tiene gracia, porque estoy haciendo x más 0 o y más 0. No tiene gracia. Y también fíjense que si x fue 0, y si x fue 0, y si y fue 0, y si y fue 0, y si y fue 0, bueno, y también fíjense que si x fuese justo menos y, si fuesen opuestos, tendría un problema porque la suma me daría 0. Y el error relativo en la suma no estaría bien definido. O sea, tengo que asumir acá, medio escondidamente. Y no sean opuestos. Si sean 0 opuestos, el error relativo en la suma no está definido, porque la suma te da 0. Entonces tengo dos números de signo cambiado, que no son el opuesto uno del otro. Uno de los 12 es más grande en valor absoluto, entonces. Entonces, supongamos, voy a llamar que x es el más grande en valor absoluto. No importa si x es positivo o negativo, lo importante acá es que el signo de x es distinto del signo de y, y x es el más grande en magnitud. Entonces, si no son opuestos, esto quiere decir entonces, que, yo qué sé, x es igual a, bueno, uso una c. ¿Está bien? O sea, ¿hay algún factor ahí más grande que uno, como el valor absoluto de x es más grande del de y? Bueno, nada, el cociente le llamo c, y ese c estoy suponiendo que es más grande que uno. ¿Está bien? Quiero hacer la cuenta así, lo más precisa que pueda. Bueno, vuelvo a esta forma, y ahora voy a hacer la misma cosa que yo. Y ahora, vamos a hacer la misma cosa que yo. Y ahora, vamos a hacer la misma cosa que yo. Bueno, vuelvo a esta fórmula entonces. ¿Qué puedo decir ahora? Sobre estos estos factores. A ver. ¿Pueden ser grandes? O sea, ¿pueden ser grandes? ¿Pueden ser grandes? ¿Cuánto sería grande este factor? Cuando estén muy cerca de ser x igual menos y, ¿no? Cuando x más y esté muy cerca de ser cero. Ahí te vas a tener un problema. Si x más y está muy cerca de ser cero, quiere decir que estoy muy cerca de donde el error relativo no está definido, y además si x no es chiquito en magnitud, este número es gigantesco, y voy a tener que pagar el precio. Me va a salir caro esto. Veamos cómo es la cosa. Por ejemplo, yo podría hacer este jueguito, ¿no? La vez que quería es igualdad triangular. De ¿qué? de cálculo... Ya no sé si se da esto en cálculo 1 o no. Sube un resto y, uso la desigualdad triangular. El valor absoluto de menos y es el valor absoluto de y. Se va. Y ahora, por ejemplo, puedo usar que esta propiedad está acá. Entonces, y es una constante por el valor absoluto de x. Esto es x más y más perdón. y es 1 sobre x por la constante. Está. Perdón, me relayé un poquito con la vuelta. Paso el valor absoluto de x para otro lado. Y ahora, lo que estoy diciendo entonces, perdón, mayor igual no, menor igual. Estoy diciendo que este factor, si lo quiero controlar con algo, si quiero controlar este factor con algo, lo puedo controlar con el inverso de este número que me queda por el valor absoluto de x. Y ahora, el valor absoluto de x es el valor absoluto de y. El inverso de este número que me queda c sobre c menos uno. Tratando de hacer la cuenta lo más precisa que pueda. Está. O sea, si quiero controlar el factor que multiplica x en estas condiciones, básicamente esto va a ser lo mejor que puedo decir. Está. Fíjense que no estoy diciendo que es un igual, estoy diciendo, lo puedo controlar con esto, pero créanme que esta cuenta no se puede mejorar mucho. Básicamente, cuando esta desigualdad triangular sea una igualdad, marché. Esto va a ser casi que una igualdad. O va a ser una igualdad. También podría haber hecho de esta misma cuentita, ¿cómo tengo que hacer acá? ¿Dejéme razonar? Ah, claro. Replazo x ahora por c por el valor absoluto de y. Entonces me queda c por el valor absoluto de y menor o igual, x más y, así. De vuelta, paso el y para el otro lado, divido por x más y, y lo que me va a quedar es algo así. Me queda, a ver, ayuden, 1 sobre c menos 1. Listo. ¿Sí? No hice una cuenta muy estrambótica, usé la desigualdad triangular y un poquito de muñeca, nada más. Entonces, lo que estoy diciendo es esto, fíjense. Si quiero controlar el factor que multiplica la x, el épsilon x, tengo este numerito, y si quiero controlar el que multiplica y, tengo este numerito. Combino todo, en aquella fórmula, o sea, vuelvo acá, vuelvo a esta formulita, lo que estoy diciendo es que el error relativo en x más y se puede controlar con este número, y el épsilon x, y el épsilon x, más número por épsilon y, y esto, lo mejor que puedo hacer, lo mejor que puedo hacer, y acá estamos en el horno, es acotarlo así. Bueno, aleja. Si quieren, incluso podemos ordenarlo un poquito más. Podemos ordenarlo un poquito más. Podría poner un menos uno más uno acá, y me quedaría así. Si quieren ver lo lindo, te queda así. Nada, lo escribí, esto es una igualdad, no hice nada, hice algo muy elemental, que fue, este c lo escribí como c menos uno más uno, el c menos uno sobre c menos uno me da uno, y el uno lo pasé y lo compartí, con el numerador ahí, el denominador, c menos uno. Está, nada, me metí en un mundo de cuentas. Épsilon x pelado, bien, notable. Pero, acá me quedó la suma esta, con un c menos uno dividiendo. Entonces, ¿qué pasa? Si c está muy lejos de ser uno, si c está muy muy lejos de ser uno, este numerito está muy muy cerca de ser cero, ¿no? Uno sobre c menos uno, c menos uno es enorme, está muy lejos de ser cero. Perdón, muy cerquita de ser cero. ¿No? c es un millón, uno sobre un millón, entonces cerquita de ser cero, y entonces, el error relativo en la suma se parece al error relativo en x. O sea, ¿qué estoy diciendo? Si tengo un número que es como un millón, y le estoy molestando un número que es como menos cero coma uno, el error relativo en la suma es básicamente el error relativo en el grande, en un millón. El i no le hace ni cosquillas. Entonces, este es un caso que estamos tranquilos. El error relativo en la salida es comparable con el error relativo en la entrada. Estamos re tranquilos porque son comparables. El problema entra cuando esta c se empieza a parecer a uno. Entonces, uno sobre c menos uno se hace enorme. ¿Si? Se va infinito. Yo que sé, cuando c se atiende a uno, esto se atiende infinito. Y entonces, ¿qué pasa ahí? El que domina en esta discomposición es el segundo término. Y este segundo término es malo. Es grande. Vamos a usar rojo. Esto caca. No hay que hacerlo. No se hace. No hay que evitar a toda costa sumar números que sean casi opuestos. ¿Por qué? Porque nos encanta exagerar, a esto le decimos cancelación catastrófica. Es una cancelación porque obviamente si sumo mil más menos mil o algo que se parece a mil más algo que se parece a menos mil se cancelan. Y es catastrófica. ¿Por qué? Porque el error relativo de repente se me fue de las manos. Si podemos evitar sumar números de magnitud opuesta, hay que evitarlo. ¿Por qué? Porque puede pasar esto. Y esto que parece un chiste, después les pongo en el EVA una anécdota de gente de la NASA que se combinó cancelación catastrófica y se le fueron unos cientos de millones de dólares por hacer eso. Por confiarse. Porque uno después se confía. Uno va a avanzar en el curso, va a ver 10.000 algoritmos, nos vamos a olvidar de esto y como que, ah, ¿qué era aquello de los errores? Ni idea. Bueno, a los ingenieros de la NASA les pasó y les costó plata. Y seguramente trabajo alguno. También. Y que 30 años después nos ligamos de ellos todavía. Esto hay que evitarlo. Les pongo un ejemplo. Les pongo un ejemplo que no está en las notas, pero es bien, bien, bien bobo. Bien, bien bobo de cómo podríamos o qué es una cancelación catastrófica. Ejemplo bobo. Quiero calcular el logaritmo de un millón uno menos el logaritmo de un millón. ¿Va? Y salvé cálculo uno copiando, entonces no me acuerdo que la resta de logaritmos es el logaritmo de la división. Porque soy un bobo. ¿Va? ¿Cuánto es el logaritmo de un millón uno? Hice los deberes, no lo hice a mano. Podría, pero no lo hice a mano. El logaritmo de un millón uno... El logaritmo, vieron que es una función que crece lento, ¿no? Se va infinito lento. Pero les cuento así con algunos dígitos. 13,815,115 y sigue, ¿está? Ni idea. ¿Cuánto es el logaritmo de un millón? Sorpresa. 13,815,115. Todos iguales. Y acá empieza la diferencia. Tiene un 0,5. Les voy a marcar en colores los números distintos. 1,5, 0,5. ¿Sí? ¿Qué quiere decir esto? Que si vos, si vos, nada, te embola escribir más de cuatro dígitos, más de cuántos, uno, dos, tres, cuatro, cinco, seis, cinco, seis, siete, cifras significativas, o tu calculadora no tiene capacidad de manipular más de siete cifras significativas, entonces no podés distinguir estos dos números. ¿No? Entonces, si solamente, si tenemos solamente capacidad de trabajar con siete cifras significativas, y hacemos la resta, el resultado nos da 0. O sea, si trabajás con siete cifras significativas, no sos capaz de distinguir estos dos números, y una vez que no sos capaz de distinguir estos dos números, marchaste. ¿Sí? La resta te da 0. ¿Se entiende? Entonces, cualquier errorcito mínimo que aparezca, yo que sé si acá este 15, en vez de tenerlo así, nada, este lo tiene representado exacto, y este capaz que también, pero nada, ahora los trunqué y tengo un errorcito chiquitito en mi representación, marché. Este errorcito chiquitito, en la octava cifra significativa, que es un error relativo al orden de 10 a la menos nueve, 10 a la menos ocho, perdón, se me transformó en un error infinito, un error enorme. ¿Qué hago ahí? ¿Me pongo en posición fetal y lloro? No, no. ¿Cómo es relativo esto? Si tengo siete cifras significativas, ¿cómo hago esto? ¿Cómo lo hace un ingeniero? ¿Divís? Sí, pero si divido, no es un error, es un error, sí, pero si divido, a ver, dale, divido, dale, yo te voy a seguir, yo te sigo. No, no necesariamente, a ver, que vos no hagas lo que yo haría, no quiere decir que esté mal, igual yo haría eso, así que dale. Está, para escribo nomás la propiedad, ya escribo así, 1.000.0001 es 10 a la 6 más 1, menos el logaritmo de 10 a la 6, voy a decir que lo escriba como división. Dale. ¿Podemos usar la división? Sí, podemos usar la división, sí, pero yo tendría que computar el logaritmo de un número espantoso, y a la mierda. Ese número, o sea, va a ser seguro que este número me va a dar muy muy cerquita de 1, ¿no? O sea, me va a dar muy cerquita de 1, y capaz que justo no lo distingo de 1. Entonces, ¿qué puedo hacer acá? Cuando tu computador ande a la mierda, y te pones en el lugar de la división, y te pones en el lugar de la división, y te pones en el lugar de la división, y te pones en el lugar de la división. Cuando tu computador no es confiable, usa la matemática un poquito. Este número, si yo divido, esto es 1 más 10 a la menos 6, ¿no? Hago Taylor. Cierro los ojos y digo, ¿sabes qué logaritmo? Te aproximo por una función lineal. Taylor para el logaritmo. Si x está cerquita de 0, o Taylor a un equivalente. Yo le digo Taylor porque todo sale con Taylor. Y si no se acuerdan de Taylor, lean Taylor. Si x está cerquita de 0, el logaritmo de 1 más x, el logaritmo de 1 más x alrededor de x igual 0, se parece al logaritmo de 1, que es 0, más x. El viejo he querido equivalente, ¿no? El logaritmo de 1 más x es equivalente a x. Para x se quita de 0. Entonces, ¿qué puedo hacer? 10 a la menos 6, para mí es un número chiquito. Entonces, es mucho más seguro, puedo hacer esto. El logaritmo de 1 más 10 a la menos 6, lo aproximo por 10 a la menos 6. ¡Y ya está! Y no tuve que hacer ninguna cuenta. Y esto termina siendo mejor. Esto termina siendo mejor. Esto tiene un error relativo, se los cuento porque lo tengo a ningún lado. Esto tiene un error relativo. Acá lo tengo. Hacer esto tiene un error relativo. O sea, si yo hago esta aproximación, mi error relativo es 5 por 10 a la menos 7. Tremenda aproximación. O sea, a los efectos de lo que necesito, esto es una muy buena aproximación. Si quisiera, podría hacer x más y buscar quién es el siguiente término, en Taylor, si no me alcanzo. Pero capaz que con mis 7 cifras no puedo representarlo. Yo tiendo a creer que no voy a poder representarlo. Pero bueno. ¿Qué puedo hacer? Pero bueno. Esta aproximación, ya hacer esto, ya es mejor. A veces no hacer las cosas exactamente termina siendo mejor. ¿Se entiende? Si vos tenés un problema de cancelación, adelante tuyo, a veces hacer una aproximación termina siendo más seguro que tratar de hacer la operación exactamente y exponerte a la cancelación. ¿Este error sale de las 7 cifras significativas? No, este error sale de la definición. Lo reemplacé. O sea, agarré la verdad absoluta de cuánto es el logaritmo de 1 más 10 a la menos 6. Lo reemplacé por esto. O sea, calculé esto. O sea, tendría que haberlo puesto... A ver, lo pongo... Este error... Hice esta cuenta. Hice... 10 a la menos 6 menos el logaritmo de... no sé qué... sobre el logaritmo. Usé la definición. Y esto me dio 5 por 10 a la menos 7. Más o menos. O sea, tal cual. Entonces, no hay que ponerse el balde de querer hacer las cuentas exactas. A veces, tus aproximaciones pueden ser mejor que tu capacidad de representar. Y si tenés una cancelación adelante, no tendrías que ser más beneficioso aproximar que tratar de representar exactamente. Hay una contraposición ahí. Hay una contraposición. Que va a parecer bien clarito la semana que viene. Pero fíjense que acá el truquito fue evitar hacer una resta de números de igual magnitud. E incluso acá... Como esto no lo podía distinguir... Bueno, tuve que hacer un truquito tipo Tyler. Otro ejemplo. Otro ejemplo también, así como... Voy a asumir que tengo pocas cifras de precisión. Y cuadrado... Están las notas este ejemplo. Les digo, menos 56x más ui. Pero con una máquina que nos deja trabajar con cinco cifras significativos. Usted dirá, loco, pero esto es un ejemplo de 1940 con cinco cifras. O sea, no cambia mucho. Si tengo cinco o tengo 16, o tengo 32, es lo mismo. El problema te aparecerá más grande antes o después, pero es más o menos el mismo problema. Y si no tienes la presentación, finita. Hago con cinco cifras y no con 32, porque para que los números queden lindos y en el pizarrón puedo hacerlo. Aclaro eso, nada más. Por eso yo tenía siete, acá tengo cinco, a veces voy a tener tres. En la computadora vamos a ver cuántos tenemos después. Bien. Bueno, ¿cómo calculan las raíces de una cuadrática? Está fácil, ¿no? Las raíces... La resolvente, báscara, no sé cómo le digan. Y me queda, se los cuento ya, me queda... ... ... ... ... ... ... ... ... ... ... Spoiler, 28 al cuadrado ... ... es 784. ... ... O sea, raíz de 383 está cerquita, muy cerquita de ser 28. ¿Dónde están los problemas acá? ¿Dónde están el peligro? En R2, ¿no? En R1 debería ser totalmente amigable para computar. No importa que tengamos cinco o tres cifras significativas. Deberíamos no tener mucho drama con R1. R1 va a ser más o menos 56. O sea, si trabajaba con dos cifras, digo 56 y va a estar bastante bien. R2, en cambio, va a ser un problema. Entonces, ¿qué haríamos acá? Si tuviésemos nuestra calculadora de cinco cifras significativas, bueno, 28 lo puedo representar exactamente. A ver si lo escribo así. Mi aproximación de 28 es 28. Eso quiere decir que cuando quiera representar al 28, está todo bien. No tengo error. Bien. Podría haber hecho el algoritmo que vimos el lunes. No lo hice. Pero les cuento que la raíz de 783 es más o menos 27,982. Y después números que me voy a perder. Pongo un par. Uno, tres, siete y sigue. Cuando yo quiera representar raíz de 783, esto que está en azul, lo perdí. Eso, obviamente, ahora sí tengo un error relativo en mi representación. No lo estoy representando exactamente. El error relativo es chiquito. No lo escribí. Ah, sí, acá lo escribí. El error relativo en este número es más o menos, uso la definición y me queda del orden de 10 a la menos 6. Más o menos menos 5 por 10 a la menos 6. Chiquitito, divino. Vamos, re tranquilo. Bueno, R1 es seguro. Si yo quiero calcular ahora mi aproximación R1, obviamente voy a hacer mi aproximación a 28 más mi aproximación a raíz de 783. Entonces en mi computadora o mi calculadora de cinco cifras, R1 va a ser sumar esto y esto y 28 y me va a quedar 55,982. Y está divino esto porque en realidad R1 es 55,982137... Error diminuto. El error en R1 es más o menos 2 con 4 por 10 a la menos 6. Divino, ¿no? O sea, lo que decíamos, si estoy sumando números que tienen el mismo signo, estamos re tranquilos. ¿Qué pasa con R2? R2, mi aproximación, va a ser la aproximación de 28 menos la aproximación de esta raíz cuadrada. Ustedes ya saben que acá va a haber problema porque ahora me va a quedar 0,0018. Observación relevante. ¿Cuántas cifras tengo en esta representación de R2? Dos. Perdí capacidad, ¿no? O sea, en teoría tendría capacidad para almacenar cinco cifras significativas y resté dos números y mi número que me quedó ya perdí cifras, perdí precisión de esa forma también. No tengo cifras. El error acá en R2 no les va a parecer tan dramático. Es el orden de 7,7 por 10 a menos 3. No les parece dramático, pero es dramático. Porque fíjense, este error es cuando lo comparo con este y con este, agarré algo que estaba, era exacto, algo que tiene un error del orden de 10 a menos 6, lo junté, hice un guiso y me salió con 10 a menos 3. O sea, acá perdí, aumentó en un factor más o menos de 1.500. Perdí tres órdenes de magnitud de un plumazo. ¿Está bien? Esto, capaz que si tu cuenta no le importaba mucho hacer esta aproximación, capaz que estabas bien. Pero fíjense que perdiste un montón de precisión. Eso es una cancelación catastrófica. Para dar precisión, podrás hacer las cosas así, cerrando los ojos y cómo sale. ¿Cómo calculás R2 de forma segura? ¿Cómo se arregla en este caso? ¿Cómo? ¿Taylor dónde va? Para, o sea, algo sí podríamos hacer con las raíces cuadradas, a ver. Si multiplico por el conjugador. Arriba y abajo, a ver. Ah, ok, ya entendí. Bueno, no va a estar muy lejos lo que vamos a hacer de eso. Sí. Uso la sugerencia de él, un segundo, la escribo nomás, la escribo en un color. Porque está bien. Uno podría haber hecho este juego. Opción 1. Esta me gustó. 28 menos raíz 783. Un truquito lindo es, si tengo dos números que son de la misma magnitud y una es una raíz cuadrada, puedo conjugar. Multiplico y divido por la raíz. Lo que está arriba es 28 al cuadrado menos 783. Les conté que 28 al cuadrado es 784. O sea, queda 1. Entonces, algo que podrán hacer ustedes, y parece muy razonable, así que te doy el crédito, es decir R2, aproximarlo por 1 sobre 28 más raíz 783. Esto lo puedes hacer de forma estable o dividir 1 por un número, también lo puedes hacer de forma estable. Esto estaría bien. Lo que le voy a contar va a ser lo mismo, básicamente, pero lo digo como lo dicen las notas, el resultado va a ser el mismo, así que me encantó. Opción 2. Escribir x cuadrado menos 56x más 1 factorizarlo, con las raíces. Si? Sin polinomio, tiene coeficiente principal 1, así que se puede escribir como x menos una raíz por x menos la otra raíz. Si desarrollo del lado derecho, me queda x cuadrado menos R1 más R2 por x más R1 por R2. Esto quiere decir entonces, tengo como una especie sistemita si quieren para R1 y R2, la suma tiene que ser 56 y el producto tiene que ser 1. ¿Cuál es la idea de acá? Esta opción sería esta. Si R1 lo podés calcular de forma de ampliación, podés calcular de forma segura, de forma estable, acá. Si? Calculate R1 de forma estable y después trata de usar esto para despejar R2. Entonces, opción 2 sería calcular R1 esto es estable, es seguro. Y después, ¿cuál de las dos voy a usar? Tengo dos formas de despejar R2, ¿no? Podría decir que R2 es 1 sobre R1 o podría decir que R2 es 56 menos R1. ¿Por qué la que hice en rojo está mal? O no está bueno. Porque la que hice en rojo me da una cancelación. R1 es más o menos 56. Entonces, si hago esto, estoy en la misma que estaba antes. Me metí una cancelación. Entonces, lo que está en rojo no está bueno acá. No está bueno usar esta. Está bueno, sí. Acá. Y si se fijan, es lo mismo que sugirió él. Termina quedándote esto. O sea, vas a tener que aproximar 28, vas a tener que aproximar raíz 783, sumaste una aproximación y hago 1 sobre eso y eso es mi aproximación de R2. Hacer esto, cualquiera de estas dos, te da un error relativo. Taca, taca, taca, taca, taca, taca, taca, taca. No lo escribí. No lo escribí. Ah, sí, acá. 8 con 9 por 10 a la menos 6. No perdiste cifras. O sea, el error relativo en R2 es comparable con el error relativo en tus entradas. O sea, si podemos evitar hacer cancelaciones catatróficas, tenemos que evitar hacer cancelaciones catatróficas. Si ven un número grande menos otro número grande, peligro. ¿Ah? Evitar, tratar de esquivar eso. Este prarito. Bien. Así que vamos a tratar de hacer pasar vergüenza a la computadora un poquito. ¿Tiene alguna pregunta hasta acá? De esto sí, dale. El principio de Taylor, acá del logaritmo de 1 más x. De cuando... A ver, ¿de qué nos agarramos de por qué usar Taylor puede ser hacer mejor que vivir? Cuando tenés una situación complicada necesitas una solución, básicamente. Una alternativa. Entonces, Taylor no va a ser lo mejor siempre. Taylor no va a ser lo mejor siempre. Pero bueno, acá estás en una situación desesperada en la que claramente hacerle esta era una mala opción. Si hago esta división, capaz que este número no lo lleve a ver. O sea, si tengo 7 cifras justo, lo puedo llegar a ver. Pero el logaritmo no creo que lo pueda ver. Ya va. Y bueno, Taylor me da su visión rápida. Es básicamente que me funciona. ¿Y por qué hago Taylor con un término y no con más? Porque puedo. ¿Está bien? Buen isio. Bueno. Entonces, ¿por qué hicimos todo este cuento? ¿Por qué hicimos todo este cuento sobre operaciones aritméticas y cancelaciones catastróficas? Y errores en las entradas. ¿Cómo se ven en la salida? Lo hicimos porque básicamente nuestra computadora, mi computadora y cualquier computadora, cualquier máquina, trabaja con precisión finita. Y como trabaja con precisión finita, la capacidad de representar números no es infinita. Vamos a empezar a ver ahora sí qué números usa la computadora. ¿Qué números, qué sistema de numeración usa la computadora? Muy rápidamente. No nos vamos a meter mucho en eso. Pero sí ya con la cabeza de qué cosas hay que evitar y qué cosas son estables. A ver, hora de hacer pasar vergüenza a una computadora. ¿Cómo hacen pasar la vergüenza a una computadora? La computadora no sabe las propiedades de la suma. ¿Cuánto da esto? Gracias. Ah, costó. Lo que costó. Bueno, si ustedes le ponen esto a una computadora, la computadora va a hacer la cuenta así, ¿no? Va a ser primero 1 más x, va a ir en orden. Dice, pará, tengo una suma y una resta, las hago en orden y hago esto. Ustedes capaz que lo que hicieron fue, dijeron, vos pará, estos unos se tacharon y me quedó una x. ¿No? Bueno, vamos a hacer eso. A ver, yo uso Matlab, pero nada, porque tengo. Sí, bueno. Es legal. Quiero que sepan. Quiero dejar constancia que es legal. Está pagado con un proyecto de acá. Pero no, en octáveis pasé exactamente lo mismo. Clear, CLC. Clear es borrarme la memoria. CLC es borrarme la pantalla. Esto es como empezar de vuelta. Me definí un numerito que es 10 a la menos 16. Si quieren, les muestro uno más. Numerito es 1 por 10 a la menos 16. Y lo que voy a hacer es 3a que sea 1 más numerito menos 1. ¿Y cuánto da esto? 0. ¿Qué pasó? ¿Por qué da 0? Sí. Hizo 1 más numerito. Hizo 1 más numerito. Si esto lo aproximo a 1, cagó. Porque si mi aproximación de 1 más X es 1, esto es una cancelación catastrófica, muy catastrófica y muy obvia. Es, ah, 1 más numerito para la computadora es 1, 1 menos 1 es 0. Si yo a la computadora le cambio el orden y le digo, hace 1 menos 1 más numerito, ahora saltó. De repente sabe hacer la cuenta. ¿Cuál es la diferencia? Me hizo ahora 1 menos 1, me dio 0, y a numerito, aparentemente lo pudo almacenar bastante bien. ¿Sí? O sea, el orden de los sumandos altera la suma. La primera, la que nos dio la a, ah, ¿puedo usar esto? Mira que lindo, ¿verdad? Mentira, ¿no puedo usarlo? Sí, puedo usarlo, claro. ¿Esto se ve ahí? ¡Oh! Lo que hemos progresado. Está. 1 más numerito menos 1 igual no me da eso para nada. 1 más numerito menos 1 me da 0, y 1 menos 1 más numerito me da lo correcto. ¿Está? Entonces, primer pauta, exacto, 1 más numerito para la computadora es 1. Esto que está acá, ¿está? X es numerito. Bien, vamos con otro ejemplo un poco más gramático. Yo solamente se lo quiero mostrar. Está más adelante en las notas. Lo puse más adelante además porque se podía. ¿Qué es esto? Tengo un polinomio. Se llama... Bueno, le puse y primero. Pero imagínense que quiero hacer p de x que sea x menos 1 a la 7. ¿Está? Quiero graficar este polinomio. Y lo quiero graficar cerquita de 1. O sea, x está entre... Acá lo hice entre 0,99 y 1,01. Quiero graficar un polinomio para una función entre... Bueno, muy cerquita de la raíz. Entonces, cuando pongo Linspace, lo que hace es una partición uniforme. Está. Tengo tres entradas, el extremo izquierdo, el extremo derecho y ¿cuántos numeritos hay? O sea, tengo 999 intervalitos iguales en el 0,99 y 1,01. Me defino y, que sea x menos 1 a la 7. Y le voy a decir que graficame ese polinomio. ¡Petacular! Bueno. Nada. Esto fue en un examen, de repente, y tuvieron la mala leche de dármelo factorizado, eh, desarrollado. ¿Está? Me dieron x a la 7, menos 7x a la 6, más 21x a la 5, más 35x a la 4, blablabla. No me avivé que esto era x menos 1 a la 7. ¿Está? Pero es x menos 1 a la 7. Bueno, vamos a cambiar. Trigui. ¿Trigui? ¿Está? En azul va a seguir estando el gráfico lindo que teníamos antes. Ahora en rojo voy a poner esta nueva representación si yo graficara z. ¿Está? Z es igual a y en lápiz y papel. ¡Tadán! ¿Está? Eso es un polinomio de grado 7. Para una computadora con un montón de cancelación. ¿Está? Eh... Este tipo de cosas son cancelaciones catastróficas. ¿Se entiende? Puede ser que un polinomio deje de ser un polinomio. Básicamente. ¿Está? Obviamente... A ver, ahí agrandé. No sé si llegan a ver, pero la escala es obvio, desde 10 a la menos 14. Es una escala chiquitita. ¿Está? Pero el error relativo que estoy haciendo es enorme. Se ve ahí en el fondo la curva azul. Espero que se vea. Que mi computadora se ve. ¿Está? Claro, esto silagro tecamente alrededor de esa curva azul. Pero tiene un error espantoso. Básicamente veo ruido. ¿Está? ¿Por qué veo ruido? Bueno. Por lo mismo. Porque si yo ahora le digo x es más o menos 1. Bueno, x a las 7 es más o menos 1. 7x a las 6 es más o menos 7. 21, 35, 35, 21, 7, 1. Se cancelan todos, me queda más o menos 0. Metí terrible cancelación catastrófico. ¿Sí? Terrible cancelación de 8 términos que se fueron cancelando entre sí. ¿Se entiende? Entonces, obviamente acá, graficar este polinomio usando z es una pésima idea. ¿Sí? Bueno. Y es una pésima idea. Yo estoy asumiendo que nuestra computadora puede multiplicar establemente, puede sumarle establemente, obviamente. Es una pésima idea básicamente porque tengo errorcitos en las entradas. Los números entre, en este intervalo capaz que no puedo representarlos a todos exactamente. Y si no puedo representarlos exactamente voy a tener una propagación de error. ¿Sí? Del tipo de la que vimos acá. Cancelación catastrófica y que después va a hacer que vea ese ruido. ¿Está bien? Entonces, básicamente este dibujito es la representación. ¡Opa! ¿Por qué se corrió ahora? Ah, está. Está igual, ya cierro. Eso es la representación gráfica de mi computadora no puede representar los números exactamente y como no puede representar mis números exactamente veo un montón de cancelaciones catastróficas. ¿Está? Entonces la idea, cuando hablemos ahora de aritmética de punto flotante es, ¿qué números puedo representar exactamente? ¿Y qué pasa cuando aproximo números? Y cuando aproximo números, tengo que tener en cuenta que después al hacer operaciones, los errores se van a propagar en esas operaciones. ¿Está bien? Entonces, todo esto es para motivar los albódrios que vienen ahora. Que es hablar un poco o sea, yo odio arrancar con aritmética de punto flotante porque es como jugar un partido de fútbol y antes de arrancar a jugar que te cuenten las reglas. No sé, yo prefiero jugar y después entender las reglas. Pero bueno, les tengo que contar un poco las reglas de juego. ¿Cómo son? Entonces, bueno. La mayoría de ustedes son estudiantes de computación, o sea que saben esto mucho más que yo. Para los que no y no saben, las computadoras almacenan 0s y 1s. Y tiras de 0s y 1s. Básicamente. Y un 0,1 es un bit. Una unidad. 0,1 es un bit. Entonces, básicamente la computadora cualquier número real lo va a almacenar con una tira de 0s y 1s. ¿Qué pasó cuando hicieron las computadoras? Y empezó a haber todo el desarrollo. Cada uno usaba el sistema que se le cantaba para representar. Había problemas de compatibilidades, problemas ahí de bueno, de cómo pasar de un sistema a otro. Había errores también asociados a este número de un sistema para poder representar y en este otro no. Y allá por los 80 se juntó la gente de a ver, alguno de los de eléctrica que es IEEE International Electronic E-Engineers Algo. Sí, algo de eso, ¿no? O sea, allá por los 80 y sacaron los, digamos estandarizaron. Allá por los 80s. ¿Verdad? Estandarizaron la representación. Hicieron como unas especies de estándares de lo que se llama de punto flotante. Hoy en día creo que todas las máquinas normales, digamos de escritorio trabajan con lo que se llama la precisión doble. Entonces yo voy a contarles el formato de precisión doble. Es un formato de precisión doble. Es un formato de estos que sacó esta gente, estos ingenieros se pusieron de acuerdo y dijeron vamos a representar números de esta forma. Precisión doble se llama así porque hay uno que es precisión simple, media precisión incluso, hay cuádruple, hay octuple hoy en día. Pero nada. Básicamente la pregunta es ¿cuántos bits, cuánta memoria quiero usar para almacenar un número? ¿Sí? Cuántos más bits uses para almacenar un número, más preciso puede ser, pero más demandante es almacenar el número. Cuántos menos bits usas, nada, sos menos preciso pero más livianito también. Entonces en el formato de precisión doble los números representables son así. ¿Vale? Pues ya estamos casi que en hora, ¿no? Está. Bien. Son los números que puedes escribir de esta forma. En realidad en cualquier formato de estos de de punto flotante de la IEE los números se representan así. La pregunta es ¿cuántos bits uso para los parámetros que aparecen acá? Entonces en precisión doble se usan 64 bits. Precisión simple usa 32 bits, precisión cuádruple usa 128, octuple usa 256. Entonces básicamente es esto. A mi X lo tengo representado por una tira de 64 ceros y unos. Bueno, necesito un bit. El primer bit lo voy a usar para el signo. El primer bit lo voy a usar para decir si X es positivo o negativo. ¿Vale? ¿Vale? Nada. Un alcahuete, positivo o negativo. Después vemos qué pasa con el cero. El cero es especial. Pero el cero lo quiero poder representar exactamente también, ¿no? Pero bueno, hay formatos que tienen ceros positivos y ceros negativos incluso. Un bit para el signo. Después voy a tener un montón de bits azul y verde para la F. Necesito 52 bits para la F que es lo que se llama la mantiza. Ahora les cuento un poquito qué es la F. Y lo que me sobra para E. 11 bits, ¿no? 63, más uno 64. 11 bits para E que es el exponente. Vamos a entrar con esto en detalle bien la semana que viene. Pero tratemos así rápidamente de entender qué hace cada parámetro, ¿no? El signo obviamente dice positivo y negativo. ¿Qué te da la mantiza? O mejor para empezar con el exponente. ¿Qué te da la exponente? El exponente te va a dar una idea de la magnitud del número. Si es grande o es chico. Y la mantiza te deja calibrar ahora vamos a ver el intervalo 1, 2. Entonces, la mantiza F es un número que se puede escribir de esta forma. Algo dividido 2 a las 52 con J que puede ser 0, 1 O sea con 52 una tira de 52 0s 1s puedo representar cualquier número entre 0 y 2 a las 52 menos 1, ¿no? O puedo representar 2 a las 52 números. Bueno. La mantiza me va a representar un número de esta pinta. ¿Cuál es el chiste acá? Observen que F está entre 0 y 1. ¿Sí? Puede llegar a ser 0 la mantiza, puede llegar a ser casi, casi, casi 1. Si es casi, casi, casi 1, este número es casi, casi, casi 2. No llega a ser 2. El exponente Bueno, para el exponente tengo 11 bits. Con 11 bits puedo representar 2 a las 11 números. 2 a las 11 es 2048. El exponente se suele almacenar como un número entre menos mil, vamos a ponerlo así, 1023 y 1024. ¿Va? Ahí tengo 2048 números. En la práctica, esto sería en teoría, en la práctica se usa algo así. Me guardo el 1024 y el menos 1023 para cosas especiales o para casos especiales. ¿Va? Es como que el exponente 1024, el exponente menos 1023, están reservados para ciertos números que después vamos a ver qué onda. Ciertos números especiales de punto flotante. Entonces, simplemente esto. Estos son los números que puedo representar exactamente. Ahora después, después no, el lunes ya enganchamos y vemos qué quiere decir esto. Pero básicamente tengo tres parámetros en estos estándares. Uno es el signo, fácil de entender. Uno que tiene que ver con la magnitud, el exponente, porque fíjense, si el exponente es muy grande, este número es muy muy grande en magnitud. Si el exponente es menos mil, 2 a la menos mil es casi casi cero. Me queda muy chiquito el magnitud. Entonces, el exponente me calibra la magnitud y la mantiza me deja moverme en el intervalo 1,2. ¿Si? Entonces me deja calibrar dentro del lango que me da el exponente. ¿Tá? Bueno, está bueno ahora. Así que paramos acá. Sí.