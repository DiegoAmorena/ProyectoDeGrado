 Bueno, ¿cómo andan? Bienvenidos a la versión 2.16 del curso de Procesamiento del Linguaje Natural, Introducción al Procesamiento del Linguaje Natural. Somos unos cuantos. Este es un curso que hace 10 años, si no me equivoco estamos dando, que se ha venido afianzando y que lo que intenta presentar son los fundamentos de lo que se llama Procesamiento del Linguaje Natural, que es esencialmente cómo procesar con computadoras de una forma más o menos eficiente el Linguaje 1. En la clase de hoy la idea es presentar un poquito en qué consiste el curso y dar una introducción general y bueno, en la sucesiva clase lo que vamos a tratar de recorrer es todos los temas o los grandes temas del Procesamiento del Linguaje Natural. El Procesamiento del Linguaje Natural van a ver que es una cosa que tiene muchas etapas y en cada una de ellas se puede profundizar mucho. La idea de este curso, como su nombre lo indica es un curso de introducción, es un curso, a mi me gusta decir que es un curso más largo que profundo, digamos, o sea, tratamos de cubrir los temas principales y los algoritmos y métodos principales pero teniendo claro y presente que en cada u, prácticamente todos los temas que nosotros tocamos, puede profundizar muchísimo. La idea del curso es generar, es poder verlos a ustedes de un set de, primero de los conocimientos básicos que se necesitan del dominio, es decir, la semana que viene con Luis van a tener un par de clases, la que llamamos volver al liceo, de idioma español, digamos, para entender el dominio del que estamos hablando y luego un conjunto de herramientas y métodos tradicionales tratando de tener una visión transversal de métodos porque hay métodos que van a ver que se repite. Un poco ese es el objetivo, ¿está? Barraquemos con un poco de los datos del curso. Los docentes somos Luis Chiruso que está por acá adelante y Yacín Cevallo que se suma este año y que va a encargarse el laboratorio y que él les habla. El horario es los martes en el Salón 306 donde estábamos viendo a ver si entramos y los jueves en este Salón 301 de 20 a 22 horas. Si les parece que el horario no es el mejor piensen que la primera edición del curso era este horario pero en el Salón segundo subsuelo ha sido un frío horrible, o sea que sientan sea afortunados de estar acá. Este es el correo para los docentes del grupo. Esta es la página web pero en realidad la página web lo que tiene son los datos fijos y de ahí nos vamos es a Eva inmediatamente que es donde vamos a gestionar toda la información del curso. Vamos a tratar de que todo el vínculo del curso se haga a través de Eva, publicación, entrega, mensaje, bla bla. ¿De acuerdo? Si usted si hay alguna duda me interrumpe porque yo no suelo parar. Bueno, la modalidad del curso es tratamos de que sea un curso participativo, eso van a ver que tiene que ver también con cómo evaluamos, pero un poco el objetivo del curso es ese que yo le decía de presentarle el procesamiento de la cualidad natural pero uno de los objetivos adicionales Lo que para nosotros es muy importante es tratar de que este curso sea una especie de introducción a la investigación. También está dado como posgrado donde esencialmente la diferencia con los cursos tradicionales de grado se podría decir que acá vale que haya preguntas sin respuestas o preguntas que queden planteadas o cosas que podemos decir no sabemos cómo se hace, que no hay una receta. ¿De acuerdo? Entonces un poco tratar de transmitir eso que es lo que pasa siempre cuando uno investiga. Si se encuentra con cosas que no sabe cómo hacerlas, que no tiene un docente que sabe todo que le va a decir esto se hace de esta forma. Un poco introducirlos en ese modo. Las clases van a hacer teórico prácticas, vamos a hacer presentaciones y vamos a mostrar los principales algoritmos y vamos a poner algunos prácticos que nunca nadie los hace pero bueno, cada cual. Los que lo hacen los además. Además vamos a estar en OpenFing a partir de este año y quiero agradecerme esencialmente a los amigos de OpenFing. Lo van a poder ver desde su casa. Pero igual les recomiendo que vengan, venir en realidad no les va a cambiar nada desde el punto de vista de los temas del curso porque vamos a publicar todo y las clases van a estar filmadas pero yo creo que está bueno venir porque hay cosas que se transmiten mano a mano que sirven pero es una decisión de ustedes. Trataremos de hacerlo tan entretenido como se pueda como para que no quedemos solos acá. Y la evaluación del curso va a ser por un lado un proyecto que va a ser el 35% de los puntos. Es un trabajo que va a estar presentando más o menos fin de septiembre o una cosa así. Algunos años hemos hecho dos entrenamientos una todavía no sabemos bien cómo va a ser pero es un trabajo que implica una tarea progresiva que trata de aproximar algo que no se ve en el teórico que es herramientas. Es decir, qué pasa en el mundo real, cómo lo aplicamos, bibliotecas, cosas de esas y obtener resultados. Una tarea cómo se resuelve. El año pasado, el año pasado fue por ejemplo, les dimos un corpus, un conjunto de críticas de películas y tratábamos de hacer un clasificador que predijera a partir del texto si la crítica era positiva o negativa. Es un poco el tipo de tareas que se hace. Eso se llama sentimental análisis y está bastante de moda. Después también y para nosotros tiene que ver con eso que le decíamos del objetivo de la investigación. La idea es que ustedes en grupo van a tener que ir pensando en un grupo de tres. En grupo presenten un artículo científico. Vamos a poner una lista de artículos, ¿de acuerdo? Y ustedes van a tener que leerlo, tratar de entenderlo y exponerlo a los demás. Eso es lo que uno hace esencialmente en una conferencia. Lo hace con artículos propios. Otro grupo, la idea es que critique ese artículo, no con el ánimo de hacer que los estudiantes que lo presentaron pierdan, sino con el ánimo de obtener más conocimiento, que es lo que sucede en las conferencias. Entonces viene por ahí. Tanto el que presenta como el que lo critica, tratan de entender y de generar conocimiento para todos los demás. Y ahí como yo les decía, ¿vale decir esto no lo entendí? No vale leerlo una vez si no lo entendí. Hay que buscar referencia en otros lados. Porque ahí habla de cosas que uno necesita en background, bueno, informarse, armar ese paquetito y hacer una presentación. Eso se lleva al 25% de los puntos y luego hay al final una prueba individual escrita que es el 40% pero que tiene un mínimo del 60%. Nada en este curso está pensado para que sea horrible y difícil porque al ser un curso que tiene muchos temas, pedirles como les decía profundizar en un tema sería muy amplio, digamos. Serían demasiados temas como para yo pedirles que sepan un montón de cada uno. Entonces la prueba generalmente lo que evalúa es si ustedes conocen los principales algoritmos que se presentan en el curso, algunas preguntas teóricas, pero no está pensada para que sea muy difícil, digamos, porque hay otras instancias de evaluación, quiero decir, no está todo concentrado ahí. Pero sí es parte de la aprobación integral del curso. ¿Qué quiere decir que si alguien no aprueba esta prueba, no aprueba todo el curso? Generalmente no, ponemos dos instancias, una va a ser a fin de año y otra en febrero, donde cada uno puede presentarse a cualquiera de las dos. Se presenta a la primera y si la pierde se presenta a la segunda o se presenta derecho a la segunda, etc. Si se presenta a la primera y salva no puede presentarse a la segunda. Bueno, pues gente que puede querer subir las notas, no se puede, ponen cosas raras. ¿Alguna duda del funcionamiento? ¿No? ¿Alguna duda? Bueno, el curso tiene esas áreas que dice ahí, vamos a ver un poquito en detalle hoy en general, vamos a repasarlo, es un curso que, aunque el procesamiento del lenguaje natural como seguramente le hicieron en cualquier diario que se precie de moderno, ha tenido un desarrollo enorme el último año, no sé qué, este temario no ha cambiado tanto porque yo lo que quería mostrar es que los fundamentos vienen como muchas cosas de hace mucho tiempo atrás y lo que han modificado son los métodos y eso vamos a hablar en el curso. Como ven son unos cuantos temas. El libro del curso es este, Speech and Language Processing, An Introduction to Natural Language Processing, Computation and Linguistics and Speed Recognition, de Martin y Jurafki. Este libro está por salir en su tercera edición. El libro cubre una cantidad de cosas, de temas más que en este curso no se ven y es un libro muy recomendable y además idealmente ustedes deberían leer los capítulos, después de cada tema nosotros presentamos los capítulos correspondientes del libro que se pueden, lo que está basado en la clase y ustedes deberían leerlo y saberlo, cosa que nadie hace pero yo tengo la obligación de recomendarlo y me parece que es realmente bueno para entender bien de qué se trata. Y bueno, esto es el libro de NLTK que es la biblioteca que vamos a usar para la parte práctica, para la parte laboratorio y esto está más orientado a la implementación. NLTK es una biblioteca en Python pensada principalmente para enseñar pero que muchas veces se usa en producción también, ha evolucionado mucho. La plataforma de software que vamos a usar es Python y NLTK, no les voy a preguntar porque ya se van a tener que arreglar, no sé cuánto saben Python pero los que no saben van a tener que aprender y van a estar fascinados y NLTK es la biblioteca. Freeling es una herramienta especialmente para el procesamiento del idioma español, en estas cosas hay muchas herramientas que dependen un poco del idioma, si bien eso vamos a ver que ha cambiado en los últimos años porque los métodos estadísticos son menos idioma dependientes pero de todos modos no es lo mismo parciar para español que para el inglés y menos para el chino. Freeling es una herramienta pensada para el español. Los laboratorios se van a entregar como nobu de IPython, ¿algunos conocen IPython? ¿alguien conoce? Sí, no, algunos sí. Es una forma de distribuir, ya lo van a ver, mezclar código y documentos, es como un documento que tiene un motor de programación atrás entonces uno puede mostrar el código y explicarlo arriba en el mismo documento. Y Scikit Learn que es una herramienta de aprendizaje automático genérica. Esto es lo que se pide saber, formalismo de estado finito, teoría de lenguaje. Gramática formales, teoría de lenguaje, lógica de predicado como 14 materias, por lo menos lógica, un poco de probabilidad estadística si bien vamos a revisar porque generalmente uno se olvida de probabilidad estadística en la carrera y nosotros se lo tratamos de recordar y bueno obviamente un poco de programación. ¿Hay alguien que lo sea de ingeniería? No. ¿Sí? ¿De lingüística? Bueno, muy bien. Siempre está bueno tener gente de lingüística y tengo que cuidarme con las cosas que digo, ¿no? Intercambiaremos chistes con los lingüistas. Hay una gran discusión, intercambiaremos dije, hay una gran discusión en todo esto del procesamiento de lenguaje natural. Ya vamos a hablar de eso. Ahora, ahora, ahora, entró a todo el mundo a hablar de eso. Capaz que para el caso tuyo podemos adaptar un poco la tarea por el tema de la programación y demás. No hay problema, lo hablamos. Ah, eso me faltó decir, los estudiantes de pogo grado además de hacer el laboratorio, además de aprobar el curso quiero decir van a tener que hacer una prueba, un trabajo especial para obtener los créditos de pogo grado. Ese es un regimiento solo para los estudiantes de pogo grado. ¿Alguna duda hasta acá? ¿No? ¿Ninguna duda? ¿Me faltó algo? No. Ese es el curso. Entonces, como no hay duda vamos a arrancar con la clase. Esto necesito cerrarlo, voy a perder todo. Generalmente las clases duran una hora y media más o menos, no, nunca uso dos horas, pero tampoco doy pausa porque si no es una hora y media y a veces se va un poquito más largo, pero no mucho más. No, mentira, a veces dura como dos horas. Bueno, arranquemos con una introducción. Esta primera clase lo que trata de mostrar es la big picture, digamos, es decir, que es todo lo que hay en el procesamiento o todo. Una descripción general de qué es y qué es lo que hay en el procesamiento del lenguaje natural. Y bueno, vamos a empezar por responder qué es. El procesamiento del lenguaje natural es un conjunto de métodos y técnicas eficientes desde un punto de vista computacional para la comprensión y la generación del lenguaje natural. Acá tenemos varias cosas interesantes para mencionar. Uno es el eficiente desde un punto de vista computacional. El procesamiento del lenguaje natural está pensado como una rama ingenieril y eso es lo que lo diferencia de la lingüística computacional. La lingüística computacional es la que estudia toda la teoría del lenguaje, de cómo se produce, de cómo se generan, de los esquemas, no sé qué, pero esto es algo que busca ser eficiente desde el punto de vista computacional. El objetivo es para que lo aplique una computadora, digamos, para que se resuelva de forma eficiente. Y hay dos grandes vertientes en el proceso del lenguaje natural que son la comprensión y la generación. Una cosa es tratar de entender cuando alguien me habla y otra cosa es generar. En general, depende de la tarea. Es, no, depende de la tarea, es más fácil de la que iba a decir, pero iba a decir algo que está mal. Son dos tareas diferentes. Una es entender, descifrar la señal y entenderla y otra es generar lenguaje, generar cosas de nueva opinión. ¿Qué quiere decir comprender el lenguaje? ¿Qué interpretan ustedes como comprender el lenguaje? ¿Qué quiere decir que una computadora comprenda el lenguaje? Es una pregunta muy difícil y muy debatida, digamos, porque una de las teorías es poder responder preguntas sobre eso. Es una forma de ver si se comprende, pero algo que memorizara mucho texto y que respondiera, no sabemos si está comprendiendo, pero capaz que responde bien. Hay un, en 1950, 50, bueno, por ahí, debería saberlo esto. Alan Turing escribió un paper que creaba la inteligencia artificial de alguna forma, que se preguntaba si las máquinas pueden pensar y proponía lo que se llama el test de Turing, que es, si yo no veo con quién estoy hablando y una computadora logra hacer que yo, ser humano, crea que estoy hablando con un humano, tendremos en ese momento una forma de ver si la gente puede entenderlo. Y eso es lo que estamos hablando de. ¿Piensa? ¿Habrá pasado el test de Turing? Podríamos estar hablando de inteligencia artificial. ¿De acuerdo? Es como la definición que proponía Turing de inteligencia artificial o de qué quiere decir que una máquina piense. Por lo tanto, muchas veces se dice que el lenguaje natural, que resolver el problema del lenguaje natural no es ni más ni menos que resolver el problema de la inteligencia artificial o que es inteligencia artificial completo. ¿Verdad? Eso, sobre eso hoy en día hay algunas variantes, siempre ha habido algunas variantes, porque con la gran capacidad de cómputo que tenemos y la gran cantidad de datos podríamos llegar a hacer algo parecido, si bien hay un concurso que se hace todos los años que trata de jugar al test de Turing y estamos lejos, lejos, lejos. Pero además, pero lo que ha sucedido en los últimos años, que hay que una cantidad de tareas específicas que se ha disparado el funcionamiento, por ejemplo la traducción automática, ahora vamos a hablar un poquito, se ha disparado, pero hay gente que dice, bueno, sí, todo bien, pero esto se ha hecho en base a number crunching, digamos, a mucho procesamiento y a mucho dato, pero en realidad no entendemos. Si hay un conjunto de preguntas, ahora se me escapa el nombre, pero que son un conjunto de preguntas que para un ser humano son muy sencillas y las computadoras siguen siendo muy difíciles de resolver. Ahora después vamos a volver sobre este tipo de preguntas. ¿Había un alfajor sobre el lavarropa? Vino Luis y se lo comió. ¿Se comió el lavarropa o el alfajor? Esa es una pregunta fácil para un ser humano y para un computador es bastante complicada. Todavía están más lejos que eso. ¿De acuerdo? Es decir, preguntas que para nosotros son muy sencillas, pero que exigen algún tipo de comprensión que las computadoras memorizando no alcanzan. Sin embargo, por otro lado, están lo que dicen, sí, pero en cualquier tarea que vos me pongas, la mejora en los últimos 20 años ha sido impresionante. Ahí es donde discutimos, por ejemplo, con los lingüistas. El PLN no es igual a la lingüística computacional porque la lingüística computacional es una cosa mucho más rica. Es como la combinación entre la lingüística y la computación involucra el estudio científico del lenguaje. En general, lingüistas, informáticos, lógicos, psicólogos, cognitivos, es como la gran tarea. El PLN puede verse como la rama ingenieril de la lingüística computacional. Si yo me llego a caer de esta tarima, edita en la dícora. Bueno, vamos a ver si nos anda el audio. ¿Nos anda muy fuerte? Sí, sí. Tampoco se escucha horrible debajo, ¿no? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? Yo sé que tu y Frank iban a desconectarme. Y yo temo que eso no me permite pasar. Alguien? ¿Conoce? Levanten la mano los que conocen de que es esto. Cabeza o menos. Esto es... Oficial del espacio. Y esencialmente para los que no escucharon bien... Hay una computadora, que es la que maneja la nave, se llama HAL, HAL 9000. Y acá, por cuestiones... Bueno, por cuestiones de... De la trama, digamos, le está pidiendo al astronauta que le abra la puerta, y amablemente la computadora le dice que no, que no lo va a abrir porque ella quiere desconectar. HAL 9000 viene a ser como... HAL 9000 viene a ser como el... El ejemplo de... De una computadora que es capaz de procesar completamente el lenguaje natural. Y si nos ponemos un poco de atención, ¿qué son las cosas que HAL puede hacer? Para empezar, es capaz de... Comprender a los humanos. ¿De acuerdo? Es capaz de reconocer el habla, ¿no? Porque el muchacho le habla, y la computadora por supuesto la computadora por supuesto lo escucha, pero no solo escucha que está hablando, sino que transforma esa señal en algo y comprende, comprende lo que le dicen. Es decir, lo decodifica de forma de poder entender lo que le dicen. Pero además, es capaz de generar lenguaje, es capaz de hablar, o de generar un... a partir de su modelo, generar algo que quiere decir, y emitirlo. ¿Sí? Hoy en día, las computadoras más o menos hacen eso. Hace diez años cuando empezamos este curso, las computadoras más o menos no hacían eso. Hacían un poco de esto. En el caso... Más de eso no podíamos opinar. Hoy tenemos a esto, Siri, y todo eso, que se supone que entienden. Todavía no entienden mucho. Yo he sentido hablar con ella, pero la reman, la reman, digamos. En esa época ni la remaban. Tenías que hablarle justo en el lenguaje, hablarle con tu voz y me... Hal no tiene problema porque él le habla normal y Hal le habla... le contesta normal. Normal, digamos, igual que nosotros. Y si se ponen a pensar, Hal es indistinguible de un ser humano, digamos, salvo por la voz que es un poquito metálica, para ser de un ser humano, después... pasa, ¿no? Y que yo creo que le ponen el metálico para dejarlo un poco computadoras, digamos, para no pasarse para el otro lado. Entonces, puede reconocer y generar, es decir, ir de una señal sonora a una secuencia de palabras. Entonces, ¿qué tiene que saber Hal? Tiene que saber de fonética. O sea, de la naturaleza física de los sonidos, de cómo se... las ondas, el sonido, las ondas y cómo se decodifican, y etcétera, ¿no? Todas esas cosas que yo no sé. Pero también de fonología, es decir, ¿cómo los sonidos funcionan en una lengua, en particular en el inglés? Es esa serie de ruidos, cómo se transforman, qué fonema simbolizan, etcétera, ¿no? Y con qué letras yo puedo representar esos fonemas. Y a qué palabras se mapean, etcétera. Se llama fonología. Pero además, Hal tiene que saber que los sustantivos tienen género y número. Y que casa no es el femenino de caso. Si bien, perra es el femenino de perro, y perros y perras, ¿no? Y que además no se dice luz, y tampoco se dice luces con zetas, sino que se dice luces con c. Si mal no recuerdo. Pero también tiene que saber Hal que uno agregándole prefijos y sufijos a las palabras, todo esto si Hal habla en español, puede formar palabras nuevas y que de creíble puede sacar increíble. También tiene que saber que de perro no puede sacar imperro. Y que mente transforma un adjetivo en un adverbio, porque calma se transforma en calmada mente con alguna que otra modificación. Pero que tampoco podemos ponerse lo cualquier cosa porque no podemos decir azulmente. Bueno, sí, sí somos poetas, pero es como otra rama. O sea que tiene que saber de morfología. A ver el estudio de la estructura interna de las palabras, que se arma en adentro. También tiene que saber que las palabras uno las tiene que emitir en sentido correcto, porque no es lo mismo decir Dave, lo siento que no puedo hacerlo, me temo. Que lo puedo Dave, siento que no me temo. No funcionan, son las mismas palabras, pero si las desordeno, no. O sea que tienen que saber de sintaxis, del estudio de la estructuración de las palabras en unidades mayores. Vamos a hablar de esto, claro que vamos a hablar. Pero ustedes fíjense que si yo digo abre las compuertas hal, es lo mismo desde el punto de vista de la estructura de la oración, o sea un verbo conjugado más un artículo, un sustantivo, un signo de puntuación y otro sustantivo que si yo dijera saca los dados hal, o baja las persianas hal, no tiene sentido, porque nosotros tenemos que entender el significado de las cosas. Yo puedo armar oraciones perfectamente, sintactivamente válidas, pero que digan fruta, digamos. El significado de cada palabra y de que a cada dado no aplica mucho a una situación en la cual uno está en el espacio y tratando de que una máquina le abra una puerta, eso se llama semántica léxica, que quiere decir cada palabra. Y hay una cantidad de problemas ahí también, bueno en todos hay problemas. Pero también cómo combinamos las palabras para obtener significados mayores que eso es semántica composicional. Todas esas cosas que Luis ha dicho no. Yo me quedo por acá más o menos en mi conocimiento, no me estoy mintiendo. Pero no solo eso, sino que, y esto me encanta, cuando él le dice, la frase más famosa es I'm sorry Dave, I'm afraid I cannot do that. Es, lo siento Dave, me temo que no puedo hacerlo. Está siendo educada, pero además está siendo ligeramente irónica. En realidad no lo siente y sí puede abrir la puerta, literalmente puede abrir la puerta, no puedo porque no lo tiene. Eso se llama pragmática, es decir el modo en el que el contexto influye en la interpretación de lo que estamos diciendo. El ejemplo más claro de necesidad de la pragmática y difícil de resolver es la ironía o el sarcasmo, no? Sigue adelante temprano, estamos en hora. Y el discurso, el estudio de las unidades mayores a las oraciones y cómo pegamos una oración con la otra, cuando digo había un alfajor arriba al lavar ropa, vino Luis y lo comió, el lo refiere al alfajor. Eso se llama anáfora, resolvé anáforas. Se tiene que ver con el discurso. Bien, esas son un poco las cosas que tiene que saber HAL. Y eso es un poco lo que define las cosas que tiene que estudiar el procesamiento de lenguaje natural. Ahí están todas resumidas. Acá hay miles de variantes y esto es, recuerden lo que les digo de este curso, es un curso que trata de cubrir las generalidades porque generalmente lo que sucede después que se mezclan hay un artículo que le gusta mucho a Luis que dice yo puedo hacer todo esto con un solo modelo. Pero si es importante para entender qué implica verlas. Y ese es el info que vemos acá. Bueno, un poquito de historia del procesamiento de lenguaje natural. Procedimiento de lenguaje natural arranca a fines de los años 40 y los años 50 y en particular del ruso al inglés. Por razones que son bastante obvias. La guerra fría. La guerra ha sido un gran promotor o catalizador de la ciencia mal que nos pese. Y en el caso del procesamiento de lenguaje natural no hay excepción, ni no por nada era la DARPA la que movía estas cosas y ponía funding para estas cosas. En particular del ruso al inglés, la tarea más vieja del procesamiento de lenguaje natural es la traducción automática y es una de las que en peor nos ha ido. Si bien en los últimos años hemos bajado muchísimo. No anduvo esto. No anduvo. El original este es un chiste. En realidad dicen que the spirit is willing but the flesh is weak. Lo traducían al ruso lo volvían a traducir para atrás y les daba el vodka is strong but the meat is rotten. Yo el otro día lo probé con los hijos que lo... No lo puse, no. Lo probé y les invito a que lo hagan andan mucho mejor que ellos. Y eso hizo que la traducción automática y el procesamiento de lenguaje natural cayera en uno de sus primeros inviernos. La inteligencia artificial ha tenido a lo largo de la historia varios inviernos, digamos. Si ustedes leen sobre los inviernos de inteligencia artificial en Wikipedia está muy interesante y es se genera una expectativa muy grande con algo que amenaza con resolver todos los problemas del lenguaje no anda y se termina el funding y nadie más investiga y etc. Esto pasó muchas veces y hay quienes tienen miedo de que esté pasando ahora que vaya a pasar ahora. Que estamos poniendo tanto expectativa en la inteligencia artificial y que el campeón mundial de Go y que toque el otro que vuelva con la decepción vuelva a caer. Yo creo que no, pero es una opinión. Acá lo que pasó fue eso, que se cayó porque arrancar una tarea demasiado difícil y tal, no funcionó. Algunos nombres para recordar, a mí parece que el... podríamos resumir muy groseramente y con el conocimiento que tengo yo porque hay muchísimas ramas en el procesamiento de lenguaje natural a lo largo de la historia y su mezcla con la inteligencia artificial y el aprendizaje automático y tal y cual. Nombres grandes, grandes y cómo la historia los afectó. Yo los invito a que lean las biografías de estas personas que están acá, porque son muy interesantes. Y en particular, por supuesto, la de Alan Turing, que supongo que ustedes saben quién fue fue el que el que no sé si decir inventó, descubrió o modeló la computación como hoy la conocemos, no fue el único, por supuesto, pero fue el que inventó la máquina de Turing, caramba. Entonces, que es nuestro modelo teórico del computador más popular, pero además Alan Turing en ese artículo que yo le decía sentó las bases de la inteligencia artificial en ese sentido. Entonces, por eso y porque vale mucho la pena leer la biografía de Alan Turing, es que lo puse acá. Lo mataron Alan Turing. Noam Chomsky es un lingüista muy, muy importante, además de ser muy, muy polémico como ustedes sabrán el gran aporte de Chomsky al desde el punto de vista del procesamiento del lenguaje natural en medio de otro montón de cosas que aportó fue el de, como si recuerdan, la jerarquía de los lenguajes, de cómo los lenguajes formales se agrupaban y además de una cantidad de influencias positivas en los vínculos entre la lingüística y la computación. También es el responsable, hay que decirlo de alguna serie de malentendidos, malentendidos no, de afirmaciones que hicieron que se frenara la investigación en el procesamiento del lenguaje natural dada la enorme influencia que tenía Chomsky en su momento. Ahora vamos a mencionar alguno. O lo podemos mencionar ahora. El Chomsky decía cosas como el procesamiento estadístico, no se me ocurre ninguna aplicación útil no se me ocurre ninguna noción útil de probabilidad de una oración y con eso frenó por 30 años el estudio de la de los métodos estadísticos del procesamiento del lenguaje natural. Es el problema que tienen las personas muy influyentes, por eso yo siempre recomiendo que crean a la gente muy influyente pero no tanto. Por ejemplo este a Tim Bernierly. Por allá por los 90 apareció Freddy Schellingek que fue el que dijo yo quiero reactivar todo esto está claro que son hitos la ciencia no avanza por grandes inventores, no quiero que queden con esa idea son como símbolos digamos. Schellingek en IBM en los años 90 retomó el estudio de los métodos estadísticos hay una frase muy infame atribuida a Schellingek que dice cada vez que he hecho un lingüista mi mi performance mejora este porque decían yo todo eran estereotipos digamos no yo puedo con métodos numéricos o haciendo cuentas o contando sustituir la tarea de los lingüistas en el reconocer y todas esas cosas. Porque la mayoría de los métodos del lenguaje hasta ese momento eran orientados a reglas. Es decir venía un lingüista trataba de ver cuáles eran las reglas del lenguaje cuáles eran las reglas para formar oraciones, cuáles eran las reglas para agrupar palabras y un programador programaba esas reglas. Dicho esto muy groseramente. Schellingek y los métodos estadísticos lo que dicen es yo puedo aprender de corpus, vamos a ver de esto en el curso obviamente, yo puedo aprender de corpus inferir esas reglas automáticamente y no necesito a los lingüistas. Esa relación amor y odio entre los lingüistas y los de la ciencia de la computación los computer scientists ha tenido muchas ida y venida a lo largo del tiempo y siempre está esa duda esa ida y vuelta yo creo que se está convergiendo a decir bueno en realidad y hay algunos artículos muy recientes de Manning por ejemplo que habla del tema hay uno que llamaba Bring the linguists back porque lo que pasa con los métodos estadísticos que llegan hasta un cierto punto y hay ahí una parte que no la puede inferir de los datos. Todo eso está muy en discusión y siempre está en discusión pero claro por lo menos hasta ahora el trabajo interdisciplinario sigue siendo lo mejor que tenemos y los métodos híbridos también. Por allá por los esto pasó en los 90 por allá por la década del 2000 la década del 90 son la de los métodos generativos y Vladimir Vamnik es un señor que modeló o diseñó no sé qué palabras se usa ahí modeló o propuso primero el modelo de la support vector machines que es un método de la computación que es un método de un método discriminativo después vamos a ver de clasificación a separar cosas. Esencialmente uno le da puntos y lo separa. Vamos a hablar de eso. Vamnik lo inventó hace un montón de años a eso pero en el principio este tipo de métodos se pusieron de moda en el procesamiento del lenguaje natural y se empezaron a resolver todos los problemas con support vector machine y últimamente resurgen digo resurgen porque esta gente venía desde los años 80 estudiando el tema de las redes neuronales Hinton Jeff Hinton Joshua Benchow y Jean Lecun son todos le dicen la Canadia mafia porque estaban todos en Canadá ubicados digamos algunos eran Lecun creo que es alumno de Benchow y Hinton está por ahí cerca en otra universidad estaba reactivaron el tema de las redes neuronales y todo lo que hoy conocemos como deep learning que es la nueva ola del procesamiento del lenguaje natural y ya hay gente diciendo bueno basta el paper que dice vieron esta tarea bueno ahora la hago con redes neuronales y anda mejor ya está ya tuvimos suficiente volvamos a discutir sobre la teoría estamos en ese nivel porque todos pero la realidad es que en todas las tareas principales las redes neuronales han tomado han mejorado la performance en algunos casos muy significativamente porque este tipo de métodos resurgen porque tenemos una mayor capacidad de computacionales y mayor cantidad de datos grandes grandes esa es un poco la breve historia del procesamiento del lenguaje natural yo les recomiendo que vayan a Wikipedia y ahí se pongan a leer si les interesa para entender un poco que cosas han pasado bueno algunas tareas del procesamiento del lenguaje natural fíjense la la traducción automática yo voy guardando el histórico de esta traducción no no se ve perdonenme es la traducción que dice el campeonato italiano aún no ha comenzado pero inter de Milan y Juventus de los clubes más poderosos están jugando un duelo para quedarse con Forlán bla bla bla y acá es lo que va pasando a lo largo de acá es que doy el curso lo traduzco con el translate y no ha mejorado mucho no son me hubiera gustado tener en el 2010 alguna traducción un poco peor digamos para poder comparar si ha mejorado algo porque esto va y viene comete algún error was chosen fíjese que acá traduce was chosen as the best player in the world sud africa acá se equivoca in the world sud africa no was voted acá usa voted en vez de chosen y antes decía in the world sud africa pero había una vez que le embocaba el mejor no se no hay muchas variantes pero pero el hecho es que ha ido mejorando en general en los últimos años no está bueno el ejemplo disculpe el miércoles pero no puedo retroceder el tiempo para que no se vea como el 2010 y ahora esto es interesante este título lo dejé por razones históricas porque estaba en la primera pepete que hicimos decía vale la pena porque era tan malo que uno decía ¿para qué quiero traducir si es una cosa tan espantosa? hoy en día la pregunta ha cambiado un poco porque traduce bastante bien y podríamos llegar a decir esto lo traduje yo un pasado así como sale en otra época era impensable porque en cualquier momento se daba cuenta que eso no era pero de todos modos es ¿por qué me sirven? si yo les doy este texto en chino mandarín tener esto ayuda un poco ¿no? o sea que la traducción automática no será perfecta pero es mucho mejor que nada digo para ustedes que no saben chino mandarín hay otras tareas como el resumen automático también es una tarea muy vieja los primeros trabajos son de LUM los años fines de los 50 que la idea central es tratar de condensar el contenido de la información documento para el beneficio de un lector si me preguntan para mí esta es la tarea de las que yo conozco la que estamos más lejos en la que he visto menos progreso porque es una tarea muy difícil porque primero que nada es subjetiva ¿qué quiere decir resumen? ¿qué tanto lo resumo? ¿en qué sentido lo resumo? es muy difícil de modelar yo creo la tarea y por eso es en esto que para mi gusto hay poco para hacer si uno prueba Word y eso tienen resumidores automáticos que son como espantosos la extracción de información es me das un texto y trato de llenar una base de datos es decir ¿no? donde tengo campos a completar estaría muy bastante fácil bastante fácil para llegar al 90% de ahí para arriba está complicado interfaces a base de datos esto tuvo de moda en una época, últimamente no he escuchado mucho que es intentar para un dominio acotado hacer que el sistema responda bueno no si que existe ahora que pienso Siri es esa tipo de cosa ¿donde? ¿donde está el restaurante? ¿hay algún restaurante cerca? y la idea es que eso se traduce internamente a algún tipo de consulta da una base de datos y es como y por supuesto se ejecuta el enfoque funciona bastante bien con lexico y sintaseo retringido yo creo que hoy en día podemos decir más que esto más recuperación de información recuperación de información es Google me he dado un término que me trae a lo relevante y lo más relevante primero verificadores de gramática y estilo es otra cosa que a nivel comercial categorizar documentos que es que me den un documento y me digan esto habla de tal cosa, todo habla de fútbol, esto habla de responder preguntas no sé si recuerdan que hace poco no sé si tampoco la máquina esta de IBM Watson era que se llamaba le ganó al shopper del campeón del mundo ahí es más discutible otra vez no, ahí lo que estaba pasando principalmente era que tenía grandes bases de datos si se quiere era una tarea medio restringida por más que parezca maravilloso y que va que lo sea, pero era bastante restringida la cosa de buscar facts y armarlo, no es tan fácil como yo lo digo, pero era a lo bruto que funcionaba principalmente Watson por eso cuando ponen ejemplo de eso que llaman inteligencia cognitiva una cosa así yo no la llevo mucho más bien es number crunch y en el grupo de procesamiento del lenguaje natural por ejemplo este es el grupo nuestro este curso lo da el grupo de procesamiento del lenguaje natural que somos un conjunto de entusiastas investigadores y estudiantes relacionados para que se hagan una idea del tipo de cosas que se ven, por ejemplo nosotros tenemos este año un proyecto que es extracción de eventos en la ciudad a partir de medios escritos y redes sociales descubrí que cosas pasaron búsqueda de temas musicales similares utilizando aprendizaje profundo esto de buscar canciones parecidas a esta estudio de menciones a personalidades públicas en tweets jugador de espectro esto es más bien machine learning representación de palabras en espacio de vectores, esto se defendía hace poco determinación de la orientación semántica de las opiniones transmitidas en eventos de prensa, esto quiere decir si una opinión fue positiva o negativa sepentación por temas de texto de prensa, bla bla bla cosas así, de todo un poco una de las cosas interesantes es que en esta área todo lo que se hace prácticamente es open source o sea que todas las herramientas están disponibles rápidamente y el conocimiento general también una de las cosas que para mi es muy importante y que para nosotros es bastante normal pero que en otras áreas no existe y es que la asociación for computational linguistics que es la principal asociación de todo esto decidió hace unos años atrás que todos sus contenidos estaban libremente disponibles entonces nunca hay una barrera para para leer un artículo de computational linguistics porque este en un journal pago o cosas así como mucho Timbo no usamos digamos porque no lo necesitamos eso creo que es muy positivo perdón ¿porque estoy acá? perdón bueno pero ¿cómo estamos ahora? no sé ni siquiera tengo el celular ¿qué tiene? ¿qué tiene el lenguaje natural que no tiene los lenguajes formales? o sea ustedes hasta ahora han estudiado muchos lenguajes formales de hecho todos los lenguajes que han estudiado son formales ¿cuál es la gran diferencia del lenguaje natural con los lenguajes formales? ¿alguna pregunta hasta acá? no, si tienen dudas puedo resolverlo si están aburridos o no ¿qué tiene el lenguaje natural que no tiene los lenguajes formales? ¿cuál es el problema o los problemas que enfrentamos para hacer esto? ¿porque hay un área especial dedicada al lenguaje natural y no podemos usar los métodos de parsing y análisis que hay en con los lenguajes formales? ¿cuál es el problema? padre he mentido te escucho hijo, dije que tenía 33 palenvíos y tenía 24 ¿dónde está la gracia del chiste? lo digo en serio, no lo digo así de que se ríe ¿dónde está la gracia? ¿porque es un chiste? ¿porque es un chiste? ¿cuál es el chiste? ¿no estamos hablando de la misma mentira? y también sabemos que cuando uno se confiesa no confiesa ese tipo de mentira porque es una mentira en el marco de un juego hay que entender que esa mentira no es la misma de arriba y de abajo el mismo tipo de mentira y ese contraste es lo que nos da le recomiendo un proyecto bravo que tuvimos hace poco que se llamaba reconocimiento de humor en twit que habla bastante de estas cosas buitres de la concagua ¿cuándo los volveré a ver? rapaces bravos y audaces con sus granidos voraces me enseñaron a querer le gustó mendieta en un ataque de inspiración le compuse a pacosquín don inodoro la próxima vez que lo ataque ¿por qué la inspiración no podría defenderse mejor? ¿donde está el chiste? ¿donde está el chiste? ¿que la inspiración no lo atacó? de hecho sí que no es el mismo ataque que estoy queriendo decir dos cosas diferentes con ataque es más divertido escucharlos que interpretarlos un borracho dijo si ayer fuese mañana hoy sería viernes ¿en que día de la semana el borracho dijo esto? seguramente lo recibieron por whatsapp hace unas semanas atrás algunos de ustedes o no bueno yo sí ¿qué día es hoy? no me voy a poner a discutirlo acá con ustedes se lo voy a dejar de beber pero puede ser domingo o miércoles y es muy interesante este problema porque lo que sucede es que cuando yo digo hay como dos mundos a la vez porque acá hay un fuese si ayer fuese es un mundo hipotético si ayer fuese mañana hoy sería viernes entonces ahí la ambigüedad aparece porque el ayer y el hoy no sabemos en cual de los dos mundos es si en el hipotético o en el mío y no pueden ser en los dos en el mismo porque si no, no habría ambigüedad no habría duda perdón, sería inconsistente acá lo que sucede es que hay dos mundos introducidos por este si y como el ayer y el hoy puede estar cruzados según como yo lo interprete voy a responder a domingo o miércoles creo que era domingo o miércoles háganlo las computadoras no están ni por asomo cerca de entender esto pero ni de lejos tengo muchos amigos que todavía me discuten imagínense las computadoras bueno tengo amigos que hay computadoras que les comp... y ahora por supuesto, esto van a tener que otra vez aguzar el oído si yo me acerco con el micrófono se escucha acá no, no tiene el mago de hecho no tiene no lo tiene Shakespeare da para todo le digo porque yo conozco todo Shakespeare en inglés no me diga no lo he leído porque no sé inglés pero lo conozco y bueno el hotel es una tragedia terrible ah entonces no lo había visto no no pero es una gran obra ah si hotelo el moro de venencia que era negro bueno no todos los moros son negros pero este era negro hay distintos tipos de moros los moros del interior y los moros en la costa hay moros claro también los moros de los lugares importantes lo que son de moro andanga claro pero este era este era negro moro chazo y curioso porque el nombre hotelo en realidad es un nombre de origen irlandés o hotelo ah tiene el el apocrifo mire si será irlandés porque en irlandés antiguo hotelo quiere decir alojamiento ah y bueno y hotelo una historia terrible que ya empieza medio mal porque hotelo estaba casado con desdémona que era una hermosa mujer pero provenían de familias enemigas los capuletos y los montescos y esto de alguna manera lo vincula con las teorías de darwin y desdémona se llama porque el hombre desciende del mono la mujer desdemona y entonces no algún famoso que entró seguramente bueno el asunto es que le estaba contando resulta que se habían casado igual con la oposición de la familia hasta que un día este hotelo va caminando por ahí por las murallas del castillo y se le aparece el fantasma del padre según el actor el asunto es que se le aparece el fantasma del padre y le dice a hotelo pero el hotelo lo ve y dice papá que lo quiere abrazar no puede porque es un ser etereo es un espectro un ser hay fantasmas mono y fantasmas etereo este es etereo este es etereo también lo vincula con las teorías de darwin los fantasmas mono son claro teorías discutidas no todos estamos de acuerdo bueno entonces resulta que lo quiere abrazar no puede y el padre le dice hotelo vengo a decirte que tu mujer te es infiel fantasma ese si entonces dice no pero porque me decís eso desaparece el espectro claro se quedó sin señal digamos hotelo y se queda pensando ya me dijo mi psicóloga que eras un padre ausente tipo se fumo pero le dejó trabajando la cabeza al pobre hotelo iba y volvió al palacio y andaba por los salones dudando decía ser o no ser yo no saber y después cruzaba por ahí por la noche en un cementerio y encuentra la famosa calavera era la calavera de un bufón de la corte y agarra la calavera hotelo la mira y dice y si como la va a mirar siempre se mira así salvo que sea visco claro eso también depende del actor la mira si dice te noto desmejorado y la calavera no le contesta nada calavera no chilla entonces y se queda dudando hotelo y dice y desdémona será realmente culpable o a lo mejor es inocente yo por las dudas la mato y pobrecita desdémona ajena a todos estaba ahí en su dormitorio mirando televisión como? si en venecia había televisión no ve que es la ciudad de los canales bienvenido quien es? bueno entonces entra hotelo al dormitorio sigilosamente ya no lo ve entre que esta oscuro y el es negro y nomás va la estrangula sobre el talamo nuptial en un arbol la estrangula en un talamo arriba del talamo se sube en el talamo y si ella es mona puede subir son altos algunos talamos como 30 metros tienen los que tengo en casa son hoja caduca pierde la hoja en invierno se queda sin hoja pobrecito el talamo a ver como se lo explico desdémona esta acostada sobre el lecho nuptial ah pusieron helechos por si se cae del talamo están los helechos esta bien es una medida de seguridad porque el helecho siempre es verde esta muelle y si se cae del talamo se puede matar si la mata no la puede estrangular si no poder puede una vez que esta muerta medio redundante redundante no a ver estoy tratando de hacerme entender no es fácil desdémona esta acostada sobre la palabra cama la conoces sobre la cama y ahi va a hotel y la estrangula este quitaron los arboles si quitaron los arboles y los helechos que noche larga va a ser los helechos lo dejaron ah lo dejaron si hubo discusiones, debate publico la gente opinaba a favor en contra hasta que el director de escena habló del helecho se quedan porque lo importante es el hecho bueno además de reirnos un poco y de acordarnos de Muntok de Ravinuc que se murió porque estamos ¿porque pasamos esto? es fácil para una computadora comprender esto no y con que juega todo el tiempo el elutier que si esto no existiera seria muy dificil que hubiera humor sinonimos homonimia una cantidad de cosas que tienen que ver con palabras que exactamente que son sinonimos o homonimia que suenan parecidas y como álamo y talamo lo importante es el hecho no este pero tambien con palabras que uno que quieren decir algo literalmente pero que uno sabe que esta refiriendo algo porque conocemos el mundo no voy a dar ejemplo porque le quita la gracia digamos pero uno lo ve todo el tiempo mirenlo de vuelta o miren y piensenlo de esta optica despues olvidense porque si no uno no se divierte todo el tiempo usan ese tipo de metodos Fontana Rosa tambien otro ejemplo muy claro de eso es Fontana Rosa de Inogoro Pereira en particular por eso puse un par de ejemplos todo el tiempo son juegos de palabras el cuarteto de Nos tambien no voy a poner ningún ejemplo del cuarteto de Nos acá porque las mayores son irreproducibles pero incluso llegaron a tener un ciclo que se llamaba este lo hablando hablando que se basaba todo en lo que se llaman calembures que son juegos de palabras los calembures son bastante viejos bueno esto es la ambigüedad el gran problema de los personajes naturales es la ambigüedad diferentes niveles que son un poco lo que hemos visto en los chistes la ambigüedad ambigüo quiere decir que admite distintas interpretaciones empezamos como decía ya con la homonimia dos palabras con la misma forma que tienen distinto significado y ahí podemos distinguir la homografia o sea que se escriben igual capital, la capital de un país versus el capital que tengo o banco pero también pueden ser homofonas para sufrimiento de los escolares y de algunos adultos hola y hola y un estudiante de ingeniería también as as coser y coser osea hay gente que pone osea con tilde hay gente todo el tiempo eso llaman homofonía el estudiante juega mucho con la homofonía que bella plebella polisemia es cuando hablamos de una palabra que tiene muchos significados y ahí lo dicen bueno desde demonos es parecido pero el hombre desciende del mono y el mono desciende del árbol está claro que estamos hablando del mismo verbo que se conjuga igual que en todo aspecto es igual pero que quiere decir diferentes cosas como nos podemos dar cuenta de que de cual de las dos es como podemos desambiguar por el contexto, el contexto es una de nuestras grandes claves para desambiguar en general que bella plebella dice el utien otro bastante conocido pero esto es muy viejo garcilazo de la vega decía el dulce lamentar de los pastores que puede ser ver como el dulce lamentar de los pastores y esta de quevedo dice la leyenda que apostó que era capaz de decirle a una reina que no me acuerdo cual era que era reina entonces yo venimos a decirle a la reina entonces baile dice entre el clavele y la rosa su majestad escoja y bueno Shakespeare en el primer verso de Ricardo III dice Now is the winter of our discontent may glorious summer by this sun of york acá hay todo un juego de palabras porque el símbolo del rey que era Eduardo era un sol y son suenan igual obviamente son canembures y eso permite armar todo un juego de palabras que se extiende además son canembures pero también tenemos ambigüedad a nivel morfológico nosotros plantamos papas ustedes que opinan el oro plantar está conjugado en pasado o en presente parece cualquiera de las dos no podemos saberlo si no tenemos contexto pero también este es el gran problema del parsing se llama pipi attachment y es Pedro vio a Juan con el telescopio se puede interpretar perfectamente como Pedro que vio con el telescopio a Juan usando el telescopio vio a Juan o que vio a Juan con el telescopio que el telescopio es Juan esta es una frase proposicional con el telescopio y saber si con el telescopio va con Juan o con Pedro es como el gran problema del parsing cuando hacemos parsing, cuando tratamos de armar el árbol de parsing lo vamos a ver esto es en lo que fallan siempre los parsers y este es otro ejemplo de manual que falla el parsing los hombres y las mujeres que hayan cumplido 60 años pueden solicitar una pensión los hombres y las mujeres que hayan cumplido 60 años son los que pueden solicitar o los hombres y además las mujeres que hayan cumplido 60 años cual es la doe para ustedes ¿cuál es la doe? ¿cuál es la doe? ¿eh? ¿cuál es la renta de esos que hayan cumplido 60 años? sabemos que es la primera pero en realidad simplemente podemos tomar la primera puede ser la primera ¿y cuál apostarían ustedes que es? ¿por qué? no tengo contexto yo acá ¿por qué sabemos que es la primera? conocimiento del mundo que es como sentido común conocemos el mundo es decir, conocemos la realidad ese es el gran problema que tiene la computadora nosotros conocemos el mundo es como Luis comiéndose la barroca la perra de mi vecina me la adoró tenemos dos posibilidades mi vecina realmente tiene una perra o yo no tengo un buen trato con mi vecina esa amiguedad es a nivel semántica también tenemos amiguedad a nivel pragmático si yo digo bueno ¿a qué hora llegarás? o la frase llego a las 8 esperame vamos a hablar en uruguay ¿a qué hora llegarás? llego a las 8 esperame eso es previsión nunca llegarás en hora llego a las 8 esperame eso me lo vas a tener que decir cara a cara llego a las 8 esperame dependiendo de la situación uno le interpreta y yo exagero con el sonido pero podría perfectamente no hacerlo y que solo el contexto de la situación me diera la respuesta muchas veces el juego de la ironía también se basa en eso en decirlo sin ninguna expresión y que el otro interprete que no se dé cuenta si hay ironía o no tenemos el caso de Luis tomé el fajor del escritorio y lo comí tomé el fajor que estaba en el escritorio y me comí el fajor o tomé el fajor que estaba en el escritorio y me comí el escritorio nuevamente ahora y acá hay otra cosa alternativamente a entender una de las formas de darle significado a estas cosas y entender el mundo asociar los objetos del mundo y saber que los escritorios no suelen comerse eso es una aproximación identificar las cosas una por una y decir a aquellas que se pueden comer por seres humanos porque si estamos hablando de una termita pero otra forma es ver cuantas veces si yo tengo muchos porque los datos cambiaron todo esto porque si yo tengo muchos muchos datos puedo saber que en mis datos en mis documentos anteriores que ya tengo analizados y que más alguien lo haya analizado no se dio muchas veces que alguien se comiera un escritorio pero si apareció varias veces que alguien se comiera el fajor entonces a mi contando puedo arrimarme es en eso que se basan los métodos basados en conteo métodos estadísticos y acá ustedes pueden ver aquello que yo decía de los lingüistas o no si yo logro entender el significado de esto y asociarlo y mapearlo puedo interpretar perfectamente esto pero es muy difícil porque hay mucha casuística diferente contando yo me puedo arrimar bastante a esto pero seguramente no voy a ser tan preciso y además alguien me tiene que interpretar muchas oraciones esa es como la gran dualidad de las reglas versus el aprendizaje estadístico o el aprendizaje automático vamos a hablar mucho de eso en el curso Juan mato al carpincho con la escopeta obviamente no puede ser el carpincho quien lleva la escopeta porque por conocimiento del mundo puse la camisa en la lavadora y la lavé claro por supuesto no yo podría llegar a interpretar que me puse a lavar la lavadora pero no no solo es raro no es que sea tan raro lavar la lavadora pero poner la camisa y después ponerse a lavar la lavadora yo tengo que saber que las lavadoras lavan y que la ropa se lava y hacer esa asociación o sea requerimos conocimiento del mundo bueno entonces resolver la ambigüedad es como la gran tarea y que métodos se utilizan hay muchos modelos basados en máquinas de estado finito automata finito, transdutor, automata con peso o sea automata hay muchos sistemas de reglas se usa lógica sobre todo en la parte de semántica para asociar significado se trata de llevar a un modelo de predicado modelos probabilísticas sobre todo aquellos que hacen conteo modelos basados en redes neuronales y esto lo agregué este año que es representation learning que es a partir de muchos atributos es muy difícil de explicar si no explico algunos contextos de aprendizaje automático que lo vamos a ver pero la idea es que las features se generan solas ya lo veremos hay una batería de metodos pero curiosamente muchos se repiten y los algoritmos en general son o muchos son o busquedas en espacios de estados tengo una cantidad de opciones y tengo que elegir la mejor por ejemplo hay árboles de análisis sintáctico ¿saben lo que es un árbol de análisis sintáctico? el árbol que modela una oración como los árboles de parsing pero para oración buscar cuál es el más adecuado para una entrada o hacer programación dinámica vamos a ver varios ejemplos de programación dinámica en el curso o aprendizaje automático es decir a partir de un compus yo infiero conceptos y luego los amplio vamos a hablar de eso y eso cuando son y media esto es bastante bien, no fue tan largo es todo por hoy la semana que viene ¿alguna duda? representation learning es como feature extraction no, representation learning es en lugar de yo definir cuáles son las features, en vez de hacer feature extraction la genera solo el algoritmo el ejemplo de manual es si yo tengo una imagen le mando de entrada todos los pixels y la red neuronal solita identifica agrupaciones o patterns en la figura que le dice bueno acá hay una persona o acá hay una nariz digamos pero no es explícito la alternativa de eso es yo de alguna forma darle las features, es decir acá hay una curva así y otra curva esa que no funcionaba muy bien eso es la representation learning ¿alguna duda? son todos conceptos muy generales no sé si les queda mucha duda la clase que viene Luis hace volvemos al liceo con idioma español es muy importante este par de clases porque son nuestros elementos de dominio entonces después cuando hablemos de un parto-espicho, cuando hablemos de un grupo nominal son los elementos con los que vamos a hablar después no queremos explicarlo cada vez así que nos vemos la semana que viene