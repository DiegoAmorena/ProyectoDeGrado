 Bueno, ¿cómo andan? Bienvenidos a la versión 2.16 del curso de Procesamiento del Linguaje Natural, Introducción al Procesamiento del Linguaje Natural. Somos unos cuantos. Este es un curso que hace 10 años, si no me equivoco estamos dando, que se ha venido afianzando y que lo que intenta presentar son los fundamentos de lo que se llama Procesamiento del Linguaje Natural, que es esencialmente cómo procesar con computadoras de una forma más o menos eficiente el Linguaje 1. En la clase de hoy la idea es presentar un poquito en qué consiste el curso y dar una introducción general y bueno, en la sucesiva clase lo que vamos a tratar de recorrer es todos los temas o los grandes temas del Procesamiento del Linguaje Natural. El Procesamiento del Linguaje Natural van a ver que es una cosa que tiene muchas etapas y en cada una de ellas se puede profundizar mucho. La idea de este curso, como su nombre lo indica es un curso de introducción, es un curso, a mi me gusta decir que es un curso más largo que profundo, digamos, o sea, tratamos de cubrir los temas principales y los algoritmos y métodos principales pero teniendo claro y presente que en cada u, prácticamente todos los temas que nosotros tocamos, puede profundizar muchísimo. La idea del curso es generar, es poder verlos a ustedes de un set de, primero de los conocimientos básicos que se necesitan del dominio, es decir, la semana que viene con Luis van a tener un par de clases, la que llamamos volver al liceo, de idioma español, digamos, para entender el dominio del que estamos hablando y luego un conjunto de herramientas y métodos tradicionales tratando de tener una visión transversal de métodos porque hay métodos que van a ver que se repite. Un poco ese es el objetivo, ¿está? Barraquemos con un poco de los datos del curso. Los docentes somos Luis Chiruso que está por acá adelante y Yacín Cevallo que se suma este año y que va a encargarse el laboratorio y que él les habla. El horario es los martes en el Salón 306 donde estábamos viendo a ver si entramos y los jueves en este Salón 301 de 20 a 22 horas. Si les parece que el horario no es el mejor piensen que la primera edición del curso era este horario pero en el Salón segundo subsuelo ha sido un frío horrible, o sea que sientan sea afortunados de estar acá. Este es el correo para los docentes del grupo. Esta es la página web pero en realidad la página web lo que tiene son los datos fijos y de ahí nos vamos es a Eva inmediatamente que es donde vamos a gestionar toda la información del curso. Vamos a tratar de que todo el vínculo del curso se haga a través de Eva, publicación, entrega, mensaje, bla bla. ¿De acuerdo? Si usted si hay alguna duda me interrumpe porque yo no suelo parar. Bueno, la modalidad del curso es tratamos de que sea un curso participativo, eso van a ver que tiene que ver también con cómo evaluamos, pero un poco el objetivo del curso es ese que yo le decía de presentarle el procesamiento de la cualidad natural pero uno de los objetivos adicionales Lo que para nosotros es muy importante es tratar de que este curso sea una especie de introducción a la investigación. También está dado como posgrado donde esencialmente la diferencia con los cursos tradicionales de grado se podría decir que acá vale que haya preguntas sin respuestas o preguntas que queden planteadas o cosas que podemos decir no sabemos cómo se hace, que no hay una receta. ¿De acuerdo? Entonces un poco tratar de transmitir eso que es lo que pasa siempre cuando uno investiga. Si se encuentra con cosas que no sabe cómo hacerlas, que no tiene un docente que sabe todo que le va a decir esto se hace de esta forma. Un poco introducirlos en ese modo. Las clases van a hacer teórico prácticas, vamos a hacer presentaciones y vamos a mostrar los principales algoritmos y vamos a poner algunos prácticos que nunca nadie los hace pero bueno, cada cual. Los que lo hacen los además. Además vamos a estar en OpenFing a partir de este año y quiero agradecerme esencialmente a los amigos de OpenFing. Lo van a poder ver desde su casa. Pero igual les recomiendo que vengan, venir en realidad no les va a cambiar nada desde el punto de vista de los temas del curso porque vamos a publicar todo y las clases van a estar filmadas pero yo creo que está bueno venir porque hay cosas que se transmiten mano a mano que sirven pero es una decisión de ustedes. Trataremos de hacerlo tan entretenido como se pueda como para que no quedemos solos acá. Y la evaluación del curso va a ser por un lado un proyecto que va a ser el 35% de los puntos. Es un trabajo que va a estar presentando más o menos fin de septiembre o una cosa así. Algunos años hemos hecho dos entrenamientos una todavía no sabemos bien cómo va a ser pero es un trabajo que implica una tarea progresiva que trata de aproximar algo que no se ve en el teórico que es herramientas. Es decir, qué pasa en el mundo real, cómo lo aplicamos, bibliotecas, cosas de esas y obtener resultados. Una tarea cómo se resuelve. El año pasado, el año pasado fue por ejemplo, les dimos un corpus, un conjunto de críticas de películas y tratábamos de hacer un clasificador que predijera a partir del texto si la crítica era positiva o negativa. Es un poco el tipo de tareas que se hace. Eso se llama sentimental análisis y está bastante de moda. Después también y para nosotros tiene que ver con eso que le decíamos del objetivo de la investigación. La idea es que ustedes en grupo van a tener que ir pensando en un grupo de tres. En grupo presenten un artículo científico. Vamos a poner una lista de artículos, ¿de acuerdo? Y ustedes van a tener que leerlo, tratar de entenderlo y exponerlo a los demás. Eso es lo que uno hace esencialmente en una conferencia. Lo hace con artículos propios. Otro grupo, la idea es que critique ese artículo, no con el ánimo de hacer que los estudiantes que lo presentaron pierdan, sino con el ánimo de obtener más conocimiento, que es lo que sucede en las conferencias. Entonces viene por ahí. Tanto el que presenta como el que lo critica, tratan de entender y de generar conocimiento para todos los demás. Y ahí como yo les decía, ¿vale decir esto no lo entendí? No vale leerlo una vez si no lo entendí. Hay que buscar referencia en otros lados. Porque ahí habla de cosas que uno necesita en background, bueno, informarse, armar ese paquetito y hacer una presentación. Eso se lleva al 25% de los puntos y luego hay al final una prueba individual escrita que es el 40% pero que tiene un mínimo del 60%. Nada en este curso está pensado para que sea horrible y difícil porque al ser un curso que tiene muchos temas, pedirles como les decía profundizar en un tema sería muy amplio, digamos. Serían demasiados temas como para yo pedirles que sepan un montón de cada uno. Entonces la prueba generalmente lo que evalúa es si ustedes conocen los principales algoritmos que se presentan en el curso, algunas preguntas teóricas, pero no está pensada para que sea muy difícil, digamos, porque hay otras instancias de evaluación, quiero decir, no está todo concentrado ahí. Pero sí es parte de la aprobación integral del curso. ¿Qué quiere decir que si alguien no aprueba esta prueba, no aprueba todo el curso? Generalmente no, ponemos dos instancias, una va a ser a fin de año y otra en febrero, donde cada uno puede presentarse a cualquiera de las dos. Se presenta a la primera y si la pierde se presenta a la segunda o se presenta derecho a la segunda, etc. Si se presenta a la primera y salva no puede presentarse a la segunda. Bueno, pues gente que puede querer subir las notas, no se puede, ponen cosas raras. ¿Alguna duda del funcionamiento? ¿No? ¿Alguna duda? Bueno, el curso tiene esas áreas que dice ahí, vamos a ver un poquito en detalle hoy en general, vamos a repasarlo, es un curso que, aunque el procesamiento del lenguaje natural como seguramente le hicieron en cualquier diario que se precie de moderno, ha tenido un desarrollo enorme el último año, no sé qué, este temario no ha cambiado tanto porque yo lo que quería mostrar es que los fundamentos vienen como muchas cosas de hace mucho tiempo atrás y lo que han modificado son los métodos y eso vamos a hablar en el curso. Como ven son unos cuantos temas. El libro del curso es este, Speech and Language Processing, An Introduction to Natural Language Processing, Computation and Linguistics and Speed Recognition, de Martin y Jurafki. Este libro está por salir en su tercera edición. El libro cubre una cantidad de cosas, de temas más que en este curso no se ven y es un libro muy recomendable y además idealmente ustedes deberían leer los capítulos, después de cada tema nosotros presentamos los capítulos correspondientes del libro que se pueden, lo que está basado en la clase y ustedes deberían leerlo y saberlo, cosa que nadie hace pero yo tengo la obligación de recomendarlo y me parece que es realmente bueno para entender bien de qué se trata. Y bueno, esto es el libro de NLTK que es la biblioteca que vamos a usar para la parte práctica, para la parte laboratorio y esto está más orientado a la implementación. NLTK es una biblioteca en Python pensada principalmente para enseñar pero que muchas veces se usa en producción también, ha evolucionado mucho. La plataforma de software que vamos a usar es Python y NLTK, no les voy a preguntar porque ya se van a tener que arreglar, no sé cuánto saben Python pero los que no saben van a tener que aprender y van a estar fascinados y NLTK es la biblioteca. Freeling es una herramienta especialmente para el procesamiento del idioma español, en estas cosas hay muchas herramientas que dependen un poco del idioma, si bien eso vamos a ver que ha cambiado en los últimos años porque los métodos estadísticos son menos idioma dependientes pero de todos modos no es lo mismo parciar para español que para el inglés y menos para el chino. Freeling es una herramienta pensada para el español. Los laboratorios se van a entregar como nobu de IPython, ¿algunos conocen IPython? ¿alguien conoce? Sí, no, algunos sí. Es una forma de distribuir, ya lo van a ver, mezclar código y documentos, es como un documento que tiene un motor de programación atrás entonces uno puede mostrar el código y explicarlo arriba en el mismo documento. Y Scikit Learn que es una herramienta de aprendizaje automático genérica. Esto es lo que se pide saber, formalismo de estado finito, teoría de lenguaje. Gramática formales, teoría de lenguaje, lógica de predicado como 14 materias, por lo menos lógica, un poco de probabilidad estadística si bien vamos a revisar porque generalmente uno se olvida de probabilidad estadística en la carrera y nosotros se lo tratamos de recordar y bueno obviamente un poco de programación. ¿Hay alguien que lo sea de ingeniería? No. ¿Sí? ¿De lingüística? Bueno, muy bien. Siempre está bueno tener gente de lingüística y tengo que cuidarme con las cosas que digo, ¿no? Intercambiaremos chistes con los lingüistas. Hay una gran discusión, intercambiaremos dije, hay una gran discusión en todo esto del procesamiento de lenguaje natural. Ya vamos a hablar de eso. Ahora, ahora, ahora, entró a todo el mundo a hablar de eso. Capaz que para el caso tuyo podemos adaptar un poco la tarea por el tema de la programación y demás. No hay problema, lo hablamos. Ah, eso me faltó decir, los estudiantes de pogo grado además de hacer el laboratorio, además de aprobar el curso quiero decir van a tener que hacer una prueba, un trabajo especial para obtener los créditos de pogo grado. Ese es un regimiento solo para los estudiantes de pogo grado. ¿Alguna duda hasta acá? ¿No? ¿Ninguna duda? ¿Me faltó algo? No. Ese es el curso. Entonces, como no hay duda vamos a arrancar con la clase. Esto necesito cerrarlo, voy a perder todo. Generalmente las clases duran una hora y media más o menos, no, nunca uso dos horas, pero tampoco doy pausa porque si no es una hora y media y a veces se va un poquito más largo, pero no mucho más. No, mentira, a veces dura como dos horas. Bueno, arranquemos con una introducción. Esta primera clase lo que trata de mostrar es la big picture, digamos, es decir, que es todo lo que hay en el procesamiento o todo. Una descripción general de qué es y qué es lo que hay en el procesamiento del lenguaje natural. Y bueno, vamos a empezar por responder qué es. El procesamiento del lenguaje natural es un conjunto de métodos y técnicas eficientes desde un punto de vista computacional para la comprensión y la generación del lenguaje natural. Acá tenemos varias cosas interesantes para mencionar. Uno es el eficiente desde un punto de vista computacional. El procesamiento del lenguaje natural está pensado como una rama ingenieril y eso es lo que lo diferencia de la lingüística computacional. La lingüística computacional es la que estudia toda la teoría del lenguaje, de cómo se produce, de cómo se generan, de los esquemas, no sé qué, pero esto es algo que busca ser eficiente desde el punto de vista computacional. El objetivo es para que lo aplique una computadora, digamos, para que se resuelva de forma eficiente. Y hay dos grandes vertientes en el proceso del lenguaje natural que son la comprensión y la generación. Una cosa es tratar de entender cuando alguien me habla y otra cosa es generar. En general, depende de la tarea. Es, no, depende de la tarea, es más fácil de la que iba a decir, pero iba a decir algo que está mal. Son dos tareas diferentes. Una es entender, descifrar la señal y entenderla y otra es generar lenguaje, generar cosas de nueva opinión. ¿Qué quiere decir comprender el lenguaje? ¿Qué interpretan ustedes como comprender el lenguaje? ¿Qué quiere decir que una computadora comprenda el lenguaje? Es una pregunta muy difícil y muy debatida, digamos, porque una de las teorías es poder responder preguntas sobre eso. Es una forma de ver si se comprende, pero algo que memorizara mucho texto y que respondiera, no sabemos si está comprendiendo, pero capaz que responde bien. Hay un, en 1950, 50, bueno, por ahí, debería saberlo esto. Alan Turing escribió un paper que creaba la inteligencia artificial de alguna forma, que se preguntaba si las máquinas pueden pensar y proponía lo que se llama el test de Turing, que es, si yo no veo con quién estoy hablando y una computadora logra hacer que yo, ser humano, crea que estoy hablando con un humano, tendremos en ese momento una forma de ver si la gente puede entenderlo. Y eso es lo que estamos hablando de. ¿Piensa? ¿Habrá pasado el test de Turing? Podríamos estar hablando de inteligencia artificial. ¿De acuerdo? Es como la definición que proponía Turing de inteligencia artificial o de qué quiere decir que una máquina piense. Por lo tanto, muchas veces se dice que el lenguaje natural, que resolver el problema del lenguaje natural no es ni más ni menos que resolver el problema de la inteligencia artificial o que es inteligencia artificial completo. ¿Verdad? Eso, sobre eso hoy en día hay algunas variantes, siempre ha habido algunas variantes, porque con la gran capacidad de cómputo que tenemos y la gran cantidad de datos podríamos llegar a hacer algo parecido, si bien hay un concurso que se hace todos los años que trata de jugar al test de Turing y estamos lejos, lejos, lejos. Pero además, pero lo que ha sucedido en los últimos años, que hay que una cantidad de tareas específicas que se ha disparado el funcionamiento, por ejemplo la traducción automática, ahora vamos a hablar un poquito, se ha disparado, pero hay gente que dice, bueno, sí, todo bien, pero esto se ha hecho en base a number crunching, digamos, a mucho procesamiento y a mucho dato, pero en realidad no entendemos. Si hay un conjunto de preguntas, ahora se me escapa el nombre, pero que son un conjunto de preguntas que para un ser humano son muy sencillas y las computadoras siguen siendo muy difíciles de resolver. Ahora después vamos a volver sobre este tipo de preguntas. ¿Había un alfajor sobre el lavarropa? Vino Luis y se lo comió. ¿Se comió el lavarropa o el alfajor? Esa es una pregunta fácil para un ser humano y para un computador es bastante complicada. Todavía están más lejos que eso. ¿De acuerdo? Es decir, preguntas que para nosotros son muy sencillas, pero que exigen algún tipo de comprensión que las computadoras memorizando no alcanzan. Sin embargo, por otro lado, están lo que dicen, sí, pero en cualquier tarea que vos me pongas, la mejora en los últimos 20 años ha sido impresionante. Ahí es donde discutimos, por ejemplo, con los lingüistas. El PLN no es igual a la lingüística computacional porque la lingüística computacional es una cosa mucho más rica. Es como la combinación entre la lingüística y la computación involucra el estudio científico del lenguaje. En general, lingüistas, informáticos, lógicos, psicólogos, cognitivos, es como la gran tarea. El PLN puede verse como la rama ingenieril de la lingüística computacional. Si yo me llego a caer de esta tarima, edita en la dícora. Bueno, vamos a ver si nos anda el audio. ¿Nos anda muy fuerte? Sí, sí. Tampoco se escucha horrible debajo, ¿no? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? ¿Alguna vez has escuchado algo? D� ¿Alguien, conocen? ¿Le van a la mano los que conocen que es esto? Cabeza o menos. Esto es oficial del espacio. Y esencialmente para los que no escucharon me... Hay una computadora que es la que maneja la nave, se llama HAL, HAL 9000. Y acá por cuestiones de la trama, digamos, le está pidiendo el astronauta que le abra la puerta y amablemente la computadora le dice que no lo va a abrir porque ella quiere desconectar. HAL 9000 viene a ser como el ejemplo de una computadora que es capaz de procesar completamente el lenguaje natural. Y si ponemos un poco de atención, ¿qué son las cosas que HAL puede hacer? Para empezar, es capaz de comprender a los humanos, ¿de acuerdo? Es capaz de reconocer el habla, ¿no? Porque el muchacho le habla y la computadora por supuesto lo escucha, ¿sí? Pero no solo escucha que está hablando, sino que transforma esa señal en algo y comprende lo que le dicen. Es decir, lo decodifica de forma de poder entender lo que le dicen. Pero además es capaz de generar lenguaje, capaz de hablar o de generar un modelo, a partir de su modelo generar algo que quiere decir y emitirlo. ¿Sí? Hoy en día las computadoras más o menos hacen eso. Hace diez años cuando empezamos este curso las computadoras más o menos no hacían eso. Hacían un poco de esto. En el caso de HAL, más de eso no podíamos pillar. Hoy tenemos a Sir y todo eso que se supone que entienden. Todavía no entienden mucho. Todavía sigue siendo bastante divertido hablar con ella, ¿no? Pero la reman, la reman, digamos. En esa época ni la remaban. Tenías que hablarle justo en el lenguaje, hablarle con tu voz y mea. HAL no tiene problema porque le habla normal y HAL le contesta normal. Normal, digamos, igual que nosotros. Y si se ponen a pensar, HAL es indistinguible de un ser humano, digamos, salvo por la voz que es un poquito metálica para ser de un ser humano, después pasa, ¿no? Y que yo creo que le ponen el metálico para dejarlo un poco a la computadora, digamos, para no pasarse para el otro lado. Entonces, puede reconocer y generar. Es decir, una señal sonora o una secuencia de palabras. ¿Sí? Entonces, ¿qué tiene que saber HAL? Tiene que saber de fonética. O sea, de la naturaleza física de los sonidos, de cómo se... El sonido y las ondas y cómo se decodifican, etcétera, ¿no? Todas esas cosas que yo no sé. Pero también de fonología. Es decir, ¿cómo los sonidos funcionan en una lengua? En particular en el inglés. Esa serie de ruidos, cómo se transforman, qué fonemas simbolizan, etcétera, ¿no? Y con qué letras yo puedo representar esos fonemas. Y a qué palabras se mapean, bla, bla. Se llama fonología. Pero además, HAL tiene que saber que los sustantivos tienen género y número. Y que caza no es el femenino de caso. Si bien perra es el femenino de perro y perros y perras, ¿no? Y que además no se dice luz, ni siquiera, y tampoco se dice luces con z, sino que se dice luces con c. Si mal no recuerdo. Pero también tiene que saber HAL que uno agregándole prefijos y sufijos a las palabras. Todo esto si HAL habla en español. Puede formar palabras nuevas y que de creíble puede sacar increíble. También tiene que saber que de perro no puede sacar imperro. Y que mente transforma un adjetivo en un adverbio porque calma se transforma en calmada mente con alguna que otra modificación. Pero que tampoco podemos ponérselo a cualquier cosa porque no podemos decir azulmente. Bueno, sí, sí, somos poetas, pero es como otra rama. O sea que tiene que saber de morfología. A ver el estudio de la estructura interna de las palabras. Cómo las palabras se arman adentro. También tiene que saber que las palabras uno las tiene que emitir en sentido correcto porque no es lo mismo decir Dave lo siento que no puedo hacerlo me temo que lo puedo Dave y siento que no me temo. No funcionan. Son las mismas palabras pero si las desordeno no. O sea que tienen que saber de sintaxis, del estudio de la estructuración de las palabras en unidades mayores. Vamos a hablar de esto. Claro que vamos a hablar. Pero ustedes fíjense que si yo digo abre las compuertas HAL es lo mismo desde el punto de vista de la estructura de la oración, o sea un verbo conjugado más un artículo, un sustantivo, un signo puntuación y otro sustantivo que si yo dijera saca los dados HAL o baja las persianas HAL. No tiene sentido porque nosotros tenemos que entender el significado de las cosas. Yo puedo armar oraciones perfectamente sintactivamente válidas pero que digan fruta. Eso es el significado de cada palabra y de que a cada dado no aplica mucho una situación en la cual uno está en el espacio y tratando de que una máquina le abra una puerta. Eso se llama semántica léxica. ¿Qué quiere decir cada palabra? Y hay una cantidad de problemas ahí también. Bueno, en todos hay problemas. Pero también cómo combinamos las palabras para obtener significados mayores que eso es semántica composicional. Todas esas cosas que Luis sabe y yo no. Yo me quedo por acá más o menos. Bueno, sí, no mentir. Pero no solo eso, sino que, y esto me encanta, cuando él le dice, la frase más famosa es, I'm sorry Dave, I'm afraid I cannot do that. Es, lo siento Dave, me temo que no puedo hacerlo. Está siendo educada, pero además está siendo ligeramente irónica. En realidad no lo siente y sí puede abrir la puerta. Literalmente puede abrir la puerta. Eso se llama pragmática, es decir, el modo en el que el contexto influye en la interpretación de lo que estamos diciendo. El ejemplo más claro de necesidad de la pragmática y difícil de resolver es la ironía o el sarcasmo. Siate temprano, estamos en hora. Y el discurso, el estudio de las unidades mayores a las oraciones y cómo pegamos una oración con la otra. Cuando digo, había un alfajor arriba al lado de la ropa, vino Luis y lo comió, él lo refiere al alfajor. Eso se llama anáfora. Se tiene que ver con el discurso. Bien, esas son un poco las cosas que tiene que saber HAL. Y eso es un poco lo que define las cosas que tiene que estudiar el procesamiento de lenguaje natural. Ahí están todas resumidas. Acá hay miles de variantes y esto es todo eso. Recuerden lo que les digo de este curso. Es un curso que trata de cubrir las generalidades porque lo que sucede es que se mezclan. Hay un artículo que le gusta mucho a Luis que dice, yo puedo hacer todo esto con un solo modelo. Pero sí es importante para entender qué implica verlas y ese es el info que vemos acá. Bueno, un poquito de historia del procesamiento de lenguaje natural. El proceso de lenguaje natural arranca a fines de los años 40 y los años 50 y en particular del ruso al inglés. Por razones que son bastante obvias. La guerra fría. La guerra ha sido un gran promotor o catalizador de la ciencia mal que nos pese. Y en el caso del procesamiento de lenguaje natural no hay excepción ni no por nada. Era la DARPA la que movía estas cosas y ponía funding para estas cosas. En particular del ruso al inglés. La tarea más vieja del proceso de lenguaje natural es la traducción automática. Y es una de las que en peor nos ha ido. Si bien en los últimos años hemos bajado muchísimo. No anduvo esto. No anduvo. El original, este es un chiste, en realidad dicen que The spirit is willing but the flesh is weak. Lo traducían al ruso, lo volvían a traducir para atrás y les daba El vodka is strong but the meat is rotten. Yo el otro día lo probé con, no lo puse, no. Lo probé y le dije que no lo puse. Lo probé y le invito a que lo hagan, anda mucho mejor que lo del... Y eso hizo que la traducción automática y el procesamiento de lenguaje natural cayera En uno de sus primeros inviernos. La inteligencia artificial ha tenido a lo largo de la historia varios inviernos, digamos. Si ustedes leen sobre los inviernos de inteligencia artificial en Wikipedia está muy interesante. Se genera una expectativa muy grande con algo que amenaza con resolver todos los problemas del lenguaje. No anda y se termina el funding y nadie más investiga y etc. Esto pasó muchas veces. Y hay quienes tienen miedo de que esté pasando ahora, que vaya a pasar ahora. Que estamos poniendo tanta expectativa en la inteligencia artificial y que el campeón mundial de Go, y que toque el otro. Que vuelva, con la decepción vuelva a caer. Yo creo que no, pero es una opinión. Acá lo que pasó fue eso, que se cayó porque arrancar una tarea demasiado difícil. Y tal, no funcionó. Algunos nombres para recordar. A mí me parece que podríamos resumir muy groseramente. Y con el conocimiento que tengo yo, digamos, porque hay muchísimas ramas en el procesamiento de lenguaje natural a lo largo de la historia. Y su mezcla con la inteligencia artificial y el aprendizaje automático y tal y cual. Pero nombres grandes, grandes. Y cómo la historia los afectó. Yo los invito a que lean las biografías de estas personas que están acá. Porque son muy interesantes. Y en particular, por supuesto, la de Alan Turing, que supongo que ustedes saben quién fue. Ese fue el que, no sé si decir, inventó, descubrió o modeló la computación como hoy la conocemos. No fue el único, por supuesto, pero fue el que inventó la máquina de Turing, caramba. Entonces, que es nuestro modelo teórico del computador más popular. Pero además Alan Turing, en ese artículo que yo le decía, sentó las bases de la inteligencia artificial. En ese sentido. Entonces, por eso y porque vale mucho la pena leer la biografía de Alan Turing, es que lo puse acá. Lo mataron. Noam Chomsky es un lingüista muy, muy importante. Además de ser muy, muy polémico. Como ustedes sabrán. El gran aporte de Chomsky desde el punto de vista del procesamiento del lenguaje natural, en medio de otro montón de cosas que aportó, fue el de, como si recuerdan, la jerarquía de los lenguajes. De cómo los lenguajes formales se agrupaban. Y además de una cantidad de influencias positivas en los vínculos entre la lingüística y la computación. También es el responsable, hay que decirlo, de alguna serie de malentendidos, no, de afirmaciones que hicieron que se frenara la investigación en el procesamiento del lenguaje natural, dada la enorme influencia que tenía Chomsky en su momento. Ahora vamos a mencionar alguno. O lo podemos mencionar ahora. El Chomsky decía cosas como el procesamiento estadístico, no se me ocurre ninguna aplicación útil. No se me ocurre ninguna noción útil de probabilidad de una oración. Y con eso frenó por 30 años el estudio de los métodos estadísticos del procesamiento del lenguaje natural. Ese es el problema que tienen las personas muy influyentes, por eso yo siempre recomiendo que crean a la gente muy influyente, pero no tanto. Por ejemplo, a Tim Berners-Lee. Por allá por los 90 apareció Freddy Zelenyck, que fue el que dijo yo quiero reactivar todo esto. Está claro que son hitos, la ciencia no avanza así por grandes inventores, no quiero que queden con esa idea. Son como símbolos, digamos. Zelenyck en IBM en los años 90 retomó el estudio de los métodos estadísticos. Hay una frase muy infame atribuida a Zelenyck que dice cada vez que he hecho un lingüista mi performance mejora. Porque decían yo, todo eran estereotipos, yo puedo con métodos numéricos o haciendo cuentas o contando sustituir la tarea de los lingüistas en reconocer y todas esas cosas. Porque la mayoría de los métodos del lenguaje hasta ese momento eran orientados a reglas. Es decir, venía un lingüista trataba de ver cuáles eran las reglas del lenguaje, cuáles eran las reglas para formar oraciones, cuáles eran las reglas para agrupar palabras. Y un programador programaba esas reglas. Dicho esto muy groseramente. Zelenyck y los métodos estadísticos lo que dicen es yo puedo aprender de corpus, vamos a ver esto en el curso obviamente, yo puedo aprender de corpus, inferir esas reglas automáticamente y no necesito a los lingüistas. Esa relación amor y odio entre los lingüistas y los de la ciencia de la computación, los computer scientists, ha tenido mucha ida y venida a lo largo del tiempo y siempre está esa ida y vuelta. Yo creo que se está convergiendo a decir, bueno, en realidad, y hay algunos artículos muy recientes de Manning, por ejemplo, que habla del tema, que había uno que llamaba Bring the Linguist Back, porque lo que pasa con los métodos estadísticos es que llegan hasta un cierto punto y hay ahí una parte que no la puede inferir de los datos. Todo eso está muy en discusión y siempre está en discusión, pero claro, por lo menos hasta ahora, el trabajo interdisciplinario sigue siendo lo mejor que tenemos y los métodos híbridos también. Por allá por los... esto pasó en los 90, por allá por la década del 2000, la década del 90 son la de los métodos generativos y Vladimir Vamnik es un señor que modeló o diseñó, no sé qué palabras se usa ahí, modeló o propuso primero el modelo de la Support Vector Machines, que es un método discriminativo, después vamos a ver, de clasificación, a separar cosas, esencialmente uno le da puntos y lo separa, vamos a hablar de eso. Vamnik lo inventó hace un montón de años a eso, pero en el principio este tipo de métodos se pusieron de moda en el procesamiento del lenguaje natural y se empezaron a resolver todos los problemas con Support Vector Machines. Y últimamente resurgen, digo resurgen porque esta gente venía desde los años 80 estudiando el tema de las redes neuronales, Hinton, Jeff Hinton, Joshua Benio y Jean Lecun, son todos, le dicen la Canadia mafia porque estaban todos en Canadá ubicados, Lecun creo que es alumno de Benio y Hinton está por ahí cerca, en otra universidad estaba, reactivaron el tema de las redes neuronales y todo lo que hoy conocemos como Deep Learning, que es la nueva ola del procesamiento del lenguaje natural y ya hay gente diciendo, bueno, basta, el paper que dice, vieron esta tarea, bueno ahora la hago con redes neuronales y anda mejor, ya está, ya tuvimos suficiente, volvamos a discutir sobre la teoría. Estamos en ese nivel porque todos, pero la realidad es que en todas las tareas principales las redes neuronales han tomado la, han mejorado la performance en algunos casos muy significativamente. ¿Por qué este tipo de métodos resurgen? Porque tenemos una, muchas mayores capacidades computacionales y muchas mayores cantidades de datos, grandes, grandes. Esa es un poco la breve historia del procesamiento del lenguaje natural, yo les recomiendo que vayan a Wikipedia y ahí se pongan a leer si les interesa, para entender un poco qué cosas han pasado. Bueno, algunas tareas del procesamiento del lenguaje natural, fíjense, no se ve mucho, la traducción automática, yo voy guardando el histórico de esta traducción, no, no se ve, perdónenme, es la traducción que dice, el campeonato italiano aún no ha comenzado pero Inter de Milani y Juventus, los clubes más poderosos del canal ya están jugando un duelo para quedarse con Forlán, bla, bla. Y acá es lo que va pasando a lo largo de, acá es que doy el curso, lo traduzco con el translate, y no ha mejorado mucho, no son, me hubiera gustado tener en el 2010 una traducción un poco peor, digamos, para poder comparar si ha mejorado algo, porque esto va y viene, comete algún error, was chosen, fíjense que acá traduce, was chosen as the best player in the world Sudáfrica, acá se equivoca, en the world Sudáfrica no, was voted, acá usa voted en vez de chosen, y antes decía, in the world Sudáfrica, pero había una vez que le embocaba, no sé, no hay muchas variantes, pero de a poco, pero el hecho es que ha ido mejorando en general en los últimos años, no está bueno el ejemplo, disculpe el mío, pero no puedo retroceder el tiempo para cambiarlo, digamos, pero tenés que volver al 2010. Y ahora, esto es interesante, este título lo dejé por razones históricas, porque estaba en la primera, en la primera pepete que hicimos decía, vale la pena, porque era tan malo que uno decía, ¿para qué quiero traducir si es una cosa tan espantosa? Hoy en día la pregunta ha cambiado un poco, porque traduce bastante bien, y podríamos llegar a decir, esto lo traduje yo, un pasado así como sale, en otra época eso era impensable, porque en cualquier zapallo se daban cuenta que eso no era, no era una traducción, pero de todos modos, por eso digo que lo dejé por el... es, ¿por qué me sirven? Bueno, si yo les doy este texto en chino mandarín, tener esto ayuda un poco, ¿no? O sea que la traducción automática no será perfecta, pero es mucho mejor que nada, digo para ustedes que no saben chino mandarín. Hay otras tareas como el resumen automático, también es una tarea muy vieja, porque los primeros trabajos son de LUM en los años fines de los 50, que la idea central es tratar de condensar el contenido de la información de un documento para el beneficio de un lector. Si me preguntan para mí, esta es la tarea de las que yo conozco, la que estamos más lejos, en la que he visto menos progreso, porque es una tarea muy difícil, porque primero que nada es subjetiva, ¿qué quiere decir resumen? ¿qué tanto lo resumo? ¿en qué sentido lo resumo? Es muy difícil de modelar yo creo la tarea y por eso es en esto que para mi gusto hay poco para hacer. Si uno prueba Word y eso, tienen resumidores automáticos que son como espantosos, digamos. La extracción de información es, me das un texto y trato de llenar una base de datos, es decir, ¿no? que donde tengo campos a completar, estaría muy, bastante fácil, bastante fácil para llegar al 90%, de ahí para arriba está complicado. Interfaces a base de datos, esto tuvo de moda en una época, últimamente no he escuchado mucho, que es intentar para un dominio acotado hacer que el sistema responda, bueno, sí que existe, ahora que pienso, Siri es esa tipo de cosas, ¿dónde está el restaurante? ¿Hay algún restaurante cerca? ¿Hay algún restaurante cerca? Y la idea es que eso se traduce internamente a algún tipo de consulta, da una base de datos y por supuesto se ejecuta, ¿no? El enfoque funciona bastante bien con lexigo y sintaseo retrigido, yo creo que hoy en día podemos decir más que esto. Ahí está, ahí está. Más, recuperación de información, recuperación de información es Google, me he dado un término que me trae a lo relevante y lo más relevante primero, verificadores de gramática y estilo, es otra cosa que a nivel comercial, categorizar documentos, que es, que me den un documento y me digan esto habla de tal cosa, esto habla de fútbol, esto habla de responder preguntas, no sé si recuerdan que hace poco, no sé si tampoco, la máquina esta de IBM, Watson era que se llamaba, le ganó al Chopper, el campeón del mundo, ahí es más discutible, otra vez, ¿no? Ahí lo que estaba pasando principalmente era que tenía grandes bases de datos, si se quiere era una tarea medio restringida por más que parezca maravilloso, y que va que lo sea, pero era bastante restringida la cosa de buscar facts y armarlo, no es tan fácil como yo lo digo, pero era a lo bruto que funcionaba principalmente Watson. Por eso cuando ponen ejemplo de eso que llaman inteligencia cognitiva, una cosa así, yo no la llevo mucho, más bien es number crunching, pero está, y en el grupo de procesamiento del lenguaje natural por ejemplo, este es el grupo nuestro, este curso lo da el grupo de procesamiento del lenguaje natural, que somos un conjunto de entusiastas, investigadores y estudiantes relacionados, y para que se hagan una idea del tipo de cosas que se ven, por ejemplo, nosotros tenemos este año un proyecto que es extracción de eventos en la ciudad a partir de medios escritos y redes sociales, descubrí que cosas pasaron, busqueda de temas musicales similares utilizando aprendizaje profundo, esto de buscar canciones parecidas a esta, estudio de menciones a personalidades públicas en tweets, jugador de espectro, no, esto es más bien machine learning, representación de palabras en espacio de vectores, esto se defendía hace poco, determinación de la orientación semántica a las opiniones transmitidas en eventos de prensa, esto quiere decir si una opinión fue positiva o negativa, sepentación por temas de texto de prensa, bla, bla, bla, cosas así, de todo un poco. Una de las cosas interesantes es que en esta área todo lo que se hace prácticamente es open source, o sea que todas las herramientas están disponibles rápidamente, y el conocimiento general también, una de las cosas que para mí es muy importante y que para nosotros es bastante normal pero que en otras áreas no existe, y es que la Association for Computational Linguistics, que es la principal asociación de todo esto, decidió hace unos años atrás que todos sus contenidos estaban libremente disponibles, entonces nunca hay una barrera para leer un artículo de computational linguistics porque esté en un journal pago o cosas así, como mucho timbo no usamos, digamos, porque no lo necesitamos, eso es muy positivo, es muy positivo, perdón, ¿por qué estoy acá? Perdón. Bueno, pero ¿cómo estamos ahora? No sé ni dónde tengo el celular, cómo me voy a desarlar. ¿Qué tiene? ¿eh? Y cinco. ¿Qué tiene el lenguaje natural que no tiene los lenguajes formales? O sea, ustedes hasta ahora han estudiado muchos lenguajes formales, de hecho todos los lenguajes que han estudiado son formales. ¿Cuál es la gran diferencia del lenguaje natural con los lenguajes formales? ¿Alguna pregunta hasta acá? No, si tienen dudas puedo resolverlos si están aburridos o no. ¿Qué tiene el lenguaje natural que no tiene los lenguajes formales? ¿Cuál es el problema o los problemas que enfrentamos para hacer esto? ¿Por qué hay un área especial dedicada al lenguaje natural y no podemos usar los métodos de parsing y análisis que hay con los lenguajes formales? Padre, he mentido, te escucho hijo, dije que tenía 33 palenvíos y tenía 24. ¿Dónde está la gracia del chiste? Lo digo en serio, no lo digo así, que de que se ríe. ¿Dónde está la gracia? ¿Por qué es un chiste? Porque lo que dice ahí, ¿cuál es el chiste? Es la misma mentira. ¿Eh? Es la misma mentira. Nos estamos hablando de la misma mentira y también sabemos que cuando uno se confiesa, no confiesa ese tipo de mentira porque es una mentira en el marco de un juego. Hay que entender que esa mentira no es la misma de la arriba y la de abajo. Es el mismo tipo de mentira y ese contraste es lo que nos da. Le recomiendo un proyecto bravo que tuvimos hace poco que se llamaba reconocimiento de humor en tweet que habla bastante de estas cosas. ¿Dónde está el chiste? Vuitres de la concagua, ¿cuándo los volveré a ver? Rapaces bravos y audaces con sus granidos voraces me enseñaron a querer. ¿Le gustó mendieta en un ataque de inspiración? Le compuse a Paco Esquín. Don Inodoro, la próxima vez que lo ataque en la inspiración no podría defenderse mejor. ¿Dónde está el chiste? ¿Dónde está el chiste? ¿Que la inspiración no lo atacó? De hecho sí. No es el mismo ataque. Que no es el mismo ataque. Que estoy queriendo decir dos cosas diferentes con ataque. Es más divertido escucharlos que interpretarlos, ¿no? Un borracho dijo si ayer fuese mañana, hoy sería viernes. ¿En qué día de la semana el borracho dijo esto? Seguramente lo recibieron por whatsapp hace unas semanas atrás, algunos de ustedes, ¿o no? Bueno, yo sí. ¿Qué día es hoy? No me voy a poner a discutirlo acá con ustedes. Se lo voy a dejar de beber, pero puede ser domingo o miércoles. Y es muy interesante este problema, porque lo que sucede es que cuando yo digo, hay como dos mundos a la vez. Porque acá hay un fuese. Porque acá hay un fuese. Si ayer fuese es un mundo hipotético. Si ayer fuese mañana, hoy sería viernes. Entonces ahí la ambigüedad aparece porque el ayer y el hoy no sabemos en cuál de los dos mundos es. Si en el hipotético o en el mío. Y no puede ser en los dos en el mismo, porque si no, no habría ambigüedad, no habría duda. Sería inconsistente. Acá lo que sucede es que hay dos mundos introducidos por este sí. Y como el ayer y el hoy pueden estar cruzados, según como yo lo interprete, voy a responder a domingo o miércoles. Creo que era domingo o miércoles. Háganlo. Las computadoras no están ni por asomo cerca de entender esto. Pero ni de lejos. Tengo una jueta andándola nosotros. Tengo muchos amigos que todavía me discuten. Imagínense las computadoras. Bueno, tengo amigos que hay computadoras que les comp... bueno. Y ahora, por supuesto, a ver, esto van a tener que otra vez, perdónenme, agusar el oído. Si yo me acerco con el micrófono se escucha acá. No tienen volumen. No, no tienen más volumen. De hecho no tienen. No, no tienen. Shakespeare da para todo. Le digo porque yo conozco todo Shakespeare en inglés. No me diga. No lo he leído porque no sé inglés, pero lo conozco. Y bueno, ahí el Otelo es una tragedia terrible. Ah, entonces no lo había visto. No, no, pero es una gran obra. Otelo, el Moro de Venecia. ¿Era negro? Sí. Bueno, no todos los moros son negro, pero este era negro. Hay distintos tipos de moros. Hay los moros del interior y los moros en la costa. Hay moros, claro. También los moros de los lugares importantes y los que son de moro andanga. De morón. Claro, pero este era negro. Moro chazo. Es curioso porque el nombre Otelo en realidad es un nombre de origen irlandés. No me diga. Claro, es O-Telo. ¿Y tiene el...? Sí, tiene el apócrifo. Que le ponen. Miren, si será irlandés, porque en irlandés antiguo, Telo quiere decir alojamiento. Ah. Y bueno, ahí Otelo, una historia terrible que ya empieza medio mal, porque Otelo estaba casado con Desdemona, que era una hermosa mujer, pero provenían de familias enemigas, los Capuletos y los Montescos. Y esto de alguna manera lo vincula con las teorías de Darwin. Claro, porque... Y Desdemona se llama una mujer porque el hombre desciende del mono y la mujer Desdemona. Y entonces... No, algún famoso que entró, seguramente. Bueno, el asunto es que le estaba contando. Resulta que se habían casado, igual, con la oposición de la familia, hasta que un día Otelo va caminando ahí por las murallas del castillo y se le aparece el fantasma del padre. ¡Uf! Y le va a decir... No, según el actor, algunos actores... Algunos le van... Bueno, el asunto es que se le aparece el fantasma del padre y le dice a Otelo... Pero Otelo lo ve y dice, papá, ¿qué quiere abrazar? No puede porque es un ser etéreo, es un espectro, un ser etéreo. Hay fantasmas mono y fantasmas etéreo. Y este es etéreo. Claro. Eterio, sí, sí. También lo vincula con las teorías de Darwin, los fantasmas mono. Claro, son fantasmas monos, son... Claro, bueno, es algo de teorías discutidas esas. No todos estamos de acuerdo. Bueno, entonces resulta que lo quiere abrazar, no puede, y el padre le dice, Otelo, vengo a decirte que tu mujer te es infiel. ¡Uf! Es fantasma ese. Y entonces dice, no, pero ¿por qué me decís eso? Y desaparece el espectro. Claro, se quedó sin señal, digamos, Otelo. Y se queda pensando, dice, ya me dijo mi psicóloga que eras un padre ausente. Claro, porque... Tipó, se fumó, pero le dejó trabajando la cabeza al pobre Otelo, y volvió al palacio y andaba por los salones dudando, decía, ¿ser o no ser? Yo no saber. Y después cruzaba por ahí por la noche en un cementerio y encuentra la famosa calavera, era la calavera de un bufón de la corte, y agarra la calavera a Otelo en la mira, y le dice, ¿y si cómo le va a mirar? Así, siempre se mira así. Salvo que sea visco. Claro, ah, también es cierto. Eso también depende del actor, ¿no? Bueno, en la mira sí dice, te noto desmejorado. Era la calavera de... Y la calavera no le contesta nada. Claro, calavera no chilla. Entonces, este... Y se queda dudando, Otelo, dice, ¿qué hago? Y dice, ¿desdémona será realmente culpable o a lo mejor es inocente? Y dice, yo por las dudas la mato. Y pobrecita desdémona, ajena a todos, estaba ahí en su dormitorio mirando televisión. ¿Cómo mirando? Sí, en Venecia había televisión. ¿No ve que es la ciudad de los canales? ¿Quién es? Bueno, entonces entra Otelo al dormitorio, sigilosamente, ella no lo ve. Entre que está oscuro y él es negro. Y va, y nomás va y la estrangula ahí sobre el tálamo nuptial. ¿En un árbol la estrangula? ¿En un tálamo? ¿Arriba del tálamo? O a la sombra del tálamo. No, no, no. ¿Se suben al tálamo? Y si ella es mona, puede subir, porque... No, no me entendía. Son altos algunos tálamos. Como 30 metros tienen. Los que tengo en casa son... Hoja caduca, pierde la hoja en invierno. Se queda sin hoja, pobrecito el tálamo. No, pero a ver cómo se lo explico. No, no, desdémona está acostada sobre el lecho nuptial. Ah, pusieron helechos. Por si se cae del tálamo están los helechos, está bien. Es una medida de seguridad, porque el helecho siempre es verde, está muelle. Y si se cae del tálamo se puede matar. Si la mata no la puede estrangular. Si no, poder puede. Pero una vez que está muerta, medio redundante. Una redundancia. No, a ver. No, estoy tratando de hacerme entender. No es fácil, le diré. Desdémona está acostada sobre... ¿La palabra cama la conoces? Sí. Sobre la cama. Y ahí va a hotel y la estrangula. ¿Quitaron los árboles? Sí, quitaron los árboles. ¿Y los helechos? Uy, qué noche larga va a ser. Los helechos lo dejaron. Ah, lo dejaron. Sí, hubo discusiones, debate público, la gente opinaba a favor en conas. Y se quedaron. Hasta que el director de Esco no habló de ese lecho se quedan. ¿Por qué? Porque lo importante es el hecho. Bueno. Además de reírnos un poco y de acordarnos del mundo de Rabinucho, que se murió. ¿Por qué? ¿Por qué pasamos esto? ¿Es fácil para una computadora comprender esto? No. ¿Y con qué juega todo el tiempo el elutier y dicen que si esto no existiera sería muy difícil que hubiera humor? Con los sinónimos. Con la línea. Hace una cantidad de cosas que tienen que ver con palabras que son sinónimos o homonimia que suenan parecidas. Como álamo y tálamo, lo importante es el hecho. Pero también con palabras que quieren decir algo literalmente pero que uno sabe que está refiriendo algo porque conocemos el mundo. No voy a dar ejemplo porque le quita la gracia, pero uno lo ve todo el tiempo. Mirenlo de vuelta o piénsenlo desde esta óptica. Después olvídense porque si no uno no se divierte. Todo el tiempo usan ese tipo de métodos. Y Fontana Rosa también. Otro ejemplo muy claro de eso es Fontana Rosa de Inogoro Pereira en particular. Por eso puse un par de ejemplos. Todo el tiempo son juegos de palabras. El cuarteto de Nos también. No voy a poner ningún ejemplo del cuarteto de Nos acá porque las masías son irreproducibles. Incluso llegaron a tener un ciclo que se llamaba este lo hablando hablando que se basaba todo en lo que se llama calembures que son juegos de palabras. Los calembures son bastante viejos. Esto es la ambigüedad. El gran problema de procesamiento de las cosas naturales, o responde a esta pregunta, es la ambigüedad. La ambigüedad de diferentes niveles que son un poco lo que hemos visto en los chistes. La ambigüedad. Ambigüo quiere decir que admite distintas interpretaciones. Empezamos como decía ya con la homonimia. Dos palabras con la misma forma que tienen distinto significado. Y ahí podemos distinguir la homografía. O sea que se escriben igual. Capital. La capital de un país versus el capital que tengo. O banco. Pero también puede ser homófonas. Para sufrimiento de los escolares y de algunos adultos. Hola y hola. Y uno estudiante de ingeniería también. Haz, haz, coser y coser. O sea. Hay gente que pone o sea con tilde. Hay gente todo el tiempo. Eso se llama homofonía. El luthier juega mucho con la homofonía. Que bella plebella. Polisemia. Es cuando hablamos de una palabra que tiene muchos significados. Y ahí lo dicen. Bueno, desde demonos es parecido. Pero el hombre desciende del mono y el mono desciende del árbol. Está claro que estamos hablando del mismo verbo que se conjuga igual. En todo aspecto es igual pero que quiere decir diferentes cosas. ¿Cómo nos podemos dar cuenta de que? ¿De cuál de las dos es? ¿Cómo podemos desambiguar? Por el contexto. Y son grandes claves para desambiguar en general. Que bella plebella dice el luthier en otro bastante conocido. Pero esto es muy viejo, ¿no? Garcilazo de la Vega decía. El dulce lamentar de los pastores. Que puede ser ver como el dulce lamentar de los pastores. Y esta de Quevedo dice la leyenda que apostó que era capaz de decirle a una reina. ¿Me acuerdo Valera? Me acuerdo. Que era reina. Yo venimos a decirle a la reina. Entonces Baile dice, entre el clavele y la rosa su majestad es coja. Bueno, Shakespeare en el primer verso de Ricardo III dice. Now is the winter of our discontent, may glorious summer by this sun of york. Acá hay todo un juego de palabras. No hay más palabras porque el símbolo del rey que era Eduardo. Eduardo no me acuerdo de cuando. Era un sol y San y Son juega. Suenen igual obviamente, es en inglés. Y eso permite armarte un juego de palabras que se extiende además. Son calembures. Pero también tenemos ambigüedad a nivel morfológico. Nosotros plantamos papas. ¿Ustedes qué opinan? ¿El oro plantar está conjugado en pasado o en presente? Parece cualquiera de las dos. Parece cualquiera de las dos, no podemos saberlo. Si no tenemos contexto. Pero también, este es el gran problema del parsing. Se llama pipí attachment. Y es, Pedro vio a Juan con el telescopio. Se puede interpretar perfectamente como Pedro que vio con el telescopio. Que vio a Juan usando el telescopio. O que vio a Juan con el telescopio. Que el telescopio es Juan. Esto es una frase preposicional con el telescopio. Y distinguir, saber si con el telescopio va con Juan o con Pedro es como el gran problema del parsing. Cuando hacemos parsing, cuando tratamos de armar el árbol de parsing, lo vamos a ver. Esto es en lo que fallan siempre los parsers. Y este es otro ejemplo de manual que falla el parsing. Los hombres y las mujeres que hayan cumplido 60 años pueden solicitar una pensión. Los hombres y las mujeres que hayan cumplido 60 años son los que pueden solicitar. O los hombres y además las mujeres que hayan cumplido 60 años pueden. ¿Cuál es la doe para ustedes? ¿Cuál es la doe? ¿Eh? ¿Cuál? Sabemos que es la primera, pero en realidad, sin realmente, puede ser la primera. ¿Y cuál apostaría en ustedes que es? ¿Por qué? No tengo contexto yo acá. ¿Pase el pente si no lo es, es un machista? ¿Por qué sabemos que es la primera? Conocimiento del mundo. ¿Qué es como sentido común? Conocemos el mundo, es decir, conocemos la realidad. Ese es el gran problema que tiene la computadora, nosotros conocemos el mundo. Es como Luis comiéndose la barbopa. La perra de mi vecina me la adoró. Tenemos dos posibilidades. Mi vecina realmente tiene una perra o yo no tengo un buen trato con mi vecina. Esa amiguedad es a nivel semántica, ¿no? También tenemos amiguedad a nivel pragmático. Si yo digo, bueno, ¿a qué hora llegarás? O la frase, llego a las ocho, espérame. Vamos a hablar en uruguay. ¿A qué hora llegarás? Llevo a las ocho, espérame. Eso es previsión. ¿A qué hora llegarás? A las ocho, espérame. Llevo a las ocho, espérame. Eso es previsión. Nunca llegará cenora. Llevo a las ocho, espérame. Eso me lo vas a tener que decir cara a cara. Llevo a las ocho, espérame. Dependiendo de la situación, uno le interpreta... Y yo exagero con el sonido, pero podría perfectamente no hacerlo y que solo el contexto de la situación me diera la respuesta. Muchas veces el juego de la ironía también se basa en eso, en decirlo sin ninguna expresión y que el otro interprete que no se dé cuenta si hay ironía o no. Tenemos el caso de Luis. Tomé el fajor del escritorio y lo comí. Tomé el fajor que estaba en el escritorio y me comí el fajor. O tomé el fajor que estaba en el escritorio y me comí el escritorio. Nuevamente... Ahora, y acá hay otra cosa. Alternativamente a entender... Una de las formas es darle significado a estas cosas y entender el mundo, asociar los objetos del mundo y saber que los escritorios no suelen comerse. Eso es una aproximación. Identificar las cosas una por una y decir a aquellas que se pueden comer por seres humanos. Por seres humanos, porque si estamos hablando de una termita... Pero otra forma es ver cuántas veces... Si yo tengo muchos... ¿Por qué los datos cambiaron todo esto del procesamiento del movimiento natural? Porque si yo tengo muchos, muchos datos... Puedo saber que en mis datos, en mis documentos anteriores que ya tengo analizados, tengo que tener datos y además alguien lo haya analizado... No se dio muchas veces que alguien se comiera un escritorio. Pero sí apareció varias veces que alguien se comió en el fajor. Entonces a mí... Contando puedo arrimarme. Es en eso que se basan los métodos basados en conteo, métodos estadísticos. Y acá ustedes pueden ver aquello que yo decía de los lingüistas o no. Es decir, si yo logro entender el significado de esto y asociarlo y mapearlo, puedo interpretar perfectamente esto. Pero es muy difícil porque hay mucha casuística diferente. Contando, yo me puedo arrimar bastante a esto... Pero seguramente no voy a ser tan preciso. Y además alguien me tiene que interpretar muchas oraciones. Esa es como la gran dualidad de las reglas versus el aprendizaje estadístico, digamos. O el aprendizaje automático. Vamos a hablar mucho de eso en el curso. ¿Juan mató al carpincho con la escopeta? Obviamente no puede ser el carpincho quien lleva la escopeta. ¿Por qué? Por conocimiento del mundo, ¿no? ¿Puse la camisa en la lavadora y la lavé? Yo podría llegar a interpretar que me puse a lavar la lavadora. No es que sea tan raro lavar la lavadora, pero poner la camisa y después ponerse a lavar la lavadora es como... Yo tengo que saber que las lavadoras lavan y que la ropa se lava y hacer esa asociación. O sea, requerimos conocimiento del mundo. Entonces, resolver la ambigüedad es como la gran tarea. ¿Y qué métodos se utilizan? Hay muchos modelos basados en máquinas de estado finito. Autómatas finitos, transdutorias, autómatas con peso. O sea, autómatas. Hay muchos sistemas de reglas. Se usa lógica, sobre todo en la parte de semántica, para asociar significado. Se trata de llevar a un modelo de predicado, ¿sabes? ¿Un modelo de predicado? ¿Un modelo de predicado? Modelos probabilísticas, sobre todo aquellos que hacen conteo. Modelos basados en redes neuronales. Y esto lo agregué este año, que es Representation Learning, que es a partir de muchos atributos... Es muy difícil de explicar si no explico algunos contextos de aprendizaje automático, que lo vamos a ver. Pero la idea es que las features se generan solas. Ya lo veremos. Hay una batería de metros, pero curiosamente muchos se repiten. Y los algoritmos en general son, o muchos son. O busquedas en espacio de estados. Es decir, tengo una cantidad de opciones y tengo que elegir la mejor. ¿Sí? Por ejemplo, tengo una serie de árboles de análisis sintáctico. ¿Sabes lo que es un árbol de análisis sintáctico? El árbol que modela una oración. Como los árboles de parsing, pero para oración. Buscar cuál es el más adecuado para una entrada. O hacer programación dinámica. Vamos a ver varios ejemplos de programación dinámica en el curso. O aprendizaje automático. Es decir, a partir de un cómpus, yo infiero conceptos y luego los aplico. Vamos a hablar de eso. Y bueno, y eso cuando son... ¿qué hora? Y media. Esto va bastante bien, no fue tan larga. Esto por hoy. ¿La semana que viene? Bueno, ¿alguna duda? La representación learning es como feature extraction. No, el representation learning es... En lugar de yo definir cuáles son las features, en vez de hacer feature extraction, la genera solo el algoritmo. El ejemplo de manual es, si yo tengo una imagen, le mando detrás a todos los pixels, y en la red neuronal, solita identifica agrupaciones o patterns en la figura que le dice, bueno, acá hay una persona. O acá hay una nariz, digamos. Pero no es explícito. La alternativa de eso es, yo de alguna forma darle las features. Es decir, acá hay una curva así y otra curva esa, que no funcionaba muy bien en general. Eso es la representation learning. ¿Alguna duda? No, hoy son todos conceptos muy generales, no. No sé si les queda mucha duda. La clase que viene, Luis hace, volvemos al liceo con idioma español. Es muy importante este par de clases, porque son nuestros elementos de dominio. Entonces, después, cuando hablemos de un parto-ospecho, cuando hablemos de un grupo nominal, son los elementos con los que vamos a hablar. Después no queremos explicarlo cada vez. Así que, nos vemos la semana que viene. ¡Adiós!