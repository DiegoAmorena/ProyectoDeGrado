 Bueno, buen día. El lunes llegamos ahí, hablábamos de errores. Bueno, primero definimos error absoluto, que la idea simplemente es, tengo una magnitud o un numerito de X, lo quiero aproximar, lo aproximo por un numerito x barra, que obtengo por, anda a saber qué procedimiento, y bueno, me puedo definir el error absoluto, esto es lo que llamamos el error absoluto, que es simplemente por cuánto le estoy errando y el error relativo que es normalizar por la magnitud o por el número que estoy aproximando. Esa definición nada más la tiramos ahí, no la usamos mucho. Hoy justamente quiero que empecemos a avanzar en entender qué pasa con estos errores, en particular con el error relativo, cuando hacemos operaciones. Primero que nada, asumiendo que podemos hacer nuestras operaciones exactamente. Si nos da el tiempo, ya nos vamos a meter después en el mundo computadora, en el mundo encima, no puedo representar mis números exactamente. Podemos tener algunos errores y nos empezamos a ver cómo nos puede afectar un mal algoritmo, cómo nos podemos ver percutido en que estos errores aumenten de magnitud. Entonces, hoy la clase va a ir básicamente de esto, propagación de errores. Hola, ¿qué tal? Buenos días. Lo primero que quiero que hagamos es a evaluar una función. El color este se llega a ver todavía, ¿no? Está todo bien. ¿Se ve un chico? ¿La cámara está bien? ¿El color? Sí, está perfecto. Avíseme si me quedo sin tinta y si ya se deja de ver, avíseme. Entonces, la idea es esta. Tengo una función f, no importa, definida en un dominio en R, una función real y la puedo derivar. Es una función razonable. Y nosotros tenemos la suerte de que esta f la podemos computar exactamente. Exactamente. Y queremos hallar, no sé, vamos a llamar así, y igual f de x para un cierto x. O sea, aquí lo evaluo en la función. Y puedo computar f, la f la puedo calcular exactamente. O sea, si me das la entrada, yo la calculo exacta. Detalle, la trampa está en que el x viene sucio. El x viene mal. Entonces, pero no tenemos x, sino una aproximación. ¿Se entiende cómo es el problema? O sea, tengo un error en la entrada, pero mi algoritmo es perfecto. No le falla a la f. La pregunta obvia es, yo voy a computar, obviamente, voy a computar f en este x barrita. Esto no va a ser y, esto va a ser una aproximación de y. Y la pregunta es, ¿cómo se relacionan el error que tengo en mi nueva aproximación O sea, el error en mi salida con el error en la entrada. ¿Se entiende la pregunta? O sea, tengo una máquina perfecta, pero le entró algo mal, algo con un errorcito. La pregunta es, ¿qué pasa con el errorcito a la salida? Vale. Lo que podemos hacer nosotros es usar la definición que tengo allá. Y acordadme, nada más, que y es f de x y que y barra es f de x barra. Y bueno, buen día. Y acordadme ahora de que, bueno, para, si, yo qué sé, no está mal, no es descabellado pensar, bueno, yo qué sé, si este x barrita es una aproximación razonable de x, si x barrita no está muy lejos de x, y bueno, f de x barrita menos f de x, le puedo hacer un desarrollo de Taylor para comparar esa diferencia. O sea, si yo hago un Taylor de primer orden, acá, Taylor me diría, bueno, f en x barrita es, hago un Taylor alrededor del punto x para estimar f de x barrita. Si hago un Taylor de primer orden, estoy reemplazando, acá escribí, hay algo mal acá, es x barrita menos x. Esto no es una igualdad, esto es una aproximación, ¿sí? Estoy aproximando mi función f por un polinomio de grado 1, como una función de nx barrita, perdón que capaz que la notación fuera, pero como que es una función de x barrita, por ejemplo, como que es una función de nx barrita, perdón que capaz que la notación es confusa. No me importa que no conozca x, Taylor vale igual por más que no conozcas el punto, eso lo digo porque alguien lo preguntaba el otro día en el foro. Y reemplazo entonces, más que una igualdad, esto va a ser un cuchuflo de se parece, y cuando reemplazo fx barrita por esto, fx barrita menos f de x me queda aproximadamente f prima de x. Y ahora lo que hago simplemente es hacerme aparecer, yo quiero relacionar el epsilon y con el epsilon x, y fíjense que yo tengo x barrita menos x, esto está bueno, mejor a favor. Para tener el epsilon x me falta dividir por x, así que voy a multiplicar y dividir por x, y si aparece el epsilon x, esto me queda igual a f prima de x por x sobre f de x por epsilon x. Igualdad tiene que haber estado centrada. Está bien, cuentitas sencillas, cuentitas amigables, pero ya son significativas. Fíjense que tenemos que el error relativo en y es más o menos, a menos de aproximación a primer orden que hicimos acá, es igual a el error relativo en x multiplicado por algo. Esto de vuelta estoy asumiendo que la f la puedo concular exactamente. Simplemente esto es una medida, o sea, lo que estoy haciendo con este numerito es cuantificar cuánto aumenta el error relativo de la salida respecto a la entrada por el solo hecho de que tenga una función, por el solo hecho de que le arruen un poquito a la entrada. Está bien, pero asumiendo que estoy haciendo todo exactamente. Este numerito le vamos a llamar el número de condición de f. No es una k, es una kappa. Les digo porque va a haber k's dentro de un ratito. Esto es una kappa. Yo trato de que las kappas, yo sé que es totalmente imperceptible, mis kappas tienen como una curva ahí. Las kappas son mucho más derechas. Les aclaro por las dudas. Kappa sub f en x. Voy a agarrar ese numerito que tenía ahí. Y los números de condición generalmente, como no lo vamos a usar para hacer cuentas en el medio sino al final, ya le voy a poner el valor absoluto. También me va a interesar la magnitud de esto y ya le voy a poner el valor absoluto de 1. O sea, si yo quisiera escribir esta igualdad usando el número de condición, por ejemplo, podría escribirlo así. El error relativo en i en magnitud es aproximadamente el número de condición de f. Ya metí una k, me dio una kappa. Acertó el cuentito de la curva. Número de condición en la salida. Perdón. Error relativo en la salida es número de condición, que es un factor que te dice cuánto aumenta por error relativo en la entrada. Es un factor de magnificación. Es como un indicador del nivel de dificultad de evaluar tu f. ¿Sí? Es como, ¿qué tan sensible es la f? ¿Cuánto te puede perdonar la f si te equivocas un poquito en la entrada o no? ¿Está? Entonces, en general, medio así en el aire, si el número de condición de una función está cerquita de 1, decimos que evaluar el problema de evaluar la f en x es un problema bien condicionado. Y si es mucho más grande que 1, decimos que el problema de evaluar la f en x está mal condicionado. ¿Qué es cerquita de 1 y qué es mucho más grande de 1? Ni idea. Depende de tu problema. ¿Está? Yo qué sé, para mí moralmente más de 100 ya es mucho más grande que 1. ¿Está? Yo qué sé, para mí moralmente más de 100 ya es mucho. Alrededor de 10 está bien. Entre 10 y 100 puede estar subjetivo. Pero totalmente depende de tu problema. ¿Sí? Sí. Bien, para, voy a repetir tu pregunta por un tema de micrófono. A usted suena raro que pongamos la derivada en x porque podrá una función medio patológica, como x cuadrado por seno de 1 sobre x, que la derivada en 0 da 0. ¿Sí? Y afuera no tenés nada. Bueno, ¿qué pasa con esa función? En 0 vale 0 también. Entonces, acá tenés un pequeñísimo problema con la definición de número de condición. ¿Está? Si a esa función yo le pego un tiquiñazo y la levanto, está re bien condicionada, ¿no? Porque no me importa que haga una basura así. Si esta basura la hace alrededor del 4. Porque todos estos errorcitos son errorcitos alrededor del 4. Entonces, como error relativos son chiquitos. Es esa sutileza que está escondida ahí. Esto es todo. Nada, dejémoslo. Lo presentamos, muy lindo. Es un parámetro que no es hablar de sensibilidad, de evaluar una función. Lo dejamos reposo un ratito. ¿Está? Volvemos a esto seguramente más tarde. Este... O bueno, o capaz que ya la semana que viene. ¿Está? Simplemente mensaje acá es esto. El número de condición me dice cuánto se magnifica el error si pudiese computar mi F exactamente. ¿Está? El error en la entrada y la salida si pudiese computar la F exactamente. Segunda cosa, segunda forma de ver cómo se puede poner el error si hacemos las operaciones aritméticas. O sea, sumar dos números, restar dos números, multiplicarlos, dividirlos. ¿Está? Hagamos... Quiero hacer la suma sí o sí y la multiplicación y división hago una de las dos. ¿Está? ¿Cuál? ¿Multiplicación y división? Es un penal. Hay que presión. ¿Multiplicación o división? ¿Qué te gusta más? Multiplicación. Multiplicación, perfecto. Multiplicación. ¿Está? Lo que les digo, la división está ahí en las notas. ¿Está? Multiplicación. ¿Está? Lo que les digo, la división está ahí en las notas. Es esencialmente la misma cuentita. ¿Está? Entonces yo ahora tengo dos números, X y. En vez de tener X e Y, lo que tengo es X barrita y barrita. ¿Está? Y si yo tengo la capacidad de multiplicar exactamente, lo mejor que puedo hacer es, a ver si entendemos el juego de las barritas, tomar como aproximación a X por Y al producto de la aproximación en X por la aproximación en Y. ¿Se entiende? Tengo mi número que aproxima X, mi número que aproxima Y, tengo la capacidad de multiplicar exactamente, los multiplico y lo que me queda es una aproximación al producto. Bien, entonces repetimos el jueguito de preguntarnos cómo se relaciona el error relativo en este producto respecto al error relativo en las entradas. Entonces, lo voy a hacer, creo que era vos que me habías preguntado en el foro. Lo voy a hacer como vos decías, total. En las notas lo hago de otra forma, pero da lo mismo. Uso la definición nomás. Entonces, el error en este producto es, bueno, debería poner esto, pero ya estoy usando que es el producto de las aproximaciones, menos X por Y sobre X por Y. ¿Sí? La definición. Bueno, algo que uno puede sacar de aquella igualdad que puse, de la definición de error relativo, que también la habíamos escrito la clase pasada, era que de acá uno puede despejar la aproximación en función del error relativo y el número que quiere aproximar. ¿Sí? O sea, que podría acá reemplazar X barlita por 1 más epsilon X por X, e Y barlita lo puedo aproximar por 1 más epsilon Y por Y. Está palmando. ¿Tenés alguna pregunta? ¿Ahí? Pregúntenme. ¿Quién está escuchando algo de la aproximación? Dale, pregúntenme, no hay miedo. Sí, esa última. ¿Marcáme a qué? ¿Esto? ¿Aga? Esta es la definición. El error relativo en el producto es, la realidad, hago dos pasos acá en el pizarro, van de una, pero lo correcto sería decir esto, es el error relativo al aproximar algo es lo que obtuve de aproximarlo, perdona, esta barlita no va, ¿no? Esta barlita no va, capaz que se confundió. Mi aproximación, menos el número, dio el número, uso esta propiedad, tiki, y ahora sigo yo. Bien, esa barlita no iba. Bien. Bueno, simplifico un montón de cosas ahí, ¿no? Los X por Y se van todos. Ni que hablar estoy asumiendo que X e Y son distintos de 0. Si X e Y fueran 0, ya está. Para empezar, no podría hablar del error relativo o en X o en Y, ni mucho menos puedo hablar del error relativo en el producto, ni tampoco tendría sentido porque estoy multiplicando por 0. Voy a ver 0. Entonces, puedo simplificar acá X por Y, y esto me queda 1 más epsilon X, 1 más epsilon Y, menos 1, y se tacho el X por Y. ¿Buenas? Distributivo a todo, esto me queda epsilon X más epsilon Y más epsilon X epsilon Y. Bien. ¿Sí? Si tus aproximaciones son más o menos buenas en el sentido de que epsilon X y epsilon Y son chiquitas, entonces uno espera que el producto sea en magnitud más chiquito que alguno de los dos, ¿no? O sea, esto va a ser comparable con la suma. Bien. ¿Cuál es la moraleja de este cuento? Moraleja multiplicar es seguro. Muy... Lo que me cuesta es escribir la palabra multiplicar en el pizarro, no saben lo que es. Tengo que pensarlo 7 veces. Multiplicar es seguro. ¿En qué sentido? En el sentido de que el error relativo en la salida, si yo lo puedo hacer exactamente, no va a ser mucho peor que los errores que tiene la entrada. Incluso, fíjense esto que interesante y también que intuitivo, yo a los epsilon los dejaba que fueran positivos o negativos, ¿no? Entonces claro, fíjense, si vos tenés el epsilon X que es negativo, quiere decir que tu aproximación de X es un poquito más chica que X. Si tu epsilon Y es positivo, quiere decir que tu aproximación de Y es un poquito más grande que Y. ¿Sí? Si epsilon X y epsilon Y tienen signos distintos, capaz que esto se compensa y hasta te queda mejor. Podría pasar. ¿Sí? Que es como decir que se agarra un número un poquito más chico que lo que quiero y uno más grande que lo que quiero y los multiplico, capaz que justo se arregla todo. ¿Tá? No importa, lo importante acá es... Multiplico con el X y el X es igual a X. Y si el X es igual a X, no importa, lo importante acá es... Multiplico número 2, estoy tranquilo, no va a pasar nada grave. ¿Tá? Fíjense que acá sí podía pasar. Si el número de condiciones es grande, si mi f está mal condicionada, puedo tener un problema. Acá no voy a tener ningún problema. ¿Tá? La división no la vamos a hacer. Pueden hacer ustedes la misma cuenta. Lo que van a llegar es a esto. ¿Tá? Misma cuenta. No tiene nada misterioso. Y tampoco tiene nada de así, de estrambótico. El épsilon y puede ser positivo o negativo, o sea que este signo de menos no dice nada en especial. ¿Tá? Lo que importa es, de vuelta, si yo quiero ver qué magnitud tiene este error relativo, esta magnitud es comparable con... Yo qué sé, el peor de los dos. Bueno, bien. Entonces, multiplicar o dividir, estamos tranquilos, los errores no se van a propagar mucho. ¿Qué pasa cuando sumas o restas? Cada sumar y restar, o sea, la vez multiplicar y dividir Y también hay que pensar que es más o menos lo mismo. Pero yo qué sé, tendría que haber entendido cómo es el número de condición de hacer 1 sobre i. Podría haberlo hecho con aquella función. Pero bueno, preferí hacerlo separado. Bueno, sumo o resto de números. ¿Tá? Entonces, de vuelta, si puedo hacer la suma exactamente, mi aproximación a la suma va a ser la suma de las aproximaciones. Y con la resta lo mismo, ¿no? Para fijar ideas, ¿vindríamos la suma? ¿Sí, no tengo que poner más menos todos lados? ¿Me dejan? Me tienen que decir que sí. ¿Me dejan? Gracias. Está, listo. Está igual y y puede ser negativo. O sea que en realidad hay como una resta camuflada. Bueno, a ver, ¿cómo sería entonces el error en esta suma? Día. Y bueno, mismo razonamiento, ¿no? Mi aproximación menos el número que quiero aproximar dividido el número que quiero aproximar hago el jueguito ese de escribir x barrita como x por 1 más epsilon x y barrita como y por 1 más epsilon y menos x menos y sobre x más y acá se tachan un par de cosas y ordeno y me queda algo así, si no me equivoco. A ver, x por 1 se va con este, me queda epsilon x por x dividido x más y y por simetría tiene que ser así entonces. Está. ¿Sí? Bueno, la pregunta es, ¿eso es bueno o es malo? ¿Es bueno o es malo? O sea, ¿es bueno que me haya parecido x sobre x más y por epsilon x o y sobre x más y por epsilon y? Este término, ¿es chico o es grande? Depende, ¿no? Depende. Vamos a mirar. Si x e y tienen el mismo signo, le pongo así, rapidito, x por y mayor a 0, quiere decir que tiene el mismo signo, entonces es fácil ver x más y tiene el mismo signo que x, ¿no? ¿Tiene el mismo signo? Este número va a estar atrapado entre 0 y 1. Sí, decime. ¿Dónde? Acá, ¿falta un menos 1, decís? No, pero fíjate, x por 1x menos x se van. Sí, o sea, queda ahí que... Está. ¿Están de acuerdo con esto? Es hacer una cuentita nomás, ¿no? Pero... Está, y lo mismo puedo decir obviamente para el otro. Para y sobre x más y. Sale el toque. Este... ¿Y esto qué quiere decir? Quiere decir que estos factores que están acá multiplicando están entre 0 y 1. O sea que estas cosas realmente no son muy grandes, ¿no? Entonces, lo que pasa en este caso es que si miro, le pongo barrita, le pongo valor absoluto a este error relativo, me queda algo así. Estos números están entre 0 y 1. De hecho, incluso podría haber hecho las cosas un poco mejor y decir, suman 1 entre sí, ¿no? Si sumo estos dos me da 1 la suma. Pero está, no importa. No calienta. Por ejemplo, lo puedo escribir así. O sea, el error relativo en la suma no es peor que la suma de los errores relativos en valor absoluto. O no es peor que el peor de los dos. Estamos tranquilazos. Y si los números del mismo signo es seguro. Y repito, es seguro en el sentido de que el error relativo en magnitud no aumenta mucho. Está controlado. El error relativo en la salida está controlado por el error relativo en la entrada. De forma así, estable. ¿Se entiende? Bueno, ¿qué pasa si tienen signo distinto? La cuenta está hecha de una forma que va a ser un poquito distinta. Tal vez sea un poquito más precisa que como están las notas. Así no me tratan de vender humo. Ni que hablar que si x o y son 0 no tiene gracia. Porque está haciendo x más 0 o y más 0. No tiene gracia. Y también fíjense que si x fuese justo menos y, si fuesen opuestos. Tendría un problema porque la suma me daría 0. Y el error relativo en la suma no estaría bien definido. Tengo que asumir acá, medio escondida, porque si no hubiera sido el error relativo en la suma, tengo que asumir acá, medio escondidamente. Y no sean opuestos. Si sean 0 opuestos, el error relativo en la suma no está definido. Porque la suma te da 0. Entonces tengo dos números de signo cambiado. Que no son el opuesto uno del otro. Uno de los 12 es más grande en valor absoluto entonces. Entonces supongamos, voy a llamar que x es el más grande en valor absoluto. No importa si x es positivo o negativo. Lo importante acá es que el signo de x es distinto del signo de y. Y x es el más grande en magnitud. Entonces, si no son opuestos, esto quiere decir entonces que, yo qué sé. X es igual a... bueno, uso una C. ¿Va bien? O sea, ¿hay algún factor ahí más grande que uno? Como el valor absoluto de x es más grande del de y. Bueno, nada, el cociente le llamo C. Y ese C estoy suponiendo que es más grande que uno. Quiero hacer la cuenta así, lo más precisa que pueda. Bueno, vuelvo hasta fórmula entonces. ¿Qué puedo decir ahora sobre estos factores? A ver. O sea, ¿pueden ser grandes? ¿Pueden ser grandes? ¿Cuánto sería grande este factor? Cuando esté muy cerca de ser x igual a menos y, ¿no? Cuando x más y esté muy cerca de ser cero. Ahí te vas a tener un problema. Si x más y está muy cerca de ser cero, quiere decir que estoy muy cerca de donde el error relativo no está definido. Y además si x no es chiquito en magnitud, este número es gigantesco. Y voy a tener que pagar el precio. Me va a salir caro esto. Veamos cómo es la cosa. Por ejemplo, yo podría hacer este jueguito. La vez que quería desigualdad triangular. ¿Qué de cálculo? Ya no sé si se da esto en cálculo uno o no. Sumo y resto y. Uso la desigualdad triangular. El valor absoluto de menos y es el valor absoluto de y. Se va. Y ahora, por ejemplo, puedo usar esta propiedad que está acá. Entonces, y es una constante por el valor absoluto de x. Esto es x más y más perdón. y es 1 sobre x por la constante. Y es 1 sobre x por la constante. Perdón, me reale un poquito con la cuenta. Paso el valor absoluto de x para otro lado. Divido por x más y. Lo que estoy diciendo entonces. Perdón, mayor igual no. Menor igual. Estoy diciendo que este factor, si lo quiero controlar con algo, si quiero controlar este factor con algo, lo puedo controlar con el inverso de este número que me queda c sobre c menos uno. Tratando de hacer la cuenta lo más precisa que pueda. O sea, si quiero controlar el factor que multiplica x en estas condiciones, básicamente esto va a ser lo mejor que puedo decir. Fíjense que no estoy diciendo que es un igual. Estoy diciendo, lo puedo controlar con esto, pero créanme que esta cuenta no se puede mejorar mucho. Básicamente cuando esta desigualdad triangular sea una igualdad, marché. Esto va a ser casi que una igualdad. O va a ser una igualdad. También podría haber hecho de esta misma cuentita. ¿Cómo tengo que hacer acá? ¿Dejémoslo acceder? Ah, claro. Replazo x ahora por c por el valor absoluto de y. Entonces me queda c por el valor absoluto de y menor o igual x más y así. De vuelta, paso el y para el otro lado, divido por x más y y lo que me va a quedar es algo así. Me queda, a ver, ayuden, tiki, uno sobre c menos uno. Listo. ¿Va? ¿Sí? Eso no es una cuenta muy estrambótica. Usé la desigualdad triangular y un poquito de muñeca, nada más. Entonces, lo que estoy diciendo es esto. Fíjense, si quiero controlar el factor que multiplica la x, el épsilon x, tengo este numerito. Y si quiero controlar el que multiplica y, tengo este numerito. Combino todo en aquella fórmula, vuelvo acá, vuelvo a esta formulita. Lo que estoy diciendo es que el error relativo en x más y se puede controlar con este número y el error relativo en x más y se puede controlar con este número ypsilon x más número por ypsilon y y esto, lo mejor que puedo hacer, lo mejor que puedo hacer, y acá estamos en el horno, es acotarlo así. Bueno, aleja. Si quieren, incluso podemos ordenarlo un poquito más. Podemos ordenarlo un poquito más. Podría poner un menos uno más uno acá y me quedaría así. Quieren verlo lindo. Y ahora, vamos a ver qué pasa. Quieren verlo lindo, te queda así. Nada, lo escribí. Esta es una igualdad, no hice nada, hice algo muy elemental, que fue, este c lo escribí como c menos uno más uno. El c menos uno sobre c menos uno me da uno y el uno lo pasé y lo compartí con el numerador ahí, el denominador c menos uno. Nada, me metí en un mundo de cuentas. Epsilon x pelado, bien, notable. Pero acá me quedó la suma esta con un c menos uno dividiendo. Entonces, ¿qué pasa? Si c está muy lejos de ser uno, si c está muy muy lejos de ser uno, este numerito está muy muy cerca de ser cero. Uno sobre c menos uno, c menos uno es enorme, está muy lejos de ser cero. Perdón, muy cerquita de ser cero. C es un millón, uno sobre un millón, todo cerquita de ser cero. Y entonces, el error relativo en la suma se parece al error relativo en x. O sea, ¿qué estoy diciendo? Si tengo un número que es como un millón y le estoy molestando un número que es como menos cero coma uno, el error relativo en la suma es básicamente el error relativo en el grande, en un millón. El i no le hace ni cosquillas. Entonces, el error relativo en la suma es como el error relativo en la entrada. Estamos re tranquilos porque son comparables. El problema entra cuando esta c se empieza a parecer a uno. Y entonces, cuando esta c es un millón, el error relativo en la suma es como entonces uno sobre c menos uno se hace enorme. ¿Si? Se va a infinito. Yo que sé, cuando c se atiende a uno, esto se atiende a infinito. Y entonces, ¿qué pasa ahí? El que domina en esta descomposición es el segundo término y este segundo término es malo, es grande. Vamos a usar rojo. Esto, caca. No hay que hacerlo. No se hace. No hay que evitar a toda costa sumar números que sean casi opuestos. ¿Por qué? Porque nos encanta exagerar y a esto le decimos cancelación catastrófica. Es una cancelación porque obviamente si sumo mil más menos mil, o algo que se parece a mil más algo que se parece a menos mil, se cancelan y es catastrófica. ¿Por qué? Porque el error relativo de repente se me fue de las manos. Hay que, si podemos evitar sumar números de magnitud opuesta, hay que evitarlo. ¿Por qué? Porque puede pasar esto. Y esto que parece un chiste, después les pongo en el EVA alguna anécdota de gente de la NASA que se combinó cancelación catastrófica y se le fueron unos cientos de millones de dólares por hacer eso. Por confiarse. Porque uno después se confía. Es lo que pasa. Uno va a avanzar en el curso, va a ver 10.000 algoritmos, nos vamos a olvidar de esto y como que ¿qué era aquello de los errores? Ni idea. Bueno, a los ingenieros de NASA les pasó y les costó plata. Y seguramente trabajo alguno también. Y que 30 años después nos ligamos a ellos todavía. Esto hay que evitarlo. Esto hay que evitarlo. Les pongo un ejemplo. Les pongo un ejemplo que no está en las notas, pero es bien, bien, bien bobo. Bien, bien bobo de cómo podríamos o que es una cancelación catastrófica. Ejemplo bobo. Quiero calcular el logaritmo de 1.000.000 uno menos el logaritmo de 1.000.000. Y salvé cálculo uno copiando, entonces no me acuerdo que la resta de logaritmos es el logaritmo de la división. Porque soy un bobo. ¿Cuánto es el logaritmo de 1.000.000.1? Hice los deberes, no lo hice a mano. Podría, pero no lo hice a mano. El logaritmo de 1.000.000.1 El logaritmo, vieron que es una función que crece lento, se va infinito lento. Pero les cuento así con algunos dígitos. 13,81515115 y sigue, ¿está? Ni idea. ¿Cuánto es el logaritmo de 1.000.000? Sorpresa. 13,81551 Todos iguales. Y acá empieza la diferencia. Tiene un 0,5. Les voy a marcar en colores los números distintos. 1,5, 0,5. ¿Qué quiere decir esto? Que si vos, si vos nada, te embola escribir más de cuatro dígitos, más de cuantos, uno, dos, tres, cuatro, cinco, seis, siete cifras significativas o tu calculadora no tiene capacidad de manipular más de siete cifras significativas, entonces no podés distinguir estos números. Entonces, si solamente si tenemos solamente capacidad de trabajar con siete cifras significativas y hacemos la resta el resultado nos da cero. O sea, si trabajás con siete cifras significativas, no sos capaz de distinguir estos dos números y una vez que no sos capaz de distinguir estos dos números, marchaste. ¿Sí? La resta te da cero. ¿Se entiende? Entonces, cualquier error mínimo que aparezca, yo que sé si acá este 15 en vez de tenerlo así, nada, este lo tiene representado exacto y este capaz que también, pero nada, ahora los trunqué y tengo un error chiquitito en mi representación, marché. Este error chiquitito en la octava cifra significativa, que es un error relativo al orden de 10 a la menos nueve, 10 a la menos ocho, perdón. Se me transformó en un error infinito, un error enorme. ¿Qué hago ahí? ¿Me pongo en posición fetal y lloro? No, no. ¿Cómo arreglo esto? Si tengo siete cifras significativas, ¿cómo hago esto? ¿Cómo lo hace un ingeniero? ¿Divís? Sí, pero si divido a ver, dale. Divido, dale, yo te voy a seguir, yo te sigo. No. No necesariamente, a ver. A ver, que vos no hagas lo que yo haría no quiere decir que esté mal. Igual yo haría eso, así que dale. Para escribo nomás la propiedad, ya escribo así, un millón uno es 10 a la seis más uno. Menos el logaritmo de 10 a la seis, voy a decir que lo escriba como división. Dale. Sí, podemos usar la división, sí. Pero yo tendría que computar el logaritmo de un número espantoso y a la mierda. O sea, va a ser seguro que este número me va a dar muy muy cerquita de uno, ¿no? O sea, me va a dar muy cerquita de uno y capaz que justo no lo distingo de uno. Entonces, ¿qué puedo hacer acá? Cuando tu computadora no es confiable, usa la matemática un poquito. Este número, si yo divido, esto es uno más diez a la menos seis, ¿no? Hago Taylor, cierro los ojos y digo, ¿sabes qué logaritmo? Te aproximo por una función lineal. Taylor para el logaritmo. Si X está cerquita de cero, Taylor o un equivalente. Yo le digo Taylor porque todo sale con Taylor. Y si no se acuerdan de Taylor, lean Taylor. Si X está cerquita de cero, el logaritmo de uno más X el logaritmo de uno más X alrededor de X igual cero se parece al logaritmo de uno que cero más X. El mismo que he querido equivalente, ¿no? El logaritmo de uno más X es equivalente a X para que se quita de cero. Entonces, ¿qué puedo hacer? Para mí es un número chiquito. Entonces, es mucho más seguro. Puedo hacer esto. El logaritmo de uno más diez a la menos seis lo aproximo por diez a la menos seis. Y ya está. Y no tuve que hacer ninguna cuenta. Y esto termina siendo mejor. Y si no tengo que hacer nada, no tengo que hacer nada. Y si no tengo que hacer nada, no tengo que hacer nada. Y esto termina siendo mejor. Esto termina siendo mejor. Esto tiene un error relativo, se los cuento, porque lo tengo a algún lado. Esto tiene un error relativo. Acá lo tengo. Hacer esto tiene un error relativo. Si yo hago esta aproximación, mi error relativo es cinco por diez a la menos siete. Tremenda aproximación. A los efectos de lo que necesito, esto es una muy buena aproximación. Si quisiera, podría hacer X más y buscar quién es el siguiente término en Taylor. Si no me alcanzo. Pero capaz que con mis siete cifras no puedo representarlo. Yo tiendo a creer que no voy a poder representarlo. Pero bueno, esta aproximación, ya hacer esto, ya es mejor. A veces no hacer las cosas exactamente, termina siendo mejor. ¿Se entiende? Si vos tenés un problema de cancelación, adelante tuyo. A veces hacer una aproximación termina siendo más seguro que de tratar de hacer la operación exactamente y exponerte a la cancelación. No, este error sale de la definición de reemplacé. Reemplacé, o sea, agarré la verdad absoluta de cuánto es el logaritmo de uno más diez a la menos seis. Lo reemplacé por esto, o sea, calculé esto. O sea, tendría que haberlo puesto... Este error, hice esta cuenta. Hice diez a la menos seis, menos el logaritmo de no sé qué, sobre logaritmo. Saucé la definición. Y esto me dio cinco por diez a la menos siete. O sea, tal cual. Entonces, no hay que ponerse el balde de querer hacer las cuentas exactas. A veces tus aproximaciones pueden ser mejor que tu capacidad de representar. Y si tenés una cancelación adelante, puedes ya ser más beneficioso aproximar que tratar de representar exactamente. Hay una contraposición ahí. Hay una contraposición. Que va a parecer bien clarito la semana que viene. Pero fíjense que acá el truquito fue evitar hacer una resta de números de igual magnitud. E incluso acá, nada, como esto no lo podía distinguir, bueno, tuve que hacer un truquito tipo Taylor. Otro ejemplo. Otro ejemplo también, así como... Voy a asumir que tengo pocas cifras de precisión. E Charlie Young. Hubo con la examina este de se, no siente nada. Reg Belt Still. El de la P. Visittimus y cuadrado, está en las notas este ejemplo, les digo, menos 56x más ui. Pero con una máquina que nos deja trabajar con cinco dígitos, con cinco cifras significativos. O sea, ustedes dirán, ah loco, pero esto es un ejemplo de 1940 con cinco cifras. O sea, no cambia mucho, si tengo 5 o tengo 16 o tengo 32, es lo mismo. El problema te parecerá más grande antes o después, pero es más o menos el mismo problema. Tu problema es que tenés la presentación finita. O con cinco cifras y no con 32, porque para que los números queden lindos y el pizarrón pueda hacerlo. Aclaro eso, nada más. Por eso yo tenía siete, acá tengo cinco, a veces voy a tener tres. En la computadora vamos a ver cuántos tenemos después. Bien, bueno, ¿cómo calculan las raíces de una cuadrática? Está fácil, ¿no? Las raíces. Hago la resolvente, báscara, no sé cómo le digan y me queda, se los cuento ya, me queda 28, más o menos raíz de 783. ¿Está? Spoiler, 28 al cuadrado es 784. O sea, raíz de 783 está cerquita, muy cerquita de ser 28. ¿Dónde están los problemas acá? ¿Dónde están el peligro? En R2, ¿no? La raíz 1 debería ser totalmente amigable para computar, no importa que tengamos cinco o tres cifras significativas. Deberíamos no tener mucho drama con R1. R1 va a ser más o menos 56. O sea, si trabajaba con dos cifras, digo 56 y va a estar bastante bien. R2, en cambio, va a ser un problema. Entonces, ¿qué haríamos acá? Si tuviésemos nuestra calculadora de cinco cifras significativas, bueno, 28 lo puedo representar exactamente. A ver si lo escribo así. La aproximación de 28 es 28. Eso quiere decir que cuando quiera representar al 28, está todo bien, no tengo error. Bien. Podría haber hecho el algoritmo que vimos el lunes, no lo hice, pero les cuento que la raíz de 783 es más o menos 27,982. Y después números que me voy a perder. Pongo un par. 1, 3, 7 y sigue. Cuando yo quiera representar raíz de 783, esto que está en azul, lo perdí. ¿Sí? Eso, obviamente, ahora sí tengo un error relativo en mi representación. No lo estoy representando exactamente. El error relativo es chiquito. ¿No lo escribí? Ah, sí, acá lo escribí. El error relativo en este número es más o menos, uso la definición y me queda del orden de 10 a la menos 6. Más o menos menos 5 por esa menos 6. Chiquitito, divino. Vamos, re tranquilo. Bueno, R1 es seguro. Calcular R1 es seguro. Si yo quiero calcular ahora mi aproximación R1, obviamente voy a hacer mi aproximación a 28 más mi aproximación a raíz de 783. Entonces en mi computadora o mi calculadora de cinco cifras, R1 va a ser sumar esto y esto y 28 y me va a quedar 55,982. Y está divino esto porque en realidad R1 es 55,982137, blablabla. Error diminuto. El error en R1 es más o menos 2 con 4 por 10 a la menos 6. Divino, ¿no? O sea, lo que decíamos, si estoy sumando números que tienen el mismo signo, estamos re tranquilos. Bueno, ¿qué pasa con R2? R2, mi aproximación, va a ser la aproximación de 28 menos la aproximación de esta raíz cuadrada. Ustedes ya saben que acá va a haber problema porque ahora me va a quedar 0,018. ¿Sí? Observación relevante. ¿Cuántas cifras tengo en esta representación de R2? Dos. Perdí capacidad, ¿no? O sea, en teoría tendría capacidad para almacenar cinco cifras significativas y resté dos números y mi número que me quedó ya perdí cifras, perdí precisión de esa forma también. No tengo cifras. El error acá en R2 no les va a parecer tan dramático. ¿Qué es el error? Es el orden de 7,7 por 10 a menos 3. No les parece dramático, pero es dramático. Porque fíjense, este error es cuando lo comparo con este y con este, agarré algo que estaba, era exacto, algo que tiene un error del orden de 10 a menos 6, y usted hizo un guiso y me salió con 10 a menos 3. O sea, acá perdí, aumentó en un factor más o menos de 1500. Perdí tres órdenes de magnitud de un plumazo. Esto, capaz que si tu cuenta no le importaba mucho hacer esta aproximación, capaz que estabas bien. Pero fíjense que perdiste un montón de precisión. Eso es una cancelación catastrófica. Para dar precisión, podrás hacer las cosas así, cerrando los ojos y cómo sale. ¿Cómo calculás R2 de forma segura? ¿Cómo se arregla? ¿Cómo se arregla? ¿Cómo calculás R2 de forma segura? ¿Cómo se arregla en este caso? ¿Cómo? ¿Taylor de dónde va? Para... o sea... Algo sí podríamos hacer con las raíces cuadradas, a ver. Si multiplico por el conjugador. Arriba y abajo, a ver. Ah, ok, ya entendí. Bueno, no va a estar muy lejos lo que vamos a hacer de eso. Uso la sugerencia de él un segundo. La escribo nomás. La escribo en un color. Porque está bien. Uno podría haber hecho este juego. Opción 1. Esta me gustó. 28 menos raíz 783 Un truquito lindo es si tengo dos números que son de la misma magnitud y uno es una raíz cuadrada, puedo conjugar. Multiplico y divido por la raíz. Lo que está arriba es 28 al cuadrado menos 783. Les conté que 28 al cuadrado es 784. O sea, queda 1. Entonces, algo que podrán hacer ustedes y parece muy razonable, así que te doy el crédito, es decir R2 aproximado por 1 sobre 28 más raíz 783. Esto lo puedes hacer de forma estable y hacer 1 dividido por un número también lo puedes hacer de forma estable. Esto estaría bien. Ya lo que voy a contar va a ser lo mismo, básicamente. Pero lo digo como lo dice en las notas. El resultado va a ser el mismo, así que me encantó. Opción 2. Escribir x cuadrado menos 56x más 1. Factorizarlo, ¿no? con las raíces. Si un polinomio tiene coeficiente principal 1, así que se puede escribir como x menos una raíz por x menos la otra raíz. Si desarrollo del lado derecho, me queda x cuadrado menos R1 más R2 por x más R1 por R2. Esto quiere decir entonces tengo como una especie de sistemita si quieren para R1 y R2. La suma tiene que ser 56 y el producto tiene que ser 1. ¿Cuál es la idea de acá? Esta opción es esta. Si R1 lo podés calcular de forma segura, de forma estable, acá, calculáte R1 de forma estable y después trata de usar esto para despejar R2. Entonces, opción 2 sería calcular R1 esto es estable, es seguro y después, ¿cuál de las dos voy a usar? Tengo dos formas de despejar R2, ¿no? Podría decir que R2 es 1 sobre R1 o podría decir que R2 es 56 menos R1. ¿Por qué la que hice rojo está mal? o no está buena. Porque la que hice rojo me da una cancelación. R1 es más o menos 56. Entonces, si hago esto, estoy en la misma que estaba antes. Me metí una cancelación. Entonces, lo que está rojo no está bueno acá. ¿No está bueno usar esta? Está bueno, sí. Y si se fijan, es lo mismo que su girivel. Te termina quedándote esto. O sea, vas a tener que aproximar 28, vas a tener que aproximar raíz 783, sumas, te doy una aproximación y hago 1 sobre eso y esa es mi aproximación de R2. Hacer esto, cualquiera de estas dos te da un error relativo taca taca taca taca taca taca Taca, taca, taca, taca, taca. No lo escribí. Ah, sí, acá. 8 con 9 por 10 a la menos 6. No perdiste cifras. O sea, el error relativo en RL2 es comparable con el error relativo de tus entradas. ¿Está? O sea, si podemos evitar hacer cancelaciones catatróficas tenemos que evitar hacer cancelaciones catastróficas. Si ven un número grande menos otro número grande, peligro. Evitar, tratar de esquivar eso. ¡Ah, este prarito! Bien, así que vamos a tratar de hacer pasar la vergüenza a la computadora un poquito. ¿Tiene alguna pregunta hasta acá? ¿De esto sí? Dale. El principio de Taylor acá del logaritmo de 1 más x. ¿De qué nos agarramos de por qué usar Taylor puede ser hacer mejor que vivir? Cuando tenés una situación complicada necesitas una solución, básicamente. Un alternativo. Entonces, Taylor no va a ser lo mejor siempre. Taylor no va a ser lo mejor siempre. Pero bueno, acá estás en una situación desesperada en la que claramente hacerle esta era una mala opción. Si hago esta división, capaz que este número no lo lleve a ver. O sea, si tengo siete cifras justo lo puedo llegar a ver, pero el logaritmo no creo que lo pueda ver. Y bueno, Taylor me da una solución rápida. Es básicamente que me funciona. ¿Y por qué hago Taylor con un término y no con más? Porque puedo. ¿Está bien? Buenicio. Bueno, entonces ¿por qué hicimos todo este cuento sobre operaciones aritméticas y cancelaciones catastróficas y errores en las entradas? ¿Cómo se ven en la salida? Lo hicimos porque básicamente nuestra computadora, mi computadora y cualquier computadora, cualquier máquina trabaja con precisión finita. Y como trabaja con precisión finita, la capacidad de representar números no es infinita. Vamos a empezar a ver ahora sí qué números usa la computadora, qué número, qué sistema de numeración usa la computadora. Muy rápidamente, no nos vamos a meter mucho en eso. Pero sí ya con la cabeza de qué cosas hay que evitar y qué cosas son estables. Bueno, a ver, hora de hacer pasar vergüenza a una computadora. ¿Cómo hacen pasar la vergüenza a una computadora? La computadora no sabe las propiedades de la suma. ¿Cuánto da esto? Gracias. Ah, costó. Lo que costó. Bueno, si ustedes le ponen esto a una computadora, la computadora va a hacer la cuenta así, ¿no? Va a ser primero una más x, va a ir en orden. Dice, para tengo una suma y una resta, las hago en orden y hago esto. Ustedes capaz que lo que hicieron fue dijeron vos, para estos unos se tacharon y me quedó una x. Bueno, vamos a hacer eso. Yo uso Matlab, pero nada, porque tengo. Sí, bueno, perdón. Es legal, quiero que sepan. Quiero dejar constancia que es legal. Está pagado con un proyecto de acá. Pero no, en octáveis pasé exactamente lo mismo. Clear, CLC. Clear es borrarme la memoria. CLC es borrarme la pantalla. Esto es como empezar de vuelta. Me definí un numerito que es 10 a la menos 16. Si quieren, les muestro uno más. Numerito es 1 por 10 a la menos 16. Y lo que voy a hacer es a que sea 1 más numerito menos 1. ¿Y cuánto da esto? Cero. ¿Qué pasó? ¿Por qué da cero? Sí. ¿Hizo 1 más numerito? Si esto lo aproximo a 1, cagó. Porque si mi aproximación de 1 más x es 1, esto es una cancelación catastrófica, muy catastrófica y muy obvia. Es 1 más numerito para la computadora es 1, 1 menos 1 es cero. Si yo a la computadora le cambio el orden y le digo, hace 1 menos 1 más numerito, ahora acortó. De repente sabe hacer la cuenta. ¿Cuál es la diferencia? Me hizo ahora 1 menos 1, me dio cero y a numerito aparentemente lo pudo almacenar bastante bien. O sea, el orden de los sumandos altera la suma. La primera, la que nos dio la... Ah, puedo usar esto. Mentira, no puedo usarlo. Sí, puedo usarlo, claro. Esto se ve ahí. Lo que hemos progresado. 1 más numerito menos 1 igual no me da cero para nada. 1 más numerito menos 1 me da cero y 1 menos 1 más numerito me da lo correcto. Entonces, primer pauta. Exacto, 1 más numerito para la computadora es 1. Esto que está acá. X es numerito. Bien, vamos con otro ejemplo un poco más gramático. Yo solamente se los quiero mostrar. Está más adelante en las notas. Lo puse más adelante porque se podía. ¿Qué es esto? Tengo un polinomio. Se llama... Bueno, le puse y primero. Pero imagínense que quiero hacer p de x que sea x menos 1 a la 7. Quiero graficar este polinomio y lo quiero graficar cerca de 1. O sea, x está entre... Acá lo hice entre 0,99 y 1,01. Quiero graficar un polinomio para una función entre... Bueno, muy cerquita de arnaís. Entonces, cuando pongo Linspace, lo que hace es una partición uniforme. Tengo tres entradas, el extremo izquierdo, el extremo derecho y cuántos numeritos hay. O sea, tengo 999 intervalos iguales en el 0,99 y 1,01. Me defino y que sea x menos 1 a la 7 y le voy a decir que graficame ese polinomio. Pectacular. Bueno, esto fue en un examen de repente y tuvieron la mala leche de darme lo factorizado, he desarrollado. Me dieron x a la 7, menos 7x a la 6, más 21x a la 5, más 35x a la 4, y la la la. No me avivé que esto era x menos 1 a la 7. Pero es x menos 1 a la 7. Bueno, vamos a cambiar. Tricky. En azul va a seguir estando el gráfico lindo que teníamos antes. Ahora en rojo voy a poner esta nueva representación si yo graficara z. Z es igual a y en lápiz y papel. Eso es un polinomio de grado 7 para una computadora con un montón de cancelación. Este tipo de cosas son cancelaciones catastróficas. ¿Se entiende? Puede ser que un polinomio deje de ser un polinomio, básicamente. Obviamente, no sé si se van a ver, pero la escala es de 10 a la menos 14. Es una escala chiquitita. Pero el error relativo que estoy haciendo es enorme. Se ve ahí en el fondo la curva azul. Espero que se vea. Claro, esto oscila grotescamente alrededor de esa curva azul, pero tiene un error espantoso. Básicamente veo ruido. ¿Por qué veo ruido? Bueno, por lo mismo. Porque si yo ahora le digo x es más o menos 1. Bueno, x a la 7 es más o menos 1. 7x a la 6 es más o menos 7. 21, 35, 35, 21, 7, 1. Se cancelan todos, me queda más o menos 0. Metí terrible cancelación catastrófica. Terrible cancelación de 8 términos que se fueron cancelando entre sí. ¿Se entiende? Entonces, obviamente, acá graficar este polinomio usando z es una pésima idea. Y es una pésima idea. Yo estoy asumiendo que nuestra computadora puede multiplicar establemente, puede sumar establemente, obviamente. Es una pésima idea, básicamente, porque tengo errorcitos en las entradas. Los números entre en este intervalo, capaz que no puedo representarlos a todos exactamente. Y si no puedo representarlos exactamente, voy a tener una propagación de error del tipo de la que vimos acá, cancelación catastrófica, y que después va a hacer que vea ese ruido. ¿Está bien? Entonces, básicamente, este dibujito es la representación. Opa, ¿por qué se corre ahora? Ah, está. Igual ya cierro. Eso es la representación gráfica de mi computadora no puede representar los números exactamente, y como no puede representar mis números exactamente, veo un montón de cancelaciones catastróficas. Entonces, la idea, cuando hablemos ahora de aritmética de punto flotante, es qué números puedo representar exactamente, y qué pasa cuando aproximo números. Y cuando aproximo números, tengo que tener en cuenta que después al hacer operaciones, los errores se van a propagar en esas operaciones. ¿Está bien? Entonces, todo esto es para motivar los albódrios que vienen ahora, que es hablar un poco... O sea, yo odio arrancar con aritmética de punto flotante porque es como jugar un partido de fútbol y antes de arrancar a jugar, que te cuenten las reglas. Yo prefiero jugar y después entender las reglas. Pero bueno, les tengo que contar un poco las reglas de juego, cómo son. Entonces, bueno, la mayoría de ustedes son estudiantes de computación, o sea, que saben esto mucho más que yo. Para los que no y no saben, las computadoras almacenan ceros y unos, y tiras de ceros y unos, básicamente. Y un 0, 1 es un bit, ¿no? Una unidad, 0, 1 es un bit. Entonces, básicamente la computadora, cualquier número real, lo va a almacenar con una tira de ceros y unos. ¿Qué pasó cuando hicieron las computadoras y empezó a haber todo el desarrollo? Nada, cada uno usaba el sistema que se le cantaba para representar. Y pasaban... Había problemas de compatibilidad, problemas ahí de cómo pasar de un sistema a otro. Había errores también asociados a este número en un sistema para lo que poder representar en este otro no. Y allá por los 80 se juntó la gente de... A ver, algunos de los de eléctrica, que es IEEE, International Electronic e-Engineers, algo. Sí, algo de eso, ¿no? O sea, allá por los 80 y sacaron los, digamos, estandarizaron. Allá por los 80. Estandarizaron la representación, hicieron como unas especies de estándares de lo que se llama de punto flotante. Hoy en día creo que todas las máquinas normales de escritorio trabajan con lo que se llama la precisión doble. Entonces yo voy a contarles el formato de precisión doble. Es un formato de estos que sacó esta gente, estos ingenieros se pusieron de acuerdo y dijeron vamos a representar números de esta forma. Precisión doble se llama así porque hay uno que es precisión simple, media precisión incluso, hay cuádruple, hay octuple hoy en día. Pero nada. Básicamente la pregunta es cuántos bits, cuánta memoria quiero usar para almacenar un número. ¿Sí? Cuantos más bits uses para almacenar un número, más preciso puede ser, pero más demandante es almacenar el número. Cuantos menos bits usas, nada, sos menos preciso pero más livianito también. Entonces, en el formato de precisión doble, los números representables son así. Pues ya estamos casi que en hora, ¿no? Son los números que puedas escribir de esta forma. En realidad en cualquier formato de estos de punto flotante de la IEE, los números se representan así. La pregunta es cuántos bits uso para los parámetros que aparecen acá. Entonces, en precisión doble se usan 64 bits. Precisión simple usa 32 bits, precisión cuádruple usa 128, octuple usa 256. Entonces, básicamente es esto. A mi X lo tengo representado por una tira de 64 ceros y unos. Bueno, necesito un bit. El primer bit lo voy a usar para el signo. El primer bit lo voy a usar para decir si X es positivo o negativo. Un alcahuete, positivo o negativo. Después vemos qué pasa con el cero. El cero es especial. Pero el cero lo quiero poder representar exactamente también. Pero bueno, hay formatos que tienen ceros positivos y ceros negativos incluso. Un bit para el signo. Después voy a tener un montón de bits. Azul y verde para la F. Necesito 52 bits. Para la F, que es lo que se llama la mantiza. Ahora les cuento un poquito qué es la F. Y lo que me sobra para E. 11 bits, 63, más uno 64. 11 bits para E, que es el exponente. Vamos a entrar con esto en detalle bien la semana que viene. Pero tratemos rápidamente de entender qué hace cada parámetro. El signo obviamente dice positivo o negativo. ¿Qué te da la mantiza? O mejor para empezar con el exponente. ¿Qué te da el exponente? El exponente te da una idea de la magnitud del número. Si es grande o es chico. Y la mantiza te deja calibrar en el intervalo 1, 2. Entonces la mantiza F es un número que se puede escribir de esta forma. Algo dividido 2 a la 52 con J, que puede ser 0, 1. O sea, con 52, una tira de 52 0, 1, puedo representar cualquier número entre 0 y 2 a la 52 menos 1. O puedo representar 2 a las 52 números. Bueno, la mantiza me va a representar un número de esta pinta. ¿Cuál es el chiste acá? Observen que F está entre 0 y 1. Puede llegar a ser 0 la mantiza, puede llegar a ser casi casi casi 1. Si es casi casi casi 1, este número es casi casi casi 2. No llega a ser 2. El exponente Bueno, para exponente tengo 11 bits. Con 11 bits puedo representar 2 a la 11 números. 2 a la 11 es 2048. El exponente se suele almacenar como un número entre menos mil, vamos a ponerlo así, 1023 y 1024. Ahí tengo 2048 números. En la práctica, esto sería en teoría, en la práctica se usa algo así. Me guardo el 1024 y el menos 1023 para cosas especiales o para casos especiales. Es como que el exponente 1024, el exponente menos 1023 están reservados para ciertos números que después vamos a ver qué onda. Ciertos números especiales de punto flotante. Entonces, simplemente esto. Estos son los números que puedo representar exactamente. Ahora después, después no, el lunes, ya enganchamos y vemos qué quiere decir esto. Pero básicamente tengo tres parámetros en estos estándares. Uno es el signo, fácil de entender. Uno que tiene que ver con la magnitud, el exponente, porque fíjense, si el exponente es muy grande, este número es muy muy grande en magnitud. Si el exponente es menos mil, 2 a la menos mil es casi casi cero. Me queda muy chiquito en magnitud. Entonces, el exponente me calibra en magnitud y la mantiza me deja moverme en el intervalo 1-2. Entonces me deja calibrar dentro del lango que me da el exponente. Estamos en hora, así que paramos acá.