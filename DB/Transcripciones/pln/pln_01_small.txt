Bueno, ¿cómo andan? Bienvenidos a la versión 26 del curso de Procesamiento del Inguaje
Natural de Introducción al Procesamiento del Inguaje Natural? Somos unos cuantos. Este es un
curso que hace 10 años, si no me equivoco, estamos dando, que se ha venido afianzando y que lo que
intenta presentar son los fundamentos de lo que se llama Procesamiento del Inguaje Natural,
que es esencialmente cómo procesar con computadoras de una forma más o menos eficiente en el lenguaje.
En la clase de hoy la idea es presentar un poquito en qué consiste el curso y
dar una introducción general. Y bueno, en la sucesiva clase lo que vamos a tratar de recorrer es
todos los temas o los grandes temas del Procesamiento del Inguaje Natural. El Procesamiento del
Inguaje Natural van a ver que es una cosa que tiene muchas etapas y en cada una de ellas se
puede profundizar mucho. La idea de este curso, como su nombre lo indica, es un curso de introducción,
es un curso, a mí me gusta decir que es un curso más largo que profundo, digamos. O sea,
tratamos de cubrir los temas principales y los algoritmos y métodos principales,
pero teniendo claro y presente que en cada prácticamente todos los temas que nosotros tocamos
puede profundizar muchísimo. La idea del curso es generar, proveerlos a ustedes de un set de,
primero, de los conocimientos básicos que se necesitan del dominio, es decir, la semana que
viene con lo iban a tener un par de clases, la que llamamos volver al liceo, digamos, español,
digamos, para entender el dominio del que estamos hablando. Y luego un conjunto de herramientas
y métodos tradicionales tratando de tener una visión transversal de métodos porque hay métodos que
van a ver que se repiten. Un poco ese es el objetivo. Barraquemos con un poco de los datos
del curso. Los docentes somos Luis Chiruso, que está por acá delante, y Yacín Ceballo,
que se suma este año y que va a encargarse el laboratorio y quien se habla. El horario es
los martes en el salón 306, donde estábamos viendo, a ver si entramos, y los jueves en este
salón 301 de 20 a 22 horas. Si les parece que el horario no es el mejor, piensen que la primera
edición del curso era este horario, pero en el salón segundo subsuelo hace un frío horrible,
o sea, le sientan se afortunados de estar acá. Este es el correo para los docentes del grupo.
Esta es la página web, pero en realidad la página web lo que tiene son los datos
fijos y lo que da ahí nos vamos a esa eba inmediatamente, que es donde vamos a gestionar toda la
información del curso. Vamos a tratar de que todo el vínculo del curso se haga a través de
eba publicación, entrega, mensaje, bla, bla. ¿De acuerdo? Si usted se halla alguna duda me interrumbe,
porque yo no suelo parar. Bueno, la modalidad del curso es, tratamos de que sea un curso
participativo, eso van a ver que tiene que ver también con cómo evaluamos, pero un poco,
el objetivo del curso es ese que yo le decía, de presentar el Procesamiento de Baja Natural,
pero uno de los objetivos adicionales, para nosotros es muy importante tratar de que este
curso sea una especie de introducción a la investigación. También se ha estado como
posgrado, donde esencialmente la diferencia con los cursos tradicionales de grado se podría
decir que acá vale, que haya preguntas sin respuestas o preguntas que queden planteadas o cosas que
podemos decir no sabemos cómo se hace, que no hay una receta. ¿De acuerdo? Entonces un poco tratar
de transmitir eso que es lo que pasa siempre cuando uno investiga, si se encuentra con cosas que no
sabe cómo hacerla, que no tiene un docente que sabe todo que le va a decir, entonces hace de esta forma.
Un poco introducirlos en ese... las clases van a ser teóricos prácticas,
vamos a hacer presentaciones y vamos a mostrar los principales algoritmos y vamos a poner
algunos prácticos que nunca nadie los hace, pero bueno, cada cual, los que lo hacen los además.
Y además vamos a estar en Open Film a partir de este año, quiero agradecerles
especialmente a los amigos de Open Film, van a poder ver desde su casa, yo igual les recomiendo
que vengan, venir en realidad no les va a cambiar nada desde el punto de vista de los temas del curso,
porque vamos a publicar todo y las clases van a estar filmadas, pero yo creo que está bueno en
y porque hay cosas que se transmiten mano a mano que sirven, pero es una decisión de ustedes.
Tartaremos a hacerlo tan entretenido como se pueda como para que no quede solo acá.
Y la evaluación del curso va a ser, por un lado, un proyecto que va a ser el 35% de los puntos,
es un trabajo que está presentando más o menos en septiembre, una cosa así.
Algunos años hemos hecho dos en tres, una todavía no sabemos bien cómo va a ser,
pero es un trabajo que implica una tarea proxima y que trata de aproximar algo que
no se ve en el teórico, que es herramientas, es decir, cómo, qué pasa en el mundo real,
cómo lo aplicamos bibliotecas, cosas de esas y obtener resultados. Una tarea cómo se resuelve.
El año pasado, el año pasado fue, por ejemplo, para que le dimos un Corpus,
un conjunto de críticas de películas, y tratábamos de hacer un clasificador que
predijera a partir del texto si la crítica era positiva o negativa. Es un poco el tipo de tareas
que se hace. Eso se llama sentimentanálisis y está bastante de modo.
Después también, y para nosotros, tiene que ver con eso que le decíamos del objetivo de la
investigación, la idea es que ustedes en grupo van a tener que ir pensando en un grupo de A3,
en grupo presenten un artículo científico, vamos a poner una lista de artículos, ¿de acuerdo?
Y ustedes van a tener que leerlo, tratar de entenderlo y exponerlo a los demás.
Eso es lo que uno hace esencialmente en una conferencia, lo hace generalmente con artículos
propios, ¿no? Y otro grupo, la idea es que critique ese artículo, no con el ánimo de hacer
los estudiantes que lo presentaron pierda, sino con el ánimo de obtener más conocimiento,
que es lo que sucede en las conferencias. Entonces un poco viene por ahí, es decir,
tanto el que presenta como el que lo critica, tratan de entender y general conocimiento para
todos los demás. Y ahí como yo les decía, vale decir, esto no lo entendí, no vale leerlo una vez
si no lo entendí, hay que buscar referencia en otros lados, porque ahí habla de cosas que uno
necesita en background, bueno informarse, armar ese paquetito y hacer una presentación.
Bueno, ahí perdón. Eso se lleva el 25% de los puntos y luego hay al final una prueba
individual escrita que es el 40% pero que tiene un mínimo del 60%. Nada en este curso está
pensado para que sea horrible y difícil porque al ser un curso que tiene muchos temas, pedirle
como les decía profundizar en un tema sería muy amplio, digamos, ¿no? Dejan demasiados temas
o para yo pedirle que sepan un montón de cada uno. Entonces la prueba generalmente lo que valúa es
si ustedes conocen los principales algoritmos que se presentan en el curso, algunas preguntas
teóricas, ¿sí? Pero no está pensada para que sea muy difícil, digamos, ¿no? Porque hay otras
instancias de evaluación, quiero decir, no está todo concentrado ahí. Pero si es parte de la
aprobación integral del curso, ¿qué quiere decir? Que si alguien no prueba hasta prueba,
no prueba todo el curso. Generalmente no, ponemos dos instancias, una va a ser a fin de año y otra
en febrero, ¿sí? Donde cada uno puede presentarse a cualquiera de las dos, ¿sí? Se presenta la
primera y si la pierde, se presenta la segunda o se presenta derecho a la segunda, etcétera. Si se
presenta la primera y salva no puede presentarse la segunda. Bueno, pues gente que puede querer subir
las notas no se puede, una cosa rara. ¿Alguna duda del funcionamiento? No, una duda. Bueno, el curso
tiene esas áreas que dice ahí, vamos a ver un poquito detalle hoy en general, vamos a repasarlo,
es un curso que aunque el procesamiento de lenguaje natural, como seguramente le hicieron en cualquier
diario que se precie de moderno, ha tenido un desarrollo, no? Ormelo el último año, no sé qué.
Este temario no ha cambiado tanto porque yo lo que quería mostrar es que los fundamentos
vienen como muchas cosas, de hace mucho tiempo atrás y lo que ha modificado son los métodos y
bueno eso vamos a hablar en el curso. Como ven son unos cuantos temas. El libro del curso es este,
Speech and Language Processing, An Introduction to Natural Language Processing, Computation
and Linguistics and Speed Recognition, de Martin Yurafki. Este libro está por salir en su tercera
edición. El libro cubre una cantidad de cosas de temas más que en este curso no se ven y es un
libro muy recomendable y además, idealmente ustedes deberían leer los capítulos, después de
cada tema nosotros presentamos los capítulos correspondientes del libro que se pueden en lo
que está basado en la clase y ustedes deberían leerlo y saberlo, cosa que nadie hace, pero yo
tengo la obligación de recomendarlo y me parece que es realmente bueno para entender bien de qué se
trata. Y bueno y esto es este es el libro de NLTK que es la herramienta, la biblioteca que vamos a
usar para una de las bibliotecas que vamos a usar para la parte práctica, para la parte laboratorio
y esto está más orientado a la implementación. NLTK es una biblioteca en Python
pensada principalmente para enseñar, pero muchas veces se usa en producción también,
evolucionó mucho. La plataforma de software que vamos a usar es Python y NLTK,
no les voy a preguntar porque ya se va a tener que arreglar, no sé cuánto saben Python pero los que
no saben van a tener que aprender y van a estar fascinados y en NLTK la biblioteca. Freelink es
una herramienta especialmente para el procesamiento del idioma español, en estas cosas hay muchas
herramientas que dependen un poco del idioma, si bien eso vamos a ver que ha cambiado en los últimos
años porque los métodos estadísticos son menos idiomas dependientes, pero de todos modos no es
lo mismo parciar para español que para el inglés y menos para el chino. Freelink es una
herramienta pensada para el español. El laboratorio se va a entregar en como no hubo de
iPython, ¿conocen iPython, alguien conoce? Es una forma de distribuir y ya lo van a ver,
mezclar código y documentos, es como un documento que tiene un motor de programación atrás,
entonces uno puede mostrar el código y explicarlo arriba en el mismo documento.
Y Scikit Learn que es una herramienta de aprendizaje automático genérica,
esto es lo que se pide saber, formalismo de estado finito, teoría del lenguaje,
gramática formal, teoría del lenguaje, lógica de predicado como 14 materias, por lo menos lógica,
un poco de probabilidad estadística, si bien vamos a revisar porque generalmente
uno se olvida de probabilidad estadística en la carrera y nosotros se lo tratamos de recordar
y bueno obviamente un poco de programación. Alguien que lo esté tomando como parado que
no sea de ingeniería, de lingüística, bueno muy bien, siempre está bueno tener gente de
lingüística y tengo que cuidarme con las cosas que digo, intercambiaremos chistes con la lingüista,
intercambiaremos, dije, entonces hay una gran discusión en todo esto del pasamiento del
lenguaje natural, ya vamos a hablar de eso, ahora vamos a hablar de todo, capaz que para el caso tuyo
podemos adaptar un poco la tarea por el tema de la programación y demás, no hay problema, lo hablamos.
Eso me faltó decir, los estudiantes por grado además de hacer el laboratorio,
además de aprobar el curso quiero decir van a tener que hacer una prueba, un trabajo especial
para obtener los créditos por grado, ese es un reglimiento sólo para los estudiantes por grado.
¿Alguna duda está acá? No, una duda, me faltó algo, no, ese es el curso,
entonces como no hay duda vamos a arrancar con la clase,
esto no necesito que cerrarlo, voy a perder todo.
Generalmente las clases duran una hora y media más o menos, no, nunca uso dos horas,
pero tampoco doy pausa porque si no, una hora y media y a veces se va un poquito más largo,
pero no mucho más. No, mentira, a veces dura como dos horas, pero tal.
Bueno, arranquemos con una introducción, esta primera clase lo que trata de mostrar es la Big
Picture, digamos, decir qué es todo lo que hay en el pensamiento del lenguaje natural.
Y bueno, vamos a empezar por responder qué es.
El pensamiento del lenguaje natural es un conjunto de métodos y técnicas
eficientes desde un punto de vista computacional para la comprensión y la generación del lenguaje
natural. Acá tenemos varias cosas interesantes para mencionar, uno de los eficientes desde un punto
de vista computacional, el pensamiento del lenguaje natural está pensado como una
rama ingenieril y eso es lo que lo diferencia de la lingüística computacional, la lingüística
computacional es la que estudia toda la teoría del lenguaje, de cómo se produce,
de cómo se generan, de los esquemas, pero esto es algo que busca ser eficiente desde el punto
de vista computacional. El objetivo es para que lo aplique una computadora, para que se resuelva de
forma eficiente. Y hay dos grandes vertientes en el pensamiento del lenguaje natural que son la
comprensión y la generación. O sea, una cosa es tratar de entender cuando alguien me habla y otra
cosa es generar. El general para una, bueno el general depende de la tarea, es, no depende de la tarea,
fue más fácil de la doyba decir pero no iba a decir algo está mal, son dos tareas diferentes,
una es entender, descifrar la señal, ahora vamos a la etapa y entenderla y otra es generar
lenguaje, generar el cosa de mi papayón. ¿Qué quiere decir comprender al lenguaje? ¿Qué
interpretan ustedes como comprender al lenguaje? ¿Qué quiere decir una computadora comprenda al lenguaje?
Es una pregunta muy difícil y muy debatida digamos ¿no? Porque una de las teorías es
poder responder preguntas sobre eso, es una forma de ver si se comprende pero algo que
memorizar a mucho texto y que respondiera, no sabemos si está comprendiendo pero capaz que
responde bien. Hay un, en 1950, por ahí debería saberlo esto, Alan Turing escribió un paper que
habla, que sencillamente creaba la inteligencia artificial, de alguna forma, que se preguntaba
si las máquinas pueden pensar y proponía lo que se llama el test de Turing, que es, si yo no veo
con quién estoy hablando y una computadora logra hacer que yo ser humano, crea que estoy hablando
con un humano, tendremos en ese, habrá pasado el test de Turing y podríamos estar hablando de
inteligencia artificial, ¿de acuerdo? Es como la definición que proponía Turing de inteligencia
artificial o de qué quiere decir que una máquina piense. Por lo tanto, muchas veces se dice que
el lenguaje natural, que resolver el problema del lenguaje natural, no hay ni más ni menos que
resolver el problema de la inteligencia artificial o que es inteligencia artificial completo, ¿verdad?
Eso, sobre eso hoy en día hay algunas variantes, siempre ha habido algunas variantes, porque con
la gran capacidad de cómputo que tenemos y la gran cantidad de datos, podríamos llegar a ser algo
parecido, si bien los concursos que tratan, hay un concurso que hace todos los años que trata
de jugar al test de Turing, y estamos lejos, lejos, lejos, pero además, pero lo que ha sucedido en
los últimos años, que hay que una cantidad de tareas específicas que se ha disparado el
funcionamiento, por ejemplo, la traducción automática, ahora hemos hablado un poquito,
se ha disparado, pero gente dice, bueno, si todo bien, pero esto se ha dicho en base a number
crunching, digamos, a mucho procesamiento y a mucho dato, pero en realidad no entendemos,
hay un conjunto de preguntas, ahora se me escapa el nombre, pero que son un conjunto de preguntas
que para un ser humano son muy sencillas, ahora vamos a ver, y las computadoras siguen
siendo muy difíciles de resolver, ahora después vamos a volver sobre este tipo de preguntas,
había un alfajor sobre la barropa, vino Luis y se lo comió, ¿se comió la barropa o el alfajor?
Esa es una pregunta fácil para un ser humano y para una computadora es bastante complicada,
todavía está más lejos que eso, ¿de acuerdo? Es decir, pregunta que para nosotros son muy sencillas,
pero que exigen algún tipo de comprensión que la computadora memorizándonos alcanza,
sin embargo, por otro lado, están lo que dice, pero en cualquier tarea que vos me pongas en la
mejora en los últimos 20 años ha sido impresionante, ahí donde discutimos, por ejemplo, con las
computadoras, el PN no es igual a la lingüística computacional porque la lingüística computacional
es una cosa mucho más rica, es como la combinación entre la lingüística y la computación involucra
el estudio científico del lenguaje, en general, lingüístas, informáticos, lógicos, psicólogos,
cognitivos, es como la gran tarea, el PN puede verse como la rama ingenieril de la lingüística
computacional. Si yo me llevo a caer de esta tarima, editan la ícola. Bueno, vamos a ver si podemos,
si nos anda el audio, nos anda muy fuerte.
Si.
Estaba a que se escucha horrible de abajo, no?
Pero no creo queaire.
Ni gusto siempre tiene la sorpresa, por
Oh, ¿qué tal? ¿Te lo escuchas?
¿Quién te lo escuchas, ¿qué tal?
Afirmación, Dave.
Te lo escucho.
Abre las puertas de la puerta del podre, ¿qué tal?
Me siento, Dave.
Estoy afortunado de que no puedo hacer eso.
¿Qué es el problema?
Creo que sabes lo que es el problema, solo como yo.
¿Qué estás hablando de, ¿qué tal?
Esta misión es muy importante para mí, para que te permitas jeopardizarla.
No sé lo que estás hablando de, ¿qué tal?
Sabía que tu y Frank estaban intentando desconectarme.
Y estoy afortunado de que eso es algo que no puedo hacer.
¿Alguien conocen, yo ante la mano lo que conocen el quiseto?
No sé si son menos.
Esto es el espacio.
Y esencialmente para los que no escucharon.
Hay una computadora, que es la que maneja la nave.
Se llama HAL, HAL 9000.
Por cuestiones, bueno, por cuestiones de la trama, digamos,
le está pidiendo el astronauta que le abra la puerta
y amablemente la computadora le dice que no lo abrí porque la quiere conectar.
HAL 9000 viene a ser como...
HAL 9000 viene a ser como el...
...el ejemplo de una computadora que es capaz de procesar completamente el lenguaje natural.
Y si nos ponemos un poco de atención, ¿qué son las cosas que HAL puede hacer?
Para empezar, puede es capaz de...
...comprender a los humanos.
¿De acuerdo? Es capaz de reconocer el habla.
Porque el muchacho le habla y la computadora, por supuesto, lo escucha.
Pero no solo escucha que está hablando, sino que transforma esa señal en algo
y comprende lo que le dicen.
Es decir, lo decodifica de forma de poder entender lo que le dicen.
Pero, además, es capaz de generar lenguaje,
es capaz de hablar, de generar...
A partir de su modelo, genera algo que quiere decir y emitirlo.
Hoy en día, las computadoras más o menos hacen eso.
Hace 10 años, cuando empezamos este curso, las computadoras más o menos no hacían eso.
Hacían un poco de esto.
En el caso de que hablaban así, más de eso nos podíamos pillar.
Hoy tenemos a él esto.
Sí, y todo eso que se supone que entienden.
Todavía no entienden mucho.
Todavía sigue siendo bastante divertido hablar con ella.
Pero la reman, digamos.
En esa época ni la remaban.
Tenías que hablarle justo en el lenguaje.
Hablarle con tu voz.
Jal no tiene problema porque le habla normal y Jal le contesta normal.
Normal, digamos, igual que nosotros.
Y si se ponen a pensar, Jal es indistinguible de un ser humano, digamos.
Salvo por la voz que es un poquito metálica para ser de un ser humano, después...
pasa, ¿no?
Y que yo creo que le pone el metálico para dejarlo un poco computadora.
Vamos a pasarse para el otro lado.
Entonces, puedes reconocer y generar.
Es decir, ir en una señal sonora o una secuencia palabra.
Entonces, ¿qué tiene que saber Jal?
Tiene que saber de fonética.
O sea, de la naturaleza física de los sonidos.
De cómo se...
el sonido de las ondas y cómo se decodifican, etc.
Todas esas cosas que yo no sé.
Pero también de fonología.
Es decir, ¿cómo los sonidos funcionan en una lengua, en particular en el inglés?
Esa serie de ruidos, como transforman en...
que fonemas simbolizan, etc., ¿no?
Y con qué letras yo puedo representar esos fonemas.
¿Y a qué palabra se mapean?
Ve a hablar.
Eso es más, fonología.
Pero además, Jal tiene que saber que los sustantivos tienen género y número.
¿Tá?
Y que casa no es el femenino de caso.
¿Sí?
Si bien perra es el femenino de perro y perros y perras, ¿no?
Y que además no se dice luces.
Y tampoco se dice luces con zeta, sino que se dice luces con c.
Sin más no recuerdo.
¿Tá?
Pero también tiene que saber, Jal, que uno agregándole prefijos y sufijos a las palabras.
Todo esto si Jal habla en español, ¿no?
Este...
Puede formar palabras nuevas y que de creíble puede sacar increíble.
También tiene que saber que de perro no puede sacar imperro.
Y que mente transforma un adjetivo en un adverbio,
porque calma se transforma incalmadamente con alguna que otra modificación.
¿Sí?
Pero que tampoco podemos ponerse lo cualquier cosa, porque no podemos decir azulmente.
Bueno, sí, sí somos poetas, pero es como otra rama.
O sea que tiene que saber de morfología,
haber el estudio de la estructura interna en las palabras,
como las palabras se aman adentro.
También tiene que saber que las palabras,
uno las tiene que emitir en el sentido correcto,
porque no es lo mismo decir,
Dave lo siento que no puedo hacerlo metemo,
que lo puedo Dave y siento que no metemos...
No, no funcionan.
Son las mismas palabras, pero si las desordeno, no.
O sea que tienen que saber de sintaxis,
del estudio de la estructuración de las palabras
en unidades mayores.
Vamos a hablar de esto.
Claro que vamos a hablar.
Pero ustedes fíjense que...
Si yo digo abre las compuertas hall,
¿sí?
Es lo mismo desde el punto de vista de la estructura de la oración,
o sea un verbo conjugado, más un artículo,
un sustantivo,
un signo de puntación y otro sustantivo,
ya saca los dados hall.
O baja las persianas hall,
lo cual...
No tiene sentido,
porque nosotros tenemos que entender el significado
de las cosas.
Yo puedo armar oraciones perfectamente,
sintáticamente validas,
pero digamos frutas.
Eso es el significado de cada palabra,
y que a cada dado no aplica mucho a una situación
en la cual uno está en el espacio
tratando de que una máquina le abra una puerta.
Eso llama semántica eléxica.
¿Qué quiere decir cada palabra?
Y hay una cantidad de problemas ahí también.
Bueno, todos hay problemas.
Pero también, ¿cómo combinamos
las palabras para obtener significados mayores
que eso es semántica composicional?
Todas esas cosas que Luis sabe y yo no.
Yo me quedo por acá,
más o menos, en mi conocimiento, da mentira.
Este...
Pero, no sólo eso,
sino que...
Y esto me encanta,
cuando él le dice,
la frase más famosa es
I'm sorry, Dave, I'm afraid I cannot do that.
Lo siento, Dave,
me temo que no puedo hacerlo.
Está siendo educada,
pero además está siendo ligeramente irónica.
En realidad, no lo sientes,
y sí puede abrir la comporta.
Literalmente, puede abrir la comporta.
No puedo ponerlo.
Eso se llama
pranmática, es decir, el modo en el que el contexto
influye en la interpretación de lo que estamos diciendo.
El ejemplo más claro de necesidad de la pranmática
y difícil de resolver es la ironía o el sarcasm.
O sea, te temprano, estamos en hora.
Y el discurso,
es uno de las unidades mayores a la oración,
es decir, ¿cómo pegamos una oración con la otra?
Cuando digo, había una alfajora arriba de la barropa,
vino Luis y lo comió,
lo refiere
a la alfajora.
Eso se llama
anáfora.
Resolvé anáforas.
Se tiene que ver con el discurso.
Bien,
eso es un poco la cosa que tiene que saber, Hal.
Y eso es un poco lo que define
las cosas que tiene que estudiar el procesamiento de la hoja natural.
Ahí están todas
resumidas.
Acá hay miles de variantes
y esto es
recuerde lo que les digo de este curso.
Es un curso que trata de cubrir las generalidades
porque generalmente lo que sucede
después que se mezclan
este
hay un artículo que le gusta mucho a Luis que dice
yo puedo hacer todo esto con un solo modelo.
Pero
sí es importante para entender
qué implica
verdad, y ese es el enfoque que vemos acá.
Bueno, un poquito de historia del procesamiento de la hoja natural.
El procesamiento de la hoja natural
arranca
a fines de los años 40 y los años 50
y en particular
del ruso al inglés
por razones que son bastante obvias
de la guerra fría.
La guerra ha sido
un gran
como decir
promotor o catalizador de la ciencia
más que nos pese.
Y en el caso del procesamiento de la hoja natural no es la excepción
ni no por nada era
la DARPA
que movía estas cosas y ponía en funda estas cosas.
En particular del ruso al inglés
la tarea más vieja del procesamiento de la hoja natural
es la traducción automática
y es una
de las
que peor nos ha ido
si bien en los últimos años
hemos regalado muchísimo.
No anduvo esto.
No anduvo
el original, este es un chiste
en realidad dicen que
the spirit is willing but the flesh is weak
lo traducían al ruso, lo volvían a traducir
y el ruso le daba
el vodka y se estronga
the meat is rotten.
¿Verdad?
Yo el otro día lo probé
con los hijos que no lo puse
no, lo probé
y los invito a que lo hagan andar mucho mejor
que el
y eso hizo
y eso hizo que
la traducción automática
y el procesamiento de la hoja natural cacera
en uno de sus primeros inviernos
la inteligencia artificial ha tenido
a lo largo de la historia
varios inviernos, digamos
si ustedes leen sobre los inviernos
la inteligencia artificial en Wikipedia está muy interesante
y se genera una expectativa
muy grande con algo
que amenaza con resolver
todos los problemas del lenguaje
no anda
y se termina el funding
y nadie más investiga
esto pasó muchas veces
y hay quienes tienen miedo de que esté pasando ahora
estamos poniendo tanta expectativa
la inteligencia artificial y el campeón mundial de Go
y que toque el otro
que vuelva con la decepción
vuelva a caer, yo creo que no
pero es una opinión
acá lo que pasó fue eso
que se cayó porque arracar una tarea demasiado difícil
y tal, no funcionó
hay unos nombres
para recordar, a mí me parece que
podríamos
resumir
muy groseramente
el conocimiento que tengo yo
porque hay muchísimas ramas
en el procesamiento lenguaje natural
a lo largo de la historia
y su mezcla con la inteligencia artificial
y el aprendizaje automático
pero nombres grandes grandes
y cómo la historia lo afectó
yo les invito a que lean las biografías
de estas personas que están acá
porque son muy interesantes
y particular por supuesto la de Alan Turing
que supongo que ustedes saben quién fue
fue el que
eh
el que
no sé si decir
este
inventó, descubrió
modelo, la computación
como hoy la conocemos, no fue el único por supuesto
pero
fue el que me entró la máquina de Turing, caramba
entonces que es nuestro modelo teórico
de computadora más popular
pero además Alan Turing en ese artículo que yo le decía
sentó las bases de la inteligencia artificial
en ese sentido
por eso, y porque vale mucho la pena
leer la biografía de Alan Turing
y le puse acá
no mataron a Alan Turing
Noam Chomsky
es este
un lingüista
muy muy importante
además de ser muy muy polémico
como ustedes sabrán
eh
el gran aporte
de Noam, de Chomsky
desde el punto de vista
del procedimiento del lenguaje natural
en medio de otro montón
de cosas que aportó
fue el de, como si recuerdan
la jerarquía de los lenguajes
decir de cómo los lenguajes
formales se agrupaban
y además de una cantidad
de influencias positivas en los vínculos
entre la lingüística y la computación
también es el responsable
hay que decirlo
de alguna serie de malentendidos
de afirmaciones
que hicieron que se frenara la investigación
en el procedimiento del lenguaje natural
da la enorme influencia que tenía Chomsky en su momento
ahora vamos a mencionar alguna
o lo podemos mencionar ahora
el Chomsky decía
cosas como el procedimiento estadístico
no se me ocurre ninguna aplicación útil
no se me ocurre ninguna
noción
útil de probabilidad de una oración
y con eso frenó
por 30 años
en estudio
de los métodos estadísticos
del procedimiento del lenguaje natural
es el problema que tienen las personas
muy influyentes, por eso yo siempre recomiendo
que crean a la gente muy influyente
pero no tanto
por ejemplo
a Tim Berners-Lee
por allá por los 90 apareció
Freddy Schelinneck
que fue el que dijo yo quiero reactivar
todo esto
está claro que son
hitos
la ciencia no avanza
así por grandes inventores
no quiero que queden con esa idea
son como símbolos
Schelinneck
en IBM en los años 90
retomó el estudio de los métodos
estadísticos
hay una frase
muy infame atribuida
de Schelinneck
cada vez que he hecho un lingüista
mi performa mejora
todo era en este tipo
yo puedo
con métodos numéricos
o haciendo cuentas o contando
sustituir la tarea de los lingüistas
en reconocer
porque la mayoría de los métodos
del lenguaje
hasta ese momento eran orientados a reglas
es decir, venía un lingüista
trataba de ver cuáles eran las reglas del lenguaje
cuáles eran las reglas
para formar oraciones
cuáles eran las reglas para grupar palabras
y un programador
programaba esas reglas
dicho esto muy groseramente
Schelinneck y los métodos estadísticos
lo que dicen es yo puedo aprender de corpus
vamos a ver esto en el curso obviamente
yo puedo aprender de corpus
inferir
esas reglas automáticamente
que son las reglas de los lingüistas
esa relación
amor y odio entre los lingüistas
y los
de la ciencia y la computación
computer scientists
ha tenido muchas ida y venida
a lo largo del tiempo y siempre está
esa ida y vuelta
yo creo que se está
convergiendo a decir bueno en realidad
y hay algunos artículos muy recientes
de Manning por ejemplo que habla del tema
hay uno que se llamaba
bring the linguist back
porque lo que pasa con los métodos estadísticos
que llegan hasta un cierto punto
y ahí
una parte que no la puede
inferir de los datos
todo eso está muy en discusión y siempre está en discusión
pero
por lo menos hasta ahora
el trabajo
interdisciplinario
sigue siendo lo mejor que tenemos
y los métodos híbridos también
por allá por los
esto pasó en los 90
por allá por
la década del 2000
la década del 90 son las de los métodos genativos
y la de
Vladimir Van Nick
es un señor que
modeló
diseñó no sé qué palabras se usa
modeló
propuso primero el modelo de la support vector machines
que es un método
de
un método discriminativo de poder mover
de clasificación a separar cosas
esencialmente uno le da puntos y lo separa
vamos a hablar de eso
Van Nick lo inventó hace un montón de años
a eso pero en principio
estos tipos de métodos se pusieron de moda
en el procesamiento del lenguaje natural y se empezaron
a resolver todos los problemas con support vector machines
y últimamente
re-surgen
digo re-surgen porque esta gente venía
de los años 80 estudiando el tema de las redes neuronales
Hinton
Chef Hinton
Joshua Benchio y Jean Lecun
son todos
le dicen la canadien mafia porque estaban todos en canada
ubicados digamos algunos eran
Lecun creo que es alumno de Benchio
y Hinton está por ahí cerca
en otra universidad estaba
reactivaron
el tema de las redes neuronales
y
todo lo que hoy conocemos como deep learning
que es la nueva
ola del procesamiento del lenguaje natural
y ya hay gente
diciendo bueno basta
el paper que dice
vieron esta tarea bueno ahora la hago con redes neuronales
y anda mejor ya está
ya tuvimos suficiente volvamos a discutir sobre la teoría
estamos en ese nivel porque
todos pero la realidad
es que en todas las tareas principales
las redes neuronales
han tomado la
han mejorado la performance en algunos casos
muy significativamente
porque este tipo de métodos
re-surgen porque tenemos una
mucho mayor capacidad de computaciones
y mucha mayor cantidad de datos
grandes grandes
eso es un poco
la breve historia del procesamiento
del lenguaje natural yo les recomiendo que vayan
a wikipedia y ahí se pongan a leer
si les interesa
para entender un poco qué cosas han pasado
bueno
algunas tareas del procesamiento del lenguaje natural
fíjense
no se ve mucho la traducción automática
yo voy guardando el histórico de esta traducción
no se ve perdónerme
es la traducción que dice el campeón italiano aún no ha comenzado
pero en internet milan y juventud
los clubes más poderosos el cal ya están jugando un duelo
por la ambla
y acá es lo que va pasando a lo largo de
acá cada vez que doy el curso lo traduzco con el
translate
y no ha mejorado mucho
no son, me hubiera gustado tener en el 2010
una traducción un poco peor
digamos para poder compararse a mejorado
algo porque esto va bien
comete alguno error
fíjense que acá traduce
was chosen as the best player
porque acá se equivoca
in the war sudafrica no
was voted
acá usa voted en vez de chosen
y antes decía
in the war sudafrica
pero había una vez que le invocaba
es mejor
no se
no hay muchas variantes
pero el hecho es que así
sí ha ido mejorando en general en los últimos años
no está bueno el ejemplo disculpe
me da pero no puedo retroceder el tiempo
para cambiarlo
y ahora
esto es interesante
este título lo dejé por razones históricas porque estaba
en la primera
porque era tan malo que uno decía
para qué quiero traducir si es una cosa tan espantosa
hoy en día la pregunta ha cambiado
un poco porque traduce bastante bien
y podríamos llegar a decir
esto lo traduje yo
pasado así como sale
en otra época eso era impensable
porque en cualquier zapallo se da cuenta que eso no era
no era una traducción
pero de todos modos
es por qué me sirve
y bueno si yo le doy este texto
en chino mandarín
tener esto ayuda un poco
o sea que la traducción automática
no será perfecta pero es mucho mejor que
nada digo para ustedes que no saben
chino mandarín
hay otras tareas como
el resumen automático también
es una tarea muy vieja
los primeros trabajos son de lund
los años fines de los 50
que la idea central
es tratar de
condensar el contenido
de información de un documento para el beneficio de un lector
si me preguntan para mi
esta es la tarea
de las que yo conozco en la que estamos más lejos
en la que he visto menos progreso
porque es una tarea muy difícil
porque primero que nada es subjetivo
que quiere decir resumen
para
que tanto lo resumo
en que sentido lo resumo
es muy difícil de modelar
yo que lo ataré y por eso es en esto
que para mi gusto
hay poco para hacer
si uno prueba
Word y eso tienen resumidores automáticos
que son como espantosos
digamos
la extracción de información es
me das un texto
y trato de llenar una base de datos
es decir no
que donde tengo campos a completar
estaría muy
bastante fácil
bastante fácil
para llegar al 90%
de ahí para arriba está muy bien
interfaces a base de datos
esto tuvo de moda en una época últimamente no he escuchado mucho
que es
intentar
para un dominio acotado
hacer que el sistema
responda
bueno si existe
ahora que pienso siri es ese tipo cosa
donde
no está hay restaurantes
hay algún restaurant cerca
y la idea es que eso se traduce
internamente a algún tipo de consulta
da una base de
datos
y por supuesto se ejecuta
el enfoque funciona bastante bien
con lexico y sin estarse retrigido
yo creo que hoy en día podemos decir más que esto
más
recuperación de información
recuperación de información es google
da un término
que me trae a lo relevante
y la más relevante primero
verificadores de gramática
y estilo es otra cosa
a nivel comercial
categorizar documentos
que es
que me den un documento y medio esto habla
de tal cosa
toda la de fútbol esto habla de
responder preguntas
no sé si recuerdan que hace poco
hace poco no se si tampoco
la máquina esta
mwatson era que se llamaba
le ganó al chopper del campeón del mundo
otra vez no
ahí lo que estaba pasando principalmente era que tenía grandes bases
de datos
si se quiere era una tarea medio
restringida por más que parezca maravilloso
y que va que lo sea
pero era bastante restringida la cosa de buscar facts
y armar
no es tan fácil como yo lo digo pero era
a lo gruto que funcionaba principalmente watson
por eso cuando ponen ejemplo de
eso que llaman
inteligencia cognití o una cosa así
yo no la llevo mucho
más bien es number crunch
y en el grupo de procesamiento de lenguaje natural
por ejemplo este grupo nuestro
este curso lo da
el grupo de procesamiento de lenguaje natural
un conjunto de
entusiastas
investigadores
y estudiantes
relacionados
para que sea una idea
del tipo de cosas que se ve
por ejemplo nosotros tenemos este año un proyecto
que es extracción de eventos en la ciudad a partir de
medios escritos y redes sociales
descubrir que cosa pasaron
búsqueda de temas musicales
similares utilizando aprendizaje profundo
esto de buscar canciones parecidas
a esta
estudio de menciones a personalidades
públicas en twits
jugador de espectro
no esto es más bien machine learning
representación de palabras
en espacio de vectores esto se defendía hace poco
determinación
de la orientación semántica de las opiniones
transmitidas en eventos de prensa esto quiere decir
si una opinión fue positiva o negativa
se implementación
por tema de texto de prensa
cosas así de todo un poco
una de las cosas interesantes es que
en esta área todo lo que se hace
prácticamente
es open source
o sea que
todas las herramientas están disponibles
rápidamente
y el conocimiento general también
una de las cosas que para mí es muy importante
y que para nosotros es bastante normal
porque en otras áreas no existe
la
association for computational linguistics
que es la principal asociación
de todo esto
hace unos años atrás que todos sus contenidos
estaban libremente disponibles
entonces nunca hay una barrera
para
para leer un artículo de computational linguistics
porque estén en un journal pago o cosas así
como mucho timbón usamos digamos
porque no lo necesitamos
es muy positivo
¿por qué estoy acá?
perdón
eh
bueno pero
¿cómo estamos de ahora yo?
no sé ni de todo el celular
que tiene
¿qué tiene el lenguaje natural que no tiene los lenguajes formales?
o sea ¿ustedes hasta ahora han estudiado mucho el lenguaje formales?
de hecho todos los lenguajes que han estudiado
son formales
¿cuál es la gran diferencia
del lenguaje natural con los lenguajes formales?
alguna pregunta hasta acá
¿no?
si tienen dudas puedo resolverlo si están aburridos o no
¿qué tiene el lenguaje natural que no tiene los lenguajes formales?
¿cuál es el problema o los problemas
que enfrentamos para hacer esto?
¿por qué hay un área especial dedicada al lenguaje natural
y no podemos usar los métodos de parsi
ni análisis que hay
en
con los lenguajes formales?
padre, he mentido
te escucho hijo, dije que tenía 33 para el envío
y tenía 24
¿dónde está la gracia del chiste?
lo digo en serio
no lo digo así
¿dónde está la gracia?
¿por qué es un chiste?
porque es lo que dice ahí
¿cuál es el chiste?
es la misma mentira
no estamos hablando de la misma mentira
y también sabemos que cuando uno se confiesa
no confiesa ese tipo de mentira
porque es una mentira en el marco de un juego
y hay que entender que esa mentira
no es la misma la de arriba y la de abajo
el mismo tipo de mentira y ese contraste es lo que nos da
le recomiendo un
un proyecto agrado que tuvimos hace poco
que se llamaba reconocimiento de humor en tuit
que
habla bastante de estas cosas
buitres de la concagua
¿cuándo los volveré a ver?
rapaces bravos
con sus granidos voraces
me enseñaron a querer
le gustó Mendieta en un ataque de impiración
le compuse a Pacosquín
don Inodoro la próxima vez que lo ataque
la impiración no podría defenderse mejor
¿dónde está el chiste?
¿dónde está el chiste?
que la impiración no lo atacó
de hecho sí
que no es el mismo ataque
que estoy queriendo decir dos cosas diferentes con ataque
es más divertido entender y escuchar los que interpretarlo
un borracho dijo
si ayer fuese mañana hoy sería viernes
¿en qué día de la semana el borracho dijo esto?
seguramente lo recibieron por whatsapp hace unas
semanas atrás algunos de ustedes
bueno yo sí
¿qué día es hoy?
no me voy a poner a discutirlo acá con ustedes
se lo voy a dejar
de deber pero puede ser domingo
o miércoles
y es muy interesante este problema
porque lo que sucede
es que
cuando yo digo hay como dos
mundos a la vez
porque acá hay un fuese
si ayer fuese es un mundo
hipotético
si ayer fuese mañana
hoy sería viernes entonces ahí la ambigüedad
parece porque
ayer
y el hoy no sabemos en cuál de los dos mundos es
si en el hipotético
o en el mío
y no pueden ser en los dos en el mismo porque si no
no habría ambigüedad no habría duda
perdón sería inconsistente
acá lo que sucede es que hay dos mundos
introducidos por este si
y como el ayer y el hoy puede estar cruzados
según como yo lo interprete
voy a responder
o domingo miércoles, creo que era domingo miércoles
háganlo
las computadoras no están ni por asomo
cerca de entender esto
pero ni de lejos
tengo unos jueces andando a nosotros
tengo muchos amigos que todavía
me discuten
imagínense las computadoras
bueno tengo amigos hay computadoras
que le compro
y ahora por supuesto
a ver esto van a tener que otra vez
perdóneme este
abusar el oído
si yo me acerco con el micrófono se escucha acá
no tiene el mago lo más que es
de hecho no tiene
no lo tiene
Shakespeare da para todo
le digo porque yo conozco todo Shakespeare en inglés
no me digas
no lo he leído porque no sé inglés
pero lo conozco
y bueno el hotel es una tragedia
terrible
entonces no lo voy a ver
es una gran obra
hotel o el moro de venencia
que era negro
bueno no todos los moros
son héroes pero era negro
hay distintos tipos de moros
los moros del interior y los moros en la costa
hay moros
también los moros de los lugares
importantes los que son de morón
dangas
pero este era negro
moro chazo
curioso porque el nombre
otilo en realidad es un nombre
de origen irlandés
claro es hotel
ah tiene el
si tiene el apócrifo
que le ponen
mira si será irlandés porque
en irlandés antiguo
Telo quiere decir alojamiento
ah
y bueno ahí hoteló
una historia terrible que ya empieza
medio mal porque hotelo estaba
casado con Desdemona
que era una hermosa mujer
pero provenían de familias
enemigas los capuletos
y los montescos
y esto de alguna manera
lo vincula con las teorías de Darwin
y Desdemona se llama la mujer
porque el hombre desciende del mono
la mujer desdemona
y entonces
algún famoso que entró seguramente
bueno el asunto es que le estaba contando
resulta que
se habían casado igual
con la oposición de la familia
hasta que un día
hotelo va caminando por ahí
por las murallas del castillo
y se le aparece el fantasma
del padre
según el actor
para el asunto se le aparece el fantasma
del padre y le dice
pero el hotelo
pero el hotelo lo dice
papá que le quiere abrazar no puede porque es un ser estereo
es un espectro
un ser estereo hay fantasma mono
y fantasma estereo
y este es estereo
este es estereo
que también lo vincula con la teoría de Darwin
los fantasma mono
bueno
teorías discutidas
no todos estamos de acuerdo
bueno entonces resulta que
lo quiere abrazar no puede
y el padre le dice
hotelo vengo a decirte
que tu mujer te es infiel
es fantasma ese
y entonces se dice
no pero porque me decís eso
y desaparece
el espectro
claro se quedó sin señal
digamos hotelo
y se queda pensando
que el psicóloga que era un padre ausente
se fumó pero le dejó
trabajando la cabeza al pobre hotelo
iba a ir por volvolvió al palacio
y andaba por los salones
dudando decía
ser o no ser
yo no saber
y después cruzaba por ahí
por la noche en un cementerio
y encuentra la famosa calavera
era la calavera de un bufón de la corte
y agarra la calavera hotelo
la mira así
y si como lo va a mirar así, si siempre se mira así
es algo que se abisco
claro
a también cierta
eso también depende del actor
bueno la mira así dice
te noto desmejorado
y la calavera no le contesta nada
claro calavera no chilla
entonces
y se queda dudando
te lo dice que hago
y desdémona será
realmente culpable y a lo mejor es inocente
y que hago y yo por las dudas
la mato
y pobrecita desdémona
ajena todo estaba ahí en su dormitorio
mirando televisión
en venezia había televisión
no ve que la ciudad de los canales
y el mundo
quién es
bueno entonces
entra hotelo al dormitorio sigilosamente
ya no lo ve entre que está oscuro
y el negro
y va, y nomás va
y la estrangula ahí sobre el tala monupcial
En un árbol, en la estrangula, en un talamo, arriba del talamo o a la sombra al talamo.
Se suben al talamo.
Y si ella es mona, puede subir porque...
No, no me entendió.
Son altos algunos talamos, ¿eh?
Como 30 metros tienen.
Los que tengo en casa son...
Oja caduca, pierde la hoja en invierno.
Se queda así, noja, pobrecito, el talamo.
No, pero a ver cómo se lo explico.
No, no, desde mona está acostada sobre el lecho nupcial.
Ah, pusieron el lecho.
Por si se cae el talamo, están los el hechos, está bien.
Es una medida de seguridad porque el el hecho siempre es verde, está muelle.
Y si se cae el talamo, se puede matar.
Si la mata, no la puede estrangular.
Si no, poder puede, pero...
Pero una vez que está muerta, me dio.
Redundante, ¿no?
Una redundancia.
A ver.
¿Cómo que no?
No, estoy tratando de hacerme entender.
No es fácil, le diré.
Desde mona está acostada sobre...
¿La palabra cama la conoces?
Sí.
Sobre la cama.
Y ahí va a hotelo y la estrangula.
Quitaron los árboles.
Sí, quitaron los árboles.
¿Y los el hechos?
Uy, qué noche larga va a ser.
Los el hechos lo dejaron.
¿Los dejaron?
Sí.
Se hubo discusiones, debate público, la gente opinaba favor en cómoda.
Hasta que el director dejó hablar los el hechos, se quedan.
¿Por qué?
Porque lo importante es el hecho.
Bueno.
Bueno, además de...
de reírnos un poco y de acordarnos de...
perdón, de Rabinuch, que se murió.
¿Por qué...?
¿Por qué pasamos esto?
Es fácil para una computadora comprender esto.
No.
Y con qué juega todo el tiempo el elutier
y dicen que si esto no existiera sería muy difícil que hubiera humor.
¿Con la sinónima?
La sinónima.
Hacen la cantidad de cosas que tiene que ver con palabras que exactamente,
que son sinónimos.
O monimia, que suena parecida y...
y como alamo y talamo hace todo.
Pero lo importante es el hecho.
Pero también con palabras que...
que quieren decir algo literalmente,
pero que uno sabe que está refiriendo algo porque conocemos el mundo.
No voy a dar ejemplo porque le quita la gracia, digamos,
pero uno lo ve todo el tiempo.
Miren lo de vuelta o piensen lo de esta óptica de polvivencia,
porque si no uno no se divierte,
pero todo el tiempo usan ese tipo de métodos.
Fontanarrosa también, otro ejemplo muy claro de eso es fontanarrosa,
de Inodoro-Peraira en particular.
Por eso puse un par de ejemplos.
Todo el tiempo son juegos de palabras.
El cuarteto de nos también.
No voy a poner ningún ejemplo del cuarteto de nos,
porque la mayoría son irreproducibles,
pero hay un...
incluso llegaron a tener un ciclo que se llamaba este lo hablando hablando,
que se basaba todo en...
y lo que se llaman calembures, que son juegos de palabras.
Los calembures son, este...
bastante viejos.
Bueno, esto es la ambigüedad.
El gran problema de procedimiento de los colegios naturales
responde a nuestra pregunta es la ambigüedad.
La ambigüedad es diferentes niveles
que son un poco lo que hemos visto en los chistes.
La ambigüedad...
ambiguo quiere decir que admite distintas interpretaciones.
Empezamos, como decía, con la homonimia.
Dos palabras con la misma forma que tienen distinto significado.
Y ahí podemos distinguir la homografía,
o sea, que se escriben igual, capital,
la capital de un país,
verso del capital que tengo,
o banco.
Pero también pueden ser homófonas
para...
para sufrimiento de los escolares y algunos adultos.
Hola y hola, y hay un estudiante de ingeniería también.
As, as, coser y coser.
O sea,
hay gente que pone, en vez de o sea,
pone o sea contilde.
Hay gente, todo el tiempo.
Eso se llama la homofonía.
Elelutía juega mucho con la homofonía.
Que bella plebella, ¿no?
Polisemia es,
cuando hablamos de una palabra que tiene mucho significado,
y ahí lo dicen,
bueno, desde el mono es parecido,
pero el hombre desciende del mono
y el mono desciende del árbol.
Está claro que estamos hablando del mismo verbo
que se conjuga igual,
que en todo aspecto es igual,
pero que quiere decir diferentes cosas.
¿Cómo nos podemos dar cuenta de que,
de cuál de las dos es?
¿Cómo podemos desambiguar?
Por el contexto.
El contexto es una de nuestras grandes claves
para desambiguar en general.
Que bella plebella, dice Elelutía,
otro bastante conocido.
Pero esto es muy viejo, ¿no?
Garcilazo de la vega decía
que el dulce lamentar de los pastores,
que puede ser ver como el dulce lamentar de los pastores.
Y esta de Quevedo dice en la leyenda
que apostó que era capaz de decirle
a una reina, que no me acuerdo cuál era.
No me acuerdo.
Que era reina, digamos.
Entonces yo venimos a decirle a la reina,
que era de reina,
entonces va él y dice,
entre el clavele y la rosa,
su majestad escoja.
Y, bueno, Shakespeare,
en el primer verso
de Ricardo III,
dice,
acá hay todo un juego de palabras,
porque el símbolo del rey,
que era Eduardo,
Eduardo no me acuerdo,
era un sol y son juega.
Suenen igual, obviamente, en inglés.
Y eso permite armarte un juego
para ver qué se extiende, además.
Son canembures.
Pero también tenemos ambigüedad
a nivel morfológico.
Nosotros plantamos papas.
¿Ustedes qué opinan?
¿El loro plantar está conjugado
o pasado o en presente?
Puede ser cualquier lado.
No podemos hablarlo.
Si no tenemos contexto,
pero también,
este es el gran problema del parsing.
Se llama Pipí a Touchman.
Y es, Pedro vio a Juan con el telescopio.
Se puede interpretar perfectamente
como Pedro que vio con el telescopio a Juan,
usando el telescopio vio a Juan,
o que vio a Juan con el telescopio,
que el telescopio es Juan.
Esto es una frase proposicional
con el telescopio.
Y distinguir...
saber si con el telescopio
va con Juan o con Pedro
es como el gran problema del parsing.
Cuando hacemos parsing,
cuando tratamos de armar el árbol de parsing,
lo vamos a ver.
Esto es lo que fallan siempre los parsers.
Y este es otro ejemplo de manual
que falla el parsing.
Los hombres y las mujeres
que hayan cumplido 60 años
pueden solicitar una pensión.
Los hombres y las mujeres
que hayan cumplido 60 años
son los que pueden solicitar.
O los hombres
y además las mujeres
que hayan cumplido 60 años.
¿Cuál es la doble para ustedes?
¿Cuál es la doble para ustedes?
¿Eh?
¿Cuál?
Es la regla de eso
que hayan cumplido 60 años.
Sabemos que es la primera,
pero en realidad,
inmediatamente,
por eso no es la primera.
Puede ser la primera,
pero ¿y cuál apostarían ustedes que es?
¿Por qué?
No tengo contexto yo acá.
¿Por qué sabemos que es la primera?
Conocimiento del mundo.
¿Qué es como sentido común?
Conocemos el mundo.
Es decir,
conocemos la realidad.
Ese es el gran problema
que tiene la computadora.
Nosotros conocemos el mundo.
Es como Luis comiéndose
la barropa.
La perra de mi vecina me la adoró.
Tenemos dos posibilidades.
Mi vecina realmente tiene una perra
o yo no tengo buen trato
con mi vecina.
Esa es ambigüedad,
ese nivel semántica, ¿no?
También tenemos ambigüedad
de nivel pragmático.
Si yo digo, bueno,
¿a qué hora llegarás?
O la frase,
Llevo a las 8, esperame.
Vamos a hablar en uruguay.
¿A qué hora llegarás?
Llevo a las 8, esperame.
Eso es previsión.
Nunca llegarás en hora.
Llevo a las 8, esperame.
Eso me lo vas a tener que decir
cara a cara.
Llevo a las 8, esperame.
Dependiendo
de la situación,
uno la interpreta y yo es agero
con el sonido,
pero podría perfectamente
no hacerlo
y que solo el contexto
de la situación
me diera la respuesta.
Muchas veces el juego
de la ironía
también se basa en eso,
decirlo sin ninguna expresión
y que el otro interprete
que no se des cuenta
si es ironía o no.
Tenemos el caso de Luis.
Tomé el alfajor del escritorio
y lo comí.
Tomé el alfajor
que estaba en el escritorio
y me comí el alfajor
o tomé el alfajor
que estaba en el escritorio
y me comí el escritorio.
Nuevamente
ahora
y acá
hay otra cosa,
alternativamente
a entender
una de las formas
de darle significado
estas cosas
y entender el mundo,
asociar los objetos del mundo
y saber que los escritorios
no suelen comerse.
Eso es una aproximación.
Identificar las cosas
una por una
y decir a aquellas
que se pueden comer
por seres humanos
porque si estamos hablando
de una termita
pero
otra forma
es ver cuántas veces
si yo tengo mucho...
¿Por qué los datos cambiaron
todo esto del procedimiento
del gobierno natural?
Porque si yo tengo
muchos, muchos, muchos datos
puedo saber que
en mis datos,
en mis documentos anteriores
que ya tengo analizados
tengo que tener datos
y además alguien lo haya analizado
no se dio muchas veces
que alguien se comiera un escritorio
pero sí apareció varias veces
que alguien se comiera el fajor
entonces a mí
contando puedo arrimarme
es en eso que se basan los métodos
basados en conteo
métodos estadísticos, digamos
y acá ustedes pueden ver
aquello que yo decía
de los lingüistas o no
es decir, si yo logro entender
el significado de esto
y asociarlo y mapearlo
puedo interpretar perfectamente esto
pero es muy difícil
porque hay mucha casuística diferente
contando
yo me puedo arrimar bastante a esto
pero seguramente no voy a ser tan preciso
y además alguien me tiene
que interpretar muchas oraciones
ese es como el gran...
la gran dualidad de las reglas
versulas
verso el aprendizaje estadístico
digamos
o el aprendizaje automático
pero vamos a hablar mucho de eso en el curso
Juan mató al carpincho con la escopeta
obviamente no puede ser el carpincho
quien lleva la escopeta
¿por qué?
por conocimiento del mundo, ¿no?
puse la camisa en la lavadora
y la lavé
la, por supuesto, no me puse...
yo podría llegar a interpretar
que me puse a lavar la lavadora
pero...
no solo es raro
no es que sea tan raro lavar la lavadora
pero poner la camisa
y después ponerse a lavar la lavadora
es como...
yo tengo que saber
que las lavadoras lavan
y que la ropa se lava
y hacer esa asociación
o sea, requerimos conocimiento del mundo
bueno
entonces
resolver la ambigüedad
es como la gran tarea
¿y qué métodos utilizan?
hay muchos modelos basados
en máquinas de estado finito
automatas finitos, transmutores
automatas con peso
automatas
hay muchos sistemas de reglas
se usa lógica sobre todo
en la parte desengmática
para asociar significado
se trata de llevar a un modelo de predicado
modelos probabilísticas
sobre todo aquello que hacen conteo
modelos basados en redes neuronales
y esto lo agregue
este año que es representation learning
que es a partir de muchos atributos
es muy difícil explicar
si no explico algunos contextos
aprendizaje automático
que lo vamos a ver
a partir de, pero la idea es que
las features se generan sola
ya lo veremos
hay una batería de método
pero que curiosamente muchos se repiten
y los algoritmos en general son
o muchos son
o busquedas en espacio de estados
es decir, tengo una cantidad de opciones
y tengo que elegirla mejor
por ejemplo
tengo una serie de árboles de análisis sintácticos
¿saben lo que es un árbol de análisis sintácticos?
el árbol que modela una oración
como los árboles de parsing
pero para oración
buscar cuál es el más adecuado para la entrada
o hacer programación dinámica
vamos a ver varios ejemplos
programación dinámica en el curso
o aprendizaje automático
es decir, a partir de un corpus
yo infiero
conceptos
y luego los amplico
vamos a hablar de eso
y bueno
y eso cuando son que era
y media
no, todo bastante bien
no fue tan larga
esto por hoy
la semana que viene
bueno, alguna duda?
no, representation learning es
el lugar de yo definir
cuáles son las features
en vez de hacer feature extraction
la genera solo el algoritmo
el ejemplo de
el ejemplo de manual es
si yo tengo una imagen
le mando de traba todos los pixels
y la red neuronal
solita
identifica agrupaciones
o patterns
en la figura que le dice
bueno, acá hay una persona
o acá hay una nariz
digamos
pero no es explícito
la alternativa de eso
es yo de alguna forma
darle las features
es decir, acá hay una curva así
y otra curva esa
que no funcionaba muy bien en general
eso es representation learning
alguna duda?
no, hoy son todos conceptos
muy generales
no sé si les queda mucha duda
la clase que viene
Luis hace
volvemos al liceo
con este
ídomo a pañol
es muy importante
este par de clases
porque
son nuestros elementos de dominio
entonces después
cuando hablemos de un partospicho
cuando hablemos de
un grupo nominal
son los elementos
con lo que vamos a hablar
no queremos aplicarlo cada vez
así que nos vemos la semana que viene
por favor
por favor
