1
00:00:00,000 --> 00:00:04,600
Bueno, hoy vamos a ver este tema, la idea es que el otro día estuvieron viendo con Luis

2
00:00:04,600 --> 00:00:10,000
traducción automática, que es un problema súper clásico del área de PLN.

3
00:00:10,000 --> 00:00:14,800
Hoy vamos a ver otro problema, capaz que no está en clásico en el sentido de que no es

4
00:00:14,800 --> 00:00:19,400
lo que se estudia en PLN desde los origines, como era traducción.

5
00:00:19,400 --> 00:00:24,800
Pero así se volvió ahora como un tema súper, súper trabajado y no sólo es el PLN,

6
00:00:24,800 --> 00:00:32,280
hay como investigaciones sin otras áreas sobre todas áreas más sociales que están haciendo

7
00:00:32,280 --> 00:00:38,000
muchos trabajos de este tipo. Análisis de subjetividad, como tema general, y nos vamos a

8
00:00:38,000 --> 00:00:43,600
centrar mucho en análisis de sentimientos, que es como un problema un poquito más específico.

9
00:00:43,600 --> 00:00:51,320
Cuando hablamos de análisis de subjetividad, las cosas que se hacen en PLN son un poco

10
00:00:51,320 --> 00:01:01,200
todo esto que ven ahí, que es extraer de los textos, información bien subjetiva, que

11
00:01:01,200 --> 00:01:12,200
o sea no hechos, hechas, de nombres, no responder preguntas, o sea, es realmente un trabajo

12
00:01:12,200 --> 00:01:18,280
que tiene su dificultad porque es muy subjetivo y entonces es difícil van a una máquina también

13
00:01:18,280 --> 00:01:25,480
es difícil para un humano o para un conjunto de humanos estar del todo de acuerdo en, por

14
00:01:25,480 --> 00:01:32,000
ejemplo, si algo es, a lo que se está diciendo es positivo o es negativo o habla bien o habla

15
00:01:32,000 --> 00:01:37,040
mal, o de qué está hablando bien y sobre qué otra cosa está hablando mal, o sea algo

16
00:01:37,040 --> 00:01:44,360
es humor o no es humor, hay muchísima variabilidad, incluso en el juicio de los humanos en estas

17
00:01:44,360 --> 00:01:51,520
tareas que estamos mostrando acá, análisis de sentimientos como la que más se ha trabajado y

18
00:01:51,520 --> 00:01:56,200
es en la que nos vamos a detener bastante hoy, así que no la comiendo mucho ahora sigo

19
00:01:56,200 --> 00:02:01,880
del largo, porque vamos a hablar casi toda la clase de eso, análisis de emociones que

20
00:02:01,880 --> 00:02:06,960
está muy vinculada, análisis de sentimientos, pero es una tarea en donde se estudia a nivel

21
00:02:06,960 --> 00:02:15,520
bastante más fino, la presencia o el de emociones en los textos, alegría, tristeza

22
00:02:15,520 --> 00:02:24,280
de enojo, y ahora vamos a comentar un poquito más sobre esta, y como parte del análisis

23
00:02:24,280 --> 00:02:28,680
de sentimientos, solo que el nombre análisis de sentimientos se terminó usando para lo que

24
00:02:28,680 --> 00:02:34,680
es, más se hace que solamente decirse algo es positivo o negativo, entonces se le llama

25
00:02:34,680 --> 00:02:40,160
análisis de emociones, esto otro que es mucho más fino y como mucho más, con una granularidad

26
00:02:40,160 --> 00:02:46,160
mucho más fina el estudio que se hace de los textos, análisis de humor, esto un área

27
00:02:46,160 --> 00:02:54,840
también, ahí adentro hay típicamente clasificación, textos, decirse de un texto es humorístico

28
00:02:54,840 --> 00:03:00,000
o no, se trabaja bastante con tweets, en casi todo esto que está acá se trabaja mucho con tweets

29
00:03:00,000 --> 00:03:06,520
porque hasta hace muy poco de tiempo se podían descargar los tweets y trabajar con ellos,

30
00:03:06,520 --> 00:03:13,520
ahora te contendió que ya no, o sea que va a dejar de ser la red social más analizada,

31
00:03:13,520 --> 00:03:20,600
pero ya existen igual muchos corbús de tweets pensados, anotados, preparados para este tipo

32
00:03:20,600 --> 00:03:26,960
de tareas y muchas tareas más. Bueno, entonces clasificar tweets, por ejemplo, en esas

33
00:03:26,960 --> 00:03:32,800
dos categorías son humorísticos o no son humorísticos, o la intención es que sea humor o

34
00:03:32,800 --> 00:03:39,880
no hay una intención de que sea humor, también algunos trabajos en determinar qué tan gracioso

35
00:03:39,880 --> 00:03:47,440
es un chiste, una escala anóntre, es un un 5, por ejemplo, ser un 5, detectar también

36
00:03:47,440 --> 00:03:53,200
el mecanismo que se usó para expresar el humor, el humor se expresa de montón de maneras

37
00:03:53,200 --> 00:03:59,800
diferentes, por ejemplo, juegos de palabras, eso no ocurre ningún otro, pero bueno, como

38
00:03:59,800 --> 00:04:08,280
que la base, en qué se basa ese texto para generar un efecto humorístico, hay como unas

39
00:04:08,280 --> 00:04:15,680
categorías, muy estudiado en tema en realidad. El tema del chiste puse ahí, pero esa es lo

40
00:04:15,720 --> 00:04:22,360
5, como el objetivo, el target, es un humor que está dirigido hacia, no sé, personas

41
00:04:22,360 --> 00:04:33,520
ancianas, personas de otros países, a mujeres, no sé, ahí se mezcla muchísimo el tema del

42
00:04:33,520 --> 00:04:39,400
humor con el tema que viene después, que es el discurso de odio, el racismo, la misogínia,

43
00:04:39,400 --> 00:04:44,520
hay un montón de chistes que en realidad son muy ofensivos, el humor puede ser muy ofensivo

44
00:04:44,560 --> 00:04:51,880
y muy dilviaccionado a grupos particulares, eso también se estudia, dentro de todo el

45
00:04:51,880 --> 00:04:56,960
análisis de humor hay como unos dos mecanismos muy típicos que son la ironía y el sarcasmo

46
00:04:56,960 --> 00:05:03,160
que son muy difíciles detectar, se podrán imaginar, pero se estudia y trabajos desde esta

47
00:05:03,160 --> 00:05:08,960
área del peléneo para estudiar la ironía y el sarcasmo. Y bueno, un poco separado de

48
00:05:08,960 --> 00:05:14,120
el humor, detección de discurso de odio de cualquier tipo, a través del humor o a través

49
00:05:14,120 --> 00:05:22,040
de nada, mensaje discriminatorio directo que incluyen múltipo humor, este hay un montón

50
00:05:22,040 --> 00:05:28,800
por ahí, lo sabemos, racismo, misogínia, todo tipo de discriminación, eso se estudia

51
00:05:28,800 --> 00:05:36,120
mucho, bueno, se podrán imaginar el objetivo de todas estas tareas, la última clara, detectar

52
00:05:36,120 --> 00:05:42,320
este discurso de odio en redes sociales, por ejemplo, parece súper importante para prevenir

53
00:05:42,320 --> 00:05:50,440
cosas, sobre todo, para filtrar, para tratar de bloquear algunas cuentas quizás que se dedican

54
00:05:50,440 --> 00:05:58,000
a eso, detectar humor parece una tarea medio superficial, pero puede servir porque si yo estoy

55
00:05:58,000 --> 00:06:05,000
tratando de encontrar información, bueno, información verdadera, sobre hechos que sucedieron,

56
00:06:05,000 --> 00:06:12,120
yo que se sacaron de dejar un poco de lado, de despejar un poco los textos serios, por

57
00:06:12,120 --> 00:06:16,400
decirlo una manera de textos que en realidad capaz que transmiten ese tipo de información,

58
00:06:16,400 --> 00:06:22,820
pero en forma de humor sirve también es útil, no solo porque quiero encontrar chistes

59
00:06:22,820 --> 00:06:30,520
para raíz, sino porque también los quiero dejar de lado, y bueno, todo lo demás, sentimientos,

60
00:06:30,520 --> 00:06:36,560
se usan muchísimo para saber lo que opina la gente, que las tendencias, lo que por ejemplo

61
00:06:36,560 --> 00:06:42,680
lo uso una empresa para saber lo que opina la gente de sus productos, se usa en la prensa

62
00:06:42,680 --> 00:06:48,000
para saber lo que opina la gente sobre lo que está pasando, la evolución de la opinión

63
00:06:48,000 --> 00:06:53,840
de las personas sobre distintos hechos, sobre personalidades públicas, etcétera, ¿no?

64
00:06:53,840 --> 00:06:57,820
Es una de las consultaciones. Sí. Capacidad se lo tiene, pero en el Comuncio, es un

65
00:06:57,820 --> 00:07:07,720
quimiendo con esto, por lo que habéis entendido, era con medio estándar el uso de tuís con

66
00:07:07,720 --> 00:07:13,620
cuatro categorías, en qué porcentaje estamos en los que he estado de lado de esto.

67
00:07:13,620 --> 00:07:19,800
Galo, vamos a ver, al final, para así no te tiro un número que capaz que me esté aguardando

68
00:07:19,800 --> 00:07:26,560
mal, pero está acá en la presentación. Bueno, así que vamos a empezar, voy a comentar

69
00:07:26,560 --> 00:07:31,880
algunas cosas sobre análisis de emociones y después vamos a pasar análisis de sentimientos.

70
00:07:31,880 --> 00:07:36,160
Algo para comentarles sobre análisis de humor, que si les interesa, en nuestro grupo

71
00:07:36,160 --> 00:07:40,800
hemos trabajado bastante, trabajamos mucho en la primera, trabajamos bastante también

72
00:07:40,800 --> 00:07:46,680
en humor, también en el último detección de discurso de odio, o algún proyecto de

73
00:07:46,680 --> 00:07:52,320
lado de Juanjo, con otro compañero Matías, también hicimos algo de análisis de emociones

74
00:07:52,320 --> 00:07:57,680
con Luis, pero sobre todo análisis de sentimientos de humor hemos trabajado mucho en el grupo

75
00:07:57,680 --> 00:08:06,840
nuestro, en análisis de humor construimos un corpus muy grande de tweets anotados, primero

76
00:08:06,840 --> 00:08:14,920
que nada clasificado es humor o no es humor y segundo con un grado de, creo que es graciosidad,

77
00:08:14,920 --> 00:08:21,920
la palabra que inventamos para decir, bueno, que tan gracioso es. Bueno, esto se hizo

78
00:08:21,920 --> 00:08:29,480
con anotaciones, lo difundimos mucho en Twitter, yo que sé, creo que se había difundido

79
00:08:29,480 --> 00:08:35,320
en el Facebook del centro estudiante, nada, mucha gente, como se determina si un chiste

80
00:08:35,320 --> 00:08:41,320
es humor o no, si mucha gente dice que es humor, esa fue como la definición, porque esto

81
00:08:41,320 --> 00:08:51,040
no es humor o no es el grado, lo mismo, mucha gente lo anota en 3, 0 y 5, bueno, si mucha

82
00:08:51,040 --> 00:08:57,480
gente dice 3, parecería que el chiste es más o menos gracioso, si mucha gente dice 0,

83
00:08:57,480 --> 00:09:03,680
que no es humor, que no es humor, que es un primer corpus que se armó en un proyecto de

84
00:09:03,680 --> 00:09:09,440
lado, que nos dimos cuenta que está bastante mala anotado, los anotadores, las personas

85
00:09:09,440 --> 00:09:15,360
que entraron a la aplicación para anotar y a poner sus scores, habían confundido

86
00:09:15,360 --> 00:09:22,200
mucho el cero con no es humor y el cero es, me quisiste hacer un chiste, pero no tiene

87
00:09:22,200 --> 00:09:27,760
cero gracia, que no es lo mismo que no es humor, no es humor, es mañana, son las elecciones

88
00:09:27,760 --> 00:09:35,440
de no sé qué, eso es claramente un información que no contiene, por eso la notación se

89
00:09:35,440 --> 00:09:41,560
convirtió en decir si hay una intención del que escribió de hacer humor o no, más allá

90
00:09:41,560 --> 00:09:48,280
hay que aboster resulte gracioso o no, entonces la escala de 0 a 5 es aboster resulta 0 gracioso

91
00:09:48,280 --> 00:09:54,680
o muy gracias, creo que tenemos todavía el link andando que les tira a tu hit si ustedes

92
00:09:54,680 --> 00:10:00,880
van poniendo si les es graciana, esa es la tarea en la que logramos un corpus más grande,

93
00:10:00,880 --> 00:10:06,680
de hecho le presentamos, hicimos una competencia con esto, con esos corpus que armamos en el

94
00:10:06,680 --> 00:10:11,120
marco de un evento que se reenza en España, la sociedad española del PLN organiza

95
00:10:11,120 --> 00:10:15,720
que daño como una serie de competencias en distintos temas, un poco para motivar

96
00:10:15,720 --> 00:10:21,440
la gente a experimentar, a probar, se distribuyen conjuntos de datos y se hacen experimentos,

97
00:10:21,440 --> 00:10:27,760
nosotros venimos organizando un amor, no todos los años, pero hace un tiempo y les sorprendió

98
00:10:27,760 --> 00:10:31,760
el tamaño del corpus que habíamos logrado a notar y claro la clave está en que son

99
00:10:31,760 --> 00:10:37,880
chistes, se la gente empieza a notar y la verdad que empezás y estás un buen rato porque la

100
00:10:37,880 --> 00:10:42,760
mayor, hay muchas cosas que no son chistes y la vas poniendo, no es humor, no es humor, pero van

101
00:10:42,760 --> 00:10:46,920
apareciendo muchas chistes, entonces como trabajo es entretenido, no, mucho más que si les

102
00:10:46,920 --> 00:10:54,120
pido que anoten un corpus con mensaje de odio, que está, no es entretenido, ahora que

103
00:10:54,120 --> 00:11:01,480
está desagradable hacerlo, no es una tarea grata, pero la de anotar chiste sí y se notó en el

104
00:11:01,480 --> 00:11:07,160
resultado, tuvimos mucha gente que se conectó y que se quedaba pila de rato anotando, anotando

105
00:11:07,160 --> 00:11:13,960
y dan, no me acuerdo si llegamos a un corpus de 30.000 tuitos, algo así, anotados por varias

106
00:11:13,960 --> 00:11:19,400
personas, nada más, porque para cada uno obviamente en este tema, estos temas tan subjetivos

107
00:11:19,400 --> 00:11:24,720
donde estamos varias anotaciones para decir, bueno, es humor, no es humor, si hay por lo menos

108
00:11:24,720 --> 00:11:30,200
yo que se tres anotadores que dicen que es humor, bueno, ya está, es humor, si hay uno

109
00:11:30,200 --> 00:11:40,800
solo y uno dice que no, ahí ya vamos, se van descartando, bueno, ahora tenemos un módulo

110
00:11:40,800 --> 00:11:45,920
de taller ahora que está funcionando ya de estar cerca de terminar, que está trabajando

111
00:11:45,920 --> 00:11:50,920
en una competencia parecida a esta, que no nos organizamos nosotros, que es sobre detección

112
00:11:50,920 --> 00:11:58,040
de humor ofensivo, es una mezcla entre humor y ofensa, y este hicimos un módulo de taller

113
00:11:58,040 --> 00:12:01,760
y los estichantes que están en el módulo de taller trabajando, que están con Luis y otros

114
00:12:01,760 --> 00:12:07,720
compañeros, Santiago Bongo y Santiago Castro, los estichantes están participando, están

115
00:12:07,720 --> 00:12:11,800
haciendo experimentos para participar en la competencia, se dan a registrar la competencia,

116
00:12:11,800 --> 00:12:15,920
bueno, pues hay que mandar un paper, hay que presentar los resultados, se puede hacer

117
00:12:15,920 --> 00:12:24,480
a distancia y bueno, está bueno, son cosas muy entretenidas y a la vez son trabajo para

118
00:12:24,480 --> 00:12:33,800
experimentar y profundizar un poco en el área, bueno, sobre la análisis de emociones, una

119
00:12:33,800 --> 00:12:39,120
primera dificultad, por ejemplo, en esta tarea, específicas definir el esquema o el conjunto

120
00:12:39,120 --> 00:12:46,840
de emociones con las que se quieren trabajar, hay como un primer enfoque que es bastante

121
00:12:46,840 --> 00:12:54,040
complejo en el que se define en tres dimensiones, valencia, esto que se traduce a algo así

122
00:12:54,040 --> 00:13:00,580
como activación y esto que es como un control, que se van combinando distintas maneras y

123
00:13:00,580 --> 00:13:05,920
según el peso que se le da a cada una de esas dimensiones, queda como definida una

124
00:13:05,920 --> 00:13:13,100
emoción y ese esquema se usa bastante en un momento, pero parece bastante difícil

125
00:13:13,100 --> 00:13:18,160
de entender, un poco práctico, entonces es más bien, se pasó a trabajar con esquemas

126
00:13:18,160 --> 00:13:26,480
de este tipo, con un conjunto fijo de emociones, por ejemplo, este autor Eggman definió este esquema

127
00:13:26,480 --> 00:13:33,280
con seis emociones medio básicas y este otro autor, este otro esquema con ocho emociones

128
00:13:33,280 --> 00:13:37,120
y hay un montón de trabajos que usan o el esquema de seis o el esquema de ocho que

129
00:13:37,120 --> 00:13:43,280
son muy parecidas y es un poco lo que más se ha usado después, como que el primer enfoque

130
00:13:43,280 --> 00:13:49,200
se usa hace mucho tiempo, viene más de la psicología y como que aplicarlo en un área como

131
00:13:49,200 --> 00:13:56,040
esta es un poco más complejo. El esquema de este blockchain de ocho emociones en realidad

132
00:13:56,040 --> 00:14:04,020
es bastante más complejo y hay algo que se llama esto, la rueda de emociones, de

133
00:14:04,020 --> 00:14:12,280
blockchain, que va agregando más emociones, más detalladas, más refinadas, no se ven

134
00:14:12,280 --> 00:14:18,760
nada, pero lo importa acá están las ocho básicas, alegría, confianza, miedo, sorpresa y después

135
00:14:18,760 --> 00:14:26,200
otras relacionadas en distintos ejes, pero también este esquema más complejo es muy difícil

136
00:14:26,200 --> 00:14:32,160
de usar para clasificar en forma automática, clasificar en seis emociones o en ocho emociones

137
00:14:32,160 --> 00:14:41,480
es más o menos viable, aunque es igual una tarea bastante compleja. Para trabajar en

138
00:14:41,480 --> 00:14:48,120
esto se han creado eléxicos anotados con emociones o sea palabras que tienen que están anotadas

139
00:14:48,120 --> 00:14:52,640
como bueno, si se usan o no se usan o se están vinculadas, se me están vinculadas con cada

140
00:14:52,640 --> 00:14:59,520
una de las emociones, también con juntos de texto, clasificados con las emociones,

141
00:14:59,520 --> 00:15:04,480
típicamente de tweets, de vuelta también se han usado mucho tweets para esto, todo un tweet

142
00:15:04,480 --> 00:15:15,160
y decirse el tweet transmite, tristeza, alegría, hay enfoque multitiqueta, enfoque en que

143
00:15:15,160 --> 00:15:19,600
tendan clasificar en una sola emoción multitiqueta, que es decir bueno, para cada tweet

144
00:15:19,600 --> 00:15:24,880
pongo todas las emociones que transmiten, porque pueden hacer una sola, por ejemplo este

145
00:15:24,880 --> 00:15:37,240
transmite tristeza y en ocho, alegría, sorpresa y yo que sea. Hay trabajos de clasificación

146
00:15:37,240 --> 00:15:43,200
de tweets o de textos regional, pero son muchos de tweets, por ejemplo una de esas competencias

147
00:15:43,200 --> 00:15:48,280
que les mencionaba hoy de ese evento Ibarlef, que hace la Sociedad Española de Belénes,

148
00:15:48,280 --> 00:15:57,400
que se llamó Imoeval en 2021, ahí ellos proporcionan un corpus de tweets anotados y bueno

149
00:15:57,400 --> 00:16:03,640
algunos, pero ellos usaron el Skirmann de Ekman, que tiene seis emociones y agregan una

150
00:16:03,640 --> 00:16:11,880
emoción más que es la categoría otro, bueno, tiene un montón de problemas, si hay dificultades

151
00:16:11,880 --> 00:16:18,640
de trabajar en este tema, por ejemplo el corpus es en particular estaba muy desbalanceado,

152
00:16:18,640 --> 00:16:25,080
algunas categorías como creo que disgusto, sorpresa, no me acuerdo más, tenían muy poquito,

153
00:16:25,080 --> 00:16:30,800
les cuento por qué los tuvimos usando para algunas cosas, muy poquitos ejemplos, o sea

154
00:16:30,800 --> 00:16:38,800
un corpus que tenía en la categoría otros, era la que tenía más ejemplos, más instancias,

155
00:16:38,800 --> 00:16:44,520
las categorías tenían muy poquitos, otras más o menos intermedios, eso hace muy difícil

156
00:16:44,520 --> 00:16:51,360
la clasificación, las categorías que tienen poquitos ejemplos en el corpus en entrenamiento,

157
00:16:51,360 --> 00:16:57,640
después cuando uno entraena y una aplica sobre un corpus nuevo a veces encontrá cero directamente,

158
00:16:57,640 --> 00:17:03,360
tenía muy pocos ejemplos, quedan completamente subrepresentados, perdidos, el modelo que

159
00:17:03,360 --> 00:17:12,360
entrenaste no reconoce después ninguno, y además este tipo de tareas tiene problemas

160
00:17:12,360 --> 00:17:17,200
bastante específicos, por ejemplo hay clases que son muy difíciles de distinguir, como

161
00:17:17,200 --> 00:17:24,600
por ejemplo, me dio que en vez de fiel quise poner odio, odio y disgusto, por ejemplo,

162
00:17:24,600 --> 00:17:31,480
anger, bueno, si mirás los tweets que te quedan clasificados con una con otra, bueno,

163
00:17:31,480 --> 00:17:36,800
si usamos mirando las anotaciones que vienen en el corpus, no, que es el gol de standard,

164
00:17:36,800 --> 00:17:43,280
que tomamos como el verdadero, la etiqueta verdadera o esperada de cada tweet, es un

165
00:17:43,280 --> 00:17:49,520
poco dudoso, cómo fue anotada, así que bueno, y bueno, por ejemplo esa categoría

166
00:17:49,520 --> 00:17:53,360
otros que además era la que estaba más representada en el corpus, termina haciendo la etiqueta

167
00:17:53,360 --> 00:18:00,120
que más asina el clasificador que uno entraena y entonces es la que al final más se confunde

168
00:18:00,120 --> 00:18:07,080
con todas las demás, o sea, bueno, es una tarea complicada, bueno, igual es interesante

169
00:18:07,080 --> 00:18:11,480
y les quería contar porque bueno, no todo eso es solamente decirse algo positivo negativo

170
00:18:11,480 --> 00:18:15,520
aunque es lo que más se hace, hay cosas con mucho más interesantes como ésta y mucho

171
00:18:15,520 --> 00:18:22,720
más complejas, después pasando si es lo que se llama hoy en día análisis de sentimiento

172
00:18:22,720 --> 00:18:26,760
que en realidad originalmente incluía todo lo que acabamos de decir sobre las emociones

173
00:18:26,760 --> 00:18:35,840
que se terminó convirtiendo solamente esto, es una área que también se llama minería

174
00:18:35,840 --> 00:18:41,960
de opiniones, puse ahí unas referencias como desde los inicios hasta ahora, desde

175
00:18:41,960 --> 00:18:53,520
el 2002, 2005, 2008, esta referencia liú 2020 está bueno porque es un material súper

176
00:18:53,520 --> 00:18:58,880
completo, con un montón de definiciones, con una revisión súper completa de toda

177
00:18:58,880 --> 00:19:06,440
la área, de todos los infos, de todos los subproblemas que se abordan, etcétera, como más

178
00:19:06,440 --> 00:19:14,840
completo para leer y después están estas competencias de tas que son parte de lo que les decía

179
00:19:14,840 --> 00:19:21,120
hoy de esas competencias que organizan la sociedad española para el TLN y estas tas que

180
00:19:21,120 --> 00:19:29,120
son análisis de sentimiento para el español, dentro del BLN son como las más, las que

181
00:19:29,120 --> 00:19:34,280
tienen más años y que se han hecho de manera más continua a lo largo de tiempo un montón

182
00:19:34,280 --> 00:19:40,120
de decisiones, más que las que se hacen a nivel internacional, que son las semebal que

183
00:19:40,120 --> 00:19:48,760
han tenido en algunos años, algunos tracks orientados a análisis de sentimiento, pero

184
00:19:48,760 --> 00:19:54,680
la verdad es que hay más para el español o desde hace más tiempo y más de correo.

185
00:19:54,680 --> 00:20:01,120
Bueno, el análisis de sentimiento en realidad es muy diferente de tareas, la más clásica

186
00:20:01,120 --> 00:20:07,440
la que más se está haciendo es clasificar textos, por ejemplo tweets, opiniones sobre películas

187
00:20:07,440 --> 00:20:12,920
en sitios donde la gente pone sus comentarios sobre las películas que veo, opiniones sobre

188
00:20:12,920 --> 00:20:19,480
moteles, clasificación de noticias que ya es un poco distinto, porque no son textos

189
00:20:19,480 --> 00:20:26,840
escritos por persona, hay que ir a las noticias, son bien diferentes para analizar, según

190
00:20:26,840 --> 00:20:33,480
la polaridad, decir si son positivos o negativos, siempre surge también, por lo menos una tercera

191
00:20:33,480 --> 00:20:42,200
categoría que es bueno, que es algo así como NEU, es difícil definir el esquema y hay

192
00:20:42,200 --> 00:20:48,480
muchos esquemas distintos, típicamente se agrega al menos la categoría neutra, puede haber

193
00:20:48,480 --> 00:20:54,720
un texto que no es ni positivo ni negativo, bueno, puede decir que es neutra. Nentros

194
00:20:54,720 --> 00:21:03,920
he usado con distintas secciones, se usa para lo que creo que intuitivamente uno pensaría

195
00:21:03,920 --> 00:21:10,960
que es algo que no tiene sujetividad, no es ni positivo ni negativo, porque es más

196
00:21:10,960 --> 00:21:17,040
que nada, información objetiva, como les decía hoy en mañana, se hace las elecciones

197
00:21:17,040 --> 00:21:26,240
en Uruguay, punto, ahí no hay ni positiva ni negativa, esa información factual, objetiva

198
00:21:26,240 --> 00:21:31,440
podríamos decir, no sé si hay algo que es 100% objetivo, pero bueno, principano de

199
00:21:31,440 --> 00:21:36,840
objetivo, pero también se ha usado en neutro, por ejemplo, para cosas que tienen combinación

200
00:21:36,840 --> 00:21:44,440
de positivo y negativo, entonces se le ha llamado neutro a los textos que tienen un mix

201
00:21:44,440 --> 00:21:54,760
de las dos cosas. También se ha usado etiquetas con una graduación positiva, muy positivo,

202
00:21:54,760 --> 00:22:04,560
negativo, muy negativo, y una vez se denetronen. O sea, usamos escalas numéricas, discretas o

203
00:22:04,560 --> 00:22:10,480
bueno, un rango de reales y un valor entre 0 y 5, por ejemplo, donde cero es lo más

204
00:22:10,480 --> 00:22:17,180
negativo o de entre menos 5 y más 5, todos los números negativos son opiniones más

205
00:22:17,180 --> 00:22:25,520
negativos, los más positivos positivos. Además de clasificar, simplemente eso, la polaridad

206
00:22:25,520 --> 00:22:32,200
también hay trabajos de extracción de opiniones, a partir de texto, más que nada prensa,

207
00:22:32,200 --> 00:22:39,640
y ahí se extrae información como más estructurada, por ejemplo, lo que está ahí abajo, ¿no?

208
00:22:39,640 --> 00:22:44,640
De cada opinión me o quién es el que opina, ¿cuál es la polaridad? La opinión es

209
00:22:44,640 --> 00:22:52,040
positiva, negativa más, este es muy positiva, muy negativa, etcétera, y también a veces

210
00:22:52,040 --> 00:22:57,280
se hace lo que se llama análisis de sentimiento a nivel de aspectos, que es bueno analizar,

211
00:22:57,280 --> 00:23:08,840
de todo, en este evaluaciones de productos, distintos aspectos del producto y este valorar

212
00:23:08,840 --> 00:23:15,320
distintos aspectos y algunos pueden ser positivos y otros negativos. El tema del autor

213
00:23:15,320 --> 00:23:22,120
de la opinión se hace más que nada, por ejemplo, en textos de prensa, ¿no? En la prensa

214
00:23:22,160 --> 00:23:33,800
hay muchísimas referencias a opiniones vertidas por distintas personas, muchas citas, no cualquier

215
00:23:33,800 --> 00:23:41,360
persona, en las prensas nos cuentan lo que opinan, que se yo, los políticos, las artistas,

216
00:23:41,360 --> 00:23:49,200
personalidades públicas, entonces leyendo la prensa podemos saber lo que opinan, un diputado,

217
00:23:49,200 --> 00:23:55,600
un ministro, un cantante, un jugador de fútbol, sobre ciertos temas, también es importante,

218
00:23:55,600 --> 00:24:03,480
ahí no lo puse, pero saber sobre qué están opiniones, ¿no? ¿Qué opinó el diputado tal en

219
00:24:03,480 --> 00:24:15,000
tal fecha sobre la reforma de tal ley, ¿no? ¿Qué opinó o con qué polaridad cuál fue

220
00:24:15,000 --> 00:24:24,040
su opinión, su orientación, positiva, negativa? Está bueno detectar eso en un cierto año y

221
00:24:24,040 --> 00:24:29,840
ver qué opinó esa misma persona sobre el mismo tema que se yo 10 años después, son cosas

222
00:24:29,840 --> 00:24:34,640
interesantes para estudiar. Eso se estudia más que nada en la prensa, no voy a estudiar en

223
00:24:34,640 --> 00:24:39,600
los tweets, no me interesan en general en los tweets, quién no vino, porque son usuarios

224
00:24:39,600 --> 00:24:45,000
comunes, somos todos nosotros, nadie le importa qué piensa cada uno de nosotros, ahí importa

225
00:24:45,000 --> 00:24:53,200
lo que piensa de la mayoría, lo que piensa en general lo que estaba opinando la gente. Y esto

226
00:24:53,200 --> 00:25:01,200
acá de los aspectos es porque bueno, cuando estamos analizando por ejemplo por ahí opiniones

227
00:25:01,200 --> 00:25:08,000
sobre películas, sobre teles, sobre productos como decía hoy, suele haber comentarios de usuarios

228
00:25:08,000 --> 00:25:15,680
de tipo bueno, como dice ahí, me compre un celular tal, la pantalla es muy buena, bien amplia,

229
00:25:15,680 --> 00:25:22,560
se ve bien todo lo que es inne que ver, pero la batería dura muy poco, entonces al final

230
00:25:22,560 --> 00:25:28,880
no estoy muy conforme con la compra, yo que sé, es un texto solo, es difícil clasificarlo

231
00:25:28,880 --> 00:25:32,960
como posición negativo, que pasa que como al final dije no estoy conforme con la compra,

232
00:25:32,960 --> 00:25:39,800
puede decir bueno, negativo, no, la síntesis es que es negativo, pero hay un comentario ahí

233
00:25:39,800 --> 00:25:53,320
positivo sobre la pantalla, uno negativo sobre la batería, etcétera, sí, por ejemplo si te

234
00:25:53,320 --> 00:25:58,920
interesa, si, Dios, eso es una empresa y querés ver lo que pina la gente sobre tus productos,

235
00:25:58,920 --> 00:26:06,720
vas a hacer un corbuz con los reviews de todos tus productos, capaz que lo clasifica por productos

236
00:26:06,720 --> 00:26:14,280
celulares, notebooks, etcétera y podés decir bueno, tener una clas, si vos ya sabes lo que estás

237
00:26:14,280 --> 00:26:18,840
vendiendo y sabes las características de tu producto, puedes tener ya como esa taxonomía, bueno,

238
00:26:18,840 --> 00:26:26,000
de los celulares, voy a fijar en lo que dice la gente sobre pantalla, batería, conceptos y ahí

239
00:26:26,000 --> 00:26:36,880
por esa gente a notar lo que los usuarios comentan, es súper variado esto porque depende de quién

240
00:26:36,880 --> 00:26:52,760
lo hay con qué objetivo, ¿no? Sí. Y más que nada, no es el autor de la noticia, el autor de

241
00:26:52,760 --> 00:26:59,240
la opinión. No, no, sí, sí, en las noticias, no te lo aclaré por las dudas, no me importa, me

242
00:26:59,240 --> 00:27:03,520
pueden importar también, quién es el periodista que escribe, hay artículos de opinión en la

243
00:27:03,520 --> 00:27:10,000
prensa, pero hay artículos de prensa, como por ejemplo las portales, manteideo portal, las noticias

244
00:27:10,000 --> 00:27:14,240
son súper, pasó esto, fue la no dijo esto, no sé qué, y no importa quién lo escribe porque no

245
00:27:14,320 --> 00:27:21,400
están poniendo en principio, por lo menos no intencionalmente sus opiniones, sus, sus, sus, sus,

246
00:27:21,400 --> 00:27:27,200
sus, sus ego ni nada, ¿no? Está siempre, igual, ¿no? ¿Qué está creiendo algo de esta

247
00:27:27,200 --> 00:27:33,520
celular? Está sejando algo siempre, pero no, no, no, no es muy notorio ni es lo que nos importa,

248
00:27:33,520 --> 00:27:39,040
pero está poniendo información y es muy común abrir hoy, manteideo portal y vas a encontrar

249
00:27:39,040 --> 00:27:46,280
varios textos que tienen citas a cosas que dijeron, no sé, qué dijo la presidenta de

250
00:27:46,280 --> 00:27:52,960
OSC, o vicepresidenta, sobre el problema del agua, lo vas a encontrar en un montón de lugares,

251
00:27:52,960 --> 00:27:59,080
pero bueno, si lo que es automáticamente, tenés que encontrar la manera dentro de un artículo

252
00:27:59,080 --> 00:28:06,920
de prensa de detectar los lugares en donde se está transmitiendo, reproduciendo lo que dijo

253
00:28:06,920 --> 00:28:15,800
esa persona en particular, ¿qué vas a buscar cosas como según la presidenta de la comilla?

254
00:28:15,800 --> 00:28:23,160
O como dijo, o o o, toda una comilla, no sé qué, comentó a la prensa, la presidenta de no sé

255
00:28:23,160 --> 00:28:30,720
qué, un montón de cosas, de ese tipo, pues se irán analizando y para ir extrayendo quiénes

256
00:28:30,720 --> 00:28:37,040
son los que están opinando, en qué parte del texto, qué está diciendo cada uno, y cuál

257
00:28:37,040 --> 00:28:42,760
es la tendencia, la valencia de eso que está diciendo es positivo, negatío, la polaridad.

258
00:28:44,240 --> 00:28:50,080
Ah, eso me refería con el autor, lo sea todos los principantes que aparecen en

259
00:28:50,080 --> 00:28:52,680
ahí en la noticia como personas que están opinando sobre algo.

260
00:28:53,680 --> 00:29:00,720
Pues ahora te importa, bueno, para verificar una prendería que es lo que dice la presidenta de

261
00:29:00,720 --> 00:29:06,360
12 porciones de cosas y una prendería, a reconocer cita dentro de un texto. Ahí está.

262
00:29:06,360 --> 00:29:11,520
Ahí está, entonces si después querés saber qué dice la presidenta de 12 vas a buscar,

263
00:29:11,520 --> 00:29:16,920
ahí hay un montón de problemas más, en una noticia, al principio dice la presidenta de

264
00:29:16,920 --> 00:29:24,080
12, Fulana, de tal, nombre a Pesido, no sé qué, dijo hoy a la prensa, y más abajo vuelve

265
00:29:24,080 --> 00:29:30,560
a aparecer, dice solo la presidenta de 12, sin el Fulana de tal, y más abajo va a aparecer

266
00:29:30,560 --> 00:29:37,320
y aparece solo la Pesido. Fulana, además agregó, no sé qué, ahí está un problema que se

267
00:29:37,320 --> 00:29:45,160
llama, que es resolución de correspondencias, son muchas expresiones distintas, que tienen

268
00:29:45,160 --> 00:29:50,480
un mismo referente o que hacen el referencia a una misma persona. ¿Qué es otro problema

269
00:29:50,480 --> 00:29:57,640
del VLN que es súper interesante que se estudia un montón? Porque si no, porque en un texto

270
00:29:57,640 --> 00:30:02,920
puede haber opiniones, pueden estar contrastando opiniones distintas personas, tener que ir a veces

271
00:30:02,920 --> 00:30:07,780
esos textitos tan cortos, trámite en solo lo que dijo esa persona y entonces no, no me

272
00:30:07,780 --> 00:30:21,980
complicado, está hablando siempre el mismo, pero a veces no. Bueno, esto, ¿para qué

273
00:30:21,980 --> 00:30:27,220
se usa el sentimiento más o menos todo lo que venimos diciendo? No sé, para encontrar

274
00:30:27,220 --> 00:30:31,140
relevancia y clasificación de textos en un supolaría, me importa, voy a encontrar

275
00:30:31,140 --> 00:30:38,580
los textos que hablas positivamente, de alumntema, clasifico, me quedo con los que necesito,

276
00:30:38,580 --> 00:30:42,740
para que se usa, para proceso de tomas decisiones, como empezamos las empresas, por ejemplo,

277
00:30:42,740 --> 00:30:48,620
necesitan saber lo que opinan en los usuarios o en sus productos, para saber si hacer una campaña,

278
00:30:48,620 --> 00:30:53,220
si sacar un producto, si cambiar, que es eso para lo que sea, análisis de la tendencia

279
00:30:53,220 --> 00:30:59,620
de opiniones, esos más de interés de la prensa, probablemente, o bueno, de los políticos,

280
00:30:59,620 --> 00:31:05,620
también, campañas políticas, campañas de mercado, bueno, todo se combina un poquito.

281
00:31:05,620 --> 00:31:15,580
Les decía, este es un tema que en el pelén estás muy presente, hace ya unos cuantos años,

282
00:31:15,580 --> 00:31:20,780
está, no era un problema clásico del pelén, como dijimos, traducion automática, y

283
00:31:20,780 --> 00:31:27,620
porque, bueno, claramente, en piezo por el final, incremento masivo del uso de las redes

284
00:31:27,620 --> 00:31:31,580
sociales, por el público en general, para expresar opiniones, hoy en día tenemos acceso

285
00:31:31,580 --> 00:31:38,260
a opiniones de todo el mundo, sobre todas las cosas, ¿verdad? En todas las redes sociales,

286
00:31:38,260 --> 00:31:47,460
hay de todo. Y bueno, también, lo que estamos arriba, hay más datasets, ya generados,

287
00:31:47,460 --> 00:31:52,260
yo les decía, bueno, ahora Twitter no va a dejar descargar más tweets para dar más datasets,

288
00:31:52,260 --> 00:31:56,180
pero ya existen un montón de conjuntos de datos que están anotados, para muchos de estos

289
00:31:56,180 --> 00:32:01,340
problemas que mencionamos, y en muchos idiomas, yo estoy hablando mucho del español, como

290
00:32:01,340 --> 00:32:05,980
siempre hay mucho hecho para el inglés, siempre hay más para el inglés, pero también,

291
00:32:05,980 --> 00:32:10,980
para muchos idiomas más, por ejemplo, en estos áreas, hay muchos trabajos para el árabe,

292
00:32:10,980 --> 00:32:15,900
también, y después, en los frances, en Italia, no bueno, todos los idiomas que más o menos

293
00:32:15,900 --> 00:32:24,020
cercanos al nuestro seguro, ya existen un montón de conjuntos de datos, y también,

294
00:32:24,020 --> 00:32:28,580
porque bueno, los métodos de aprendizaje automático, que explotan esos datos, que usan esos

295
00:32:28,580 --> 00:32:37,220
datos anotados, también han ido mejorando un montón, dan resultados muy buenos, hoy en día

296
00:32:37,220 --> 00:32:43,900
estamos en una situación hasta un poco diferente, y bueno, los modelos, como lo que hay detrás

297
00:32:43,900 --> 00:32:50,620
de chatGPT, ya ni siquiera necesitan estos datos anotados, pueden resolver estos problemas

298
00:32:50,620 --> 00:32:58,540
de manera más o menos bien, sin usar conjuntos de datos de ejemplo, que dicen, este tweet

299
00:32:58,540 --> 00:33:04,540
es positivo, este tweet es negativo, este positivo, este es neutro, si ustedes le dan a chatGPT

300
00:33:04,540 --> 00:33:09,420
un ejemplo, un tweet y le preguntan, este tweet es positivo, negativo es neutro, probablemente

301
00:33:09,420 --> 00:33:21,860
les responde a lo bastante acertado, pueden probarlo después siquiera, bueno, el análisis

302
00:33:21,860 --> 00:33:26,860
de redes sociales, como les decía, es una de las cosas que más se ha hecho, sobre todo,

303
00:33:26,860 --> 00:33:35,300
porque tweet tenía, permitía descargar un montón de datos y usarlos, tiene sus desafíos,

304
00:33:35,300 --> 00:33:40,460
no es lo mismo analizar la prensa, que analizar tweet, ustedes ya estuvieron trabajando

305
00:33:40,460 --> 00:33:47,340
con Twitch, en la tarea, y hicimos ahí algunos ejemplitos, que ya, por lo menos el análisis

306
00:33:47,340 --> 00:33:55,220
lingüístico se cumplió bastante, hay un lenguaje muy informal, por un lado hay muchos

307
00:33:55,220 --> 00:34:01,780
errores, ortográficos, bueno, hablar de la syntax, si no, no, no, son oraciones necesariamente

308
00:34:01,780 --> 00:34:12,020
correctas ni nada, signos de puntuación, rectamente no se usa, además de la informalidad,

309
00:34:12,020 --> 00:34:19,220
el tipo de lenguaje, las expresiones, y cosas como eso que está ahí, que bueno, es casi

310
00:34:19,220 --> 00:34:28,820
que es difícil entender, ¿no?, quiere decirme que es eso, creo que dice, letras repetidas,

311
00:34:28,820 --> 00:34:34,860
un montón, la caa, que no es una letra del español, que aparece en cosas como esa,

312
00:34:34,860 --> 00:34:40,300
esa M, mayúscula ahí, al final de decirme que es rarísima, bueno, todas esas cosas

313
00:34:40,300 --> 00:34:47,740
complican bastante el análisis de los tweets, un poco el ejercicio de la tarea de hacer

314
00:34:47,740 --> 00:34:53,420
una análisis sintáctico de un tweet era más que nada para desestimularlos, y cuando

315
00:34:53,420 --> 00:34:59,980
trabajen ahora en la segunda tarea con tweets, que no intenten hacer un análisis sintáctico,

316
00:34:59,980 --> 00:35:06,020
simplemente, bueno, son herramientas de teléneques, queríamos que conocieran, pero no los vamos

317
00:35:06,020 --> 00:35:17,060
a usar para analizar tweets, así que, no se preocupen, bueno, otros desafíos, bueno,

318
00:35:17,060 --> 00:35:21,380
si quiero hacer análisis de sentimiento en Twitter, bueno, voy a encontrar con un montón

319
00:35:21,380 --> 00:35:28,220
de formas de transmitir sentimientos, emociones, opiniones, que no se, no siempre son tan

320
00:35:28,220 --> 00:35:33,020
simples, la primera Mario Nette es un excelente escritor, bueno, hay una palabra que es excelente

321
00:35:33,020 --> 00:35:39,580
que transmite una polaridad bien clara, pero después hay cosas como la segunda, bueno,

322
00:35:39,580 --> 00:35:47,020
tiene palabras positivas o negativas, no, transmite algo negativo, pero si no usan

323
00:35:47,020 --> 00:35:52,460
una palabra negativa, y bueno, la ironía, como eso que está ahí, si seguro, como no,

324
00:35:52,460 --> 00:35:57,540
es un comentario ironico, pero podría no hacerlo, podría yo estar diciendo, no es ningún

325
00:35:57,540 --> 00:36:05,260
tipo ironía, si, seguro, como no, abrirle a puertas, si tienes calor, yo no sé, nada,

326
00:36:05,260 --> 00:36:09,860
bueno, expresiones coloquiales, parecieron lo del lenguaje informal que decíamos recién,

327
00:36:09,860 --> 00:36:15,420
vamos a ponerse las pilas, totalmente figurado, no, no lo podemos interpretar en forma

328
00:36:15,420 --> 00:36:22,260
literal, y la buena, y cosas llamas, ahora sí más lingüísticas, más intactas, como

329
00:36:22,260 --> 00:36:28,260
de bueno, el efecto que produce la negación en un texto, no, no fue una buena elección,

330
00:36:28,260 --> 00:36:33,860
bueno, la palabra que aparece ahí con polaridad es buena, la palabra buena que es polaridad

331
00:36:33,860 --> 00:36:39,340
positiva, pero está negada, bueno, no, o sea que lo que está transmitiendo es algo negativo,

332
00:36:39,860 --> 00:36:45,900
un poco de todo esto aparece en los tweets, y bueno, entonces vamos a empezar a ver algunos

333
00:36:45,900 --> 00:36:52,300
ejemplos y distintas formas de enfocar el problema, siendo desde lo más simple, a bueno, los enjuges

334
00:36:52,300 --> 00:37:00,620
como un poco más complejos, estos son cuatro tweets, reales, saltados de Twitter, el primero dice

335
00:37:00,620 --> 00:37:05,140
qué bien que marcaron a MED, si, gracias a la gente de Booksfield por su excelente atención,

336
00:37:05,140 --> 00:37:11,300
y ahí después es un link, no sé qué, después ahí hay un usuario, top secret, el

337
00:37:11,300 --> 00:37:17,740
peso de la Lucia de Stilfarra, otros 90 millones de euros en sus emociones, y ahí otro que

338
00:37:17,740 --> 00:37:22,820
se puede, pues a mí me ha encantado, estos son tweets que es bastante fácil clasificar, ¿verdad?

339
00:37:22,820 --> 00:37:28,620
¿Qué dirían del primero que vien que marcaron a MED, si? El positivo, gracias a la gente de Booksfield,

340
00:37:28,620 --> 00:37:35,940
positivo, el de allá abajo, el del peso, el de la Lucia, en el atío, como te das cuenta de

341
00:37:35,940 --> 00:37:40,620
que es que es un atío, ahí está una palabra, ahí que es súper negativa, ¿no? desplifarrarnos y

342
00:37:40,620 --> 00:37:46,220
manera de encontrarlo una connotación positiva, y este pues a mí me ha encantado

343
00:37:46,220 --> 00:37:54,420
ayerlo, bueno, también positiva, y no me encantar es número positiva, bueno, ésta son las clasificaciones

344
00:37:54,420 --> 00:37:59,340
que podríamos dar para estos cuatro tweets, los cuatro son, los cuatro transmiten, tienen una

345
00:37:59,340 --> 00:38:03,420
polaridad, ¿verdad? No pusimos ninguno ahí que fuera anero, pero podría haber alguno ahí que

346
00:38:03,420 --> 00:38:09,620
el mismo que estoy diciendo desde hoy, ¿no? Mañana son las elecciones, no sé dónde, eso no

347
00:38:09,620 --> 00:38:17,180
debería ni positivo ni negativa, yo en ahí lo único que hicimos fue destacar, no sé

348
00:38:17,180 --> 00:38:22,100
de mucho, me parece las palabras que podrían estar ayudando, ¿no? la palabra bien, el que,

349
00:38:22,100 --> 00:38:30,740
que también es muy intensificador, gracias, excelente, encantado, y acá está despilfarra que

350
00:38:30,740 --> 00:38:37,500
es la palabra negativa, ¿no? Bueno, estos son tweets, yo diría que más o menos fáciles de

351
00:38:37,500 --> 00:38:42,020
clasificárselo, lo único que estoy haciendo es buscar palabras en un lexico, por ejemplo,

352
00:38:42,020 --> 00:38:46,980
tengo un conjunto para las positivas, un conjunto para las negativas, si es suficientemente amplio,

353
00:38:46,980 --> 00:38:52,820
mi lexico, las va a tener a todas y todas van a estar como positivas a negativas, como esperamos,

354
00:38:52,820 --> 00:38:59,260
y bueno, encuentro una en cada cosa y digo, estos positivos están negativos, hay textos un poco

355
00:38:59,260 --> 00:39:06,300
más complicados, por ejemplo, el primero, entró la magia al Camp Nou, vamos Messi, ahí ya es un

356
00:39:06,300 --> 00:39:12,220
poco más difícil, ¿no? Sabemos que es positivo, ¿no? Porque todos nosotros sabemos lo que quiere decir,

357
00:39:12,220 --> 00:39:21,580
vamos, así escrito, imagía, bueno, hablando de un jugador de fútbol, es un término bien positivo,

358
00:39:21,580 --> 00:39:27,820
en realidad, magia, no necesaria, no, quiere decir algo que no es positivo en el negativo, es bueno,

359
00:39:29,980 --> 00:39:35,260
pero ya se complica un poquito más, no, no es tan directo como buscar en un lexico,

360
00:39:36,140 --> 00:39:43,740
yo podría estar la palabra magia, como positiva en un lexico de análisis de sentimiento,

361
00:39:43,740 --> 00:39:50,380
pero no sé, si debería estar siempre como positiva, después bueno, Uruguay sin mucho fútbol,

362
00:39:50,380 --> 00:39:57,180
pero con abundante marca y actitud, ese es positivo en negativo, es positivo,

363
00:39:58,180 --> 00:40:05,300
es positivo, pero tiene una primera parte negativa, ¿no? Pero es verdad que el perro, lo que dio

364
00:40:05,300 --> 00:40:09,660
a lo que pongo un perro y lo que viene después del perro parece predominar sobre el resto, parece

365
00:40:09,660 --> 00:40:14,620
hacer lo que, lo que realmente quiero transmitir es lo que viene ahí, o sea que podríamos decir, bueno,

366
00:40:14,620 --> 00:40:21,100
es positivo, porque o podríamos decir que es mixto y que tiene negativo y positivo y clasificarlos,

367
00:40:21,100 --> 00:40:34,220
y agregar una etiqueta que sea mixto y ponerle esa etiqueta, no es no edad, pues sería como

368
00:40:34,220 --> 00:40:42,100
que raro, pues si acá parece un comentario que bueno, no es necesario agregarlo,

369
00:40:42,100 --> 00:40:48,700
si hubo alcanzado con decir abundante marca y actitud, bueno, el tercero volvió la bestia,

370
00:40:48,700 --> 00:40:55,620
volvió a Leonel Andrés Messi, gigante, es decir, no sé, un volcuno, no sé qué,

371
00:40:55,620 --> 00:41:02,540
y este que es positivo en negativo, es positivo, ¿no? Pero acá vas a que la palabra

372
00:41:02,540 --> 00:41:03,540
la bestia es amigua, ¿no?

373
00:41:03,540 --> 00:41:23,740
Sí, puede sacar el símbolo y quedarte con la palabra, incluso con lo hashtag, se puede

374
00:41:23,740 --> 00:41:27,860
hacer un procedimiento más complicado que es separar en palabras, porque a veces el hashtag

375
00:41:27,860 --> 00:41:39,900
tiene, es una secuencia de palabras, claro, en general eliminarla por completo, no es lo

376
00:41:39,900 --> 00:41:44,780
mejor, sacar el símbolo y dejar lo que viene ahí, ya puede ser un poco mejor, pero además

377
00:41:44,780 --> 00:41:48,660
de ver si hay más de una palabra, ya puede ser mejor, no siempre fácil segmentar,

378
00:41:48,660 --> 00:42:00,700
si tenemos suerte hay mayúsculas que nos ayudan a ver, sí, si son varias palabras

379
00:42:00,700 --> 00:42:06,780
en minúsculas, si lo ha sentido, no es nada, no lo reconoce como un término, si tratas

380
00:42:06,780 --> 00:42:10,180
de segmentar lo que tendrías que hacer, ¿cómo segmentarían? ¿Entonces una secuencia

381
00:42:10,180 --> 00:42:23,020
de la palabra? Sí, pero como se es donde cortar si no hay mayúsculas, si hay mayúsculas,

382
00:42:23,020 --> 00:42:27,940
claro, esto es un problema en sí mismo, segmentar una secuencia de letra para ver cuál es

383
00:42:27,940 --> 00:42:32,700
primero, puede haber varias soluciones posibles, ¿cómo segmentarlo en tres palabras, en

384
00:42:32,700 --> 00:42:33,700
dos palabras?

385
00:42:33,700 --> 00:42:39,060
Tengo que tener un diccionario para el buscando que palabras existen, igual es, no encontrar

386
00:42:39,060 --> 00:42:44,700
distintos cortes que me den palabras que existen, y lo ideal, lo ideal sería de más

387
00:42:44,700 --> 00:42:49,420
tener algo así como un modelo de lenguaje que me diga, ¿vieron algo de modelo de lenguaje

388
00:42:49,420 --> 00:42:56,420
con Luis? La semana pasada, ¿qué es un modelo de lenguaje? Sí, de negramas o de lo que

389
00:42:56,420 --> 00:43:01,860
sea, el modelo de lenguaje, si yo le doy tres palabras, que encontré una secuencia

390
00:43:01,860 --> 00:43:08,100
de tres palabras, que las tres están en mediccionario o en el eléxico, pero tengo también

391
00:43:08,100 --> 00:43:12,300
otras secuencias posibles, porque lo puedo cortar distintas maneras, el modelo de lenguaje

392
00:43:12,300 --> 00:43:17,460
me puede decir, bueno, es la más probable, para eso si lo en los modelos de lenguaje y

393
00:43:17,460 --> 00:43:24,860
es lo que hoy se hace, todo es modelo de lenguaje hoy, para distintas maneras, y ahí podrá

394
00:43:24,860 --> 00:43:28,540
resolver, pero claro, es un problema gigante, yo no les voy a pedir a ustedes como

395
00:43:28,540 --> 00:43:36,420
preparamiento de la tarea 1 que hagan todo eso, pero sería como el camino más completo

396
00:43:36,420 --> 00:43:43,420
para resolverlo, bueno, igual creo que se usa bastante usar mayúsculas para no, como

397
00:43:43,420 --> 00:43:49,580
para separar, ¿no? Me suena, capaz que es de formación que nosotros lo haríamos

398
00:43:49,580 --> 00:43:54,580
seguro, porque estamos acostumbrados a hacer eso con identificadores de lo que sea, pero

399
00:43:54,580 --> 00:44:00,100
bueno, en todo caso si esto es un problema, eso, chiquitito, no más, ya es un problema,

400
00:44:00,100 --> 00:44:05,060
el otro problema al que iba yo es la palabra bestia, esa es mi igual, nosotros usamos

401
00:44:05,060 --> 00:44:11,580
mucho la palabra bestia con una connotación negativa, decimos que bestia, bueno, lo usamos

402
00:44:11,580 --> 00:44:17,380
en las dos, totalmente, ahí es un montón de palabras que usamos de maneras, como terrible,

403
00:44:17,380 --> 00:44:22,100
la verdad terrible, lo usamos como malo, como malo o bueno, y solo nosotros sabemos

404
00:44:22,100 --> 00:44:26,620
ni hoy todos, nosotros sabemos que es clarísimo, todos sabemos cuando es malo, cuando es

405
00:44:26,620 --> 00:44:32,220
bueno, en general, bueno, ahí empiezan los problemas, después hay una palabra gigante

406
00:44:32,220 --> 00:44:38,740
que puede ser la que ayuda un poquito a darnos cuenta de que es algo bueno, también

407
00:44:38,740 --> 00:44:43,900
sabemos que como es Messi, difícil que alguien día que Messi desvestia, en el sentido de

408
00:44:43,900 --> 00:44:48,660
negativa de jugar al fútbol, porque sería un poco raro que alguien tenga esa opinión,

409
00:44:48,660 --> 00:44:53,540
tan extrema, alguien puede no gustarle mucho, pero nadie se diría ese extremo de alguien

410
00:44:53,540 --> 00:45:02,180
súper reconocida, ¿no? Bueno, el cuarto ahí, ¿qué fantasma de este pelado roja inexistente

411
00:45:02,180 --> 00:45:08,300
de buena? Eso parece ser bastante negativo, parar a fantasma para nosotros es muy negativa

412
00:45:08,300 --> 00:45:14,820
¿verdad? Pero también hay que ver si en otros lugares se usa también, de habla español

413
00:45:14,820 --> 00:45:19,460
que habla de español y se usa un buen negativo. Después de esto, como para que no lo echaran

414
00:45:19,460 --> 00:45:31,820
a San Martino, es tan idea, si es posible, ¿no? Es negativa. Es negativa. Sí, y ese

415
00:45:31,820 --> 00:45:37,340
tal San Martino, no sé quién es, era un jugador, ¿no? Directo, bueno, no sé, y solo

416
00:45:37,340 --> 00:45:41,940
malo, claramente. ¿Puedes lo que hizo? ¿Cómo va a haber chana? O lo que hizo alguien,

417
00:45:41,940 --> 00:45:45,140
en un jugador, bueno, no sé. ¿Y está ahí el último?

418
00:45:45,140 --> 00:45:53,420
Está positivo, ¿no? Ajá, está muy bueno, pero no sabemos qué está hablado, ¿no?

419
00:45:53,420 --> 00:45:56,860
Eso es otro problema. Es positivo, pero sobre qué, ¿sí?

420
00:45:56,860 --> 00:46:00,180
¿Por qué? Por una cosa, a los dos no sé, a los dos no sé qué pasó en la tarea,

421
00:46:00,180 --> 00:46:06,700
era que ponían en el tweet, decían, de 46 cont, y ponían entre tweet, tweet continuando

422
00:46:06,700 --> 00:46:14,580
entre tweet. Ah, sí. Ahí sí, y estaba lo que venía. Pues, ¿no? Porque ustedes

423
00:46:14,580 --> 00:46:18,820
ya los tweet sueltos, como instancias. Claro, pues, después de ponían un link, y nosotros

424
00:46:18,820 --> 00:46:24,580
con el del colega de El Corpo, que teníamos, ya no teníamos, con el índice. Claro. ¿Qué hicieron

425
00:46:24,580 --> 00:46:30,380
con eso? No, terminaron eso. Claro, pero no sé si, que eso es algo que se le ha dado.

426
00:46:30,380 --> 00:46:35,540
¿Y ahí donde tenés que tener cuidado con esas cosas o en dónde podrías resolver ese

427
00:46:35,540 --> 00:46:40,500
problema? ¿Un qué momento? Si yo te ha dado un corpus de tweet, si te digo, trabaja con

428
00:46:40,500 --> 00:46:46,540
este corpus, y bueno, bueno, vas a poder resolver mucho de chup. Dijeron que el extremo

429
00:46:46,540 --> 00:46:51,220
sea nada. Soy yo, ¿no? Si yo voy a crear el corpus, soy yo que tengo que resolver que

430
00:46:51,220 --> 00:46:58,740
hago con los tweets, con los hilos, con los retuits, con los respuestas a un tweet, si

431
00:46:58,740 --> 00:47:04,220
quieren incluirlas o no, si quiero que sean parte de mi corpus o no, si quiero eliminarlos,

432
00:47:04,220 --> 00:47:11,220
para que quiero solo tweets cortitos y que no tengan, que no dependan de otros, y entonces

433
00:47:11,220 --> 00:47:18,700
está, es la construcción del dataset, ahí lo que es el momento en el que podemos tomar

434
00:47:18,700 --> 00:47:24,220
esas definiciones. Después de que ya está armada el dataset y lo tenés ahí, lo tenés

435
00:47:24,220 --> 00:47:32,340
que usar, no puedes resolver mucho para atrás. Así que, bueno, ahora cuando trabajen

436
00:47:32,340 --> 00:47:37,800
con este conjunto de datos, vean, si encuentran cosas así, decían lo que quieran las

437
00:47:37,800 --> 00:47:43,100
tareas de este curso, son bastante amplias. Ustedes tienen libertad de acción para muchas

438
00:47:43,100 --> 00:47:48,740
cosas, ¿no? Hay una respuesta única para una solución única para lo que les pegamos.

439
00:47:48,740 --> 00:47:56,100
Bueno, entonces el último lo que decían, o sea, hay otro problema que es interesante

440
00:47:56,100 --> 00:48:00,380
saber si algo opositió negativo, pero sobre qué cosa, de qué se está hablando, qué

441
00:48:00,380 --> 00:48:05,700
es eso. Probablemente eso sea una respuesta a algo, entonces ahí se mezcla con lo que

442
00:48:05,700 --> 00:48:11,380
nos decías que más que por eso te agarraste, bueno, no tengo contexto, no me sirve

443
00:48:11,380 --> 00:48:17,500
para nada. Sí puedo decir que opositió y tal, con eso roceló con lo que es el problema

444
00:48:17,500 --> 00:48:28,420
del análisis sentido. Bueno, entonces, algo de esto ya hicimos, no, tareas preveas.

445
00:48:28,420 --> 00:48:32,940
Bueno, primero obtener los textos de interés, tweets, comentarios, en forums, blogs, lo que

446
00:48:32,940 --> 00:48:36,460
sea, armar y conjunto de datos, algo que alguien me lo dé, y media, tienes que trabajar con

447
00:48:36,460 --> 00:48:42,940
esto. Si lo tengo que armar yo, es una tarea previa que no es una simple, hay que descargar,

448
00:48:42,940 --> 00:48:47,660
hay que decidir cosas como lo que hacíamos recién, descargo todos los tweets, me parece

449
00:48:47,660 --> 00:48:51,380
que es más o menos simple, yo nunca lo hice, pero bueno, grupos de estudiantes lo han

450
00:48:51,380 --> 00:48:58,620
hecho y lo hacen rapiditos y mucho problema. Hasta ahora, hasta que pendearse pudo,

451
00:48:58,620 --> 00:49:03,780
Twitter tenía una API para hacer eso de manera sencilla, pero hay que decidir esas cosas.

452
00:49:03,780 --> 00:49:09,100
Voy a guardarme los tweets y elimino todos los retuits de tweets, porque si no tengo un

453
00:49:09,100 --> 00:49:14,260
montón de datos repetidos, me guardo los hilos, los tweets con sus respuestas, me guardo

454
00:49:14,260 --> 00:49:21,100
también, los me gusta de la gente, porque esa información me guardo los tweets que

455
00:49:21,100 --> 00:49:27,700
están citados, que tienen como un texto extra, como registro eso, cuál es el modelo,

456
00:49:27,700 --> 00:49:33,020
que voy a definir para todos esos datos, hay un montón de cosas que hay que resolver,

457
00:49:33,020 --> 00:49:40,140
y bueno, lo mismo con cualquier otro conjunto de datos, mensajes de foros, lo que sea.

458
00:49:40,140 --> 00:49:44,420
Bueno, después otra parte de que ya estuvieron experimentando ustedes un poco, limpiar

459
00:49:44,420 --> 00:49:50,820
los datos, eliminar esos tutuurs símbolos en las etiquetas, bueno, emojis, los emojis

460
00:49:50,820 --> 00:49:57,260
puedo eliminarlos, o puedo querer conservarlos, o convertirlos en palabras, para el análisis

461
00:49:57,260 --> 00:50:05,660
de sentimiento, los emojis pueden ser interesantes, transmiten cosas positivas o negativas,

462
00:50:05,660 --> 00:50:11,620
bueno, eso, como guardarlos, como me parece el modelo de datos, cuáles son los cambos

463
00:50:11,620 --> 00:50:22,900
y tipos de datos, o no sé qué, o solo un archivo JSON, lo que sea. Y bueno, después

464
00:50:22,900 --> 00:50:28,140
como voy a enfocar el tema de decir si son positivos negativos, son otros, acá no

465
00:50:28,140 --> 00:50:33,980
lo dije, lo sé por qué, pero tengo que definir el esquema con el que quiero anotar,

466
00:50:33,980 --> 00:50:38,060
si ya me vienen anotados, bueno, ¿cuáles son las etiquetas que se usaron y trabajan

467
00:50:38,060 --> 00:50:46,380
con eso? Por ejemplo, positivo, negativo y neutro, ¿vale? Entonces, es un primer enfoque,

468
00:50:46,380 --> 00:50:51,940
el más simple es escribir reglas a mano, bueno, yo estudio un poco a mis datos y encuentro

469
00:50:51,940 --> 00:50:58,060
ciertos patrones, ciertas regularidades y definio cómo clasificarlos con algunas reglas

470
00:50:58,060 --> 00:51:05,220
que pienso yo, ¿no? Puedo usar herramientas de análisis lingüístico, por ejemplo, un

471
00:51:05,220 --> 00:51:10,820
lematizador y quedarme con los lemas de las palabras, en vez de con las palabras originales,

472
00:51:10,820 --> 00:51:15,420
puedo usar para algo los postags, las categorías gramaticales, en este tweets hay muchos

473
00:51:15,420 --> 00:51:20,420
objetivos y capaz que eso para mí es un indicio de que hay mucha subjetividad, podría

474
00:51:20,420 --> 00:51:27,380
hacer y me sirve con un dato más, puede hacer un parsing del tweet, hacer el árbol

475
00:51:27,380 --> 00:51:33,740
sintáctico, como les decía, es general, no se lleve mucho, porque están las indexes

476
00:51:33,740 --> 00:51:42,100
del tweet no es muy analizable, así que no se suele hacer. Y después también puedo

477
00:51:42,100 --> 00:51:46,420
tener algunos recursos que tienen que ver con ese problema particular, con el que estoy

478
00:51:46,420 --> 00:51:52,260
trabajando, por ejemplo, para análisis de sentimientos, tener lexicos efectivos, con

479
00:51:52,260 --> 00:51:58,460
juntos de palabras que tienen una categoría, positiva negativa, un grado de un número

480
00:51:58,460 --> 00:52:06,140
entre cero y cinco, por ejemplo, las palabras excelente que capaz que tiene el untaje cinco,

481
00:52:06,140 --> 00:52:11,340
horrible, tiene el menos cinco, bueno, cosas así, o simplemente positiva en el antiguo

482
00:52:11,460 --> 00:52:18,340
más, también para análisis de sentimientos, me puede interesarte en una lista de palabras

483
00:52:18,340 --> 00:52:29,540
que introducen negación, como no, pero también hay otras, como nadie, ninguno, nada, alumnos

484
00:52:29,540 --> 00:52:35,220
verbos que en realidad invierten la polaridad de lo que vienen después, como, por ejemplo,

485
00:52:35,220 --> 00:52:41,700
evitar impedir, hay verbos que tienen como una, como implícinamente en una especie de

486
00:52:41,700 --> 00:52:50,140
negación, etcétera. O intensificadores muy importantes, interesantes, son interesantes

487
00:52:50,140 --> 00:52:56,740
más positivos, pero muy, o importante, le agregan intensidad a algo, pero ese a algo

488
00:52:56,740 --> 00:53:00,620
puede ser una exposición negativa, ¿verdad? Muy lindo, muy feo, ¿no? Es muy el que es

489
00:53:00,620 --> 00:53:07,020
positivo, ni es negativo, pero sí es el que le suma positividad o negatividad. Bueno,

490
00:53:07,020 --> 00:53:14,020
esos recursos pueden ser interesantes y voy a trabajar en análisis de sentimiento. Entonces,

491
00:53:14,020 --> 00:53:20,380
bueno, tengo los lexicos, tengo, por ejemplo, un lematizador que me convierte las palabras

492
00:53:20,380 --> 00:53:25,660
como sugerencias, sugerencias, las dos, en la misma sugerencia, de pilfarras, de pilfarras

493
00:53:25,660 --> 00:53:32,780
donde pilfarrando, en el mismo barbo de pilfarrar, el lema, bueno, buenas, buenas, todas,

494
00:53:32,780 --> 00:53:37,980
las convierten en el lema bueno, etcétera. A veces, en vez del lema, usamos lo que se

495
00:53:37,980 --> 00:53:48,500
llama el STEM o la raíz, que me ayuda a generalizar un poco más, porque es como intercategorías

496
00:53:48,500 --> 00:53:54,140
o así. Si yo me quedo con el lema, con la raíz de de pilfarras, de pilfarras donde

497
00:53:54,140 --> 00:54:01,740
pilfarrando, de pilfarrar, de pilfarrro, todas esas se convierten en de pilfarr, que es

498
00:54:01,740 --> 00:54:06,540
la raíz y ahí están todas las formas del verbo, hasta el sustantivo, o sea, todas las

499
00:54:06,540 --> 00:54:11,220
familias de palabras de distintas categorías, veros tantidos objetivos que tienen la misma

500
00:54:11,220 --> 00:54:18,180
raíz semántica que dan unificadas con la raíz. No con el lema, el lema siempre es dentro

501
00:54:18,180 --> 00:54:24,060
de la categoría, el lema de cualquier forma verbal es el infinitivo, el lema de un sustantivo,

502
00:54:25,060 --> 00:54:35,820
el postag, como decíamos, el árbol de Parsing podría ser rey. Bueno, un ejemplo como

503
00:54:35,820 --> 00:54:41,300
este, gracias a la gente de Buxil por su excelente atención, parece fácil de clasificar con

504
00:54:41,300 --> 00:54:48,860
las reglas muy simples, si tengo un lexico afectivo. Supongan que tengo la palabra gracias y

505
00:54:48,860 --> 00:54:55,540
la palabra excelente en mi lexico, clasificadas como palabras positivas, entonces mis reglas

506
00:54:55,540 --> 00:55:01,820
son estas. Busco las palabras del tweet en un lexico afectivo, si la cantidad de palabras

507
00:55:01,820 --> 00:55:08,020
positivas es mayor que las negativas, digo que es positivo el tweet y si no, digo que es negativo.

508
00:55:10,020 --> 00:55:16,220
Acá estoy trabajando con palabras, pero si el texto, en vez de decir su excelente atención,

509
00:55:16,220 --> 00:55:22,460
dice gracias por sus excelentes sugerencias. Bueno, mi lexico afectivo probablemente tenga

510
00:55:22,460 --> 00:55:27,900
lemas y no todas las palabras, porque si yo en un lexico pongo todas las palabras, voy a tener

511
00:55:27,900 --> 00:55:34,620
para un verbo todas las conjugaciones, y son muchísimas, se que multiplica por 10, por lo menos,

512
00:55:34,620 --> 00:55:40,220
el lexico. Es que para que mi lexico tiene solo lemas, si mi lexico tiene lemas, tengo que

513
00:55:40,220 --> 00:55:47,660
leimatizar el tweet y buscar los lemas, entonces busco los lemas, entonces en vez de buscar la palabra

514
00:55:47,660 --> 00:55:53,620
excelente, voy a buscar excelente porque primero tengo el lema con una herramienta que me

515
00:55:53,620 --> 00:56:03,540
postage a ver, me da los lemas de todas las palabras, y bueno, después ¿qué pasa? Acá

516
00:56:03,540 --> 00:56:07,420
puse un ejemplo con Perro que no es el mismo que hemos visto hoy, tengo ahí un elemento

517
00:56:07,420 --> 00:56:16,220
perro que introduce una contraste, siempre el perro, aunque alguna otra cosa parecía, está

518
00:56:16,220 --> 00:56:21,580
contrastando dos cosas, en este caso estoy analizando sentimientos, voy a estar contrastando

519
00:56:21,580 --> 00:56:28,300
algo positivo con agonidad. Entonces puedo querer una etiqueta como decíamos hoy para esos

520
00:56:28,300 --> 00:56:34,620
casos en donde hay de las dos cosas, y la etiqueta podría ser neutro, si ha sido usado,

521
00:56:34,620 --> 00:56:39,940
se usan a unos esquemas, la etiqueta neutro con ese sentido detiene un poco de gajos, no me gusta

522
00:56:39,940 --> 00:56:50,860
mucho porque para mi neutro que decir que no tiene polaridad, pero bueno, y bueno, sí, claro,

523
00:56:50,860 --> 00:56:57,060
no me he decidido, podríamos decir como, y bueno el perro, en general lo que la forma en que uno

524
00:56:57,060 --> 00:57:03,180
lo usa, como hablante es, vio algo, pongo un perro y lo que viene después es lo que de verdad

525
00:57:03,180 --> 00:57:07,900
estoy queriendo resaltar, acá no se está aplicando ese criterio, digo bueno, hay una parte

526
00:57:07,900 --> 00:57:12,540
que es positiva, tiene porque encontré la palabra excelente, hay una parte que negativa, porque

527
00:57:12,540 --> 00:57:19,140
encontré la palabra mala, entonces le puse en neutro. De hecho, ahí estoy haciendo súper estricto,

528
00:57:19,140 --> 00:57:25,500
estoy poniendo, si hay más positivos que negativos es positivos, hay más negativos, menos positivos

529
00:57:25,500 --> 00:57:30,660
que el negativo es negativo, y si no, que quiere decir que si son exactamente iguales, las

530
00:57:30,660 --> 00:57:35,500
cantidades, digo que es neutro, que en que me se cazan que no hay de ninguna, si los

531
00:57:35,500 --> 00:57:38,220
son cero, también digo que es neutro.

532
00:57:38,220 --> 00:57:45,740
¿La vida de tu pollo para la evaluación de seis por una palabra que le está esperando

533
00:57:45,740 --> 00:57:51,260
en un positivo, la relación al peso de las cuatro, tres, cuatro, tres, cuatro, tres, cuatro,

534
00:57:51,260 --> 00:57:53,420
tres, sí, acá está con el quema, ¿qué es?

535
00:57:53,420 --> 00:58:00,620
Claro, claro, hay menos positivas, pero hay una sola que sea

536
00:58:00,620 --> 00:58:07,140
excelente y hay mucha negativa, pero ninguna es muy, sí, porque acá estamos asumiendo

537
00:58:07,140 --> 00:58:11,220
que tenemos un lexico que sólo nos dice esta para la positiva, esta es negativa.

538
00:58:11,220 --> 00:58:18,060
Si tenemos un lexico que nos dice esta palabra es muy positiva, o tiene cinco de positiva,

539
00:58:18,060 --> 00:58:22,940
y esta tiene menos dos de negatividad, ¿qué podríamos hacer con eso?

540
00:58:22,940 --> 00:58:29,900
En vez de simplemente decir cuántas hay, sumar, restar, esta hacer más cuentas, ¿no?

541
00:58:29,900 --> 00:58:38,260
Y ahí podríamos tener en cuenta lo que decía, ahí está, también podemos tratar de hacer

542
00:58:38,260 --> 00:58:44,220
algo que les decía hoy, bueno, primero descartar los tweets que no tienen subjetividad

543
00:58:44,220 --> 00:58:49,820
o que no tienen palabras de ningún tipo de estas, y entonces los considero o neutros

544
00:58:49,820 --> 00:58:55,220
que es el uso que yo le daría, lo que está neutro ya en ese significado mejor que

545
00:58:55,220 --> 00:58:59,820
es el tweet no tiene subjetividad, o pongo otra etiqueta, ¿no?

546
00:58:59,820 --> 00:59:03,460
No tiene sentimiento, ¿no? ¿Tú es sin sentimiento?

547
00:59:03,460 --> 00:59:09,220
Y si no, si hay alguna palabra positiva negativa, bueno, ahí sí, algo el estudio,

548
00:59:09,220 --> 00:59:13,780
si hay más positivas generativas, si hay más negativas positivas, si están equilibradas

549
00:59:13,780 --> 00:59:19,340
las positivas generativas, digo que es mi texto, o bueno, ahí el neutro apareció un

550
00:59:19,340 --> 00:59:25,180
poco para mostrar ese uso a mi amigo que se le ha dado etiquetas en distintos trabajos,

551
00:59:25,180 --> 00:59:26,980
¿no?

552
00:59:26,980 --> 00:59:33,020
Y también acá, bueno, es como, puedo decir que es mi texto si hay de las dos, aunque no

553
00:59:33,020 --> 00:59:38,460
sea exactamente la misma cantidad, si hay muchas de las dos, hay cinco para las positivas,

554
00:59:38,460 --> 00:59:43,900
cuatro negativas, yo diría más bien que es mi texto y no tanto que es positivo porque

555
00:59:43,900 --> 00:59:49,860
hay más positivas, pero bueno, esto es un ejemplo super simple, bueno, otros problemas que

556
00:59:49,860 --> 00:59:54,140
voy a aparecer, si yo estoy trabajando con reglas es la negación lo vimos hoy, si yo

557
00:59:54,140 --> 00:59:59,180
solo cuento palabras, yo acá encuentro dos palabras positivas, eso es decir que todo

558
00:59:59,180 --> 01:00:04,460
esto es positivo, pero me estoy perdiendo que la última positiva está negada, ¿no? Pero

559
01:00:04,460 --> 01:00:11,400
los productos no son buenos, bueno, lo mismo que decir que son buenos, claramente, tampoco

560
01:00:11,400 --> 01:00:17,660
necesariamente es lo opuesto, ¿no? A veces es la negación, no es tanto que lo vuelve

561
01:00:17,660 --> 01:00:22,700
negativo, más bien lo neutraliza un poco, decir que algo no es bueno, no es lo mismo

562
01:00:22,700 --> 01:00:27,860
que decir que es malo, ¿no? No siempre, ¿no? Así que bueno, también hay que analizar

563
01:00:27,860 --> 01:00:34,220
un poco cómo se el efecto de la negación no es exactamente invertir lo que está

564
01:00:34,220 --> 01:00:40,300
ahí, puede ser simplemente neutralizar, pero bueno, suponiendo que asumimos que la negación

565
01:00:40,300 --> 01:00:45,580
invierte, bueno, ahí tengo que, por ejemplo, un paso ahí, que es invierto, el valor

566
01:00:45,580 --> 01:00:49,980
afectió a las palabras negadas, está ahí tú un tema, ¿no? Porque no es solo la palabra

567
01:00:49,980 --> 01:00:56,380
¿no? Como decíamos, hoy hay muchas palabras que pueden introducir, tener un efecto de

568
01:00:56,380 --> 01:01:06,140
inversión, de modificación del valor, de la valencia, de las palabras que vienen después,

569
01:01:06,140 --> 01:01:11,260
acá podrían necesitar una análisis sintáctico para ver cuál es el alcance que tiene ese

570
01:01:11,260 --> 01:01:17,740
no dentro de la elaboración, cuál es el segmento que está afectado por esa negación,

571
01:01:17,740 --> 01:01:22,380
porque esta operación podría seguir, podría haber ahí otra coma y lo que viene después

572
01:01:22,380 --> 01:01:31,700
es la coma que pasa que ya no está afectado por el no, ¿no? Ahí una análisis

573
01:01:31,700 --> 01:01:36,620
sintáctico podría ayudar a determinar, bueno, no sé, el subar o los hijos, los hermanos,

574
01:01:36,620 --> 01:01:43,620
no sé, hay que analizarlo, ¿no? Así que bueno, tampoco es que sea tan simple, pero bueno,

575
01:01:43,620 --> 01:01:49,660
una eurística simple, si hay una palabra negativa, las tres que vienen después o cuatro

576
01:01:49,660 --> 01:01:54,060
que vienen después, desimbiérdola por la realidad, alguna cosa así, o todo lo que viene

577
01:01:54,060 --> 01:01:58,540
después hasta alguna coma un punto, lo que sea, o lo que le complica un poquito más

578
01:01:58,540 --> 01:02:05,300
hasta una coma un punto o alguna conjunción, porque ahí podría venir, la atención de

579
01:02:05,300 --> 01:02:10,740
Bruxine es excelente, pero los productos no son buenos, aunque no sé qué, todo lo que

580
01:02:10,740 --> 01:02:14,740
viene después, aunque ya no tiene que ver con ese no, ese no, se terminó ahí, son

581
01:02:14,740 --> 01:02:22,020
buenos, son buenos. Bueno, en fin, es también todo un problema para analizar el alcance

582
01:02:22,020 --> 01:02:30,180
de la negación. Bueno, entonces, este foque que es basado en reglas manuales, que se

583
01:02:30,180 --> 01:02:34,340
trabajó muchísimos años con esto, hasta que explotaron los métodos de aprendizaje

584
01:02:34,340 --> 01:02:39,140
automático, tiene un montón de problemas, ¿no? Para empezar es muy difícil abarcar

585
01:02:39,140 --> 01:02:44,060
todos los casos escribiendo reglas. Sí, yo puedo analizar un corpus grande, hacen

586
01:02:44,060 --> 01:02:49,140
análisis súper complejos, escribir reglas, reglas, es muy difícil también cuando uno

587
01:02:49,140 --> 01:02:54,500
está escribiendo reglas, no cometer errores, agrega reglas que te resuelven a algunos casos

588
01:02:54,500 --> 01:03:01,740
que estás viendo, pero que te rompe en otros y agregan muchos calzos positivos, o sea,

589
01:03:01,740 --> 01:03:10,680
es un trabajo muy manual, muy arpesanal, muy costoso en tiempo, dame. También lograr

590
01:03:10,680 --> 01:03:19,500
algo coherente, consistente, es bastante complejo. Entonces, se empezó a ampliar mucho la

591
01:03:19,500 --> 01:03:26,060
cobertura y también mejorar mucho la precisión con teniendo grandes candidatos de ejemplo,

592
01:03:26,060 --> 01:03:31,420
si usando métodos de aprendizaje automático, súper listado, aunque también métodos

593
01:03:31,420 --> 01:03:36,860
siridos, no puede hacer un método de aprendizaje automático, que usa como algún atributo

594
01:03:36,860 --> 01:03:41,940
y los resultados que dan un cierto conjunto de reglas que tengo hecho, aplico reglas,

595
01:03:41,940 --> 01:03:47,780
obtengo ciertos resultados y le doy a mi método de aprendizaje automático, los resultados

596
01:03:47,780 --> 01:03:55,340
de esas reglas como un posible atributo para que lo tengan en cuenta. Para eso tenemos

597
01:03:55,340 --> 01:03:59,060
que tener esos conjuntos de datos anotados por lo menos con los métodos de aprendizaje

598
01:03:59,060 --> 01:04:06,780
automático que usaron hasta ahora hace un par de años o más, porque ahora sí están esos

599
01:04:06,780 --> 01:04:12,020
grandes modelos del lenguaje, como decimos, soy que están logrando muy buenos resultados,

600
01:04:12,020 --> 01:04:17,940
sin tener necesariamente corpus anotados para la tarea, capaz que sin un corpus anotado

601
01:04:17,940 --> 01:04:24,980
con el sentimiento positivo negativo, algunos enfocos con grandes modelos del lenguaje pueden

602
01:04:24,980 --> 01:04:33,180
resolver bien. También se hace mucho ahora con modelos del lenguaje grandes como entera para

603
01:04:33,180 --> 01:04:39,820
modelar los textos, después con un corpus específico de la tarea, hago una etapa más que se

604
01:04:39,820 --> 01:04:47,020
llama Fintuning y especializo esa red para la tarea. Y ahí precisó, capaz que no tanto

605
01:04:47,020 --> 01:04:55,260
datos como se precisaban antes, cuando partíamos más como un esero. Bueno, entonces un segundo enfoque

606
01:04:55,260 --> 01:05:01,260
basada en aprendizaje automático, lo que podemos llamar como los métodos clásicos de aprendizaje

607
01:05:01,260 --> 01:05:09,700
automático, que necesitan un conjunto de atributos o features que yo le doy al modelo, que los

608
01:05:09,700 --> 01:05:16,220
calcula a partir de todos los ejemplos y entonces el modelo a partir de todos esos features es que

609
01:05:16,220 --> 01:05:24,420
durante el entrenamiento, a partir de todos esos features, se genera un modelo que después

610
01:05:24,420 --> 01:05:31,780
puede, si yo le doy un texto nuevo para el cual calculo también esos features, me da la salida,

611
01:05:31,780 --> 01:05:38,460
la cláclata. O sea, un ejemplo de clacificación como lo que vieron si las se van a basado

612
01:05:39,020 --> 01:05:46,460
el anterior. Entonces, en general tengo corpus de tweets clasificados con algún conjunto de

613
01:05:46,460 --> 01:05:54,220
tiquetas, hay que ver cuál es el conjunto de tiquetas, porque puede ser variable, esos

614
01:05:54,220 --> 01:05:59,540
conjuntos de datos que se usan para entrenar en general fueron anotados a mano o fueron anotados

615
01:05:59,540 --> 01:06:05,060
en forma automática, pero curados a mano, una redición manual de cada ejemplo para tomarlos

616
01:06:05,060 --> 01:06:13,020
como el gran trus, como un gol de estándar, se aprende la función que prediga la clase de

617
01:06:13,020 --> 01:06:19,460
datos cualquier otro tweet, con un conjunto de features. Y esto es un aprendizaje automático

618
01:06:19,460 --> 01:06:27,700
supervisado, porque estoy usando ejemplos anotados para aprender la tarea. Bueno, algunos metos,

619
01:06:27,700 --> 01:06:32,820
ahí vayas a hacer roles de decisión, SBM, MLB, que es multilayer, excepto aunque es como una

620
01:06:32,820 --> 01:06:38,740
versión más fácil de rellenos neuronales, muchos de esos se usaron un montón para estas cosas,

621
01:06:38,740 --> 01:06:45,700
y los posibles atributos, por ejemplo, para análisis de sentimientos pueden ser las palabras

622
01:06:45,700 --> 01:06:54,500
del tweet, se puede hacer un enfoque de tipo bag of words, viene un algo de eso, cómo representar un

623
01:06:54,500 --> 01:07:05,220
texto como bag of words, acá en el curso, ¿no? Vale, antes se trabajaba así o en vez de las

624
01:07:05,220 --> 01:07:09,900
palabras, pousar los lemas, no olvido de las palabras, usó los lemas, ahí no lo puse, pero

625
01:07:09,900 --> 01:07:14,740
además puedo filtrar las stop words y quedarme solo con las palabras con más significado,

626
01:07:14,740 --> 01:07:21,740
ojo cuando filtro las stop words para un problema como este, porque no me conviene eliminar palabras

627
01:07:21,740 --> 01:07:27,620
como no, pero aunque suelen estar en las listas de stop words, me las tengo que quedar,

628
01:07:27,620 --> 01:07:33,420
al trabajo que hicimos sobre estas cosas, nos hicimos nuestra propia lista de stop words, adaptada

629
01:07:33,420 --> 01:07:39,140
a este problema, y sacamos de ahí todas esas que tienen bastante que ver con la polaridad del

630
01:07:39,140 --> 01:07:46,600
tweet, nada, las negaciones, los conectivos, esos contrastivos, etcétera, las categorías

631
01:07:46,600 --> 01:07:50,800
gramaticales pueden servir en este tweet, hay adjetivos, son hay adjetivos, hay adjetivos, hay

632
01:07:50,800 --> 01:07:56,680
adjetero y suelecer, cantidad de palabras positivas son negativas que encontré en un lexico, lo

633
01:07:56,680 --> 01:08:03,160
pongo como un atributo, tres positivas, dos negativas, para cada tweet de mi conjunto de datos,

634
01:08:03,160 --> 01:08:13,800
agrego esas dos fichos, cantidad positiva, cantidad de negativas, ceneación, etcétera, hace muchos

635
01:08:13,800 --> 01:08:19,260
años ya que se trabaja más que con un enfoque de baguofuor, se trabaja con worded

636
01:08:19,260 --> 01:08:26,560
settings, yo tengo que ver ahí como manejo, si uso worded settings que es un vector para cada

637
01:08:26,560 --> 01:08:31,440
palabra, bueno, tengo un vector para cada palabra del tweet, pero mi tweet puede tener

638
01:08:31,440 --> 01:08:37,360
diferente cantidad de palabras, yo necesito una entrada de largo fijo para trabajar con

639
01:08:37,360 --> 01:08:41,980
estos modelos, entonces ahí, se ve que se hace, se pueden concatenar todos los

640
01:08:41,980 --> 01:08:47,740
efectores y llevar todo un largo uniformizado y entonces si algún tweet me queda un poquito

641
01:08:47,740 --> 01:08:53,460
más corto, lo relleno con cero, si algún tweet me queda un poquito más largo, lo trunco,

642
01:08:53,460 --> 01:08:57,940
esa es una manera de trabajar. Otra manera de trabajar es que se ha usado bastante, es

643
01:08:57,940 --> 01:09:02,740
calcular el vector promedio, tengo un vector de 300 valores para cada palabra del tweet,

644
01:09:02,740 --> 01:09:09,420
hago el promedio, coordenada y me queda un vector de 300 valores que es el tweet, suena

645
01:09:09,420 --> 01:09:19,180
oscuro y raro, pero para algo sirve, funciona más o menos, ¿no? O se calcula un sentense

646
01:09:19,180 --> 01:09:24,580
en medin o así como que ha sido un paso posterior en la historia de todo esto, después de

647
01:09:24,580 --> 01:09:28,640
que se trabajó mucho tiempo con worded settings, se empezó a trabajar con sentense en

648
01:09:28,640 --> 01:09:33,700
medin, se calcula directamente con las mismas objetos que calcula un worded medin para

649
01:09:33,700 --> 01:09:48,160
cada palabra, calcula un enmedin para un texto. Bueno, tercer enfoque, diplomán en las

650
01:09:48,160 --> 01:09:55,600
redes neuronales, profundas que ya también hace unos 4 años que se usan, ya se deja de

651
01:09:55,600 --> 01:10:01,760
trabajar en esa ingeniería de atributos. No pienso, bueno, todos los atributos que le

652
01:10:01,760 --> 01:10:07,600
puedo dar, si hay adjetivos o no hay adjetivos, si hay palabras positivas, si hay negativas,

653
01:10:07,600 --> 01:10:16,080
nada, la entrada para la red es algún tipo de autor de representación umérica del tweet,

654
01:10:16,080 --> 01:10:21,200
por ejemplo la concatenación de todos los worded medins de cada palabra del tweet, o por

655
01:10:21,200 --> 01:10:27,320
ejemplo un sentense en medin que calcula un modelo que tengo entrenado para darme un

656
01:10:27,320 --> 01:10:35,680
enmedin en texto y esa la entrada de la red, sin ningún otro atributo. La entreno, porque

657
01:10:35,680 --> 01:10:40,400
sigue siendo aprendizaje supervisado, ¿verdad? Yo sigo teniendo un conjunto de entrenamiento

658
01:10:40,400 --> 01:10:45,560
que para cada tweet tiene sus salidas peradas, entonces el entreno la red con todo ese conjunto,

659
01:10:45,560 --> 01:10:54,200
le doy el enmedin o la representación del que sea del tweet y la red apreciarlo y yo

660
01:10:54,200 --> 01:11:01,360
sé cual era la etiqueta esperada, se ajustan todos los parámetros, etcétera. Segundo ejemplo,

661
01:11:01,360 --> 01:11:08,240
la red predice a lo, se cual era el resultado esperado, se ajustan todos los parámetros y así se

662
01:11:08,240 --> 01:11:15,520
entrena con ese conjunto sin información extra. Se puede agregar alguna información a ese vector

663
01:11:15,520 --> 01:11:21,480
que yo construyo para modelar el tweet le puede agregar los números más que están representando

664
01:11:21,480 --> 01:11:26,800
más cosas. Por ejemplo eso, se hay palabras positivas negativas, le agrego como más coordenadas,

665
01:11:26,800 --> 01:11:37,560
al autor, pero normalmente no se hace mucho. Y bueno, hay montón de arquitecturas

666
01:11:37,560 --> 01:11:45,540
posibles para las redes neuronales, esas redes VLSDM fueron las que para este tipo de problemas

667
01:11:45,540 --> 01:11:53,460
se usaron más y dieron mejores resultados, esas LLSDM son las redes recurrentes, van tomando,

668
01:11:53,460 --> 01:12:05,700
van procesando cada palabra y la información que se genera al procesar una palabra se toma como

669
01:12:05,700 --> 01:12:12,700
entrada para procesar la siguiente, o sea que es clasificación secuencial, es un tipo de clasificación

670
01:12:12,700 --> 01:12:24,540
secuencial, importa el orden en que aparecen las palabras. Y VLSDM es porque se hace todo eso hacia

671
01:12:24,540 --> 01:12:30,980
adelante y hacia atrás, entonces el orden, la palabra anterior afecta a cada una que voy a procesar,

672
01:12:30,980 --> 01:12:36,100
pero también en el otro sentido la palabra siguiente, afectando y de todo eso hacia adelante y hacia

673
01:12:36,100 --> 01:12:41,420
atrás en una salida hacia otra capa, las redes neuronales de estas profundas son redes con muchas

674
01:12:41,420 --> 01:12:50,060
capas, ese es más o menos la definición del red profundo. Y bueno, ya ahora también basado en

675
01:12:50,060 --> 01:12:55,820
Diplerna, porque acá también lo que hay son redes neuronales de multi-capas, se está trabajando

676
01:12:55,820 --> 01:13:03,820
con modelos de lenguaje neuronales, con arquitectura transforma, que es distinto a eso que dije

677
01:13:03,820 --> 01:13:09,580
recién de la LLSDM, pero donde se tiene en cuenta el contexto, yo le voy como entrada a un

678
01:13:09,580 --> 01:13:17,460
transformar, le voy como entrada a una secuencia y para cada palabra que de esa secuencia se computa

679
01:13:17,460 --> 01:13:23,660
a alumbector lo que sea en función de todas las palabras que lo rodean, o sea que se está tomando

680
01:13:23,660 --> 01:13:32,900
información del contexto todo el tiempo y bueno hay muchas capas y bueno, es complicado, no

681
01:13:32,900 --> 01:13:37,460
vamos a hablar mucho de eso, con lo que se llama después a Intune, lo dije hoy medio al pasar,

682
01:13:37,460 --> 01:13:45,220
sí yo, obtengo la representación de mi tweet usando el modelo de lenguaje, eso me da un vector y

683
01:13:45,220 --> 01:13:54,220
hago una y agrega una capa que se basa en mi conjunto de entrenamiento para clasificar, en esa segunda

684
01:13:54,220 --> 01:14:00,340
etapa de entrenamiento, uso mi conjunto de tweets clasificados positivos negativos a neutro para

685
01:14:00,340 --> 01:14:13,220
tener un clasificador, y la segunda es un poco distinto, pero se usa una capa del LLSDM ya

686
01:14:13,220 --> 01:14:20,820
entrenada para clasificación, el LLSDM es esa recurrente que les dije hoy que bueno va tomando

687
01:14:20,820 --> 01:14:29,020
para cada palabra información de las anteriores para representarla. Bueno, estos son los

688
01:14:29,740 --> 01:14:35,380
enfocos que se están aplicando ahora, esto lo vamos a saltear, es un buen tito de algunos

689
01:14:35,380 --> 01:14:40,620
experimentos que estuvimos haciendo nosotros en el grupo para participar en estas competencias de Iberlès,

690
01:14:40,620 --> 01:14:47,540
que esos eventos que realiza el Sociedad Péline, quieren después lo mirar un poquito, y a

691
01:14:48,100 --> 01:15:01,700
el final, les quería contar algo como lo más reciente que he visto para tweets, para clasificación

692
01:15:01,700 --> 01:15:08,300
de tweets en español, el análisis del sentimiento, que es este un modelo de lenguaje que se llama

693
01:15:08,300 --> 01:15:16,140
Robert Twitt, que está basado en un modelo de lenguaje que se llama Roberta, que a su vez está

694
01:15:16,140 --> 01:15:22,340
basado en uno de los primeros modelos del lenguaje, estos basados en arquitectura Transformer que

695
01:15:22,340 --> 01:15:30,780
se hicieron, que es Bert, que es como de los primeros que se empezó a usar, que es un modelo de

696
01:15:30,780 --> 01:15:39,340
lenguaje, pero entrenado solamente con tweets en español, que es un modelo de lenguaje, es un modelo

697
01:15:39,340 --> 01:15:47,860
de lenguaje general, del lenguaje con texto de todo tipo, por ejemplo todo el texto existente en

698
01:15:47,860 --> 01:15:54,740
español, se usa para entrenar un modelo de lenguaje tipo verde para el español, todo la Wikipedia,

699
01:15:54,740 --> 01:16:02,420
todos los tweets, artículos, novelas, prensa, todo lo que hay es que titula el español, lo más

700
01:16:02,420 --> 01:16:07,020
grande posible el corpus que se pueda construir, se usa para entrenar un modelo de lenguaje para el

701
01:16:07,020 --> 01:16:16,180
español tipo verde o tipo GPT o lo que sea, en este caso se usó solamente todos los textos de

702
01:16:16,180 --> 01:16:21,100
tweets en español, que se pudieron recopilar, se armó un corpus bien grande de tweets en español,

703
01:16:21,100 --> 01:16:26,980
para entrenar un modelo de lenguaje que esté modelando específicamente el lenguaje de los tweets

704
01:16:26,980 --> 01:16:33,860
en español, y ese modelo de lenguaje usado como entrada para una red neuronal que classifica los

705
01:16:33,860 --> 01:16:39,980
tweets con unos corpus de tweets en español específicados que existen de esas competencias, mejoró

706
01:16:39,980 --> 01:16:47,900
bastante los resultados que se han obtenido antes con otros enfocados, así que me parece interesante

707
01:16:47,900 --> 01:16:54,140
como un foco un poco más actual y combina un poco las dos cosas, los modelos de lenguaje que se usan

708
01:16:54,140 --> 01:17:01,860
ahora, también el aprendizaje supervisado con un corpus de tweets anotados, y eso de buscar

709
01:17:01,980 --> 01:17:07,260
la vuelta para especializarlo en el tipo de texto en el que se está trabajando ahí, esto es un trabajo de los

710
01:17:07,260 --> 01:17:18,060
argentinos, está disponible, todo el código, el modelo, el corpus, por ahí está, bueno, dejamos por

711
01:17:18,060 --> 01:17:23,820
acá, hay montón de referencias, creo que hasta me faltó un par de unas cosas que agrega el final,

712
01:17:23,820 --> 01:17:31,740
más que nada, bueno por completitud, pero todavía me faltó agregar ahí, hay un par de capítulos

713
01:17:31,740 --> 01:17:40,100
en el libro de Yuraski, no hay ningún capítulo que sea la base de esta presentación, esta

714
01:17:40,100 --> 01:17:46,900
presentación, las otras, por lo menos las que vieron con mí, un barguerán bien, se apoyaban

715
01:17:46,900 --> 01:17:54,580
bien en los capítulos de Yuraski, este es un poco más de todo, así que bueno, y vale alguna

716
01:17:54,580 --> 01:18:00,460
cosa que quieran leer por ahí, tienen las referencias, bueno entonces recuerdo en mañana, hoy

717
01:18:00,460 --> 01:18:07,620
en el más tarde Juanjo les va a publicar todas las instrucciones para empezar con el trabajo para

718
01:18:07,620 --> 01:18:12,900
repartir los artículos, para armar el cronograma de presentaciones, para que vayan leyendo, para que

719
01:18:12,900 --> 01:18:18,340
vayan entrando en esa tarea, y después la letra de la tarea 2 va a estar, o sólo el fin de semana,

720
01:18:18,340 --> 01:18:20,540
lunes, martes, correcta, sí.

