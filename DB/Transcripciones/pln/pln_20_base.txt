que vamos a ver hoy, ni idea, bien, la idea es este como una clase
invitada dentro del curso de la intervención al presamiento del lenguaje natural,
dar algo de el tema de recuperación de información, pero si uno piensa en
recuperación de información, si seguida a una sociedad Google, web,
cosa, vamos a ver, no vamos a ver eso, vamos a ver los inicios de la
recuperación de información, cuando todavía internet no era tal,
estamos hablando de la década del 60, cuando empezaron a aparecer
los primeros sistemas o cuáles serán los modelos o cuáles serán los criterios
para construir un sistema de recuperación de documentos,
información donde vamos a estar comentando, la filosofía
es totalmente distinta, lo que hoy es la web, entonces, en los sistemas de recuperación
de información, como les decía, en general se habla de un dominio acotado,
un dominio conocido, y uno lo que ha tratado hacer es tratar de recuperar
la mayor cantidad de documentos o de información que exista en esa base
de documental vinculado a la necesidad del usuario.
Estas son algunas de las preguntas que uno se hace, como podemos recuperar
información relevante para nosotros contenidas en esos documentos,
en esa colección de documentos, que cosas tendrían que ser representativas,
qué es lo que va a identificar un documento de otro, cómo se van a representar
los documentos, cómo vamos a representar las consultas,
si importa la estructura que tenga el documento o solamente el contenido,
y cuál hace la relevancia asociada cada documento, esto es un tema bien importante
porque uno inevitablemente, cuando voy a estar hablando, hace su paralelismo
a la web, entonces hoy vemos, hacemos una consulta en la web,
en internet, y siempre aparece un orden de alguna manera, el tipo ordena,
según algún criterio, entonces, en aqué estamos hablando
de los primeros sistemas de recuperación de documentales,
el tema de la relevancia era muy importante y cuál sea en los criterios
y cómo se medidas a relevancia, era sumamente clave en los modelos,
en los primeros modelos teóricos y bueno, y que después aplicaron
los primeros sistemas de gestión documental.
Entonces, bueno, una brevia agenda, primero introducir al tema,
vamos a hablar algo de los modelos, de los modelos de información retrieval,
¿cuáles son las medidas para evaluar la recuperación y después muy por arriba
este hablar algo de indexación, que es clear y totalmente,
por lo menos mencionar lo que sería la recuperación de información
en la web, y después es todo tema interesante que es el tema de infracción
de información que de alguna manera es como un hermano menor
de la recuperación de información.
Entonces, para empezar a contextualizar tres preguntas distintas,
primero, veamos qué es el concepto de información,
luego qué es un sistema de información para después llegar al concepto
de qué es recuperación de información.
Acá yo saqué un par de... esto es otro concepto, ya lo tenemos,
ya lo venimos manejando, más que nada para contextualizar.
Esta es un par de definiciones que me parecieron interesantes,
de la Real Academia y la otra la saqué de Wikipedia.
Comunicación o adquisición de conocimientos que permiten ampliar o precisar
los que ya se poseen, si yo ya tengo determinada idea sobre algo
y busco aumentar esas ideas sobre determinados conceptos,
o un conjunto organizado de datos procesados que constituyen un mensaje
que cambia el estado de conocimiento de sujeto o de lo que ya conocíamos.
Son como distintas, pero orientadas a lo mismo,
un par de profundizar o de aumentar la capacidad de conocimiento
sobre determinada afecta.
Entonces, sobre esa base, un sistema de información,
también hay un par de definiciones de dos sitios,
conjunto de funciones o componentes relacionados que forman un todo,
almacena, procesa, distribución,
o un conjunto realizado de elementos que pueden ser personas, datos,
o sea, no socialo directamente al tecnología,
sino un sistema de formaciones que van mucho más allá de el concepto de tecnología.
Entonces, cualidades de un sistema de información debe ser preciso,
o sea, la información que contenga,
debe estar clara y contundente de lo que se pretende representar.
Hay un tema de oportunidad que tiene que ver con el momento en que sucede
un determinado hecho y el momento en que ese documento que refleja a ese hecho
es puesto a disposición del sistema.
Otra cualidad es el hecho de ser completo,
si bien la completitud absoluta no existe.
La idea es que cuando yo recupero en un sistema,
se puede de recuperar absolutamente todo lo relevante que a mí me interesa
contenido en el sistema, o sea que no me queden cosas por recuperar vinculados
a lo que yo quiero.
Este bueno, que tenga contenido semántico,
que la información se acuerente o sea el tema de integridad de la información,
y bueno, los aspectos de seguridad que no se pierdan con el tiempo.
Algunos ejemplos, a casi uno ya orientado a sistemas de información
pensando en tecnología.
Bueno, son los sistemas transaccionales,
hay cualquiera de lo que va a un JRP a un sistema de gestión de archivos,
soporte a partir de ahí, uno genera un montón de información.
Entonces, esa información existe en otros tipos de sistemas que serían los sistemas
para la toma de decisiones basados en data warga, hubo, etcétera.
Pensamos al día de hoy.
Hoy los sistemas basados en conocimiento que a grande rago podemos enumerar
como sistemas expertos.
Esto son simplemente algunos ejemplos, que se basan en grandes bases de conocimiento.
Entonces, podemos clasificarlos en dos tipos.
A veces hablamos de sistemas de base de datos o de gestión de datos,
de gestión de datos o sistemas de recuperación de información.
Por un poco lo que yo quiero tratar de mostrar la diferencia entre datos e información.
Nada, una definición para fijar ideas, un sistema de gestión de base de datos,
un software dedicado a servir de intenfasc entre la base de datos,
ilusuario y las aplicaciones, tiene un lenguaje de definición de datos,
un lenguaje de consulta, etcétera.
Bien, yendo a recuperación de información, también un par de definiciones,
la básica de Wikipedia, ciencia de la búsqueda de información en documentos,
la búsqueda de los documentos, de metadatos que describan esos documentos.
En fin, me interesa porque rescatar la definición de salto,
porque salto es un poco considerado el padre de la recuperación de información.
Disciplina en cargada la representación, porque aparte contextualiza bien el concepto.
De la representación, el almacenamiento, la organización,
y su posterior acceso y recuperación de esa información.
Entonces, en los sistemas de recuperación de información, el objetivo es muy simple.
Tengo un conjunto de documentos, tengo un usuario,
con una cierta, quiere investigar o quiere averiguar algo sobre determinado tema,
y sisto, estamos pensando en conjuntos no en la huevo que es heterogenea,
sino en un conjunto de documentos homogéneos y, bueno, y nada,
ayudarse de herramientas tecnológicas.
Entonces, lo que decía recién,
distinguamos lo que es recuperar datos de recuperar información.
Yo decíamos en un sistema de base datos,
yo tengo un lenguaje de manipulación, por ejemplo, de SQL,
que busca padrón, valor de una tabla que se llama padrón,
es que tengan mayores a tal valor.
En los sistemas de base datos, yo sé exactamente lo que quiero
y tengo o debería tener el conocimiento, el usuario,
el usuario, el conocimiento para precisar exactamente el tipo de datos
que quieres traer.
Cuando yo formulo una consulta en los sistemas de recuperación de información,
quiero saber sobre equipos uruguayos clasificados a las copas internacionales
en la última década.
¿Qué me va a traer eso?
¿Qué me debería traer?
Sí. ¿De qué?
Me va a traer de los equipos de base que volve, de los equipos de fútbol,
no estoy a decir la consulta.
Es bien distinta cuando yo conozco la tabla, la estructura,
mientras en el otro lado, yo no lo soy lo suficientemente preciso
para expresar lo que yo necesito, el tipo lo sabe,
y me va a recuperar todo lo que hablé de lo que estoy diciendo ahí.
Bueno, claro, pero si yo...
sobre lo mismo, no decíamos, no es lo mismo,
es lo mismo en dominio de la biología,
yo voy a decir el dominio deportivo.
Entonces acá tenemos el problema,
especialmente eso.
Entonces, un cuadrito que, de alguna manera,
muestra un esquema de diferencia entre los dos grandes sistemas,
en el de base de datos estamos pensando en un modelo,
esencialmente de talos, un modelo relacional,
donde los objetos son tablas, su modelo estructurado,
acá en los sistemas de recuperación son documentos,
texto, no es estructurado.
La operación básica es la misma, es recuperación,
de alguna manera lo que decíamos recién,
es determinista en el sentido de yo,
select, padrón y valor, voy directamente al campo que quiero recuperar,
en el otro lado, puse probabilístico,
con cierto grado de ser tesa, me va a devolver,
capaz que lo que quiero, más alguna otra cosa que tendría que ver
como lo filtro, etcétera.
Las consultas son no ambiguas y bueno,
en lo que veíamos recién,
al utilizar lenguaje natural,
en los sistemas de recuperación de información,
la consulta puede ser ambigua,
y la base es lo mismo.
Y este es que mita, de alguna manera,
plantea muy a grandes rasgos,
lo que es todo el proceso de un sistema de información retrieval.
Tengo ilusuario,
y por un lado tengo la base de documentos.
En cualquiera de los dos casos,
se realiza un procedimiento por el cual,
el usuario,
se realiza el determinado tipo de operaciones sobre las consultas,
antes de largar la búsqueda.
Después vamos a profundizar un poquito más,
pero por ejemplo,
cosas que seguramente ya han estado viendo en el curso,
si empezamos en el ejemplo que teníamos recién,
de quiero los equipos,
que si yo el quiero,
no lo voy a considerar,
los artículos no lo voy a considerar,
es decir,
tendré que operar, ver de qué manera represento
yo las consultas,
antes de largar la búsqueda.
Por otro lado, lo mismo con los textos,
es decir, yo tendría que tener un criterio
por el cual voy a representar esos textos de mi base documental,
o sea que voy a tener que manipular esos textos
y hacer ciertas operaciones,
hasta indicar.
Y eso es lo que yo busco.
Objetos dentro de una base con cierto índice,
voy a decir algo de índice,
lo ideal es que esos documentos me los ordenen de alguna manera
en función de cierto ranking,
cierto grado de relevancia,
y hay una primera evaluación del resultado.
Dependiendo del modelo que uno tenga,
esos resultados se tiran de una lusuario,
o podría eventualmente hacer una retroalimentación
o agregar más términos de búsqueda
o reformular la consulta,
con lo cual el sistema vuelve a...
o se los presenta a la lusuario
o vuelve a largar una nueva lucha.
Pero conceptualmente,
ese es el esquema genérico de...
este tipo de sistemas.
Bien, empecemos a ver algunos de los problemas.
Quiero información sobre las batallas
de la Segunda Guerra Mundial que no se libraron en Europa.
Entonces,
mi mamá, que siempre le usamos en los ejemplos,
a la madre de uno,
el procedimiento de mi madre,
si esto, y yo le digo,
tenés que...
le explico lo que son las stop wars,
y que si yo...
esta tiene que sacarla,
ella va a poner,
y bueno,
lo queremos poner son los sustantivos,
no, claro, batalla,
Segunda Guerra Mundial Europa.
Es correcto esto.
Claro.
El procedimiento intuitivo parece ser razonable.
Es decir,
yo en largo,
este es una consulta con las palabras clave,
por decirlo de alguna manera
o los términos en donde
podría llegar a estar
los documentos de esa información.
Sin embargo,
tengo que manejar el concepto,
por ejemplo,
de la negación,
que justamente no son las que se llevaron a Europa.
Quiero las otras.
Entonces,
no es tan directo,
cuando uno quiere expresar una consulta,
o esa,
esas operaciones que decíamos recién hoy,
que hay que hacer cosas sobre las consultas, ¿no?
Entonces,
lo básico en
información,
en recuperación de información,
es muy simple,
dado un conjunto de palabras,
la consulta,
encontrar esas palabras en un documento,
de alguna manera,
y devolver los documentos
en los documentos
y corresponde
y en algún orden.
La simántica de texto y la consulta
se representan por un conjunto de términos.
Y bueno,
hay uno de los problemas
que ya seguramente
ustedes están imaginando.
Hay muchas formas de decirlo mismo.
Un mismo término puede tener distintos significados
en diferentes contextos,
hasta ahora,
por ahí estamos poniendo términos,
se estamos hablando de identificar
a los textos y a las consultas,
exclusivamente,
por el término.
Cuando tenemos términos
con más de un significado,
podemos llegar a tener problemas, ¿no?
Si no es preso de alguna otra forma,
en el dominio, ¿no?
Nada, ni que hablar de Apple,
lo banco,
yo que se ve ahí términos,
con más de un significado,
en contextos distintos.
Y después,
el otro tema es el predecir,
cuáles son más relevantes,
cuáles como va a mi sistema
a decir,
este documento es más importante que este otro.
Entonces,
yo tengo como dos grandes aspectos,
a tener en cuenta.
Por un lado,
elegir un modelo de representación,
como decíamos,
de las consultas
de documentos y la base de documentos,
y por otro lado,
diseñar algoritmos,
lo suficientemente,
eficientes,
para que me devuelvan esos documentos
en un orden aceptable,
o importante,
para mí.
¿Se entendió?
¿Sí?
Bien.
Entonces, vamos a empezar a hablar de los modelos.
Para definiciones bastante abstractas,
del concepto del modelo,
una estación de un proceso real,
o un esquema de un sistema realidad compleja,
que se elabora para facilitar su comprensión
y estudios comportamientos.
Es decir,
es un definición conceptualmente de lo que es un modelo.
Ahora, un modelo
en los sistemas de recuperación de información,
yo los puedo especificar
como esa cuadro plaqueta ahí.
¿Dónde yo tengo?
¿De qué es un conjunto de representaciones lógicas
de los documentos?
Sí, de todos los documentos,
¿cómo lo voy a representar?
Mi base documental,
cu que es el conjunto de representaciones lógicas
que modelan las consultas que yo voy a poder hacer?
Pues,
pensemos que en que yo podría tener
una, así como tengo una base de documentos,
yo podría tener prestablecidos,
un conjunto de consultas también.
Efe es un esquema operacional que específica
las representaciones de los documentos
y de las consultas.
Ahí tendríamos que ver
¿cómo cuáles son las operaciones que yo voy
a tener tanto en los documentos como en las consultas?
Y la R en las funciones
de ranking que yo les decía, ¿no?
Que valúe de alguna manera
esa relación que existe entre la consulta Kusubi
del conjunto CUBE consultas,
vinculada el documento de subjota
del conjunto de documentos.
O sea, la función de ranking.
Y eso es importante,
porque en los sistemas de cómo se recupera la información,
tiene mucho que ver,
tiene,
yo intoablemente también me vuelvo a la web,
pero por ahí capaz que,
para mí,
los documentos me lo devuelve de determinada manera
y está bien,
pero para vos no.
O sea, ¿hay todo un tema ahí de cuál es la mejor función
o el concepto de relevancia?
No es una definición muy exacta,
muy precisa y siempre hay cierto grado
de alguna manera de sujetividad en ese tema.
Bien,
entonces,
nosotros vamos a hablar
básicamente de los modelos
de los clásicos,
el buleano y el vectorial.
Vamos a mencionar algo, algo del probabilístico
y después,
hubieron algunos intentos
de mejorar tanto el modelo vectorial
como el modelo probabilístico,
que son utilizar redes neuronales
y redes,
redes bellesianas que tienen,
que es,
ambos son,
mejoras en algún sentido,
del modelo vectorial,
tanto las neuronales como las redes bellesianas,
y el LSI es como una extensión
del modelo probabilístico,
no arrojaron buenos resultados
y medio como que se descontinuaron.
Si hoy se usan las redes neuronales
y las redes bellesianas para otras cosas,
pero no para como extensiones de estos modelos.
Bien,
entonces,
modelo buleano.
El documento se representa básicamente
como un conjunto de términos.
En general,
uno lo es,
los términos que elige
para representar a los documentos
son sustantivos.
Entonces,
el concepto que deseamos recién
de si un documento va a ser relevante o no,
en este modelo es,
si está el término,
que es relevante,
si no está, no lo es.
¿Está?
El buleano,
sí o no,
está, no está.
La regla que rige al modelo buleano
es vocabulario similar,
el contenido similar.
Es decir, si yo tengo un documento
que tiene determinados términos
que lo identifican,
o si tengo dos documentos
que tienen los mismos términos,
el contenido es similar.
Y ya se las tiro para que la tenga pensando,
si eso no me cocina,
me puede llegar a ocasionar problemas.
Claro.
El problema que comentábamos hace un rato,
si yo tengo utilizo
el concepto,
yo que es ese banco,
está bien,
el banco para como término de identificación,
para mis documentos,
bueno,
el texto banco va a ser el banco de plaza
y el otro contexto banco va a ser el banco
del sistema económico,
que es eso.
Ya me estoy adelantando
a uno de los problemas,
obviamente, que tiene el modelo buleano.
Bien,
y se utiliza los operadores clásicos.
Entonces,
el modelo lo que haces
es solucionar eso,
el problema que te llamé mamá,
yo le digo,
mira,
voy a tener una forma de expresar
las consultas,
vas a tener que hacer una especie de ganálisis
del texto S,
antes de largar la consulta al sistema.
Entonces, ahí va a tener que interpretar
lo de que no fueron en Europa.
Además de poder utilizar,
por ejemplo,
si puse batallas y combates,
como términos similares,
porque si yo no tengo herramientas
que me ayuden al sistema,
es decir,
herramienta sado,
que yo lo hago,
tendría que poner conoz
todos los distintos sinónimos.
Me expreso,
me expreso,
lico.
Bien.
Ah, acá,
simplemente ejemplo,
yo tengo el documento para,
para poco,
fija la idea,
tengo el documento 1,
que dice,
de jardina,
hay plantas y flores todo el año,
a mi mamá,
nuevamente,
a dos le gusta que le regalen flores y bombones.
Entonces,
como decíamos,
los términos que se eligen
para identificar al documentos
en general son los sustantivos,
con lo cual,
son los términos en esta,
en esta colección de documentos formados,
por eso todos serían,
jardin, plantas,
flores,
año, mamá,
bombones.
Entonces,
decíamos que los documentos
los íbamos a identificar
por los términos,
si estaba o no estaba presenta
en el documento,
si estaba ponemos 1,
si no está poniendo 1,
entonces,
el documento 1 me quedaría 1, 1, 1, 1, 1, 1, 0, 0,
asociado,
a cada uno de estos términos,
y tal,
el documento 2, 0, 0, 1, 0, 1, 1, 1.
Si la consulta,
es,
yo quiero flores o plantas,
y mamá,
me va a devolver el documento 2,
pero si es preso,
plantas y jardin,
entonces me va a devolver el documento 1,
un ejemplo de cómo sería,
la asociación de documentos
y consultas.
Bueno, críticas.
Al principio,
cuando yo hablaba esa introducción,
hablé el concepto de relevancia,
y en lo que hemos estado viendo
del modelo buleano,
claramente vemos que lo primero que marco ahí es,
yo no hablo de más o menos relevantes,
porque fíjense que,
el segundo, el segundo,
que claro,
es indiferente si un documento contenga 1
si en vez de la palabra de la consulta,
además,
si yo,
en el mismo documento aparece 3 o 4 veces,
la misma palabra,
yo le pones solamente 1,
o sea, no se le da mayor peso
en función de la cantidad de ocurrencias
de la palabra dentro del documento.
Da lo mismo que se cumpla una o todas las cláusulas
en el caso de un or.
Ahora,
lo vemos con el ejemplo ahí.
Y no considera el casi.
¿Qué quiere decir?
Yo, por ejemplo, fíjense el ejemplo de acá.
Quiero investigar sobre los charruas y los guaraníes.
¿Cuál sería la consulta?
Claro.
Intuitivamente, la consulta de charruas y guaraníes.
¿Qué podría llegar a pasar?
Exacto.
Si yo pongo charruas en guaraníes,
me tiene que cumplir las 2,
ahora yo puedo tener un documento
que me abre de la historia de los charruas
sin que sea súper blah, blah, blah y me interesaría.
Porque yo quiero charruas y de los guaraníes.
Un documento cable exclusivamente de los charruas me sirve.
Entonces, ¿tiene ese tema?
Lo que hablamos hoy, el casi.
Yo que ese, el angle, lo que hace es,
me obliga a cable exactamente de los 2.
Entonces, aquello de lo intuitivo,
tal vez lo ideal sería usar un or.
Y como decíamos, no es institucivo para mí, mamá.
A favor de las primeras ideas que aún no se lo ocurren,
fue adoptado de hecho por los primeros sistemas
de recuperación bibliográficos.
Y bueno, como hemos visto es muy simple de formalizar.
de formalizar. Inmediatamente llevense al día de hoy, año 2016, aplicar esto en lo que
sería Internet. Bueno, es que los sistemas de bibliotecas se basan en estas cosas.
El sistema de bibliotecas de gestión de documentos de las bibliotecas se basan en estas cosas y
tiene esa dificultad, pues sí, recuerda. ¿Se entendió el modelo buliano? Después
apareció una extensión del modelo buliano, le llamaron modelo buliano extendido que le
agregaba algún operador más, agregaba un operador de proximidad de las palabras o ya consideraba
si este estaba cerca de este, agregaba más cosas, aparte de los operadores bulianos,
agregaba un operador de proximidad, pero una fracasó con total éxito. Bien, modelo
editorial. Muchos dicen, yo de lo que he estudiado, me incluyo en esa en esa barra, que saltó
en ese el padre, por decirlo alguna manera, de los sistemas de información retrieval. Con su el
modelo vectorial es el clásico en los sistemas de recuperación de información. El generó un
sistema llamado Smart. ¿Qué le sugieren? Claro, sí, pero no. Claro, porque ahora está muy de
modo de Smart, Smart City, nada, no tiene que ver. Smart is system, system, for de
mechanical, análisis, for retrieval, texto. Es era Smart, no sé, en el 60, claro, en el
80, en el 60 no estaba como el concepto de hoy. Bien, el sistema Smart se selecciona un conjunto
de palabras o términos útiles para discriminar, eso es lo mismo que veníamos manejando hoy. Lo que le
agrega es el concepto de grado de similitud entre consultas y documentos. Ahora vamos a hablar sobre
eso, que de alguna manera lo que hace es expresar la relación entre cada documento de su
híde, una colección de n-documentos con el conjunto de los catárminos elegidos para indexar.
Yo elijo, fíjense que en el ejemplo de Boolean, el tipo agarraba todos los sustantivos de todos los
documentos, y chao, ponía un o cero o un o cero para el documento. Estuvieron, nos tuviera,
acá el tipo dice para, no vamos a tomar las 320 sustantivos que hay, vamos a elegir K y sobre
los oscados, que hay que ver cuáles son, sobre esos K es que vamos a representar a los documentos.
Bien, los documentos y las consultas, entonces son victories de un espacio indivencional,
te sube, te sube, te sube, te sube, se alcante el conjunto de términos, te sube una de sus
dos de subjenes el conjunto de documentos, eso es un espacio indivencional. Entonces un
un documento de su jota, se modela como un vector, W1 j, W2 j, W1 j, donde a cada término
I, en un documento de su j, se le asigna un peso W1 j, o sea, alí entre unicano, fíjese
que el tema va a ser, bueno, ¿cómo asignó los pesos? El buliano que era la que cidad, ¿eh?
Estable, está, el peso era uno o cero, acá el tipo lo que propone es una forma distinta de
ver el término si es relevante o no dentro del documento. Entonces, lo clave, o una de
las claves fuertes del modelo vetorial es el tema de la asignación de pesos. Bien, algunas
definiciones de fí es la cantidad de documentos que contienen ahí y por otro lado definimos I de fí
que es la frecuencia inversa del término I, está un poco más que nada para, solento términos
de atenuar la cantidad de veces que aparezca un término dentro de los documentos.
O sea, que es de fí es la cantidad de documentos que contienen ahí y de fí es la frecuencia inversa.
Ejemplito, estamos hablando ahora de los documentos y las consultas son vectores.
Supongan que el documento I, los pesos son dos tres cinco, o sea, está representado por la
eterna 2, 3, 5, el documento 2, 3, 7, 1 y la consulta Q, 0, 0, 2, elegí eso, en tres
dimensiones me manimaba hacer el dibujito, ¿no? Un dato que sí podemos inferir, seguramente
se animen a inferir de la consulta 2 con respecto a los términos que estoy utilizando,
¿qué significa? ¿Qué seguro va a significar el 0 y el 0? ¿Qué significa el 0, 0 en
la consulta? ¿Qué eso? Que esos no los, en esta consulta Q, esos dos primeros términos
no los estoy utilizando, o sea que en realidad esta consulta la expreso como un vector también
porque la consulta se expresa sobre los mismos términos en que se indexan los documentos,
que se eligen para representar los documentos. Entonces lo que estoy queriendo decir ahí es
que la consulta Q solamente contiene el término 3, el tercer término. Lo que me falta
ahora es, tengo los documentos y tengo de alguna manera, así es, los pesos esos que
están ahí, lo que tengo que ver es, ¿cuál documento es el más parecido a Q?, ¿cuál
es el de los dos?, ¿cuál es el que me debería de volver el sistema, por lo menos este
primero? Entonces los términos más frecuentes en un documento serían mejores indicadores
del tema del documento, eso es una bastante razonable, si hay un documento que hable
muchas veces determinada cosa, ese término debe ser pesado ahí adentro. Pero por otro
lado, si hay un término que aparece en muchos documentos distintos, por ahí no me sirve,
porque si todos hablan, elijo un término y todos hablan de lo mismo, voy a tener poca
forma de diferenciarlos, entonces ese capaz que no lo he dicho. Habíamos definido
I de F e I de F, acá definimos F i j, cantidad de ocurrencias del término I en el documento
J y definimos el concepto de T F, T F i j, ¿cómo? La cantidad de ocurrencias del término
I en el documento J dividido el max de F i j, eso para que lo hacemos, ¿eh?, para
normalizar, exacto, para justamente el tema de que tengan muchos elementos de alguna manera
atenuamos justamente el crecimiento del valor F. Bien, existen varias fórmulas para
asignar los pesos, la primera aproximación, la misma que sea el modelo buliano, el tipo
estábano está poniendo uno o un cero, ¿eh?, si aparece el término I en el documento J,
el valor del I de F i j va a ser uno y en caso contrario cero, esa es la primera aproximación
del mundo vector y ponemos uno cero. El término I puede aparecer más de una vez en el
mismo documento de J, o puede considerarse como más significativo que otra, entonces el
donleve subijotas un poquito más sofisticado, porque queremos introducirles justamente
todo esto que estamos diciendo. Entonces, un indicador típico de la importancia en un
esquema de modelo vectorial es el que sigue el concepto llamado T F i de F para la asignación
de pesos, que es simplemente el peso de cada uno de los términos se calcula en función
del T F y el I de F de ese término dentro de la base de documentos. Y acá hacemos
un ejemplo para fijar bien esos conceptos. Supongan sí que tengo un documento que quiero
allá al subector, los términos son ABC, ese documento, el término A parece tres veces,
el término B aparece dos veces y el término C una vez. Mi base de documentos son 10.000
y la cantidad de documentos que contienen a cada uno de los términos son, hay 50 de esos
10.000, hay 50 documentos que contienen el término A, hay 1.300 que contienen el término
B y hay 250 que contienen el término C. Entonces, para allá el vector asociado al documento
del primero de todos, lo que hacemos es calcular el T F i de F para cada uno de los términos.
Entonces, si se acuerdan, el T F era el F, la cantidad de ocurrencia que aparecía el
elemento, dividido el máximo de todos los Fs, el máximo de todos los Fs, 3, 2, 1,
el máximo a 3. Entonces, el T F de A es 3, 3, 1, el T F de B es 2, dividido 3 y el T F
de C es 1 y 3. Y el IDF era la fórmula que ya al logaritmo de N, que era la cantidad de documentos
de la colección, dividido la frecuencia con la cual aparecían dentro de esa colección.
Entonces, el IDF del término A es el logaritmo de 10.250 que da 5.3, el logaritmo del B es, bueno,
la cuenta da 2 y en el caso del C da 3.7, o sea que el vector sería 5.3, 1.3, 1.2, ese sería
el vector asociado al documento que tenemos allá. ¿Se entendió? Bien, una vez que tenemos cada
documento con sus pesos y la consulta tiene su vector de términos con sus correspondentes de
pesos, lo que tenemos que ver ahora es, bueno, la similitud entre cada uno de documentos
y la consulta. ¿Cómo comparamos? Ahora, aquella pregunta que decíamos, ¿cuál del Q siempre
más parecido al 1 o al 2? Entonces, esto es de la medida de similitud que es introducida por
Salton, una medida de similitud es una función en realidad que lo que hace, lo que ve es la distancia
entre dos vectores, esencialmente eso. Usando este concepto de grado de similitud, yo voy a
poder ranquear todos los documentos recuperados en función de un cierto orden, y tal, además,
de fijar un umbral, pues decir, bueno, aquello que me den por debajo de tanto, eso ya
ni lo muestro, calos, considero que no son relevantes. Bien, nada, el cálculo del
similitud es la distancia cosena entre dos vectores y es el producto de los pesos de cada uno
de los vectores. ¿Por qué es una sumatoria? Entonces, la sumatoria de 1 a n, entonces, uno
de esos sumando me va a dar 0, entonces, que era el caso del cubo, no importa con qué,
o sea, ¿qué es lo que estamos diciendo en el ejemplo este? Que la clave va a ser el
término 2, ese es el que me va a decir, lo demás no me interesan. Para esa consulta,
el 2 es el que me va a determinar, perdón, el tercer término, ese que me va a determinar
si el documento 1 o el 2 es más parecido a la consulta cú, que es lo tengo por ahora,
el ejemplo que teníamos hoy es 2, 3, 5, 3, 7, 1, 0, 0, 2, cuando calculo la similitud
de 1 con cú, lo que deseamos recién, ¿no? Tu pregunta, 2 por 0, 3 por 0, o sea, este por
este, este por este, este por este, 5 por 2, 10, y este 3 por 0, 7 por 0 y 1 por 2, 3 por
0, 7 por 0, 1 por 2, o sea que este medio 10 y este medio 2, de acá que deducimos, de que
de 1, porque es el de mayor grado de similitud, es el más grande, de 1 es más parecido, o tiene
más de lo que yo quiero con respecto a la consulta cú, ¿yes? Ventajas entonces del modelo
vectorial, es simple, no parece ser demasiado complicado, tiene una sólida base matemática,
mejora el tema de la recuperación, gracias a la asignación de los pesos,
considera tanto ocurrencias locales al documento como globales a la colección de documentos,
lo cual no es una cosa menor, un documento puede ser recuperado en función de una coincidencia
parcial, el tema que hablábamos hoy en el ejemplo de los guaraníes y los charrugas,
en lugar de predecirse un documento eso no relevante, pero porciones, el concepto de grado
de relevancia o grado de similitud, los resultados los puedo devolver ordenados por justamente
por esa relevancia, y tal bueno, salto un comprobodo de que el modelo era igual, funcionado.
No todo es maravilloso, acá vemos ejemplos, documento 1, un perro ataca a un niño con un virus,
documento 2, virus ataca al perro de un niño, no vean el segundo, veamos el primero,
esos documentos en principio tienen 100% de similitud, tienen la misma cantidad de,
estamos en ejemplo muy intrivial, documento que está formado por una suegación, pero bueno,
perro, niño y virus, virus, perro y niño, no importa el orden, aparecen los dos con el mismo
cosa, en principio los dos son iguales, y lo voy a decir, un perro ataca a un niño con un virus,
el virus es el del niño o el virus es el del perro, virus ataca al perro de un niño,
el virus ataca al perro, acá, ahí sí, no, esta más claro, fíjese que igual tenemos problemas,
porque en principio los dos son iguales, ¿eh? A bueno, ahí he ditito, yo estoy tirando los
problemas que podemos llegar a tener, si hubiera uno, tenemos que ver cómo lo represento,
pero si ya teníamos problemas con el primero, fíjense el segundo, el segundo ejemplo,
el banco de la plaza está pintado de rojo, en rojo quedó la plaza luego que el banco pebró,
de vuelta, estamos, tenemos el problema de, en distintos contextos palabras, términos que
pueden decir cosas distintas, entonces capas que en el primero por ahí pasa de que los dos,
pero en el segundo no me lo podría devolver a los dos, y para él sería lo mismo,
entonces, problemas que tiene, sin duda el modelo vectorial es, carece de información sintáctica,
el orden de las palabras, las relaciones entre los términos, la proximidad, decir si una
palá, un término está más cerca de otro, eso puede ser importante, y esto no, y yo no lo
puedo reflejar aquí, por lo menos con lo que estamos viendo, ¿no? El ejemplo recién que decíamos
el banco, existencia de ambigüedad semántica, un mismo término puede tener distintos, distintos
definiciones, distintos conceptos, ahí no, ahí no era la sinonimia, no hay nada que, en el caso anterior,
perro, y podría haber otro lado de can, y en realidad estamos hablando de también el mismo animal,
yo que sé, no me lo reconoce. Los modelos, o sea, bueno, que yo les dije hoy, al principio les
hablaba de modelos alternativos, les deablé neuronales, neuronales, vallesianas, es lo que hacen,
es, en vez de utilizar términos para indizar, utiliza conceptos, y el tipo hace como una red donde
activa los documentos que tengan tal concepto, o sea, trata de manejar, o sea, trabaja con un
grafo, y lo que utiliza son conceptos, o sea, ayuda de otras herramientas, o sea, en vez de,
o sea, entre perro y can, elige uno de ellos, y de alguna manera hace que cuando yo diga perro,
dispare, o active, aquellos documentos que hablen de sinonimos, por ejemplo, o sea, que las
neuronales y las vallesianas es lo mismo, pero con otra función de los pesos, pero los dos tienen
la misma idea, manejar conceptos y no términos. ¿Se entendió el modelo vectorial?
Bien, y algo del modelo probabilístico, fue un nuevo paradigma teórico para los sistemas de
recuperación de información en la década de 70, fíjese que salta una pareció con el
vectorial a fines de los 60, acá una de las autora de las actores, de los investigadores
principales, es Sparchons, fue una de la Cannons Sparchons, una de las colorados, de qué
universidad era, es el que la que empieza a investigar hay más, Taku, para también hay otros
autores más, pero Sparchons es de las más reconocidas que he trabajado sobre el modelo probabilístico,
y el problema es de este modelo que en teoría está bueno, es que presupone la existencia de que
existe un conjunto ideal de documentos relevantes, o sea que parte de una suposición y le asignó
una probabilidad de que exista el conjunto óptimo que me resuelve tal consulta, entonces
la tira, el tipo va funcionando, va a tirar la consulta, la compara con ese conjunto óptimo y
si no le da, trata de reformular, o sea lo que sí es importante que introduce el modelo
probabilístico es el concepto de relevance feedback, es decir, interacción con el usuario,
te devuelvo esto y si no es igual a lo que yo quiero reformúlo, cambio y largo de vuelta.
Lo crítico es determinar las propiedades que marcan la relevancia de un conjunto ideal,
ok, lograr una aproximación al conjunto de probabilidades a partir de una suposición inicial
de propiedades e ir refinando con el usuario luego de la consulta, especialmente el problema
sustancial es que con morraro, yo sé de antemano cuál es mi conjunto óptimo, con cierta
probabilidad y si ya se conjunto óptimo para que lo va, bueno, pero está, nada, acá
simplemente una idea, una definición muy básica de probabilidad, la probabilidad p de aparición
de un suceso es en total de n casos posibles, igualmente, factible es el cociente entre
el número de ocurrencias H de dicho suceso, entre la cantidad total de casos, esto es
repasito fácil, pero bueno, el objetivo es lo que decíamos tratar de refolvurar la consulta
sucesivamente utilizando ponderación de términos, es decir, cambiar modificar la asignación
de los pesos a los términos de la, o sea, que se cambia la consulta, ¿no?
¿Cuáles son los problemas? Bueno, he dado una consulta acuy, un documento de jota de la
colección, el modelo probabilístico estima la probabilidad de que el documento de jota
sea relevante para el usuario, el modelo asume que esta probabilidad de relevancia depende
solo del documento de la consulta y para mí la mayor dificultad es que asume que hay un
conjunto R de documentos que el usuario prefiere como respuesta a la consulta Q, o sea,
asume que sí te se conjunto R y trato de llegar a él, tema es que parte de la base que
ya lo tengo, entonces es como raro. Bueno, lo que plantea no es una simplificación muy
sencilla, que pone cero y uno a los términos de la consulta para arrancar, y bueno, y en función
de eso después va cambiando. Y la similitud entre un documento de jota y la consulta,
ahí usa valles, la formula de valles, R es el conjunto de documentos conocidos o inicialmente
supuestos como relevantes, y reprimas el noto, el opuesto, el complemento, y si, bueno,
la probabilidad de los documentos de jota, del conjunto R de documentos relevantes para
consulta Q y la probabilidad de que el documento de jota no sea relevante a la consulta Q,
o sea que esté en el conjunto de los reprimas. La similitud se define entonces la similitud
en el conjunto, en el modelo vectorial, la define como la probabilidad condicional, esa,
que si operamos y jugamos un poquito con valles, me da que la probabilidad de jota,
dado R, sobre la probabilidad de jota, dado, reprimas, o cual, vamos. Ventajas, por ahí decía
la asignación de los pesos a los términos, no me queda tan claro, claro, arranca con
0 y 1, entonces por ese lado es muy sencillo. Lo que sí está bueno es la idea de esa de
interacción con el usuario, que el usuario trata de refinar la consulta, ahí que ordena
la función de ranking en base a las probabilidades. Contras, no toma en cuenta que sé que no
hable para nada del DF, no de la frecuencia del término, no toma en cuenta todos los elementos
del documento, asume independencia en los términos, necesita una hipótesa, para mí es la
clave esto, necesita una hipótesa inicial que no siempre es acertada de cuál es el conjunto
R de documentos relevantes, cuál es el R de partida, y claramente es poquititivo y
lo tuvo en definitiva por el resultado. Se tendió la idea de modelos. Bueno, ahora veamos
por qué estamos hablando de este tema en el curso de intropelén. Problema común es este
que tenemos acá, ejemplo muy clásico, este ejemplo se lo veaba a esa ya, es un chileno
que trabaja en Yahoo, uno de los padres contemporáneos de Infomarcial Retribal. Consulta guerra
fría y el documento habla de la crisis de los misiles cubanos. El sistema no tiene ni idea
de que estas dos son parecidos, que estas dos cosas están relacionadas a priori no tendría
por qué saber que esas cosas están conceptualmente, el sistema no lo considera, porque no maneja
esas cosas. Es más, capaz que si yo largo guerra fría el tipo me va a hablar de volver
cosas de ladera, yo que se invierno, ¿por qué? Porque es más parecido e intuitivamente
fría, no sé. Entonces, bueno, nada, la solución a este tipo de problemas o lo que se empieza
a incorporar es hacer análisis lingúístico. Entonces, cosas que han estado viendo en el curso
como lematización, el steaming, tratar de reducir los términos a la raíz, el etiquetado,
cosa de poder distinguir si es un verbo sustantivo, militar, yo que se no, es verbo sustantivo.
Entonces, no es lo mismo, es este término en una consulta o en un documento, o sea que
es importante el tag que identifique, por ejemplo, la categoría de cada una de las palabras,
es detectar frases comunes, el ejemplo de guerra fría y lo misiles cubanos, la ayuda
de tesauros, bien tesauros y el concepto de tesauros lo manejaron, es como, pero no es
un diccionario que tiene mucha más información, no solamente de la definición, sino de relaciones
entre los términos, y piperónimos o ponimos, por ejemplo, Warner, exacto. Entonces,
herramientas como el uso de tesauros nos ayudan, también el uso de la estructura del texto,
es decir, si un término aparece en un título, o sea, título, primer párrafo, abajo,
sí, si yo tengo información de ese documento, si es de un título, si es un párrafo, si
está abajo, si está en el medio, eso me puede ayudar a mí a orientar a la hora de asignar
pesos o saber si en términos más relevante o más importante o no, para identificar
un documento. Bien, volvemos entonces al tema de recuperación de información, para hablar
de bueno, ¿cómo evaluamos un sistema? ¿Cómo sabemos si está bueno o malo, si me devuelve
lo que yo quiero o no me devuelve lo que yo quiero? ¿Cómo se hace? Paramos todos los
documentos contra todos, entre sí, hasta donde miren la lista de documentos relevantes,
eso que costo tiene, es posible o no es posible, la lista, además de los documentos, puede
cambiar con el tiempo, puede ser algo muy dinámico. No es lo mismo que yo ahora, una consulta
sobre los documentos que hablen del presidente de Uruguay ahora, que hace tres años, los
documentos que me deberían ver son otros, que intiene que ver con lo de la cualidad
de los sistemas de información que hablamos al principio. Entonces, la evaluación no
es una cosa, lo que quiero decir, lo que quiero transmitir con esto es que la evaluación
no es una cosa fija, sino que puede cambiar en función de varios factores. Y una cosa importante,
si ya de estas cosas tienen un componente humano. Entonces, lo que decíamos, creo que
pusimos un ejemplo, por ahí un documento para mí es importante y es relevante, pero para
aquel no. Entonces, puede haber distintos criterios para los evaluadores de un mismo
sistema, así como probablemente lo hayan comentado en el curso, cuando yo quiero trabajo con un
cuerpo, si quiero etiquetarlo, rotularlo de alguna manera, por ahí dos no nos ponemos de acuerdo
en si está lo cual, ¿no? Con qué peso le damos, en factor humano sigue siendo importante
y clave entre todo esto, por suerte. Bien, bueno, ¿qué significa este término de relevancia
que hemos estado hablando? En recuperación de información, ¿no? A relevancia es importante,
destacado, en fin, pero en recuperación de información un documento es relevante cuando
su contenido posee alguna importancia relativada a la consulta. Es ese concepto para mí de relevanza.
Esto haya positivo de tener 20 años, fácil, ha sido de las primeras que hicimos cuando
dimos algún curso de cosas de hace muchos años, en más yo no sé si no la hizo dinas,
pero está bárbara, porque en realidad marca los problemas o el universo de cosas que surgen
al momento de recuperar, yo tengo una gran base en un universo de documentos, todo lo que está
ahí en azul y lo ver son los documentos recuperados, pero de acuerdo a mi consulta, los relevantes
son las de las estrecitas. Entonces, ¿qué es lo que me puede pasar cuando yo la alguna consulta?
¿Qué me quede? Claro, que haya ausencias, ¿no? Que me falten o que recuperen cosas que no
tienen ningún sentido. Lo que hablamos, el ejemplo de la, me recuperen cosas de la de era cuando había
hablado de la guerra fría, ¿no? Entonces, estas son las dos medidas clásicas utilizadas en
recuperación de información, que son precisiones y recol, que es el cociente entre el
precisione, el documento recuperado relevantes sobre la cantidad de documentos recuperados y
el recol, la exactividad es el cociente entre los documentos recuperados relevantes, o sea
el cociente es el mismo, sobre la cantidad de documentos relevantes. Lo ideal en un sistema
ideal es que tanto precisione como recol sean uno, el ideal lamentablemente en general, no
se da, y uno cuando hace este tipo de sistemas, lo que trata de hacer es bueno darle más, cuando
quiere mejorar la precisione por lo general, tiende a bajar el recol. Este es un cuadernito
como está eso, no? Precision y recol, lo ideal es allá, el uno a uno, que le ha doce a uno a uno,
el recol en uno es casi todos los documentos relevantes de la colección, pero recuperen muchos
irrelevantes, y en el precisione uno es podos costos documentos relevantes, pero no tengo documentos
irrelevantes recuperados. Entonces, bueno, a veces me pueden quedar muchos documentos afuera,
por eso es que se lo recol tampoco es bueno, y uno trata de, bueno, manejar ambas medidas.
También la otra es la F, la F es cor, la medida F y la medida E que son una ponderación de
ambas de la precisione y el recol, la medida F, la diferencia es que la F es 2 por PR y
P más R, y la E lo que hace es agregar un factor, un factor real entre 0 y 1, el VTS, que le
puede dar más peso a uno o a otro, a la precisione en este caso, para si yo quisiera cambiar algo.
La persona esencialmente variante de las alternativas a las dos medidas. Bien, entonces para evaluar
un sistema de recuperación, lo que yo necesito es, o sea, yo tengo un conjunto de documentos,
tengo una consulta, en definitiva lo que yo tengo que hacer es haber si es bueno o malo,
testiarlo contra algo. Entonces, se fija un conjunto de documentos, un conjunto de consultas,
se hace lo que decíamos hace un rato, un etiquetado humano de cada documento fusion de la
consulta, en general son juicio binario, es buena o no es buena, la consulta y bueno y lo largo,
largo un sistema, o sea, yo pienso un modelo, pienso un sistema, pienso todo el algoritmia,
mi función de ranking, etc. y lo testeo. La conexión desde este o, conjunto de documentos,
un conjunto de consultas, tengo el algoritmo ese mío testiar y bien, en función de eso
se valúa. Estas son algunas, algunas colecciones de la más usada, fíjense en lo que decíamos
desde el principio, estamos hablando, todos los conjuntos o estas bases son documentales,
están asociados, tienen asociados un dominio, son particulares de un dominio, por eso
no estamos hablando de la web, donde es heterogénio, esto es modo referencia, bien, y lo que
sea, si yo quería agregar esto, lo que se hizo fue lo que se llaman las conferencias
trek, de text retrieval conference, que existen desde el año 1992 hasta el día de hoy
se siguen haciendo, o sea, lo que hacen es involucrar a la academia, a la industria, al
gobierno, porque no sé si saben lo que dar para honestos, la silla d'arpa, de petro,
dirección, bueno, ese es el departamento de defensa de los Estados Unidos, cinemas lejos,
no me acuerdo la silla igual es, pero es del departamento de defensa de los Estados Unidos,
o sea, el área tecnológica del departamento de defensa de los Estados Unidos,
de hecho fueron los, de ahí surge el proyecto ARPANET, que es de alguna manera el precursor
de Internet, y o sea, la conferencia es entre que la patrocinada por DARPA y NIST, que es el
instituto de normalización de normas técnicas de los Estados Unidos, como decía, existen
desde el año 1992, todavía se siguen haciendo, o sea, que lo que hacen es tratar de mejorar
eso, tengo una base de documentos, tengo un conjunto de consultas, hagan algoritmos para ver
qué cosas se pueden recuperar, y eso es eso, esas competencias y sitios se siguen haciendo,
creo que la del 2016, no sé si ya se hizo, o se hizo hoy va a ser, creo que eran
mar y la en Estados Unidos, bien, entonces hablamos de modelos, hablamos de evaluación, brevemente
vamos a comentar algo de índices, recuerdan que cuando planteábamos al principio el esquema general
de un proceso de recuperación de información, tenemos por ahí, por acá teníamos el dibujito
de la base de documentos, que se hacían ciertas operaciones sobre esa documentos, y esos documentos
se indizaban, entonces bueno, lo que tenemos que pensar es cómo es que construimos esos índices
para identificar a mis documentos, la estructura más simple es la denominada índices invertidos,
que salgo muy trivial, un vocabulario, que es un conjunto de términos, que aparezcan en el texto,
y asociado a cada uno de esos términos, como si fuera una raíz de términos, y una lista
asociada a cada uno de esos elementos de la raíz, que tiene los id de cada uno de los documentos
donde aparece ese término. El esquema de construir de construcción de un índice invertido es algo muy
sencillo, tengo el conjunto de documentos aserindizados, hago una tokenización de esos documentos para
dar los términos, con algún criterio en interesa cual, llevo a goesteming para llevar a la raíz
de general uno usa cuatro caracteres, pero podría eventualmente ser más, y da a la forma canónica,
no, no se olviden las mayús, los infinitivos, y general algo de este estilo.
Vento autos y camionetas, entonces Vend, ahí no me puse los cuatro elementos del estéming, pero bueno,
el documento de uno, de todo lo que aparece en acá, el Vend, o el de Vender aparece solamente en el de uno,
auto aparece, acá aparece autos, autos, autos, autos, y acá auto, pero si la forma canónica sería auto,
y aparecen todos esos documentos, o sea, no importa si están pluralos en singular, la lista de posteo,
la tenia, y bueno, a partir de este sería la base de índices, o sea, de documentos indizados,
y el tipo el algoritmo tiene que tratar de acceder por medios de esos índices, que habitualmente
los en el espacio, la estructura de índices es algo así, con un 30% de lo que ocupa la base
de documental en su totalidad. Bien, y un poco lo que decíamos, al momento de general proceso de
indización, hay que hacer esas cosas de análisis lingüístico, porque hay que hacer transformaciones
sobre el texto, eliminar las stopwatch, porque esas términos no los voy a considerar como términos
relevantes a la hora de iniciar un documento, llevar a la alema, y hay que hacer, también
decimos lo que hay que ser una análisis conceptual, es decir, tratar de elegir términos asociados
a conceptos, si ven ahí en el ejemplito, no lo hice, pues sí, uno podría elegir el concepto,
empezando el auto y camioneta, uno que tuviera por arriba, o sea, vehículo, bien, vehículo,
y en realidad, yo lo que asoció es tanto auto como camioneta al concepto vehículo, o sea,
elegir conceptos más allá de términos, trabajar con grupos nominales, sobre todo,
yo que se es pensando en estado de sitio, frente a amplio, o sea, conceptos que no sean conceptos
y que no sean solamente un término, porque yo es lo que puede estar compuesto por más de una
palabra, y también trabajar sobre reconocimiento de entidades con nombres, es decir, en personas,
lugares, organizaciones que podrían ser también elementos a ser considerados en el índice.
Si, bien, entonces hablamos de información retrieval, y otra que anda por ahí es el clear,
que es lenguaje, cross-language, información retrieval, que significa, no importa en que
este escrita la consulta, a mí dame los documentos que hablen más allá de la lengua,
independientemente del idioma en el cual están escritos los documentos. Entonces, este es todo
un campo que existe en la recuperación de información, para nada trivial, porque bueno,
requieren a lo que vamos a estar viendo, pero fíjense que requieren de mucho trabajo que van desde
corpos paralelos, o bueno, ¿qué lo que tiene que hacer traducirla? ¿Cómo hacer para buscar en
español documentos que en realidad, o sea, vuelve a largar la consulta en español, pero te interesan
aquellos documentos que sean relevantes, pero que estén escritos en inglés, por poner dos
lenguas distintas, ¿no? Y bueno, ¿por qué surge y nada? Porque hay mucha información en
más de un idioma y hay interés en realidad de recuperar lo más importante, más allá de la
lengua en la cual está escrita. Como decíamos, sirve para eso, para acceder a la mayor cantidad
de información, pero también es usada para la traducción de documentos, es decir, yo podría
utilizar algunos algoritmos o estrategias en empleadas en clear para hacer traducción.
Bien, lo que decía, bueno, la consulta puede estar escrita en una lengua distinta de los documentos,
pero la pregunta es ¿y qué traduzco? Uno podría decir, bueno, lo mejor está traducirla
consulta, porque porque más quita, pero bueno, capaz que en realidad no de fíjense que si yo
traduzco la consulta, yo podría agarrar y traducir al principio todos los documentos que tengo en
mi base documental y eventualmente después tiene un costo muy grande al principio, pero después,
a la hora de la recuperación es bien directa. Es puede ser mucho más deficiente, o sea que hay que
poner en la balanza en función ¿qué es lo que yo quiero? Ahora, ¿qué es lo que me sirve más?
Ahora, eso lo puedo no hacer en función de los recursos lingüísticos que tenga, debería
tener diccionarios, tesauros, si tengo corpus paralelos o no, que se llevo los postadas,
de repente, con la ayuda de eso es que voy a poder elegir uno u otro criterio, y si esto
en términos de eficiencia. Ok, se tendió lo que es el concepto de lo que es el clear,
un poco la idea era que simplemente que tuvieran el patallazo del concepto para cuando lo
sí se veíamos adelante. Entonces, como decíamos al principio, como uno de esto de recuperación
de información, hoy no los setenta, como Salton, lo asocia, con el auge, con el auge de internet,
toda esta teoría de Salton y la barra del modelo vectorial, del buleano y del probabilístico,
como que estaba asociado a un corpus donde era muy dependiente del dominio, era un corpus
acotado, una base homogénea, ya la cosa con la web descontrola totalmente, porque justamente
estamos hablando de un universo, primero, estamos hablando de un universo de información enorme.
Yo creo que la barra de Sal, ni se imaginó, más allá de que la teoría sigue siendo la misma,
no se imaginó, con el auge de internet que va a surgir este tipo de cosas. Entonces,
estas son cifras que yo ya lo se había traído en el año 2012, pero hay ahí un número de
lo que se presume que se incrementan por año, lo cual asusta bastante. Más de 600 millones
de sitios web, más de 50 millones se agregan por año, o sea que bueno, si esto fue el 2002,
imagínense todo lo que tenemos hoy, más de 100 millones de blog, más de 70 millones
de sitios de estos hechos como press, más de 600 millones de archivos. Entonces, esto
que decíamos hoy de este bueno, la base de documentos, metir a los documentos más relevantes,
metir a son 10, son 15, son 20, esos plotas en la web, esos plotas. Entonces, lo que
se hizo y el... A ver, Google no fue el primer buscador. De hecho, uno de los primeros
buscadores era altavista y altavista se basaba en el modelo vectorial de Salton. Pero, claro,
como estamos diciendo, estamos hablando de la principio de la década en 90, con el
auge de internet esto que te peñamos siendo crecido tanto, que bueno, nada, que el tema
de identificar a cada uno de los documentos, de esos millones de documentos que existían
en internet, indizá a los efectos de eso y hacer todo el cálculo de similitud, entre
Consuelo Aguento, se hace, tornaba de una ineficiencia terrible. Entonces, bueno, nada,
la barra de, como es la RIPage y Brian, no? El otro que... De Google lo que hicieron
fue proponer el uso de clicks como una cerralder de relevancia, la cantidad de clicks que tenía
y referencias cruzadas de los documentos y ahí apareció el conocido PageRank como
algoritmo de muestra de la similitud de una consulta sobre el mundo de lo que es internet.
Acá también hay un nombre, una gráfica bastante vieja de uno de los primeros cursos de
información retrieval, que bueno, nada, que cuenta lo que es la web, tengo un montón
de información que es pública, tengo un montón de información que es dinámica, después
aparece cierta información que se mantica, hay cierta información estática, pero lo curioso
de este gráfico es que yo no tengo toda la web indizada, es que es como imposible
indizar absolutamente todo la web. Entonces, haciendo hoy como hicimos un cuadro de comparación
entre lo que era un sistema de base de datos y un sistema de recuperación de información,
me parecía que estaba bueno hacer un paralelismo entre lo que es, un sistema tradicional
de recuperación de información y lo que es el sistema en la web, ¿no? En los RIP
tradicionales, los documentos están bajo un dominio, o sea, los documentos son similares
en algún sentido, hablan del más o menos lo mismo en la web, tenemos documentos diferentes
de todo tipo, en la RIP tradicional existe cierto control terminológico, mientras que en
la web no, en la RIP tradicional la interfaz de consulta, yo hago un sistema que utilice
tal modelo, lo que sea, como contaba el Yasin, un sistema de biblioteca, la interfaz
es única, en la web yo tengo depende del buscador que yo tenga, tengo interfazes distintas,
o sea que no hay una homogeneización de ese tío, el conjunto de documentos en la
recuperación de información es bastante estable, más allá que yo pueda agregar algún
documento de la colección, lo cual te aniría a quintizar lo que es yo, pero es más o menos
estable, acá por lo que decíamos recién, hay una buena atiridad enorme, y bueno, si
el volumen de información en un sistema tradicional es grande, como veamos marcado hoy en el cuadro
que comparaba con los sistemas de gestión de base de datos, acá es enorme, por poner
otro objetivo, otro sustativo, y bueno, nada, algunos desafíos de los buscadores, la calidad
en la relevancia de los resultados, ser más o menos eficiente en la búsqueda, la información
malestrutura, hay en la web información malestruturada, información redundante, entonces la clave
está en tratar de ver cómo el buscador es capaz de filtrar eso, el contenido es muy volátil,
hoy está mañana la está, esto se conoce es bastante clave, esto se lo pueden imaginar,
cuando conoce la intención del usuario, cuando lanza la búsqueda, esto, bueno, hoy Google
ya lo, como que tipo ya sabe por dónde viene, que de alguna manera él tiene identificado
cuál es tu perfil o va definiendo tu perfil, y ya te sugiere, te sugiere cosa, cuál es
la intención del usuario, este, bien, y acá de alguna estadística me parecía interesante,
si el 80% de las compartir, el 80% de las consultas no utilizan operadores, ahora cuáles
pongan a ustedes, pongan a ustedes, piensen cuando hacen larga en internet una cosa, nada,
pongan una secuencia de palabras, por lo general, el 25% utiliza una palabra y el 50%
utiliza 2, y ya con eso larga la búsqueda, el 80% decía por ahí no utiliza regla de
ansiedad, es decir, no hay retroalimentación, o sea que como que el general le pega en
los primeros documentos, además de los primeros documentos en la primera búsqueda,
es decir, no tengo que refinarla y cambiarte al término en un 80%, eso es lo que decían
las estadísticas, y bueno, esta bien interesante, el 85% mira las dos primeras páginas de
resultado, yo creo que sería menos, la gran mayoría, creo que en la primera, ya, sobre
todo Google le pega bastante a lo que estoy buscando, yo hablaba de baezas llates y
quise compartir una frase de él, que es buscar el agua, no es un problema de recuperar
documentos, no, no es documento es lo que yo quiero recuperar en el agua, mecanismo
para entre las personas y las necesidades que se encuentran detrás de tus objetivos,
es decir, como me da filosófica la frase, no, yo lo que busco es un objetivo, sí tengo
un objetivo que encontrar y no un documento, si lo pensamos en lo que decíamos hoy,
yo busco información, quiero ver que hay en la vuelta sobre tal tema, no busco un documento
específicamente, y eso es un cambio de paradigma bien importante entre lo que es la
RID tradicional y la RID en la web, bueno y por último, ablar de extracción de información,
el objetivo de extracción de información es obtener la información relevante e ignorar
la irrelevante, el proceso es tratar de identificar, aquí ya partes del documento que
yo recuperé, las partes importantes o que a mí me interesan del documento y no tener
que leer absolutamente todo el documento, como un desafío, como un desafío, ya lo vamos
a decir, es como un complemento o debería de verse como un complemento a la extracción
de información, a los sistemas de recuperación de información, que lo tengo por acá, ¿no?
La idea es que justamente que se complementen, que yo por un lado tengo un sistema de recuperación
de información que obtenga todos los documentos que hablan de lo que yo quiero, entonces
yo tengo un proceso que hace eso, me extrae los documentos y luego un sistema de extracción
lo que hace es extrae y organiza la información que a mí me interesan. Con todos los documentos,
sistema de recuperación de información, me extrae aquellos que son relevantes, aquellos
que me interesan. Luego, los sistemas de extracción de información parten de ese
con la colección de documentos y a partir de ahí, o tienen datos, y vuelvo a hablar del
concepto de datos, porque la idea es tratar, si bien, yo lo que obtengo es información,
yo trato de esos documentos que están ahí, expresarlos de alguna forma que sean posible
de ser manipulados por humanos, inclusive, pero por algún sistema más fácil, más sencillo,
que en general, uno podría decir, un similar a lo que sería un esquema de base de datos,
pero lo que ponía por allá abajo es lo que yo tengo es una plantilla atributo valor,
o sea que los sistemas de extracción lo que hacen es tratan, yo tengo una plantilla de
cuales son los campos que yo quiero recuperar y en función, mi algoritmo, lo que tienen
que hacer es extrader del documento y completar la plantilla. Esencialmente, a grandes
rasgos, eso es lo que sería el sistema de extracción de información.
Para ejemplo, bien sencillos, si yo tengo un documento, estamos pensando en la medellidad
de facultad y ya hay que llenar en función de las licencias, así que yo hay distintas
formas de expresarlo mismo, pero lo que me interesa saber es quién, o sea, lo que yo
quiero saber es quién es la persona que se va a tomar la licencia, cuánto va a ser la
licencia y por qué motivo. Entonces, más allá de cómo este escrito el texto que
hable de la licencia de los funcionarios, yo lo único que extraigo de ese documento
es nombre, motivo y duración de la licencia. Entonces, acá se concede y dice, si hay
reglamentaria, el docente Juan Pérez, por un mes, mi estructura atributo valor, lo que
me hace la plantilla es que me va a determinar. Una licencia es una tarna, forma por nombre,
duración y este, y motivo, y lo mismo, bueno acá, o sea, está en escrita de manera distinta,
pero yo tengo que tener algoritmos, que de alguna forma extraigan justamente esos términos
y llenen en esa estructura. También, al igual que con la strec, con recuperación de
información, existían unas conferencias para evaluar algoritmos de extracción de información,
se llamaban las MOOC, las Messages Understanding Conference, celebradas entre el 87 y el 97,
también nuevamente patrocinada por DARPA y el gobierno de los Estados Unidos, comenzaron,
este es muy cómico porque las primeras MOOC en el año 87, el dominio eran sobre terrorismo,
o sea, los tipos querían buscar cosas, asociadas a terrorismo, lo llan quien hace nada,
de manera inocente, lo tiraron, y bueno, la gente trataba de extraer a ver documentos
que hablaran sobre terrorismo. Se les daba información que es lo que pretenden obtener,
que es la plantilla, lo que decíamos, los atributos, que iba a tener la estructura de datos
que iba a tener que completar infusión de los documentos, y bueno, para evaluar sus
avance, las medidas que ya habíamos visto para información retriba, o sea, precisión
recoge media F. Las MOOC dejaron de funcionar el el año 97, pero después se reactivaron
otras conferencias en el 2000, que se llaman las HACES, Automatic Content Extraction,
esa también durante el 2008, y a partir de ahí fueron sustituidos esas competencias
por las TAC, las text análisis conference que se celebran siempre con las conferencias
de Natural Language Learning, las con LL, es donde se hacen estas competencias al día
de hoy. Acá metí unas diapositivas sobre corpus, de corpus ya estuvieron hablando,
hemos hablado, así que las voy a pasar medio rápido, pero las quise poner por las dudas,
bueno, ya saben lo que es un corpus, cómo se construye un corpus, recopilación de un
conjunto de documentos, y hay que definir las características de sea, si es escrito,
oral, si es multilíngue, bueno, monolíngue, el tipo de texto, si es de prensa, si
aliterario, pues no es lo mismo. Podemos hablar de corpus, hoy hablamos en la huevo, hablamos
de la heterogeneidad, acá, podíamos hablar de corpus sobre un determinado dominio, si
está notado, si no está notado, en fin, nada, y a modo de ejemplo, creo que algunos
ya los estuvieron viendo en el curso, yo pensé que estaba funcionando de esto, bueno,
rápido, bueno, voy, nos terminamos, terminamos, algunos de los corpus está en inglés,
esos son algunos de los más importantes, algunos de los corpus en español, yo quise
destacar acá, estos son los conocidos, los de la Real Academia, el corpus de Mark Davies,
encore a Dese, este de Vervos, quería destacar algunos de los corpus, yo le puse nuestros,
porque son generados acá, distinto porque en general, para todo esto hay muchísimo, lo
deben de haber estado viendo en el curso, es muchísimo para el inglés y para otras
lenguas, pero para el español hay pocos recursos, y bueno, tratamos nosotros de generar
más recursos, entre los curs recursos que generamos en nuestros trabajos, es que muchos
surgen de proyectos de grado, proyectos de poblado, son el trabajar con nuevos corpus,
entonces tenemos un corpus de noticias estrellas en la web, es un corpus muy grande, se sigue
generando, creo que al día de hoy tiene uno, hoy contaban, el otro día contaban uno
puntos 6 GB de tamaño, o sea que es un corpus bastante interesante, el corpus fue un corpus
que surgió de un proyecto que hicimos con la gente de linguística, como más de 10 años,
como 15 años, que más que 15 años, pero más 10 años, y como producto de ese corpus,
un corpus pequeño, pero lo hicimos está muy bien etiquetado, trabajamos con la gente
de linguística, y bueno, y estos son corpus que han surgido en este último tiempo en el
grupo, el corpus de opiniones, el corpus de eventos, el corpus de presiones temporales,
y hay uno que hizo Matías hace poco de la Wikipedia en español, que está bastante bueno,
entonces yo no sé si tiene entre dos o tres sigo, una cosa así que está ponienta, perdón?
Sí sí, no, no, no, son corpus, yo lo metí dentro de extracción de información, porque
iba a volver a hablarse de corpus, son recursos linguísticos que tenemos, no sabía dónde
meterlo y lo metí dentro de extracción de información, pero en realidad no necesariamente
algunas cosas sí, los hemos usado para hacer el sistema de extracción. Todo eso venía
porque bueno acá le enfoque para la construcción de un sistema de extracción de información
o basado en conocimiento linguístico o sistemas entrenados automáticamente con el uso de
eventos estadísticos, hay aprendizaje de reglas utilizando corpus anotado, en fin, pero
son dos modelos distintos de construcción de un sistema de extracción. Los criterios
nuevamente lo mismo, disponibilidad lo de siempre, si tengo recursos o no tengo recursos linguísticos
no, posibilidad de escritura de reglas porque a veces se supone que esto funcionaba, ¿no?
Apaga, está mal, ha perdado la tecidad.
De probabilidad de los recursos, ya la posibilidad de escritura de reglas, a veces que si yo puedo
escribir las reglas, eso está bueno porque soy bien preciso, pero también no me puedo
pasar para el otro lado de escribir tantas reglas y lo hago tan particular que cuando después
modifico algo, ya no me sirve y tengo que ver a una nueva regla que me puede descuajar
y cariño a lo otro, pero bueno la parte de reglas es importante, si yo uso aprendizaje
automático, el hecho de que tenga datos de entrenamiento es clave, y el tema de performance
es otra de las cosas que es importante, a tener en cuenta cuando quiero elegir, esto
era un enfoque basado en reglas o basado en aprendizaje, ¿no?
Está ahí, y ahora sí, para liquidar es simplemente un ejemplo de lo que queríamos decir con
un sistema de extracción de información, esto es simplemente un dominio de inscripciones
de muebles, aterrenos, a expropiar, etcétera, el ejemplo es, es un ejemplo real,
montevideo, fecha, director de registro de propiedad de muebles, en suscriptos, escriban
o tal, cedula, tal, internet, es decir, yo tengo un documento que me habla de una expropiación,
yo lo que tengo que hacer es a mí me dan un conjunto de documentos y me dan una plantilla,
si pensamos en lo que como yo completo esa plantilla o esa estructura de datos, entonces
esa plantilla, ¿qué es lo que yo tengo que extraer de los documentos? Un número de referencias
porque todos los documentos deberían de tener un número de referencias, una fecha,
la inscripción, el escribano actuante, pal escribano, la cedula y el nombre, el nombre
del municipio, la ubicación, el padrón, la dirección, en fin, la inscripción, ¿qué
todos estos datos? Número, folio, todo eso aparece en cosas acá, con el escrito, con
el número tal, en la calle Solano Antuña, de esta ciudad, folio, tal, es decir, yo tengo
determinadas, mi sistema debería tener determinadas reglas, hay que ver como lo hago, se
escribo reglas o un gruelo hago, para en función de ciertas parámetros, extraer justamente
la información de ese texto, y completar esa planilla, entonces yo completo esa planilla,
tengo algo ritmos que completen esa planilla y nada, acá muestro, no seme mucho, pero
negritas, está lo que, justamente los datos que yo tengo que extraer, una fecha, no,
sin los documentos no tienen por qué estar todas las fechas en el mismo formato, o sea
que tengo que tener si fueran reglas o métodos de aprendizaje automático, tengo que
ver cómo distinto las fechas, los distintos formatos de las fechas, para el número de referencias
y tengo la palabra refa delante y dos puntitos, en fin, cómo identifico los nombres propios,
los números por ahí aparece otra fecha más, monte de videos y tengo identificado los
lugares, entidades con nombres, las direcciones, y tal, y una vez que corrí mi sistema, lo que
me tendría que hacer es una planilla con los atributos en cada uno de los valores, en
cada uno de los atributos, y bueno, eso es todo, alguna pregunta, fue en medio rápido,
disculpa, sí, sí, exactamente, solar recibo, por ejemplo, sí, sí, utiliza, es que en la web índices
invertidos, yo no sé, hay un curso de una compañera libertada, un curso de extracción de
información, de recuperación de información en la web, y ahí está la ley de Hip, pero índices
invertidos es la forma, por eso además lo quise presentar, en la forma, el mecanismo por el cual
se indiza los documentos en la web, muchas de esos productos utilizan ese modelo de indización
de documentos, es cierto, las preguntas, bueno, entonces terminó el curso y la semana que viene,
arrancamos con las presentaciones, bueno, gracias.
