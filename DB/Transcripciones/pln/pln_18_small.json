{"text": " La clase de hoy y la clase que viene vamos a ver el tema de traducci\u00f3n autom\u00e1tica y bueno vamos a arrancar por esto que se conoce como la nota de weaver o el memorando de weaver warren weaver era un matem\u00e1tico norteamericano de primera mitad de siglo 20 y el tipo trabaj\u00f3 durante la guerra especialmente en cosas de criptograf\u00eda en an\u00e1lisis estad\u00edstico de c\u00f3digos etc\u00e9tera entonces en un momento dijo lo siguiente dijo es muy tentador decir que un libro escrito en chino es simplemente un libro escrito en ingl\u00e9s que ha sido codificado en el c\u00f3digo chino si tenemos m\u00e9todos \u00fatiles para resolver casi cualquier problema criptogr\u00e1fico no ser\u00e1 que con la interpretaci\u00f3n apropiada ya tendr\u00edamos m\u00e9todos \u00fatiles para traducci\u00f3n el opinaba digamos en este memor\u00e1ndum que los c\u00f3digos o los m\u00e9todos que se utilizan para romper c\u00f3digos criptogr\u00e1ficos que son m\u00e9todos estad\u00edsticos se pod\u00edan aplicar al problema de la traducci\u00f3n autom\u00e1tica y bueno esto introduce algunas ideas clave como que puede existir un mapeo autom\u00e1tico entre un lenguaje y otro y que codificar de codificar en un lenguaje es an\u00e1logo a codificar de codificar en un algoritmo criptogr\u00e1fico y bueno el tiro esa idea en 1949 tom\u00f3 como 50 a\u00f1os para que esa idea madurara digamos y despu\u00e9s de 50 a\u00f1os los m\u00e9todos m\u00e1s utilizados hoy en d\u00eda son m\u00e9todos estad\u00edsticos que bueno que se basan un poco en estos principios pero claro en esa \u00e9poca era como muy dif\u00edcil ver qu\u00e9 era lo que iba a ocurrir entonces bueno vamos a ver un poco esta esta es la agenda de lo que vamos a mirar vamos a llegar m\u00e1s o menos hasta la mitad hoy y despu\u00e9s la clase siguiente y empecemos con un poco de historia de lo que es la traducci\u00f3n autom\u00e1tica esto empez\u00f3 como muchas otras tecnolog\u00edas como una tecnolog\u00eda militar con fines militares inicialmente era durante la guerra fr\u00eda era resultado de inter\u00e9s traducir r\u00e1pidamente y a bajo costo traducir entre el ruso y el ingl\u00e9s digamos a los norteamericanos les conven\u00eda poder traducir entre el ingl\u00e9s y el ruso y bueno en aquella \u00e9poca se imaginan lo que era los inicios de la computaci\u00f3n las computadoras eran caras en las lentas no ten\u00eda mucho poder de comput\u00f3 pero igual hab\u00eda como mucho optimismo de que en poco tiempo si va a poder resolver todos los problemas \u00edbamos a tener sistemas que iban a traducir b\u00e1rbaro y bueno era m\u00e1s o menos la \u00e9poca del desarrollo de la ling\u00fc\u00edstica computacional inspirado un poco en las teor\u00edas de chonsky estaba la idea que se pod\u00eda escribir reglas para todo y que a partir de eso se podr\u00eda llegar a hacer cosas muy muy buenas en particular para traducci\u00f3n hasta que en 1964 apareci\u00f3 el reporte al pac al pac que era un comit\u00e9 que estaba estudiando cu\u00e1l eran los avances en ling\u00fc\u00edstica computacional porque se estaba poniendo se estaba poniendo mucha plata en muchas esas cosas y eso se mostraron esc\u00e9pticos acerca de la traducci\u00f3n autom\u00e1tica acerca de los logros que se hab\u00edan logrado despu\u00e9s de todos esos a\u00f1os de meter plata y dec\u00eda bueno pero se puso mucho dinero pas\u00f3 en pasar muchos a\u00f1os pero todav\u00eda los humanos lo hacen m\u00e1s barato con mayor precisi\u00f3n m\u00e1s r\u00e1pido entonces como que para qu\u00e9 estamos gastando en esto como resultado de eso hubo un recorte de fondos especialmente en estados unidos para todo lo que es traducci\u00f3n autom\u00e1tica y esto fue parte de lo que se conoci\u00f3 como el invierno de la inteligencia artificial que un mont\u00f3n de proyectos de inteligencia artificial tambi\u00e9n no ten\u00eda buenos resultados entonces separ\u00f3 la financiaci\u00f3n que hab\u00eda para todo eso durante unos cuantos a\u00f1os entonces se detuvo el desarrollo de unas cuantas cosas durante unos cuantos a\u00f1os y bueno despu\u00e9s empezaron a resurgir de a poco pero despu\u00e9s de esto digamos en los 70 y hasta los 90 m\u00e1s o menos eso logr\u00f3 que la investigaci\u00f3n se frenara un poco en estados unidos pero empezara a aparecer en otros lados del mundo como por ejemplo en europa o en jap\u00f3n y ah\u00ed empez\u00f3 llano con con files b\u00e9licos sino m\u00e1s bien con fines comerciales entonces hab\u00eda necesidad de tener traducciones o por lo menos dar soporte a los traductores humanos con algunas traducciones aunque no estuvieran del todo bien pero bueno dar algunas traducciones de inicio para que los doctores pudieran los doctores humanos pudieran continuar adem\u00e1s las computadoras empezaron a bajar de precio a tener mayor poder de c\u00f3mputo y \u00e9sta fue como la era de oro de los sistemas de traducci\u00f3n basados en reglas y vamos a caer unos ejemplos sistemas distr\u00e1n que todav\u00eda se desarrolla aunque ya no est\u00e1 completamente basado en reglas y bueno y sistemas que se realizaron en jap\u00f3n y en europa y bueno o sea estos sistemas ten\u00edan fines comerciales y no tanto fines militares pero bueno fines de los 90 y despu\u00e9s del 2000 en adelante empezaron a dejarse de usar un poco los sistemas basados en reglas porque porque empez\u00f3 a ver mayor poder de c\u00f3mputo y mayor cantidad de datos disponibles especialmente con la aparici\u00f3n de internet empezaron a ver much\u00edsimos datos de texto disponibles y eso permit\u00eda construir buenos modelos estad\u00edsticos que pudieran explotar las regularidades de los idiomas entonces aparecieron distintos tipos de modelos estad\u00edsticos los primeros los que llamamos traducciones autom\u00e1ticas estad\u00edsticas el otro traducci\u00f3n basado en ejemplos y aparec\u00edan las primeras aplicaciones comerciales que funcionaban bien que utilizaban modelos estad\u00edsticos la primera fue lengua y luego los traductores que m\u00e1s conocemos hoy en d\u00eda el bing translate de microsoft y bueno el translate que probablemente lo conozcan lo hayan usado en alg\u00fan momento y son traductores que la verdad que hoy en d\u00eda se puede decir que funcionan bastante bien entonces bueno los m\u00e9todos estad\u00edsticos empezaron su boom alrededor del a\u00f1o 2000 y siguen siendo el estado del arte pero bueno primero vamos a ver un poco de lo que son los sistemas basados en reglas que eran estos primeros sistemas que mencionamos antes en 1968 un investigador de traducci\u00f3n autom\u00e1tica se llamaba pernar bocua hizo un relevamiento de todos los sistemas que se hab\u00edan construido m\u00e1s o menos por la \u00e9poca y los clasific\u00f3 todos dentro de este diagrama el dibuj\u00f3 un tri\u00e1ngulo que ahora se llama el tri\u00e1ngulo de bocua y bueno y en este tri\u00e1ngulo se ubican los distintos tipos de sistemas de traducci\u00f3n basados en reglas se ponen como escalones dentro de este tri\u00e1ngulo y los lados del tri\u00e1ngulo tienen como distinta interpretaci\u00f3n el lado izquierdo si yo voy subiendo por este lado en realidad lo que aumenta es la cantidad o el esfuerzo de an\u00e1lisis que tengo que hacer del lenguaje origen yo siempre quiero traducirlo en lenguaje origen o lenguaje destino bueno entonces de este lado aumenta el esfuerzo de traducci\u00f3n del lenguaje origen y si voy bajando del lado derecho aumenta bueno si voy subiendo del lado derecho quiero decir aumenta el esfuerzo de generaci\u00f3n en el lenguaje destino entonces qu\u00e9 quiere decir esto yo ubico distintos sistemas de traducci\u00f3n la traducci\u00f3n directa es simplemente buscar en el diccionario las palabras y traducir palabra palabra con poca informaci\u00f3n m\u00e1s entonces eso casi no necesita ning\u00fan tipo de an\u00e1lisis y casi no necesita generaci\u00f3n pero para que son de bien yo necesito ponerle muchas ganas a las reglas o sea las reglas de traducci\u00f3n tienen que ser muy buenas y tienen que tomar en cuenta muchos casos para que esa traducci\u00f3n llegue a ser buena entonces es como que la flecha de la transferencia la flecha de la traducci\u00f3n es mucho m\u00e1s larga en cambio si yo hago un poco de an\u00e1lisis por ejemplo lleg\u00f3 hasta el nivel de an\u00e1lisis intactico tengo un parcer puedo escribir otro tipo de reglas que pueden ser un poco m\u00e1s expresivas me resulta un poco m\u00e1s f\u00e1cil y despu\u00e9s si tengo un generador puedo llegar a traducir entonces si sigo subiendo de vuelta voy a necesitar mayor esfuerzo de an\u00e1lisis de generaci\u00f3n pero las reglas pueden ser m\u00e1s expresivas y m\u00e1s f\u00e1cil de escribir y probablemente la traducci\u00f3n sea mejor hasta que si llegamos al al v\u00e9rtice del tri\u00e1ngulo llegamos a la interlingua que es una especie de noci\u00f3n en la cual no necesito ning\u00fan tipo de transferencia vamos a ver un poco dentro de un rato de que se trata eso pero bueno empecemos a ver los distintos niveles de este tri\u00e1ngulo de bocua el de m\u00e1s abajo era la traducci\u00f3n directa es el enfoque m\u00e1s simple lo \u00fanico que necesito para este para este enfoque es un diccionario biling\u00fce yo quiero traducir entre los idiomas y necesito un diccionario que tenga la correspondencia entre palabras de un idioma y palabras del otro y lo que voy a hacer es traducir palabra-palabra o sea puedo agregarle alguna cosa extra como por ejemplo alg\u00fan reordenamiento local yo que s\u00e9 para traducir entre espa\u00f1ol ingl\u00e9s yo dir\u00eda que en espa\u00f1ol el nombre se sigue al adjetivo y en ingl\u00e9s en realidad lo hacen al rev\u00e9s ponen el adjetivo seguido el nombre entonces ese tipo de reglas simples se las puedo agregar al sistema y bueno el sistema funcionar\u00eda un poco as\u00ed yo tengo una oraci\u00f3n de entrada en el idioma origen mary didn't slap de greenwich le pasa un analizador morfol\u00f3gico bastante de superficie que no hace mucho en realidad simplemente me dice que esto era el verbo du en pasado y seguido por un not y bueno el resto de los tokens siguen igual y ac\u00e1 viene la parte de diccionario digamos lo siguiente que tengo que hacer es buscar en mi diccionario cada una de las palabras y poner la palabra correspondiente del otro lado entonces mary queda mar\u00eda du en pasado como en espa\u00f1ol no se usa el du usamos simplemente el marcador de pasado no es no slap es dar una ufetada de es la green es verde witch es bruja con el diccionario voy poniendo todas las traducciones y despu\u00e9s puedo usar mis reglas de reordenamiento local reordenamiento simple como por ejemplo que el adjetivo seguido en nombre en ingl\u00e9s en realidad en espa\u00f1ol se corresponde con nombre seguido adjetivo entonces verdad de bruja lo cambi\u00f3 por bruja verde ac\u00e1 hay otro reordenamiento digamos donde tengo una marca de pasado y se la pas\u00f3 para adelante a lo largo y finalmente lo que hago es una peque\u00f1a generaci\u00f3n morfol\u00f3gica con estas marcas y digo bueno este dar en pasado se transforma en dio entonces me queda mar\u00eda no dio una ufetada a la bruja verde as\u00ed que part\u00ed de el texto en el idioma origen merited en slap de green witch y llegu\u00e9 a una oraci\u00f3n en el idioma estino mar\u00eda no dio una ufetada la bruja verde que parece est\u00e1 bastante bien digamos bastante bien la traducci\u00f3n entonces as\u00ed es como funcionar\u00eda un poco un sistema de traducci\u00f3n directa como les parece que funcionan estos sistemas en la pr\u00e1ctica digamos que tambi\u00e9n se comportan en la pr\u00e1ctica este tipo de sistemas pues ac\u00e1 vimos un ejemplo que anda bastante bien digamos pero no s\u00e9 que claro y hay otro problema m\u00e1s y es que no tenga todas las palabras pero adem\u00e1s que palabras que se pueden traducir de m\u00e1s de una manera entonces necesitas saber qu\u00e9 palabra ten\u00e9s que usar entonces bueno la web est\u00e1 llena de ejemplos de lo que puede salir mal si yo utilizo un sistema de traducci\u00f3n directa como \u00e9ste entonces lo que est\u00e1bamos viendo reci\u00e9n era los sistemas de traducci\u00f3n directa vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sint\u00e1ctica entonces para transferencia sint\u00e1ctica yo lo que voy a necesitar primero es tener un p\u00e1rsar del lenguaje origen que me lleva a una una an\u00e1lisis sint\u00e1ctico y adem\u00e1s voy a necesitar un generador del lenguaje destino que agarra un \u00e1rbol sint\u00e1ctico del lenguaje destino y genera una oraci\u00f3n entonces yo lo que puedo hacer es escribir reglas que transforma un \u00e1rbol en el otro y esas reglas son un poco m\u00e1s f\u00e1ciles digamos que lo que necesitar\u00eda para un sistema de traducci\u00f3n directa entonces para el ingl\u00e9s por ejemplo para tu siguiente el ingl\u00e9s y el espa\u00f1ol yo dir\u00eda que si tengo un nominal que es un adjetivo nombre un adjetivo ser\u00eda un nombre en ingl\u00e9s lo transformar\u00eda en un nombre seguir un adjetivo en espa\u00f1ol y la regla se escribir\u00eda algo as\u00ed dir\u00eda tengo un nominal adjetivo nombre entonces lo cambio por nominal nombre adjetivo entonces ahora que sabemos c\u00f3mo funciona esto tratemos de hacer el ejemplo en japon\u00e9s digamos c\u00f3mo ser\u00edan las reglas para transformar el \u00e1rbol en ingl\u00e9s de giador soliciendo music a el japon\u00e9s kareha ongaku uokiku no kadaizuki desu donde est\u00e1 tenemos la correspondencia de cada una de las palabras pero claro los \u00e1rboles son un poco distintos el ingl\u00e9s y el espa\u00f1ol se caracterizan por ser lenguajes de tipo no s\u00e9 si esto lo hemos visto ya en el curso pero son lenguajes de tipo sbo que significa que habitualmente yo suelo escribir un sujeto se dio un verbo seguido de un objeto el japon\u00e9s en cambio es un lenguaje de tipo sb porque habitualmente se escribi\u00f3 el sujeto seguido del objeto seguido del verbo hay muchos lenguajes que pertenecen a esta otra categor\u00eda entonces bueno queremos escribir reglas de transferencia para transformar este \u00e1rbol en aquel otro \u00e1rbol c\u00f3mo escribir\u00edamos esas reglas que les parece que reglas utilizar\u00eda yo para transformar un \u00e1rbol en el otro ah\u00ed est\u00e1 una de esas en ingl\u00e9s yo escribo una frase verbal un grupo verbal como un verbo seguido de un grupo precaucional esta es la que est\u00e1 y la cambio por qu\u00e9 otra cosa la cambio por un grupo preposicional que sigue un verbo esa es una qu\u00e9 otra regla tendr\u00eda que agregar cu\u00e1l la elaboraci\u00f3n que tiene la operaci\u00f3n la operaci\u00f3n seg\u00fan esto en ingl\u00e9s es un pronombre seguido de un verbo seguido de un grupo verbal por qu\u00e9 tendr\u00eda a cambiarlo ahora en japon\u00e9s la operaci\u00f3n va a ser el pronombre seguido del verse seguido del verbo bien alguna otra ah\u00ed est\u00e1 el grupo preposicional que est\u00e1 formado por un t\u00fa seguido de un nombre eso es en ingl\u00e9s y en japon\u00e9s que va a pasar voy a tener un grupo preposicional que es un nombre seguido de t\u00fa bien entonces con eso m\u00e1s o menos creo que tendr\u00eda las reglas suficientes para transformar un \u00e1rbol en el otro los sistemas de traducci\u00f3n vamos a ver si est\u00e1 bien son los que escribimos esta es la soluci\u00f3n del ejercicio los sistemas de traducci\u00f3n basados en sintaxis en realidad los sistemas de reglas basados en sintaxis hacen esto a alto nivel digamos tienen un mont\u00f3n de pares de \u00e1rboles hay gente que los analiza y escribe reglas de c\u00f3mo se transforma uno en el otro a veces las reglas son complicadas porque se pueden super poner entonces hay que definir prioridades y ese tipo de cosas bueno esos transferencias sint\u00e1cticas si seguimos subiendo en la en el tri\u00e1ngulo de bocua llegamos a lo que es la transferencia sem\u00e1ntica transferencia sem\u00e1ntica uno puede pensarla un poco como lo que hab\u00edamos en la clase pasada utilizando roles sem\u00e1nticos yo tengo un etiquetador de roles sem\u00e1nticos que agarra la oraci\u00f3n juan fue a la tienda y me devuelve los roles de los constituyentes me dice que juan es el agente y a la tienda es el objetivo o gol digamos es el nombre del rol entonces yo para ciertos idiomas podr\u00eda escribir reglas m\u00e1s espec\u00edficas por ejemplo en chino ocurre que los sintamas preposicionales que son de tipo objetivo se escriben antes del verbo pero los dem\u00e1s sintamas preposicionales escriben despu\u00e9s o sea el chino es un lenguaje de tipo sbo igual que el ingl\u00e9s o el espa\u00f1ol pero cuando el objeto es de tipo gol lo que hacen es ponerlo antes del verbo entonces yo podr\u00eda escribir una regla un poco m\u00e1s expresiva para este caso del chino si yo tuviera los roles sem\u00e1nticos yo dir\u00eda que un grupo verbal es un verbo seguido de esto no est\u00e1 tachado sino que era la barrita que qued\u00f3 arriba es un verbo seguido de una de un grupo preposicional de tipo gol en chino lo cambiar\u00eda por un verbo seguido de perd\u00f3n por un grupo producci\u00f3n de tipo gol seguido de un verbo es m\u00e1s costoso para generar y para parcer digamos necesito tener m\u00e1s esfuerzo de par sin m\u00e1s esfuerzo de generaci\u00f3n pero puede escribir mejores reglas que capturan ciertas particularidades de los lenguajes y si yo sigo subiendo en el tri\u00e1ngulo llego a lo que se conoce como interlingua cu\u00e1l es la gracia del interlingua cu\u00e1l es la idea estos sirve si nosotros estamos en un contexto multicultural estamos trabajando por ejemplo en la ONU o en el parlamento europeo o algo de eso donde se hablan muchos idiomas si yo quiero mantener un mont\u00f3n de documentos que est\u00e9n en todos los idiomas a la vez voy a necesitar para los sistemas que estuve viendo hasta el momento voy a necesitar tener n parsers uno para ac\u00e1 de idioma n generadores tambi\u00e9n uno para ac\u00e1 de idioma y despu\u00e9s para cada parte de idiomas voy a necesitar reglas de transferencia entonces voy a necesitar tener en total n por n menos un set de transferencia yo tengo 20 idiomas voy a necesitar 380 conjuntos de reglas de transferencia y esos conjuntos de referencia son largos son grandes son complejos hay que mantenerlos pueden tener errores entonces esto claramente no escala es como muy dif\u00edcil poder mantener un entorno de todos esos idiomas y poder mantener la traducci\u00f3n en base a reglas entonces la idea del interlingua es decir qu\u00e9 tal si pudi\u00e9ramos parsear lo suficiente o analizarlo lo suficiente como para llevar a una representaci\u00f3n com\u00fan una representaci\u00f3n que capture el significado de todos los idiomas a la vez y adem\u00e1s tuvi\u00e9ramos un generador para cada uno de los idiomas si eso pasara si nosotros pudi\u00e9ramos capturar con una representaci\u00f3n el significado de los idiomas a la vez no necesitar\u00edamos transferencia simplemente parseamos y llevamos a esa interlingua y despu\u00e9s generamos en el otro idioma esto est\u00e1 muy bien digamos del punto de vista ideal pero es muy dif\u00edcil de obtener en la pr\u00e1ctica que se podr\u00eda usar como representaci\u00f3n de interlingua que podr\u00eda ser un candidato bueno podr\u00edamos usar la l\u00f3gica de primer orden que era lo que ve\u00edamos en las primeras clases de sem\u00e1ntica como representar veraciones en los primer orden o alguna de sus variantes que dan cuenta mejor de lo que es la l\u00f3gica del lenguaje natural como la m\u00ednima recurso sem\u00e1nticos o la whole sem\u00e1ntics o si no algo m\u00e1s parecido lo que ve\u00edamos en la clase anterior de frames construirme frames con el estado de las cosas como por ejemplo esta era la misma oraci\u00f3n de hoy mary didn't slap de green wish pero escrita como un frame es hay un evento de slapping el agente es mary ocurre en pasado la polaridad negativa el tema de ese evento es la bruja y la bruja de m\u00e1s es verde yo podr\u00eda construirme este tipo de frames y usarlos como representaciones pero bueno el problema que tiene crear o pensar en crear una interlingua es que esa interlingua seguro que va a ser muy compleja y seguro que va a tener que modelar las caracter\u00edsticas de todos los idiomas al mismo tiempo y hay caracter\u00edsticas que son complicadas en los distintos idiomas y algunas que ni nos ni nos imaginamos o sea por ejemplo en chino existen palabras distintas para decir hermano mayor y hermano menor y no hay una palabra para decir hermano o sea no hay una palabra que quiere decir solamente hermano en espa\u00f1ol si y en ingl\u00e9s tambi\u00e9n en ingl\u00e9s puede decir brother pero en chino no en chino ten\u00e9s que elegir cuando vas a decir hermano si es hermano mayor o hermano menor entonces imag\u00ednense que si yo estoy traduciendo del espa\u00f1ol al ingl\u00e9s y estoy utilizando una interlingua la interlingua en su parcer necesita poder distinguir en alg\u00fan momento si estoy hablando de un hermano mayor o un hermano menor porque tiene que lograr la representaci\u00f3n suficiente como para poder traducir al chino entonces necesita esa informaci\u00f3n y no s\u00e9 d\u00f3nde la va a sacar la puede sacar de contexto lo puede sacar inventar de alg\u00fan lado pero en alg\u00fan momento va a tener que averiguar el hermano que se est\u00e1 hablando en espa\u00f1ol si es un hermano mayor o menor como para poder tener la representaci\u00f3n y despu\u00e9s de informaci\u00f3n se va a perder porque cuando baja de vuelta al lado del ingl\u00e9s de vuelta vuelve a ser brother y no importa si es mayor o menor y esto solamente un caso de un fen\u00f3meno que ocurre en chino pero digamos imag\u00ednense los fen\u00f3menos que ocurren en el idioma en en en todo el tiempo digamos y todas las peque\u00f1as variantes que hay y como en realidad no es cierto que podamos traducir exactamente los mismos conceptos como que es muy dif\u00edcil encontrar conceptos que se correspondan 100 por ciento de un idioma y otro hay una cosa que llama el principio de incertidumbre la traducci\u00f3n y dice eso que en realidad cuando yo tengo un idioma y otro los conceptos no siempre se van a traducir 100 por ciento bien o sea no siempre la traducci\u00f3n es exacta sino que hay cierto solopamiento y a veces va a funcionar y a veces no bien pero a pesar de que es una utop\u00eda tener una interlingua que funcione para todo para todos los lenguajes bien este tipo de tecnolog\u00eda si se utilizan para dominios m\u00e1s acotados para dominios peque\u00f1os como por ejemplo el de meteorolog\u00eda yo puedo escribir perfectamente puedo construir una representaci\u00f3n de todos los estados meteorol\u00f3gicos que hay si hay viento si hay lluvias y nieve hacia y granizo la temperatura la presi\u00f3n etc\u00e9tera y traducir los distintos las distintas palabras que se usan los distintos idiomas para dar cuenta de estos conceptos entonces ese dominio acotado es bastante bien manejable con una interlingua y otro ejemplo son los manuales t\u00e9cnicos hay empresas que tienen un mont\u00f3n de documentaci\u00f3n t\u00e9cnica o describen las apis de sus productos etc\u00e9tera y uno suele dar cuando cuando mira la p\u00e1gina web digamos que aparece como que con su fijo es porque est\u00e1 en espa\u00f1ol pero si se lo cambia por n autom\u00e1ticamente te genera otra p\u00e1gina exactamente igual pero en ingl\u00e9s en realidad lo que hacen es como mantener una representaci\u00f3n abstracta de lo que est\u00e1n escribiendo y generarla en los distintos idiomas bien entonces hasta ah\u00ed lo que vimos era como un paneo de lo que son los distintos sistemas basados en reglas ahora vamos a pasar a hablar de lo que es la traducci\u00f3n estad\u00edstica que es el estado del arte hoy en d\u00eda y vamos a empezar con un ejemplo un ejemplo de una frase en hebreo que es adona y roi que la traducci\u00f3n ser\u00eda el se\u00f1or es mi pastor o del or y es my shepherd y esta frase en realidad funciona bien porque nosotros conocemos que son las ovejas digamos la cultura en la que surgi\u00f3 esta frase conoc\u00eda que eran las ovejas ten\u00edan pastores los pastores este cuidaban las ovejas la llevaban a donde estaban los mejores pastos etc\u00e9tera entonces esta esta met\u00e1fora funcionaba bien digamos la gente describ\u00eda como se sent\u00eda en respecto a dios utilizando esta met\u00e1fora pero qu\u00e9 tal si quisi\u00e9ramos expresar esta misma frase a una cultura que no conoce a las ovejas como por ejemplo los primeros misioneros que vendr\u00edan de europa y tendr\u00edan contacto con los ind\u00edgenas americanos no conoc\u00edan ovejas entonces c\u00f3mo hacemos para expresarles el concepto de adona y roi una forma de expresarlo es decir bueno traduzco la met\u00e1fora el significado de la met\u00e1fora digo significa el se\u00f1or me cuidar\u00e1 que en definitiva es un poco la met\u00e1fora quiere decir eso aunque pierda un poco del contenido o si no lo que lo otro que puedo hacer es tratar de ser m\u00e1s fiel al significado original y tratar de traducirlo m\u00e1s literalmente y decir bueno el se\u00f1or ser\u00e1 para m\u00ed como un hombre que cuida de animales que tiene el pelo como algod\u00f3n que es bastante m\u00e1s fiel al original pero sin embargo se entiende mucho menos como que te van a mirar y decirte qu\u00e9 me est\u00e1s hablando y bueno un poco este es el problema que hay que se enfrentan los traductores humanos todos los d\u00edas o sea es muy dif\u00edcil tener las dos cosas ser fiel al original y sonar natural que suene bien en el lenguaje destino una traducci\u00f3n queremos que tenga esas dos propiedades pero muy dif\u00edcil lograrlo a la vez entonces los traductores humanos saben que esto es imposible en la pr\u00e1ctica lo que hacen es tratar de traducir de manera de encontrar un punto intermedio en el cual bueno suene bastante bien pero adem\u00e1s sea fiel al significado original entonces esto significa que lo que estamos tratando de hacer al traducir es que estamos tratando de maximizar dos cosas a la vez como dos medidas que queremos maximizar una medida es que tan fiel es mi oraci\u00f3n traducida a la oraci\u00f3n original a esa medida le vamos a llamar adecuaci\u00f3n o fidelidad y en ingl\u00e9s es adecuaci\u00f3n fidelidad y la otra medida es que tan natural suena la oraci\u00f3n que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en ingl\u00e9s fluency entonces esta idea de que estoy tratando de maximizar dos medidas a la vez despu\u00e9s vamos a ver que en realidad lo que vamos a total maximizar es el producto de las dos medidas porque eso significa maximizar ambas al mismo tiempo es una idea que sirve para poder inferir o para poder construir mecanismos para crear los traductores autom\u00e1ticos y tambi\u00e9n mecanismo para testarlos y vamos a ver un poco c\u00f3mo es que funciona eso yo voy a intentar traducir a partir de ahora del resto de la clase y la clase que viene vamos a hablar siempre de que voy a traducir de un lenguaje origen f a un lenguaje destino e vamos a ponerlo ac\u00e1 si no nos olvidamos f es el lenguaje origen y es el lenguaje destino esos nombres surgen porque el paper inicial en donde se empez\u00f3 a hablar de estas cosas de los m\u00e9todos estad\u00edsticos traduc\u00eda del franc\u00e9s al ingl\u00e9s entonces sac\u00f3 los nombres ah\u00ed dijo en franc\u00e9s f el ingl\u00e9s e entonces traducimos del origen al destino bueno yo quiero traducir una frase del idioma f a otra frase del idioma e lo que quiero tratar de encontrar es el mejor etecho que maximice a la vez la adecuaci\u00f3n y la fluidez o sea de todos los e posibles del lenguaje destino quiero encontrar el que maximice la fluidez de o sea que suene natural y adem\u00e1s la adecuaci\u00f3n entre la oraci\u00f3n origen f y ese que estoy buscando esto esta f\u00f3rmula as\u00ed escrita de esa manera est\u00e1s a acordar algo que hayamos visto ya en el curso en alg\u00fan momento les suena a alg\u00fan lado entrop\u00eda si valles si o sea viene por ese lado se parece al modelo de valles porque esto es otra aplicaci\u00f3n del modelo de canal ruidoso el modelo de canal ruidoso lo hab\u00edamos visto en el curso cuando vimos correcciones de errores hace ya bastante tiempo y tambi\u00e9n es una aplicaci\u00f3n de lo que es la regla de valles entonces el modelo de canal ruidoso aplicado ac\u00e1 funciona de la siguiente manera yo tengo una oraci\u00f3n origen en el lenguaje f que es f chica que tiene m palabras y es bueno f sub 1 f sub 2 hasta f sub m y quiero encontrar la mejor oraci\u00f3n en el lenguaje destino etecho que es es sub 1 hasta vez es su bene hasta es su bene que maximiza y en realidad lo que yo quiero maximizar originalmente como todos esperar\u00edamos es decir bueno yo quiero encontrar la oraci\u00f3n e que maximice la probabilidad de e dado f digamos eso es lo que uno se le ocurrir\u00eda primero dir\u00eda bueno yo quiero estoy traduciendo la oraci\u00f3n f quiero encontrar la e que me de m\u00e1ximo la probabilidad de e dado f bien pero en realidad yo esto lo puedo descomponer por valles digamos y por definici\u00f3n de probabilidad condicional puede decir que la probabilidad de e dado f es igual a la probabilidad de f dado e por la probabilidad de divido la probabilidad de f digamos esa equivalencia es directa por definici\u00f3n de probabilidad condicional y adem\u00e1s como estoy maximizando en e esta f se mantiene constante porque lo que voy variando es la e entonces la tacho o sea maximizar sobre una constante no no hace ning\u00fan cambio entonces lo que me queda el final es que yo busco un etecho que es el e que hace m\u00e1ximo la probabilidad de f dado e por la probabilidad de y eso que tenemos escrito ah\u00ed se parece mucho a la otra ecuaci\u00f3n que ten\u00edamos antes digamos se parece mucho a esta ecuaci\u00f3n de adecuaci\u00f3n de f e y fluidez de entonces esto se conoce como la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica la vamos a ver unas cuantas veces en estas dos clases la vamos a estar refrescando y funciona de la siguiente manera yo quiero encontrar el etecho que es el e que maximiza el producto de estas dos probabilidades la primera probabilidad pdf dado e es la que se encarga de medir qu\u00e9 tal la adecuaci\u00f3n digamos de la frase que tan adecuada es la frase f para la frase e la segunda probabilidad la pd es la que se encarga de la fluidez que tan natural suena esa frase en el lenguaje destino y se calculan con modelos distintos la primera se calcula con lo que se conoce como modelo de traducci\u00f3n y la segunda con lo que se conoce como modelo de lenguaje de hecho los modelos del lenguaje ya los hemos visto en el curso vamos a dar un breve repaso de qu\u00e9 se trataba bueno porque esto es una aplicaci\u00f3n de canal ruidoso es una aplicaci\u00f3n de canal ruidoso por lo siguiente nosotros estamos tratando de traducir del lenguaje f efe la lenguaje origen al lenguaje que es el lenguaje destino y lo estamos pensando al rev\u00e9s estamos pensando como que alguien emiti\u00f3 los sonidos de la oraci\u00f3n e la oraci\u00f3n del lenguaje destino eso pas\u00f3 a trav\u00e9s de un canal ruidoso y cuando lleg\u00f3 hasta m\u00ed yo escuch\u00e9 los sonidos de la oraci\u00f3n efe estoy pensando como esa especie de met\u00e1fora alguien emiti\u00f3 e pas\u00f3 por un canal ruidoso y llegaron los ruidos de efe entonces lo que yo trato de hacer como proceso de traducci\u00f3n es encontrar cu\u00e1l tiene que haber sido esa e original para que yo haya escuchado la efe cu\u00e1l es la e original que me da probabilidad m\u00e1xima de que yo haya escuchado esta efe y bueno por eso es una aplicaci\u00f3n de canal ruidoso y bueno la realidad es que en realidad damos vuelta esta probabilidad porque nos da toda otra forma de calcular lo que no podr\u00edamos hacerlo si calculamos la probabilidad directa es como que hay mejores herramientas para hacer eso bueno de vuelta esto es la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica e techo es el argumento que hace m\u00e1ximo la probabilidad de efe dado e por la probabilidad e y para poder resolver esta ecuaci\u00f3n necesitamos tres cosas necesitamos un modelo de lenguaje pde que es el que se va a encargar de la fluidez esto se calcula mediante la t\u00e9cnica de negramas en general los engramas son bastante f\u00e1ciles de construir digamos porque yo necesito texto en un solo idioma solo en el idioma destino pdf dado e es la componente que se encarga de la adecuaci\u00f3n y se resuelve mediante el modelo de traducci\u00f3n el modelo de traducci\u00f3n no es tan f\u00e1cil de construir como el modelo de lenguaje porque para el modelo de traducci\u00f3n voy a necesitar texto biling\u00fce de hecho voy a necesitar un corpus paralelo que sea texto en dos idiomas que adem\u00e1s tengan su correspondencia y adem\u00e1s necesito una tercera componente esta tercera componente se llama decodificador y se trata de lo siguiente yo cuando estoy buscando cuando se resuelve esta ecuaci\u00f3n yo veo la oraci\u00f3n efe y quiero buscar la mejor e que maximice esa ecuaci\u00f3n pero en realidad lo que tendr\u00eda que hacer es probar con todas las oraciones e del idioma destino todas las oraciones posibles que cu\u00e1ntas son las oraciones del idioma estino son infinitas oraciones posibles en el idioma estino entonces yo estar\u00eda probando con infinitas oraciones hasta que una de ellas me d\u00e9 el m\u00e1ximo obviamente esto no es un problema tratable yo no puedo probar con infinitas oraciones lo que necesito es un proceso que me limites a cantidad de b\u00fasqueda de infinitas oraciones a algo tratable entonces el decodificador va a ser un algoritmo de b\u00fasqueda que va a agarrar la oraci\u00f3n en origen y va me va a devolver las 100 200 mil oraciones destino candidatas m\u00e1s probable que a veces lo ocurra para que yo pueda resolver y calcular esa ecuaci\u00f3n para esas para esas oraciones en vez de para todas las posibles entonces lo que hace es volver este problema tratable vamos a ver tambi\u00e9n un algoritmo de codificaci\u00f3n que se llama beam search bueno entonces un poco m\u00e1s sobre modelos de lenguaje la componente pde de la ecuaci\u00f3n era la que medida la fluidez y se calculaba mediante un modelo de lenguaje los modelos de lenguaje son relativamente f\u00e1ciles de construir porque necesitamos informaci\u00f3n monolingua informaci\u00f3n solamente en el lenguaje destino entonces en la web tenemos mont\u00f3n toneladas informaci\u00f3n de muchos idiomas entonces como solo necesitamos informaci\u00f3n idiomas sacamos texto web noticias blogs etc\u00e9tera y compilamos un gran corpus del lenguaje destino los modelos que se utilizan para traducci\u00f3n autom\u00e1tica en general son modelos basados en engramas que ya hemos visto en el curso c\u00f3mo funcionaban se suele usar orden de 4 o 5 en otras tareas de pdn se suelen usar \u00f3rdenes m\u00e1s chicos pero para ac\u00e1 da buenos resultados en 4 o 5 y bueno lo importante es tener una gran cantidad de material de entrenamiento o sea los mejores modelos que usan google translate y otras empresas usan trillones de palabras y bueno son necesitan hardware especial especialmente dise\u00f1ado para poder ir r\u00e1pido y recuperar la informaci\u00f3n o si no bueno si estoy hablando un dominio acotado puedo usar datos de dominio para entrenar que tambi\u00e9n va a ser buenos resultados las t\u00e9cnicas de mutin es cuando vos haya alguna engrama que no viste lo que te va a pasar es que la probabilidad cero y ah\u00ed te va a dar todo cero en realidad las mejores t\u00e9cnicas de mutin significa darle una buena probabilidad a eso a pesar de que nunca lo has visto se dice que las mejores mejoras digamos las m\u00e1s grandes mejoras en los modelos en la traducci\u00f3n autom\u00e1tica de los \u00faltimos a\u00f1os se han dado porque hay mejor en modelo el lenguaje que me dan traducciones que son m\u00e1s fluidas y y bueno y usualmente hay como cierta cierta correlaci\u00f3n o cierta inclinaci\u00f3n hacia las fluidez la gente prefiere cuando las oraciones son sonan m\u00e1s naturales ac\u00e1 un ejemplo esto era sacado un sistema de traducci\u00f3n del chino al ingl\u00e9s el sistema estad\u00edstico basado en sintaxis que cuando no utilizaba modelo lenguaje ten\u00eda un puntaje de 25 con 2 al incorporar modelo lenguaje subi\u00f3 como un 20 por ciento su su performance y lleg\u00f3 a 31 con 2 como 6 puntos esos puntos corresponden a una medida que vamos a ver dentro un rato que se llama medida blu que es una medida muy utilizada en lo que es traducci\u00f3n estad\u00edstica traducci\u00f3n autom\u00e1tica en general pero bueno ahora solamente saber que 6 puntos es una mejora que es much\u00edsimo y como es que mejora esto mejora haciendo que las traducciones que devuelve en general sean m\u00e1s fluidas son m\u00e1s natural en el lenguaje destino y ac\u00e1 hay un ejemplo de traducciones de ese mismo sistema yo ten\u00eda una traducci\u00f3n de referencia que era I don't have enough money with me to buy a new airplane ticket el sistema sin el modelo lenguaje devolv\u00eda esta traducci\u00f3n dec\u00eda don't have enough bag on me change please go a new by plane que no nos entiende mucho que lo que dice no es gramatical pero al agregar el modelo de traducci\u00f3n su traducci\u00f3n es la siguiente I have enough money to buy a new one by air que suena mucho mejor que les parece acerca del significado el significado se lo puesto digamos ac\u00e1 est\u00e1 diciendo que tiene suficiente plata para comprar uno por aire y ac\u00e1 dice que no tiene suficiente plata para comprar un pasaje de avi\u00f3n o sea este suena much\u00edsimo mejor porque est\u00e1 ni siquiera gramatical pero est\u00e1 por lo menos manten\u00eda la negaci\u00f3n digamos manten\u00eda que era una oraci\u00f3n negativa entonces hay cuidado con esto la traducci\u00f3n suena mucho mejor pero a veces podemos estar sacrificando fidelidad sacrificando adecuaci\u00f3n de la traducci\u00f3n bien esos son los modelos de lenguaje ahora pasemos a la otra los modelos de traducci\u00f3n la componente pdf dado de la ecuaci\u00f3n mide lo que es la ecuaci\u00f3n o fidelidad de una traducci\u00f3n y la otra y para esto necesito corpus paralelos o corpus biling\u00fces que para poder entrenar estos modelos los corpus biling\u00fces son bastante m\u00e1s dif\u00edciles de construir que los corpus monoling\u00fces digamos no alcanza con hacer una pasada por la web y obtener texto de un idioma y bueno los modelos que vamos a ver son los propuestos por brown brown y su equipo en 1993 que trabajan en ibm ellos construyeron cinco modelos de c\u00f3mo construir cinco modelos digamos en creciente complejidad de c\u00f3mo construir un modelo de traducci\u00f3n para traducci\u00f3n estad\u00edstica y bueno los modelos la diferencia entre cada modelo se es en la historia de generaci\u00f3n de las de las oraciones candidatas y bueno despu\u00e9s vamos a ver tambi\u00e9n otro modelo un poco m\u00e1s moderno pero bueno vamos a empezar viendo m\u00e1s bien los modelos de brown a qu\u00e9 me refiero con historia de generaci\u00f3n de las oraciones candidatas una historia de generaci\u00f3n esto lo digo ahora pero en realidad lo vamos a profundizar despu\u00e9s una historia de generaci\u00f3n en realidad es como una especie de proceso mental que seguir\u00eda un traductor cuando quiere pasar de una oraci\u00f3n a la otra entonces estas historias se basan en decir bueno un traductor agarra una oraci\u00f3n en el idioma origen y despu\u00e9s elige la cantidad de palabras que voy a tener el idioma destino reordena palabras despu\u00e9s va traduciendo una a una seg\u00fan un diccionario despu\u00e9s agrega palabras nuevas que no estaban en la oraci\u00f3n ese tipo de cosas digamos el tipo de pasos me lo voy a escribir en la historia de generaci\u00f3n y para qu\u00e9 sirve eso sirve para que a cada uno de esos pasos yo le puedo dar un valor num\u00e9rico un valor en cuanto a probabilidades y despu\u00e9s lo que voy a hacer cuando entreno mi sistema es tunear esos valores num\u00e9ricos tunear todas esas probabilidades para darme el c\u00e1lculo de probabilidad total vamos a profundizar m\u00e1s de en esto despu\u00e9s pero antes de pasar a lo que son los modelos de traducci\u00f3n vamos a hablar un poco de c\u00f3mo se evaluan estos sistemas en general siempre es importante evaluar todo en el pln digamos porque no hay soluciones perfectas entonces voy a tener sistemas que andan mejor o peor que otros y bueno y la traducci\u00f3n autom\u00e1tica obviamente no es la excepci\u00f3n entonces me sirve poder evaluar los sistemas para poder saber qu\u00e9 sistema mejor que el otro y adem\u00e1s si yo hago cambios en mi sistema poder evaluar de vuelta a ver si mejor\u00e9 o no entonces qu\u00e9 puedo considerar una buena traducci\u00f3n para empezar eso es una pregunta que es abierto en su digamos es abierto en su respuesta no o sea yo ten\u00eda en un sistema de traducci\u00f3n ten\u00eda una referencia un candidato de referencia que era de katsat on the mat digamos esa era una traducci\u00f3n de referencia y un sistema me dio seis posibles candidatos para esa traducci\u00f3n o sea originalmente hab\u00eda una frase por ejemplo en chino la traducci\u00f3n de referencia de katsat on the mat y mi sistema a traducir el chino me dio estas opciones tengo de katsat on mat de on the mat de cat de cat on the floor a katsat on the mat de katsat on the mat con min\u00fascula o de katsat on the straw mat cu\u00e1les les parecen que son buenas traducciones de estos candidatos que me dio el sistema cu\u00e1les les gustan m\u00e1s la e que es de katsat on the mat pero con min\u00fascula en vez de comay\u00fascula que otra la b on the mat de cat que otra la de les gusta tambi\u00e9n a katsat on the mat capaz que no calienta tanto dependiendo del uso que le vas a dar esa frase en contexto capaz que no calienta tanto y bueno si la verdad no se ve nada cuando est\u00e1n las cosas marcadas en rojo pero bueno en fin cr\u00e9anme ac\u00e1 la cosa macaza en rojo son las que acaban de decir una buena traducci\u00f3n podemos decir que es una traducci\u00f3n que le gusta a la gente que la gente dice si es una buena traducci\u00f3n entonces ac\u00e1 se elige on the mat sat de cat a katsat on the mat y de katsat on the mat en min\u00fascula y bueno como como decimos es le preguntamos a la gente a ver qu\u00e9 traducciones le gustan y bueno y ah\u00ed ponemos cu\u00e1les son las mejores traducciones o si no le damos a un conjunto de jurados las traducciones y le decimos que hagan un an\u00e1lisis un poco m\u00e1s preciso y nos digan bueno cu\u00e1nto le dan en uno al diez de adecuaci\u00f3n y cu\u00e1nto le dan en uno al diez de fluidez esa es otra forma de valor digamos y ah\u00ed ya nos est\u00e1n dando las dos medidas en general a los humanos nos cuesta realizar esta evaluaci\u00f3n en general tenemos una preferencia de la fluidez como pasaba hoy con el caso de traducci\u00f3n del chino al ingl\u00e9s por los pasajes de avi\u00f3n adem\u00e1s la gente no se pone de acuerdo adem\u00e1s hay un problema que es que hacer este tipo de evaluaciones con usuarios humanos lleva tiempo digamos hay que pagarles a los usuarios por hora para que est\u00e9n evaluando sistemas y despu\u00e9s yo les di un conjunto de traducciones ellos me las evaluaron y si hay un cambio en mi sistema para mejorarlo y de vueltas le tengo que darle conjunto de traducciones a los humanos y de vuelta lo tienen que evaluar y de vuelta tengo que pagar horas de usuarios humanos para que lo evaluen entonces es dif\u00edcil de reutilizar yo estar haciendo cambios constantemente en mi sistema y bueno y necesito tener una forma m\u00e1s r\u00e1pida de evaluar a ver si estoy haciendo las cosas mejor entonces como este proceso de evaluaci\u00f3n es largo es engorroso es caro lo que se ha vuelto m\u00e1s popular son los m\u00e9todos autom\u00e1ticos de evaluaci\u00f3n y a continuaci\u00f3n vamos a ver uno que es muy utilizado en lo que es la traducci\u00f3n autom\u00e1tica bueno c\u00f3mo funciona un m\u00e9todo de evaluaci\u00f3n en realidad lo que hace alguien alguien que est\u00e1 dise\u00f1ando un sistema es crearse un conjunto de oraciones con una traducci\u00f3n cada uno con una traducci\u00f3n de referencia que est\u00e1 bien digamos una traducci\u00f3n hecha a mano entonces yo quiero evaluar un sistema que va del espa\u00f1ol al ingl\u00e9s lo que tengo es un conjunto de oraciones en espa\u00f1ol y alguien alg\u00fan traductor humano me tradujo todas esas oraciones en espa\u00f1ol y me dio un candidato o m\u00e1s candidato tal vez para cada una digamos a eso le voy a llamar referencias traducciones de referencia lo siguiente que tengo que hacer es poder dise\u00f1ar una m\u00e9trica de similitud para que cuando mi sistema me da un candidato a traducci\u00f3n yo puedo establecer una similitud entre ese candidato y alguna de las referencias y bueno despu\u00e9s lo que voy a hacer es aplicar esa m\u00e9trica para los pares candidato y referencias y bueno y sacar como un promedio de todos los valores de similitud que tengo entonces se han inventado muchos m\u00e9todos de este estilo muchos m\u00e9todos autom\u00e1ticos que vamos a ver en particular se llama blue que es este una m\u00e9trica muy difundida en lo que es la traducci\u00f3n autom\u00e1tica estad\u00edstica y bueno primero algunas definiciones le vamos a llamar referencia a una traducci\u00f3n que est\u00e1 traducida manualmente o sea consideramos que es una oraci\u00f3n correcta eso es una referencia y le vamos a llamar candidato a una traducci\u00f3n que no tiene porque estar correcta porque le tradujo el sistema autom\u00e1tico y le vamos a llamar documento al conjunto de todas las oraciones candidatas al conjunto de todas las oraciones traducidas por el sistema que es lo que vamos a estar evaluando as\u00ed que recuerden tenemos referencia candidato y documento y bueno qu\u00e9 es lo primero que se nos puede ocurrir hacer cuando queremos saber si un candidato es bueno para la referencia o no lo primero que podemos hacer es tratar de contar las palabras que ocurren en ambos entonces yo puedo tratar de contar palabras que ocurren en el candidato y palabras que ocurren en la referencia y ah\u00ed dir\u00eda que la elecci\u00f3n de las palabras del candidato si est\u00e1n las palabras del candidato si est\u00e1n tambi\u00e9n la referencia yo dir\u00eda que eso se acerca un poco la adecuaci\u00f3n se acerca que bueno por lo menos us\u00f3 palabras que son fieles a la traducci\u00f3n de referencia pero si adem\u00e1s esas palabras est\u00e1n usadas en el mismo orden ah\u00ed se acerca un poco m\u00e1s a la fluidez o sea si est\u00e1n usadas en ese mismo orden puede sonar tan natural como la referencia y esto se puede hacer autom\u00e1ticamente haciendo conteos de n gramas ac\u00e1 yo tengo un una referencia que es de cazad mi sistema me ten\u00eda que haber devuelto de cazad y ten\u00eda dos candidatos candidato a era de caz y el candidato b era cazad de entonces en \u00e9ldogs \u0432\u0435\u043b extraordinary lo que puedo hacer es prevailer de n grams cu\u00e1les en gramas de los candidatos pertenecen a la referencia entonces para el caso de deidad en la en grama de pertenece la referencia en el en grama cat pertenece a referencia al en grama de cad o sea el bigama de que tambi\u00e9n pertenece a la referencia para el caso del candidato de el Unic 1999 pertenece el pertenece, el unigrama D pertenece, pero SatCat este bigrama no pertenece la referencia y CatD tampoco pertenece a la referencia. Y adem\u00e1s el \u00fanico trigrama que hay, SatCatD tampoco est\u00e1 en la referencia. Entonces lo que aparece a la derecha son los engramas que s\u00ed pertenecen tanto al candidato como a la referencia. As\u00ed que bueno, resumiendo, yo puedo contar la cantidad de hits de unigramas, de bigramas, de trigramas y para el candidato hace cumple que todos los unigramas que hay pertenece a la referencia, as\u00ed que voy a tener dos de dos hits, para los bigramas voy a tener uno de uno, pero para el candidato B los unigramas me dan tres de tres, digamos tres hits, los bigramas no, o sea tengo dos bigramas posibles si ninguno estaba bien y los trigramas tampoco, tengo un trigrama posible y no estaba bien. Entonces por ahora parece que le va ganando de Cat, el candidato A de Cat le va ganando a SatCatD como traducci\u00f3n. Bien, \u00bfqu\u00e9 puedo hacer con los conteos de engramas? Lo que hago habitualmente, o sea contar engramas, contar unigramas, bigramas y gramas, se acerca un poco a lo que es la noci\u00f3n de una precisi\u00f3n de algo. Entonces lo que voy a hacer es contarlos por separado, voy a decir voy a contar todos los unigramas por un lado, todos los bigramas por otro, todos los trigramas por otro y para cada uno de esos me voy a armar una precisi\u00f3n. Voy a decir que tengo el candidato CSUB, digamos un candidato que voy a considerar, voy a contar los hits de orden N de CSUB, digamos los hits de unigrama de CSUB, le voy a llamar H de CSUB y voy a contar la cantidad de unigramas totales que hay, le voy a llamar T de CSUB. Pero adem\u00e1s voy a hacer esto en vez de hacerlo para una sola oraci\u00f3n, para un candidato y su referencia, le voy a hacer para todo el documento, voy a contar todos los unigramas que estaban en mis candidatos, voy a ver cu\u00e1nto de esos estaban bien y voy a hacer esta divisi\u00f3n, entonces me va a dar que cu\u00e1l es la precisi\u00f3n en unigramas. Que va a ser, bueno, tanta cantidad de unigramas estaban bien dividido, toda la cantidad de unigramas que genero en los candidatos. Despu\u00e9s voy a hacer eso para bigramas, voy a contar toda la cantidad de bigramas que estaban bien, porque estaban en el candidato en la referencia, dividido toda la cantidad de bigramas que hay en el candidato. Voy a hacer lo mismo para trigramas y voy a hacer lo mismo para 4g, en general se suele llegar hasta 4, digamos en traducci\u00f3n autom\u00e1tica estad\u00edstica, la medida blue llega a calcular hasta 4. Entonces bueno, lo que me defino ah\u00ed es lo que se llama probabilidad de orden n, la probabilidad, perd\u00f3n, precisi\u00f3n de orden n, la precisi\u00f3n para unigrama, la precisi\u00f3n para bigramas, la precisi\u00f3n para trigramas, etc\u00e9tera. Bien, esta m\u00e9trica que estamos construyendo es bastante f\u00e1cil de enga\u00f1ar, en realidad yo me defin\u00ed una probabilidad, por ejemplo la probabilidad de orden 1 y la puedo enga\u00f1ar muy f\u00e1cil, porque yo me puedo construir un candidato que tiene siempre la misma palabra. Puedo decir, bueno, un candidato para la referencia de katsato nemat es el candidato DDDDD. Como yo justo le envoqu\u00e9 a una palabra que est\u00e1 en la referencia, entonces cuento los unigramas y me da que hay 6 hits de 6, a pesar de que la traducci\u00f3n es horrible. Entonces como hago para evitar esto, lo que se suele hacer es clipping, lo que significa que cuento cu\u00e1nto es la cantidad m\u00e1xima de palabras en la referencia y no permito que haya m\u00e1s de eso, entonces yo ac\u00e1 tengo hasta dos palabras D, entonces no puedo contar 6 de 6, tendr\u00eda que contar m\u00e1ximo 2 de 6. Entonces ah\u00ed evitamos ese problema de que bueno alguien se haga el vivo y genere simplemente una sola palabra. Bien, entonces hasta ahora vimos dos cosas, calculamos la precisi\u00f3n de orden n, la precisi\u00f3n de cada uno de los unigramas o bigramas o trigramas, lo segundo que vimos es que vamos a hacer clipping para evitar pasarnos de conteo en las palabras que aparecen m\u00e1s de una vez. Lo tercero que pasa es, ve\u00edamos en este ejemplo de ac\u00e1, ac\u00e1 tenemos dos candidatos de CAT y SAT-CAT-D y lo que pasaba ac\u00e1 era que le estaba yendo mejor a la traducci\u00f3n de de CAT porque ten\u00eda todos los unigramas que est\u00e1n en la traducci\u00f3n, est\u00e1n tambi\u00e9n en la referencia y todos los bigramas tambi\u00e9n, en cambio el candidato B no, el candidato B tiene unigramas que est\u00e1n pero bigramas y trigramas que no est\u00e1n, entonces en cuanto a precisi\u00f3n el candidato A va bastante mejor. \u00bfPor qu\u00e9 va bastante mejor el candidato A? Porque es un candidato que es m\u00e1s corto que la referencia, o sea es un candidato que tiene menos palabras. Como venimos definiendo la m\u00e9trica, si yo tengo una referencia y despu\u00e9s tengo un candidato que es justo un prefijo de la referencia, entonces va a cumplir que ese prefijo anda bien en todas las medidas de precisi\u00f3n porque todos los enigramas que tiene van a pertenecer a la referencia. As\u00ed que lo que hace la medida blue es penalizar ese tipo de comportamiento, penaliza los candidatos que son muy cortos para que digamos le d\u00e9 menos puntaje. Entonces, \u00bfpor qu\u00e9 se penalizan los candidatos cortos y no los candidatos largos? \u00bfPor qu\u00e9 les parece? Candidatos que son demasiado cortos se penalizan pero los demasiado largos no. La respuesta est\u00e1 en la slide, pero bueno. Se penaliza los candidatos cortos porque los candidatos largos, si yo genero un candidato que es mucho m\u00e1s largo que la referencia, lo que va a pasar es que ese candidato tiene enigramas, seguramente tiene enigramas que no pertenecen a la referencia. Entonces, en el conteo de precisi\u00f3n me va a dar un puntaje m\u00e1s bajo. Candidatos largos ya est\u00e1n penalizados por la precisi\u00f3n, candidatos cortos no est\u00e1n penalizados por la precisi\u00f3n. Entonces, necesito otro tipo de penalizaci\u00f3n para evitar eso. Bien, entonces, lo que vamos a dar es una cosa que se llama penalizaci\u00f3n por brevedad o brevity penalty, que es un puntaje que se le da en referencia a que tan corto es un candidato respecto a la referencia y bueno, se calcula teniendo en cuenta todo el largo del documento, todo el largo del documento traducido. Entonces ac\u00e1 yo defino que R' es el largo total de todas las referencias, R' es el largo total de todos los candidatos y entonces si el largo de los candidatos es mayor a largo de las referencias, no hay penalizaci\u00f3n, le pongo un 1, si el largo total de los candidatos es menor a largo de las referencias, entonces lo calculo como e a la 1 menos la divisi\u00f3n entre los largos. Esto es una definici\u00f3n de probabilidad exponencial, digamos, no es m\u00e1s que eso y en realidad lo que trata de hacer es penalizar traducciones que son muy cortas. Entonces, si yo ten\u00eda un candidato que ten\u00eda 5 palabras, mientras la referencia ten\u00eda 10, lo voy a penalizar fuertemente, le voy a dar un 0.37 de penalizaci\u00f3n. Si yo ten\u00eda un candidato que estaba que era menor pero era m\u00e1s cercano, entonces la penalizaci\u00f3n no es tanta de 0.78 y despu\u00e9s si los largos son iguales o si el candidato es m\u00e1s largo, no penalizo nada, le doy un 1 de puntaje. Bueno, entonces la m\u00e9trica Blue, que es una m\u00e9trica muy usada en traducci\u00f3n autom\u00e1tica, pone todos estos juntos, digamos, todos estos pedacitos que estuvimos viendo los pone juntos en un solo c\u00e1lculo. Blue se calcula como la penalizaci\u00f3n por probabilidad, el brevite penalti, por e a la suma de las precisiones que se ordenen. \u00bfQu\u00e9 palabra es ruido? Por ejemplo, Stro. Bueno, esta palabra es un unigrama que le va a dar 0 de precisi\u00f3n, digamos, porque no est\u00e1. Adem\u00e1s, participan un unigrama que tambi\u00e9n le va a dar mala precisi\u00f3n porque tampoco est\u00e1 el unigrama. Entonces lo que resta en realidad porque no est\u00e1 sumando la precisi\u00f3n. Ac\u00e1 yo tengo 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 est\u00e1n bien pero hay uno que no. En cambio, en este tengo 6 unigramas de los cuales los 6 est\u00e1n bien. Entonces ac\u00e1 el hecho de agregar palabras que no est\u00e1n bien, que no est\u00e1n en la referencia ya te penaliza. La diferencia es cuando yo tengo una traducci\u00f3n que es m\u00e1s corta. Si yo dir\u00eda solo de cut-sat-on, entonces ah\u00ed es m\u00e1s corta y no tengo forma de penalizarlo solo con la precisi\u00f3n. Entonces tengo el otro penalizador que es porque la traducci\u00f3n es muy corta. Bien, entonces, les estaba comentando. Ac\u00e1. La medida Blue se define como una media geom\u00e9trica, definici\u00f3n de media geom\u00e9trica, de las precisiones de orden N. Tambi\u00e9n tienes un peso por precisi\u00f3n que se puede variar pero en general se utiliza el mismo peso para todos. Multiplicado por la penalizaci\u00f3n por brevedad. Bien, eso. O sea, esa es la definici\u00f3n de la m\u00e9trica Blue que es una m\u00e9trica que se utiliza much\u00edsimo. Esos puntajes que vemos hoy de 25,2 y 31 con algo eran ejemplos de m\u00e9trica Blue aplicados a un sistema. Y bueno, una cosa importante, algunos comentarios importantes sobre la m\u00e9trica Blue es que en general cuando un sistema le da mejor, digamos, un conjunto de traducciones le va mejor en m\u00e9trica Blue, tambi\u00e9n le va mejor con un conjunto de humanos que eval\u00faen el sistema. O sea, que tiene una correlaci\u00f3n bastante buena con lo que es la evaluaci\u00f3n subjetiva humana. Pero como contra, es dif\u00edcil de interpretar estos puntajes. O sea, si yo tengo un puntaje de, como nos pasaba hoy, que ten\u00eda un puntaje de 31, en realidad un 31 es un n\u00famero que puede ser muy bueno, muy malo, dependiendo del idioma. Pero, o sea, si todo saliera bien y yo tradujer exactamente lo mismo que est\u00e1n las referencias, por construcci\u00f3n la medida me dar\u00eda uno. Pero en realidad es muy dif\u00edcil traducir exactamente lo que est\u00e1n las referencias, porque no es cierto que exista una \u00fanica traducci\u00f3n posible en la traducci\u00f3n, digamos, humana. Oraciones se pueden traducir de manera distinta y estar igualmente bien. Entonces es muy dif\u00edcil tener un conjunto de referencias que contemple todas las posibilidades. As\u00ed que mi traductor, no es el pap\u00e1s que anda b\u00e1rbaro, pero el puntaje a\u00fan no es uno, no es 100, digamos, porque est\u00e1 eligiendo palabras distintas o eligiendo formas de escribir las oraciones distintas. Entonces bueno, por eso es dif\u00edcil interpretar. Yo tengo un puntaje blue de 30 o de 50, o sea, de 0.3 o de 0.5, y puede ser buen\u00edsimo para ese sistema. Pero para algo que s\u00ed me sirve much\u00edsimo el porcentaje, digamos, el puntaje de blue es para decir, yo tengo mi sistema, lo evaluo, despu\u00e9s hago algunos cambios, evaluo de vuelta, y si subi\u00f3 la performance con el puntaje blue, entonces estoy seguro de que mejor\u00f3 porque hay una correlaci\u00f3n con la evaluaci\u00f3n subjetiva. Para pasar el espa\u00f1ol ingl\u00e9s, en realidad lo que pasa es que entren\u00e1s otro traductor. No, ac\u00e1 estoy hablando uno solo. Ac\u00e1 estoy hablando solamente en un sentido. Yo ten\u00eda un sistema en espa\u00f1ol, por ejemplo, digo, una oraci\u00f3n en espa\u00f1ol, el gato se sent\u00f3, y alguien me dijo, bueno, la traducci\u00f3n de referencia de eso es de cat-sat, y mi sistema me dijo, bueno, pero mis traducciones posibles son de cat y sat-cat-de. Entonces yo ten\u00eda un sistema en espa\u00f1ol, pero que traduce al ingl\u00e9s, digamos, un sistema de traducci\u00f3n de espa\u00f1ol al ingl\u00e9s, pero no estoy traduciendo en el otro sentido. No, no es como las canciones. Ac\u00e1, part\u00ed del espa\u00f1ol y llegu\u00e9 al ingl\u00e9s, y estoy tratando de evaluar comparando las frases en ingl\u00e9s esperadas con las frases en ingl\u00e9s generadas. Claro. Probablemente\u2026 Ac\u00e1 est\u00e1 el mismo idioma, se entend\u00ed. Claro, pero est\u00e1 en el mismo idioma, o sea, lo que nos mostramos ac\u00e1 era cu\u00e1l era la oraci\u00f3n o origen, porque para evaluar no nos importa en realidad, para evaluar nos importa que comparar solamente la oraci\u00f3n candidato con la referencia, y la origen nos olvidamos. Sabemos que los dos intentaron traducir de la misma oraci\u00f3n, y bueno, y alguno le fue mejor que a otro. Bien, esos son comentarios de Blue, esto era evaluaci\u00f3n de los sistemas. Lo siguiente que vamos a ver es el problema de los corpus paralelos. Antes de pasar a lo que son modelos de traducci\u00f3n, vamos a hablar un poco de lo que son los corpus paralelos, que son necesarios para construir un modelo de traducci\u00f3n. Un corpus paralelo consiste en pares de textos en dos idiomas, por ejemplo, tener textos en espa\u00f1ol y en ingl\u00e9s, pero adem\u00e1s yo tengo que tener alg\u00fan nivel, tengo que tener una correspondencia entre esos textos. De alguna forma, yo tengo que saber c\u00f3mo se corresponde un texto con el otro. Entonces, bueno, tiene que estar con conjuntos, digamos, ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen, en el mundo existen corpus paralelos para algunos idiomas, o sea, hay muchos idiomas en el mundo, pero no todos los pares de idiomas tienen corpus paralelo construido, entonces existen paralela de ingl\u00e9s, el chino ingl\u00e9s para la mayor\u00eda de los lenguajes europeos, debido a su uso en la Uni\u00f3n Europea, digamos, existen tambi\u00e9n corpus paralelos para ellos, pero para la gran mayor\u00eda de pares de lenguas no hay, digamos, no tengo un par que traduzca entre el chino y el guaran\u00ed, por ejemplo, o sea, es poco probable que se construya un par de estilos. Bien, \u00bfqu\u00e9 es un corpus paralelo? Ya que no se ve nada, de vuelta. Ac\u00e1 hay un ejemplo, que no s\u00e9 si lo conocen, es un ejemplo famoso de corpus paralelo. Tiene idea de lo que es, lo han visto alguna vez, \u00bfs\u00ed? La piedra de Rosetta. La piedra de Rosetta fue una piedra que la construyeron, o por lo menos la tallaron en el a\u00f1o 196 a.C. y hablaba sobre la coronaci\u00f3n de Tolomeo V y su adoraci\u00f3n como semi-dios, etc\u00e9tera, etc\u00e9tera. Y bueno, estuvo perdida un mont\u00f3n de a\u00f1os hasta que durante las campa\u00f1as napole\u00f3nicas 1799 la encontraron en Egipto, en lugar Rosetta, casualmente, y se la llevaron para Francia y ah\u00ed la empezaron a analizar ling\u00fcistas, empezaron a tratar de entender qu\u00e9 es lo que dec\u00eda. Y bueno, descubrieron que tiene tres textos, vieron que tiene como tres regiones, tres textos y despu\u00e9s de estudiarla un rato se dieron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas distintos. Y los idiomas eran, el de arriba eran jerogl\u00edficos egipcios, del estilo de lo que uno encuentra dentro de las pir\u00e1mides, el del medio era egipcio dem\u00f3tico, que era el egipcio vulgar que se usaba digamos en el d\u00eda a d\u00eda, y el de abajo el todo era griego antiguo. Entonces, si bien ninguno de los tres idiomas se hablaban, el momento que se encontr\u00f3 la piedra, los tres idiomas antiguos, el griego antiguo por lo menos s\u00ed se sab\u00eda, digamos, se conoc\u00eda como idioma, se sab\u00eda qu\u00e9 significaba y digamos, hab\u00eda gente que lo estudiaba, los otros dos no, los otros dos eran lenguas completamente perdidas que nadie sab\u00eda identificarlas. Pero gracias al hecho de que en realidad se descubri\u00f3 que los tres textos hablan de lo mismo, son el mismo texto en tres idiomas, entonces ah\u00ed se empez\u00f3 a hacer un trabajo de alineaci\u00f3n, digamos, los arque\u00f3logos empezaron a decir, bueno, esta porci\u00f3n de texto ac\u00e1 se corresponde con esta de ac\u00e1, se corresponde con esta de ac\u00e1, y etc\u00e9tera, y a tratar de encontrar correspondencias en los idiomas, y como sab\u00edan qu\u00e9 quer\u00eda decir en griego antiguo, empezaron a poder descubrir qu\u00e9 quer\u00edan decir en los otros idiomas. Entonces, a ra\u00edz de eso, es que empez\u00f3, digamos, la egiptolog\u00eda moderna, se pudo empezar a descifrar, que dicen, por ejemplo, los jerogl\u00edficos est\u00e1n en las pir\u00e1mides y bueno, un mont\u00f3n de cultura egipcia antiguas se conoce gracias a que se pudo descifrar lo que dec\u00eda esta piedra. Y en definitiva, esto es un ejemplo de corpus paralelos, o sea, tengo el mismo texto en tres idiomas y con un poco de esfuerzo logro alinear cu\u00e1les son cada uno de los elementos de mis lenguajes y logro saber la traducci\u00f3n de los tres. Bueno, entonces, eso no llega al concepto de alineaci\u00f3n, los corpus paralelos tienen distintos niveles de alineaci\u00f3n, lo m\u00e1s f\u00e1cil de encontrar son corpus que est\u00e1n alineados a nivel de documentos, yo tengo una colecci\u00f3n de documentos en espa\u00f1ol y una colecci\u00f3n de documentos en chino y yo s\u00e9 qu\u00e9 documento se corresponde con qu\u00e9 otro, pero no s\u00e9 nada m\u00e1s. Ser\u00eda mejor incluso que estuvieran alineados a nivel de alineaci\u00f3n, adem\u00e1s de conocer los documentos, yo s\u00e9 cu\u00e1l es la relaci\u00f3n en espa\u00f1ol o con cu\u00e1l es la relaci\u00f3n en chino, digamos, tengo una correspondencia entre esas dos, pero ser\u00eda a\u00fan mejor y esto es lo que m\u00e1s nos servir\u00eda si estuvieran alineados a nivel de palabra. Cada uno de los caracteres que est\u00e1n en chino se corresponde con qu\u00e9 palabra en espa\u00f1ol o qu\u00e9 grupo de palabras y cada una de las palabras en espa\u00f1ol, con qu\u00e9 grupo de caracteres se corresponde en chino. Esto es el ideal, pero claro, o sea, si ya es dif\u00edcil conseguir cosas que est\u00e9n alineadas a nivel documento, se imaginan que nadie va a ir a mano alinear a nivel de palabra cada uno de las palabras de los idiomas. Entonces, en la pr\u00e1ctica nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que, como resultado de la construcci\u00f3n de los modelos de lenguaje, se produce tambi\u00e9n como un producto secundario, se produce la alineaci\u00f3n de los corpus, entonces obten\u00e9s las dos cosas a la vez. Bueno, y otra cosa es que a diferencia del texto monolingua que yo usaba para los modelos de lenguaje, es muy raro que naturalmente se produzcan textos en dos idiomas a la vez, o sea, hay que buscarlos bastante, digamos, bastante cuidadosamente. Existen algunos contextos en donde eso se produce. Por ejemplo, en algunos portales de noticias puede pasar que tengan versiones en distintos idiomas y lo que hagan es traducir las noticias en distintos idiomas. Entonces, si yo puedo encontrar uno de esos, es una buena fuente para construirme un corpus paralelo alineado a nivel de documento. Yo s\u00e9, esta noticia se corresponde con esta otra en el otro idioma. Pero un lugar en donde se producen naturalmente este tipo de textos es en los pa\u00edses que son biling\u00fces o multiling\u00fces. Por ejemplo, en Canad\u00e1, que hablan ingl\u00e9s y franc\u00e9s, las discusiones del Parlamento canadiense siempre por ley tienen que transcribirse en los dos idiomas, tienen que traducirse, si est\u00e1n en ingl\u00e9s se traducen en franc\u00e9s, si est\u00e1n en franc\u00e9s se traducen en ingl\u00e9s, y guardan una correspondencia entre eso, guardan los documentos de todas las discusiones del Parlamento en los dos idiomas. Entonces, ah\u00ed, naturalmente se produce un corpus paralelo en el nivel de documentos para el ingl\u00e9s y el franc\u00e9s, ese se conoce como el corpus Hansard. Eso tambi\u00e9n ocurre en Hong Kong, en Hong Kong se habla ingl\u00e9s y chino, son los idiomas oficiales. Entonces, el corpus m\u00e1s grande que se tiene para ingl\u00e9s y chino est\u00e1 hecho como una compilaci\u00f3n de lo que son las discusiones del Parlamento de Hong Kong. Y tambi\u00e9n pasa en la Uni\u00f3n Europea, en el Parlamento Europeo tambi\u00e9n tienen la costumbre de traducir todas las discusiones a todos los idiomas o a muchos de los idiomas que se usan en la Uni\u00f3n Europea. Entonces, hay corpus paralelos para casi todos los idiomas de la Uni\u00f3n Europea. Pero claro, todos estos est\u00e1n alineados a nivel de documentos. Yo s\u00e9 qu\u00e9 documento se corresponde con cu\u00e1l es otro en el otro idioma, pero no a nivel de oraciones y mucho menos a nivel de palabras. Pero bueno, partiendo de un corpus alineado a nivel de documentos, yo puedo llegar a construirme por lo menos una alineaci\u00f3n a nivel de oraciones. Si en un proceso relativamente sencillo, esto se conoce como el algoritmo de Gale y Church, que es un algoritmo relativamente f\u00e1cil para alinear corpus, o sea, para pasar corpus que est\u00e1n alineados a nivel de documentos, pasarlos a que est\u00e9n alineados a nivel de oraci\u00f3n. Y bueno, esto es un algoritmo que funciona, est\u00e1 un poco basado en lo que era el algoritmo de distancia de edici\u00f3n de Levenstein, que vimos hace bastante tiempo en el curso. Es como muy parecido, tambi\u00e9n es un algoritmo de programaci\u00f3n din\u00e1mica, similar a ese, funciona de la siguiente manera. O sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de c\u00f3mo es que funciona. El algoritmo de Gale y Church dice, yo voy a tener un conjunto de oraciones en un idioma y otro conjunto de oraciones en el otro idioma. Entonces considero que un traductor para cada oraci\u00f3n pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma. Un traductor, supongan un traductor humano, agarr\u00f3 oraciones que estaban en espa\u00f1ol y oraciones que estaban en franc\u00e9s. Vamos a no ponerles EIF porque lo que puede confundir con las otras cosas. As\u00ed que vamos a decir, el lenguaje origen era F, franc\u00e9s y el lenguaje destino era espa\u00f1ol. Bien, entonces un traductor humano cada vez que se enfrentaba una oraci\u00f3n ten\u00eda tres posibilidades. O bien traduc\u00eda una oraci\u00f3n por otra oraci\u00f3n, o bien parte esta oraci\u00f3n en dos y traduce una oraci\u00f3n por dos, o bien borra esta oraci\u00f3n. Decide que no es tan importante y agarra y borra la oraci\u00f3n. Entonces las tres operaciones que se hacen a nivel de oraci\u00f3n son la de transformarla en cero, una o dos oraciones del otro lado. Eso es una cosa. Lo otro es el costo relativo de alinear estas dos oraciones depende del largo relativo de las oraciones. Entonces, si yo tengo dos oraciones que tienen un largo muy parecido, le voy a dar un costo menor para alinearlos, era menor o mayor, si menor. Si tiene un largo muy parecido le voy a dar un valor menor para alinear, si tiene un largo muy distinto, una es muy corta y la otra es muy larga, entonces le doy un valor mayor para alinear. Entonces lo que ellos hacen es pensando en todo este tipo de operaciones que hay, todas las combinaciones de operaciones posibles, o sea, partir esta operaci\u00f3n en dos o no partirla o eliminarla o dejarla como est\u00e1. Entonces, con programaci\u00f3n din\u00e1mica ven todas las posibilidades, ven todas las posibilidades de operar distinto para llegar al otro lado y calculan las que le da un costo menor. O sea, para cada una de las posibilidades calcula cu\u00e1l es el costo de cada par de oraciones, suman todos los costos del documento y se quedan con el caso que les d\u00e9 un costo menor en alineaci\u00f3n, eso se puede hacer eficientemente usando programaci\u00f3n din\u00e1mica, lo mismo que hac\u00edamos con la distancia de edici\u00f3n de Levenstein. Bueno, y este algoritmo que es relativamente sencillo, digamos, es una soluci\u00f3n bastante simple, logra una tasa de error muy buena, que es de un 4%, digamos, sobre todo para idiomas relacionados, para idiomas que se parecen como el ingl\u00e9s y el espa\u00f1ol, etc\u00e9tera, logra una tasa bastante baja de error de un 4%, hay algunas mejoras que se pueden hacer, pero en realidad un 4% es algo que est\u00e1 bastante bien. Hay un catch que es que para sistemas de traducci\u00f3n distintos o traducciones no literales, esto se rompe un poco, por ejemplo, para traducir entre ingl\u00e9s y chino, que en chino ni siquiera est\u00e1 claro cu\u00e1les son los l\u00edmites de las palabras y eso es m\u00e1s dif\u00edcil de ver. Entonces, bueno, este tipo de algoritmos no funcionan tan bien. Y bueno, hay variantes que funcionan un poco mejor. As\u00ed que bueno. Hoy vamos a dejar por ac\u00e1 y vamos a continuar la pr\u00f3xima con modelos de traducci\u00f3n.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 23.2, "text": " La clase de hoy y la clase que viene vamos a ver el tema de traducci\u00f3n autom\u00e1tica y bueno vamos a", "tokens": [50364, 2369, 44578, 368, 13775, 288, 635, 44578, 631, 19561, 5295, 257, 1306, 806, 15854, 368, 2479, 1311, 5687, 3553, 23432, 288, 11974, 5295, 257, 51524], "temperature": 0.0, "avg_logprob": -0.24338478701455252, "compression_ratio": 1.1379310344827587, "no_speech_prob": 0.13414530456066132}, {"id": 1, "seek": 2320, "start": 23.2, "end": 30.48, "text": " arrancar por esto que se conoce como la nota de weaver o el memorando de weaver warren weaver", "tokens": [50364, 50235, 6166, 1515, 7433, 631, 369, 33029, 384, 2617, 635, 36192, 368, 321, 20655, 277, 806, 10560, 1806, 368, 321, 20655, 1516, 1095, 321, 20655, 50728], "temperature": 0.0, "avg_logprob": -0.15112406110006665, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.629345178604126}, {"id": 2, "seek": 2320, "start": 30.48, "end": 37.6, "text": " era un matem\u00e1tico norteamericano de primera mitad de siglo 20 y el tipo trabaj\u00f3 durante la guerra", "tokens": [50728, 4249, 517, 3803, 443, 28234, 41966, 13530, 38028, 368, 17382, 46895, 368, 48578, 945, 288, 806, 9746, 9618, 812, 14427, 635, 27542, 51084], "temperature": 0.0, "avg_logprob": -0.15112406110006665, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.629345178604126}, {"id": 3, "seek": 2320, "start": 37.6, "end": 42.44, "text": " especialmente en cosas de criptograf\u00eda en an\u00e1lisis estad\u00edstico de c\u00f3digos etc\u00e9tera entonces en un", "tokens": [51084, 41546, 465, 12218, 368, 12815, 662, 19815, 2686, 465, 44113, 28436, 39160, 19512, 2789, 368, 40210, 13348, 5183, 526, 23833, 13003, 465, 517, 51326], "temperature": 0.0, "avg_logprob": -0.15112406110006665, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.629345178604126}, {"id": 4, "seek": 2320, "start": 42.44, "end": 47.72, "text": " momento dijo lo siguiente dijo es muy tentador decir que un libro escrito en chino es simplemente un", "tokens": [51326, 9333, 27024, 450, 25666, 27024, 785, 5323, 7054, 5409, 10235, 631, 517, 29354, 49451, 465, 417, 2982, 785, 33190, 517, 51590], "temperature": 0.0, "avg_logprob": -0.15112406110006665, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.629345178604126}, {"id": 5, "seek": 2320, "start": 47.72, "end": 52.56, "text": " libro escrito en ingl\u00e9s que ha sido codificado en el c\u00f3digo chino si tenemos m\u00e9todos \u00fatiles para", "tokens": [51590, 29354, 49451, 465, 49766, 631, 324, 14444, 17656, 1089, 1573, 465, 806, 44195, 417, 2982, 1511, 9914, 20275, 378, 329, 6991, 83, 4680, 1690, 51832], "temperature": 0.0, "avg_logprob": -0.15112406110006665, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.629345178604126}, {"id": 6, "seek": 5256, "start": 52.56, "end": 56.36, "text": " resolver casi cualquier problema criptogr\u00e1fico no ser\u00e1 que con la interpretaci\u00f3n apropiada", "tokens": [50364, 34480, 22567, 21004, 12395, 12815, 662, 47810, 23858, 78, 572, 16502, 631, 416, 635, 7302, 3482, 1882, 1513, 39018, 50554], "temperature": 0.0, "avg_logprob": -0.10137046399966691, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.001220951322466135}, {"id": 7, "seek": 5256, "start": 56.36, "end": 66.2, "text": " ya tendr\u00edamos m\u00e9todos \u00fatiles para traducci\u00f3n el opinaba digamos en este memor\u00e1ndum que los c\u00f3digos", "tokens": [50554, 2478, 3928, 81, 16275, 20275, 378, 329, 6991, 83, 4680, 1690, 2479, 1311, 5687, 806, 3980, 5509, 36430, 465, 4065, 10560, 18606, 449, 631, 1750, 40210, 13348, 51046], "temperature": 0.0, "avg_logprob": -0.10137046399966691, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.001220951322466135}, {"id": 8, "seek": 5256, "start": 66.2, "end": 70.44, "text": " o los m\u00e9todos que se utilizan para romper c\u00f3digos criptogr\u00e1ficos que son m\u00e9todos estad\u00edsticos se", "tokens": [51046, 277, 1750, 20275, 378, 329, 631, 369, 19906, 282, 1690, 7438, 610, 40210, 13348, 12815, 662, 47810, 23858, 329, 631, 1872, 20275, 378, 329, 39160, 19512, 9940, 369, 51258], "temperature": 0.0, "avg_logprob": -0.10137046399966691, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.001220951322466135}, {"id": 9, "seek": 5256, "start": 70.44, "end": 75.24000000000001, "text": " pod\u00edan aplicar al problema de la traducci\u00f3n autom\u00e1tica y bueno esto introduce algunas", "tokens": [51258, 2497, 11084, 18221, 289, 419, 12395, 368, 635, 2479, 1311, 5687, 3553, 23432, 288, 11974, 7433, 5366, 27316, 51498], "temperature": 0.0, "avg_logprob": -0.10137046399966691, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.001220951322466135}, {"id": 10, "seek": 5256, "start": 75.24000000000001, "end": 81.76, "text": " ideas clave como que puede existir un mapeo autom\u00e1tico entre un lenguaje y otro y que codificar", "tokens": [51498, 3487, 596, 946, 2617, 631, 8919, 2514, 347, 517, 463, 494, 78, 3553, 28234, 3962, 517, 35044, 84, 11153, 288, 11921, 288, 631, 17656, 25625, 51824], "temperature": 0.0, "avg_logprob": -0.10137046399966691, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.001220951322466135}, {"id": 11, "seek": 8176, "start": 81.76, "end": 88.4, "text": " de codificar en un lenguaje es an\u00e1logo a codificar de codificar en un algoritmo criptogr\u00e1fico y", "tokens": [50364, 368, 17656, 25625, 465, 517, 35044, 84, 11153, 785, 364, 842, 38212, 257, 17656, 25625, 368, 17656, 25625, 465, 517, 3501, 50017, 3280, 12815, 662, 47810, 23858, 78, 288, 50696], "temperature": 0.0, "avg_logprob": -0.14496789914425287, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.0042087915353477}, {"id": 12, "seek": 8176, "start": 88.4, "end": 95.48, "text": " bueno el tiro esa idea en 1949 tom\u00f3 como 50 a\u00f1os para que esa idea madurara digamos y despu\u00e9s", "tokens": [50696, 11974, 806, 44188, 11342, 1558, 465, 46476, 2916, 812, 2617, 2625, 11424, 1690, 631, 11342, 1558, 5244, 374, 2419, 36430, 288, 15283, 51050], "temperature": 0.0, "avg_logprob": -0.14496789914425287, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.0042087915353477}, {"id": 13, "seek": 8176, "start": 95.48, "end": 101.44, "text": " de 50 a\u00f1os los m\u00e9todos m\u00e1s utilizados hoy en d\u00eda son m\u00e9todos estad\u00edsticos que bueno que se", "tokens": [51050, 368, 2625, 11424, 1750, 20275, 378, 329, 3573, 19906, 4181, 13775, 465, 12271, 1872, 20275, 378, 329, 39160, 19512, 9940, 631, 11974, 631, 369, 51348], "temperature": 0.0, "avg_logprob": -0.14496789914425287, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.0042087915353477}, {"id": 14, "seek": 8176, "start": 101.44, "end": 106.60000000000001, "text": " basan un poco en estos principios pero claro en esa \u00e9poca era como muy dif\u00edcil ver qu\u00e9 era lo que", "tokens": [51348, 987, 282, 517, 10639, 465, 12585, 6959, 2717, 4768, 16742, 465, 11342, 25024, 4249, 2617, 5323, 17258, 1306, 8057, 4249, 450, 631, 51606], "temperature": 0.0, "avg_logprob": -0.14496789914425287, "compression_ratio": 1.6540084388185654, "no_speech_prob": 0.0042087915353477}, {"id": 15, "seek": 10660, "start": 106.6, "end": 112.64, "text": " iba a ocurrir entonces bueno vamos a ver un poco esta esta es la agenda de lo que vamos a mirar", "tokens": [50364, 33423, 257, 26430, 10949, 13003, 11974, 5295, 257, 1306, 517, 10639, 5283, 5283, 785, 635, 9829, 368, 450, 631, 5295, 257, 3149, 289, 50666], "temperature": 0.0, "avg_logprob": -0.13555594963756035, "compression_ratio": 1.8, "no_speech_prob": 0.018508169800043106}, {"id": 16, "seek": 10660, "start": 112.64, "end": 118.36, "text": " vamos a llegar m\u00e1s o menos hasta la mitad hoy y despu\u00e9s la clase siguiente y empecemos con un poco", "tokens": [50666, 5295, 257, 24892, 3573, 277, 8902, 10764, 635, 46895, 13775, 288, 15283, 635, 44578, 25666, 288, 846, 494, 38173, 416, 517, 10639, 50952], "temperature": 0.0, "avg_logprob": -0.13555594963756035, "compression_ratio": 1.8, "no_speech_prob": 0.018508169800043106}, {"id": 17, "seek": 10660, "start": 118.36, "end": 122.8, "text": " de historia de lo que es la traducci\u00f3n autom\u00e1tica esto empez\u00f3 como muchas otras tecnolog\u00edas como", "tokens": [50952, 368, 18385, 368, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 7433, 18730, 812, 2617, 16072, 20244, 20105, 1132, 10025, 2617, 51174], "temperature": 0.0, "avg_logprob": -0.13555594963756035, "compression_ratio": 1.8, "no_speech_prob": 0.018508169800043106}, {"id": 18, "seek": 10660, "start": 122.8, "end": 128.4, "text": " una tecnolog\u00eda militar con fines militares inicialmente era durante la guerra fr\u00eda era resultado", "tokens": [51174, 2002, 48055, 30653, 416, 37989, 1962, 2786, 495, 44076, 4082, 4249, 14427, 635, 27542, 431, 2686, 4249, 28047, 51454], "temperature": 0.0, "avg_logprob": -0.13555594963756035, "compression_ratio": 1.8, "no_speech_prob": 0.018508169800043106}, {"id": 19, "seek": 10660, "start": 128.4, "end": 134.32, "text": " de inter\u00e9s traducir r\u00e1pidamente y a bajo costo traducir entre el ruso y el ingl\u00e9s digamos a los", "tokens": [51454, 368, 728, 2191, 2479, 1311, 347, 18213, 49663, 288, 257, 30139, 2063, 78, 2479, 1311, 347, 3962, 806, 367, 24431, 288, 806, 49766, 36430, 257, 1750, 51750], "temperature": 0.0, "avg_logprob": -0.13555594963756035, "compression_ratio": 1.8, "no_speech_prob": 0.018508169800043106}, {"id": 20, "seek": 13432, "start": 134.32, "end": 139.23999999999998, "text": " norteamericanos les conven\u00eda poder traducir entre el ingl\u00e9s y el ruso y bueno en aquella \u00e9poca se", "tokens": [50364, 41966, 13530, 8914, 329, 1512, 7158, 2686, 8152, 2479, 1311, 347, 3962, 806, 49766, 288, 806, 367, 24431, 288, 11974, 465, 2373, 9885, 25024, 369, 50610], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 21, "seek": 13432, "start": 139.23999999999998, "end": 143.12, "text": " imaginan lo que era los inicios de la computaci\u00f3n las computadoras eran caras en las lentas no ten\u00eda", "tokens": [50610, 23427, 282, 450, 631, 4249, 1750, 294, 26817, 368, 635, 2807, 3482, 2439, 2807, 5409, 296, 32762, 1032, 296, 465, 2439, 23556, 296, 572, 23718, 50804], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 22, "seek": 13432, "start": 143.12, "end": 147.44, "text": " mucho poder de comput\u00f3 pero igual hab\u00eda como mucho optimismo de que en poco tiempo si va a poder", "tokens": [50804, 9824, 8152, 368, 2807, 812, 4768, 10953, 16395, 2617, 9824, 5028, 6882, 368, 631, 465, 10639, 11772, 1511, 2773, 257, 8152, 51020], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 23, "seek": 13432, "start": 147.44, "end": 153.76, "text": " resolver todos los problemas \u00edbamos a tener sistemas que iban a traducir b\u00e1rbaro y bueno era", "tokens": [51020, 34480, 6321, 1750, 20720, 18645, 65, 2151, 257, 11640, 48720, 631, 741, 5144, 257, 2479, 1311, 347, 272, 20335, 5356, 78, 288, 11974, 4249, 51336], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 24, "seek": 13432, "start": 153.76, "end": 157.88, "text": " m\u00e1s o menos la \u00e9poca del desarrollo de la ling\u00fc\u00edstica computacional inspirado un poco en las teor\u00edas", "tokens": [51336, 3573, 277, 8902, 635, 25024, 1103, 38295, 368, 635, 22949, 774, 19512, 2262, 2807, 13608, 17432, 1573, 517, 10639, 465, 2439, 40238, 10025, 51542], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 25, "seek": 13432, "start": 157.88, "end": 162.4, "text": " de chonsky estaba la idea que se pod\u00eda escribir reglas para todo y que a partir de eso se podr\u00eda", "tokens": [51542, 368, 417, 892, 4133, 17544, 635, 1558, 631, 369, 45588, 30598, 10119, 1121, 7743, 1690, 5149, 288, 631, 257, 13906, 368, 7287, 369, 27246, 51768], "temperature": 0.0, "avg_logprob": -0.13328275925073868, "compression_ratio": 1.8132530120481927, "no_speech_prob": 0.006723933853209019}, {"id": 26, "seek": 16240, "start": 162.4, "end": 170.24, "text": " llegar a hacer cosas muy muy buenas en particular para traducci\u00f3n hasta que en 1964 apareci\u00f3 el", "tokens": [50364, 24892, 257, 6720, 12218, 5323, 5323, 43852, 465, 1729, 1690, 2479, 1311, 5687, 10764, 631, 465, 34314, 15004, 19609, 806, 50756], "temperature": 0.0, "avg_logprob": -0.17517596839839578, "compression_ratio": 1.75, "no_speech_prob": 0.018489068374037743}, {"id": 27, "seek": 16240, "start": 170.24, "end": 175.24, "text": " reporte al pac al pac que era un comit\u00e9 que estaba estudiando cu\u00e1l eran los avances en", "tokens": [50756, 2275, 68, 419, 15165, 419, 15165, 631, 4249, 517, 395, 5066, 631, 17544, 13542, 72, 1806, 44318, 32762, 1750, 1305, 2676, 465, 51006], "temperature": 0.0, "avg_logprob": -0.17517596839839578, "compression_ratio": 1.75, "no_speech_prob": 0.018489068374037743}, {"id": 28, "seek": 16240, "start": 175.24, "end": 178.76, "text": " ling\u00fc\u00edstica computacional porque se estaba poniendo se estaba poniendo mucha plata en muchas", "tokens": [51006, 22949, 774, 19512, 2262, 2807, 13608, 4021, 369, 17544, 9224, 7304, 369, 17544, 9224, 7304, 25248, 30780, 465, 16072, 51182], "temperature": 0.0, "avg_logprob": -0.17517596839839578, "compression_ratio": 1.75, "no_speech_prob": 0.018489068374037743}, {"id": 29, "seek": 16240, "start": 178.76, "end": 183.72, "text": " esas cosas y eso se mostraron esc\u00e9pticos acerca de la traducci\u00f3n autom\u00e1tica acerca de los logros", "tokens": [51182, 23388, 12218, 288, 7287, 369, 21487, 266, 4721, 526, 662, 9940, 46321, 368, 635, 2479, 1311, 5687, 3553, 23432, 46321, 368, 1750, 31013, 329, 51430], "temperature": 0.0, "avg_logprob": -0.17517596839839578, "compression_ratio": 1.75, "no_speech_prob": 0.018489068374037743}, {"id": 30, "seek": 16240, "start": 183.72, "end": 188.6, "text": " que se hab\u00edan logrado despu\u00e9s de todos esos a\u00f1os de meter plata y dec\u00eda bueno pero se puso", "tokens": [51430, 631, 369, 44466, 31013, 1573, 15283, 368, 6321, 22411, 11424, 368, 9255, 30780, 288, 37599, 11974, 4768, 369, 280, 24431, 51674], "temperature": 0.0, "avg_logprob": -0.17517596839839578, "compression_ratio": 1.75, "no_speech_prob": 0.018489068374037743}, {"id": 31, "seek": 18860, "start": 188.6, "end": 192.68, "text": " mucho dinero pas\u00f3 en pasar muchos a\u00f1os pero todav\u00eda los humanos lo hacen m\u00e1s barato con", "tokens": [50364, 9824, 27923, 41382, 465, 25344, 17061, 11424, 4768, 28388, 1750, 34555, 450, 27434, 3573, 2159, 2513, 416, 50568], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 32, "seek": 18860, "start": 192.68, "end": 198.0, "text": " mayor precisi\u00f3n m\u00e1s r\u00e1pido entonces como que para qu\u00e9 estamos gastando en esto como resultado", "tokens": [50568, 10120, 7974, 2560, 3573, 24893, 13003, 2617, 631, 1690, 8057, 10382, 17898, 1806, 465, 7433, 2617, 28047, 50834], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 33, "seek": 18860, "start": 198.0, "end": 201.92, "text": " de eso hubo un recorte de fondos especialmente en estados unidos para todo lo que es traducci\u00f3n", "tokens": [50834, 368, 7287, 11838, 78, 517, 850, 12752, 368, 9557, 329, 41546, 465, 871, 4181, 517, 7895, 1690, 5149, 450, 631, 785, 2479, 1311, 5687, 51030], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 34, "seek": 18860, "start": 201.92, "end": 206.68, "text": " autom\u00e1tica y esto fue parte de lo que se conoci\u00f3 como el invierno de la inteligencia artificial que", "tokens": [51030, 3553, 23432, 288, 7433, 9248, 6975, 368, 450, 631, 369, 33029, 19609, 2617, 806, 1048, 19689, 368, 635, 24777, 3213, 2755, 11677, 631, 51268], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 35, "seek": 18860, "start": 206.68, "end": 210.72, "text": " un mont\u00f3n de proyectos de inteligencia artificial tambi\u00e9n no ten\u00eda buenos resultados entonces", "tokens": [51268, 517, 45259, 368, 23832, 329, 368, 24777, 3213, 2755, 11677, 6407, 572, 23718, 49617, 36796, 13003, 51470], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 36, "seek": 18860, "start": 210.72, "end": 215.95999999999998, "text": " separ\u00f3 la financiaci\u00f3n que hab\u00eda para todo eso durante unos cuantos a\u00f1os entonces se detuvo el", "tokens": [51470, 3128, 812, 635, 24323, 3482, 631, 16395, 1690, 5149, 7287, 14427, 17780, 2702, 394, 329, 11424, 13003, 369, 1141, 43744, 806, 51732], "temperature": 0.0, "avg_logprob": -0.13142928210171786, "compression_ratio": 1.8717948717948718, "no_speech_prob": 0.061200305819511414}, {"id": 37, "seek": 21596, "start": 215.96, "end": 220.6, "text": " desarrollo de unas cuantas cosas durante unos cuantos a\u00f1os y bueno despu\u00e9s empezaron a resurgir de", "tokens": [50364, 38295, 368, 25405, 2702, 49153, 12218, 14427, 17780, 2702, 394, 329, 11424, 288, 11974, 15283, 18730, 6372, 257, 725, 5476, 347, 368, 50596], "temperature": 0.0, "avg_logprob": -0.12916864013671875, "compression_ratio": 1.6870748299319729, "no_speech_prob": 0.014728378504514694}, {"id": 38, "seek": 21596, "start": 220.6, "end": 228.44, "text": " a poco pero despu\u00e9s de esto digamos en los 70 y hasta los 90 m\u00e1s o menos eso logr\u00f3 que la", "tokens": [50596, 257, 10639, 4768, 15283, 368, 7433, 36430, 465, 1750, 5285, 288, 10764, 1750, 4289, 3573, 277, 8902, 7287, 31013, 812, 631, 635, 50988], "temperature": 0.0, "avg_logprob": -0.12916864013671875, "compression_ratio": 1.6870748299319729, "no_speech_prob": 0.014728378504514694}, {"id": 39, "seek": 21596, "start": 228.44, "end": 232.28, "text": " investigaci\u00f3n se frenara un poco en estados unidos pero empezara a aparecer en otros lados del mundo", "tokens": [50988, 48919, 369, 33596, 2419, 517, 10639, 465, 871, 4181, 517, 7895, 4768, 18730, 2419, 257, 43336, 465, 16422, 40301, 1103, 7968, 51180], "temperature": 0.0, "avg_logprob": -0.12916864013671875, "compression_ratio": 1.6870748299319729, "no_speech_prob": 0.014728378504514694}, {"id": 40, "seek": 21596, "start": 232.28, "end": 237.32, "text": " como por ejemplo en europa o en jap\u00f3n y ah\u00ed empez\u00f3 llano con con files b\u00e9licos sino m\u00e1s bien con", "tokens": [51180, 2617, 1515, 13358, 465, 22139, 64, 277, 465, 48330, 1801, 288, 12571, 18730, 812, 4849, 3730, 416, 416, 283, 4680, 15807, 1050, 329, 18108, 3573, 3610, 416, 51432], "temperature": 0.0, "avg_logprob": -0.12916864013671875, "compression_ratio": 1.6870748299319729, "no_speech_prob": 0.014728378504514694}, {"id": 41, "seek": 21596, "start": 237.32, "end": 243.92000000000002, "text": " fines comerciales entonces hab\u00eda necesidad de tener traducciones o por lo menos dar soporte a los", "tokens": [51432, 37989, 43163, 279, 13003, 16395, 11909, 4580, 368, 11640, 2479, 1311, 23469, 277, 1515, 450, 8902, 4072, 370, 44614, 257, 1750, 51762], "temperature": 0.0, "avg_logprob": -0.12916864013671875, "compression_ratio": 1.6870748299319729, "no_speech_prob": 0.014728378504514694}, {"id": 42, "seek": 24392, "start": 243.92, "end": 248.67999999999998, "text": " traductores humanos con algunas traducciones aunque no estuvieran del todo bien pero bueno dar", "tokens": [50364, 2479, 84, 1672, 279, 34555, 416, 27316, 2479, 1311, 23469, 21962, 572, 49777, 38516, 1103, 5149, 3610, 4768, 11974, 4072, 50602], "temperature": 0.0, "avg_logprob": -0.1924112227655226, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.06566467881202698}, {"id": 43, "seek": 24392, "start": 248.67999999999998, "end": 252.07999999999998, "text": " algunas traducciones de inicio para que los doctores pudieran los doctores humanos pudieran", "tokens": [50602, 27316, 2479, 1311, 23469, 368, 294, 18322, 1690, 631, 1750, 17112, 2706, 14166, 38516, 1750, 17112, 2706, 34555, 14166, 38516, 50772], "temperature": 0.0, "avg_logprob": -0.1924112227655226, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.06566467881202698}, {"id": 44, "seek": 24392, "start": 252.07999999999998, "end": 256.08, "text": " continuar adem\u00e1s las computadoras empezaron a bajar de precio a tener mayor poder de c\u00f3mputo", "tokens": [50772, 29980, 21251, 2439, 2807, 5409, 296, 18730, 6372, 257, 23589, 289, 368, 46916, 257, 11640, 10120, 8152, 368, 6333, 2455, 8262, 50972], "temperature": 0.0, "avg_logprob": -0.1924112227655226, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.06566467881202698}, {"id": 45, "seek": 24392, "start": 256.08, "end": 262.64, "text": " y \u00e9sta fue como la era de oro de los sistemas de traducci\u00f3n basados en reglas y vamos a caer unos", "tokens": [50972, 288, 1136, 9140, 9248, 2617, 635, 4249, 368, 45150, 368, 1750, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 1121, 7743, 288, 5295, 257, 1335, 260, 17780, 51300], "temperature": 0.0, "avg_logprob": -0.1924112227655226, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.06566467881202698}, {"id": 46, "seek": 24392, "start": 262.64, "end": 267.28, "text": " ejemplos sistemas distr\u00e1n que todav\u00eda se desarrolla aunque ya no est\u00e1 completamente basado en reglas y", "tokens": [51300, 10012, 5895, 329, 48720, 1483, 81, 7200, 631, 28388, 369, 21464, 340, 3505, 21962, 2478, 572, 3192, 28381, 987, 1573, 465, 1121, 7743, 288, 51532], "temperature": 0.0, "avg_logprob": -0.1924112227655226, "compression_ratio": 1.8446969696969697, "no_speech_prob": 0.06566467881202698}, {"id": 47, "seek": 26728, "start": 267.28, "end": 274.67999999999995, "text": " bueno y sistemas que se realizaron en jap\u00f3n y en europa y bueno o sea estos sistemas ten\u00edan fines", "tokens": [50364, 11974, 288, 48720, 631, 369, 22828, 6372, 465, 48330, 1801, 288, 465, 22139, 64, 288, 11974, 277, 4158, 12585, 48720, 47596, 37989, 50734], "temperature": 0.0, "avg_logprob": -0.13113001559643037, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.018214819952845573}, {"id": 48, "seek": 26728, "start": 274.67999999999995, "end": 281.96, "text": " comerciales y no tanto fines militares pero bueno fines de los 90 y despu\u00e9s del 2000 en adelante", "tokens": [50734, 43163, 279, 288, 572, 10331, 37989, 1962, 2786, 495, 4768, 11974, 37989, 368, 1750, 4289, 288, 15283, 1103, 8132, 465, 40214, 51098], "temperature": 0.0, "avg_logprob": -0.13113001559643037, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.018214819952845573}, {"id": 49, "seek": 26728, "start": 281.96, "end": 287.59999999999997, "text": " empezaron a dejarse de usar un poco los sistemas basados en reglas porque porque empez\u00f3 a ver mayor", "tokens": [51098, 18730, 6372, 257, 24391, 405, 368, 14745, 517, 10639, 1750, 48720, 987, 4181, 465, 1121, 7743, 4021, 4021, 18730, 812, 257, 1306, 10120, 51380], "temperature": 0.0, "avg_logprob": -0.13113001559643037, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.018214819952845573}, {"id": 50, "seek": 26728, "start": 287.59999999999997, "end": 291.84, "text": " poder de c\u00f3mputo y mayor cantidad de datos disponibles especialmente con la aparici\u00f3n de", "tokens": [51380, 8152, 368, 6333, 2455, 8262, 288, 10120, 33757, 368, 27721, 23311, 14428, 41546, 416, 635, 34115, 15534, 368, 51592], "temperature": 0.0, "avg_logprob": -0.13113001559643037, "compression_ratio": 1.6483050847457628, "no_speech_prob": 0.018214819952845573}, {"id": 51, "seek": 29184, "start": 291.84, "end": 298.79999999999995, "text": " internet empezaron a ver much\u00edsimos datos de texto disponibles y eso permit\u00eda construir buenos", "tokens": [50364, 4705, 18730, 6372, 257, 1306, 29353, 8372, 27721, 368, 35503, 23311, 14428, 288, 7287, 13423, 2686, 38445, 49617, 50712], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 52, "seek": 29184, "start": 298.79999999999995, "end": 303.76, "text": " modelos estad\u00edsticos que pudieran explotar las regularidades de los idiomas entonces aparecieron", "tokens": [50712, 2316, 329, 39160, 19512, 9940, 631, 14166, 38516, 1490, 310, 289, 2439, 3890, 10284, 368, 1750, 18014, 7092, 13003, 15004, 537, 16308, 50960], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 53, "seek": 29184, "start": 303.76, "end": 307.44, "text": " distintos tipos de modelos estad\u00edsticos los primeros los que llamamos traducciones autom\u00e1ticas", "tokens": [50960, 49337, 37105, 368, 2316, 329, 39160, 19512, 9940, 1750, 12595, 329, 1750, 631, 16848, 2151, 2479, 1311, 23469, 3553, 44997, 51144], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 54, "seek": 29184, "start": 307.44, "end": 311.28, "text": " estad\u00edsticas el otro traducci\u00f3n basado en ejemplos y aparec\u00edan las primeras aplicaciones", "tokens": [51144, 39160, 19512, 9150, 806, 11921, 2479, 1311, 5687, 987, 1573, 465, 10012, 5895, 329, 288, 15004, 66, 11084, 2439, 2886, 6985, 18221, 9188, 51336], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 55, "seek": 29184, "start": 311.28, "end": 315.55999999999995, "text": " comerciales que funcionaban bien que utilizaban modelos estad\u00edsticos la primera fue lengua", "tokens": [51336, 43163, 279, 631, 14186, 18165, 3610, 631, 19906, 18165, 2316, 329, 39160, 19512, 9940, 635, 17382, 9248, 35044, 4398, 51550], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 56, "seek": 29184, "start": 315.55999999999995, "end": 321.03999999999996, "text": " y luego los traductores que m\u00e1s conocemos hoy en d\u00eda el bing translate de microsoft y bueno el", "tokens": [51550, 288, 17222, 1750, 2479, 84, 1672, 279, 631, 3573, 33029, 38173, 13775, 465, 12271, 806, 272, 278, 13799, 368, 3123, 7856, 288, 11974, 806, 51824], "temperature": 0.0, "avg_logprob": -0.18929274422781808, "compression_ratio": 1.8631921824104234, "no_speech_prob": 0.21062278747558594}, {"id": 57, "seek": 32104, "start": 321.12, "end": 326.52000000000004, "text": " translate que probablemente lo conozcan lo hayan usado en alg\u00fan momento y son traductores que la", "tokens": [50368, 13799, 631, 21759, 4082, 450, 416, 15151, 7035, 450, 4842, 282, 505, 1573, 465, 26300, 9333, 288, 1872, 2479, 84, 1672, 279, 631, 635, 50638], "temperature": 0.0, "avg_logprob": -0.12362555628237518, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0024957580026239157}, {"id": 58, "seek": 32104, "start": 326.52000000000004, "end": 331.76000000000005, "text": " verdad que hoy en d\u00eda se puede decir que funcionan bastante bien entonces bueno los m\u00e9todos", "tokens": [50638, 13692, 631, 13775, 465, 12271, 369, 8919, 10235, 631, 14186, 282, 14651, 3610, 13003, 11974, 1750, 20275, 378, 329, 50900], "temperature": 0.0, "avg_logprob": -0.12362555628237518, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0024957580026239157}, {"id": 59, "seek": 32104, "start": 331.76000000000005, "end": 336.20000000000005, "text": " estad\u00edsticos empezaron su boom alrededor del a\u00f1o 2000 y siguen siendo el estado del arte", "tokens": [50900, 39160, 19512, 9940, 18730, 6372, 459, 9351, 43663, 1103, 15984, 8132, 288, 4556, 7801, 31423, 806, 18372, 1103, 29159, 51122], "temperature": 0.0, "avg_logprob": -0.12362555628237518, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0024957580026239157}, {"id": 60, "seek": 32104, "start": 338.28000000000003, "end": 342.36, "text": " pero bueno primero vamos a ver un poco de lo que son los sistemas basados en reglas que eran estos", "tokens": [51226, 4768, 11974, 21289, 5295, 257, 1306, 517, 10639, 368, 450, 631, 1872, 1750, 48720, 987, 4181, 465, 1121, 7743, 631, 32762, 12585, 51430], "temperature": 0.0, "avg_logprob": -0.12362555628237518, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0024957580026239157}, {"id": 61, "seek": 32104, "start": 342.36, "end": 349.92, "text": " primeros sistemas que mencionamos antes en 1968 un investigador de traducci\u00f3n autom\u00e1tica se", "tokens": [51430, 12595, 329, 48720, 631, 37030, 2151, 11014, 465, 29930, 517, 4557, 5409, 368, 2479, 1311, 5687, 3553, 23432, 369, 51808], "temperature": 0.0, "avg_logprob": -0.12362555628237518, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.0024957580026239157}, {"id": 62, "seek": 34992, "start": 349.96000000000004, "end": 355.48, "text": " llamaba pernar bocua hizo un relevamiento de todos los sistemas que se hab\u00edan construido m\u00e1s o", "tokens": [50366, 16848, 5509, 680, 20062, 748, 66, 4398, 28803, 517, 2951, 85, 16971, 368, 6321, 1750, 48720, 631, 369, 44466, 12946, 2925, 3573, 277, 50642], "temperature": 0.0, "avg_logprob": -0.13254261016845703, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.003967779688537121}, {"id": 63, "seek": 34992, "start": 355.48, "end": 361.72, "text": " menos por la \u00e9poca y los clasific\u00f3 todos dentro de este diagrama el dibuj\u00f3 un tri\u00e1ngulo que ahora", "tokens": [50642, 8902, 1515, 635, 25024, 288, 1750, 596, 296, 1089, 812, 6321, 10856, 368, 4065, 10686, 64, 806, 46621, 812, 517, 1376, 30344, 13455, 631, 9923, 50954], "temperature": 0.0, "avg_logprob": -0.13254261016845703, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.003967779688537121}, {"id": 64, "seek": 34992, "start": 361.72, "end": 366.20000000000005, "text": " se llama el tri\u00e1ngulo de bocua y bueno y en este tri\u00e1ngulo se ubican los distintos tipos de", "tokens": [50954, 369, 23272, 806, 1376, 30344, 13455, 368, 748, 66, 4398, 288, 11974, 288, 465, 4065, 1376, 30344, 13455, 369, 26709, 8914, 1750, 49337, 37105, 368, 51178], "temperature": 0.0, "avg_logprob": -0.13254261016845703, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.003967779688537121}, {"id": 65, "seek": 34992, "start": 366.20000000000005, "end": 372.72, "text": " sistemas de traducci\u00f3n basados en reglas se ponen como escalones dentro de este tri\u00e1ngulo y los", "tokens": [51178, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 1121, 7743, 369, 9224, 268, 2617, 17871, 2213, 10856, 368, 4065, 1376, 30344, 13455, 288, 1750, 51504], "temperature": 0.0, "avg_logprob": -0.13254261016845703, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.003967779688537121}, {"id": 66, "seek": 34992, "start": 372.72, "end": 376.88, "text": " lados del tri\u00e1ngulo tienen como distinta interpretaci\u00f3n el lado izquierdo si yo voy subiendo por", "tokens": [51504, 40301, 1103, 1376, 30344, 13455, 12536, 2617, 1483, 16071, 7302, 3482, 806, 11631, 46428, 2595, 1511, 5290, 7552, 1422, 7304, 1515, 51712], "temperature": 0.0, "avg_logprob": -0.13254261016845703, "compression_ratio": 1.8111111111111111, "no_speech_prob": 0.003967779688537121}, {"id": 67, "seek": 37688, "start": 376.92, "end": 381.6, "text": " este lado en realidad lo que aumenta es la cantidad o el esfuerzo de an\u00e1lisis que tengo que", "tokens": [50366, 4065, 11631, 465, 25635, 450, 631, 17128, 64, 785, 635, 33757, 277, 806, 49213, 4765, 368, 44113, 28436, 631, 13989, 631, 50600], "temperature": 0.0, "avg_logprob": -0.1438249572505796, "compression_ratio": 2.1605504587155964, "no_speech_prob": 0.03520680218935013}, {"id": 68, "seek": 37688, "start": 381.6, "end": 385.15999999999997, "text": " hacer del lenguaje origen yo siempre quiero traducirlo en lenguaje origen o lenguaje destino", "tokens": [50600, 6720, 1103, 35044, 84, 11153, 2349, 268, 5290, 12758, 16811, 2479, 1311, 347, 752, 465, 35044, 84, 11153, 2349, 268, 277, 35044, 84, 11153, 2677, 2982, 50778], "temperature": 0.0, "avg_logprob": -0.1438249572505796, "compression_ratio": 2.1605504587155964, "no_speech_prob": 0.03520680218935013}, {"id": 69, "seek": 37688, "start": 385.15999999999997, "end": 389.24, "text": " bueno entonces de este lado aumenta el esfuerzo de traducci\u00f3n del lenguaje origen y si voy", "tokens": [50778, 11974, 13003, 368, 4065, 11631, 17128, 64, 806, 49213, 4765, 368, 2479, 1311, 5687, 1103, 35044, 84, 11153, 2349, 268, 288, 1511, 7552, 50982], "temperature": 0.0, "avg_logprob": -0.1438249572505796, "compression_ratio": 2.1605504587155964, "no_speech_prob": 0.03520680218935013}, {"id": 70, "seek": 37688, "start": 389.24, "end": 393.8, "text": " bajando del lado derecho aumenta bueno si voy subiendo del lado derecho quiero decir aumenta", "tokens": [50982, 23589, 1806, 1103, 11631, 39055, 17128, 64, 11974, 1511, 7552, 1422, 7304, 1103, 11631, 39055, 16811, 10235, 17128, 64, 51210], "temperature": 0.0, "avg_logprob": -0.1438249572505796, "compression_ratio": 2.1605504587155964, "no_speech_prob": 0.03520680218935013}, {"id": 71, "seek": 37688, "start": 393.8, "end": 399.0, "text": " el esfuerzo de generaci\u00f3n en el lenguaje destino entonces qu\u00e9 quiere decir esto yo ubico distintos", "tokens": [51210, 806, 49213, 4765, 368, 1337, 3482, 465, 806, 35044, 84, 11153, 2677, 2982, 13003, 8057, 23877, 10235, 7433, 5290, 26709, 2789, 49337, 51470], "temperature": 0.0, "avg_logprob": -0.1438249572505796, "compression_ratio": 2.1605504587155964, "no_speech_prob": 0.03520680218935013}, {"id": 72, "seek": 39900, "start": 399.0, "end": 406.84, "text": " sistemas de traducci\u00f3n la traducci\u00f3n directa es simplemente buscar en el diccionario las palabras", "tokens": [50364, 48720, 368, 2479, 1311, 5687, 635, 2479, 1311, 5687, 2047, 64, 785, 33190, 26170, 465, 806, 14285, 10015, 4912, 2439, 35240, 50756], "temperature": 0.0, "avg_logprob": -0.12944409847259522, "compression_ratio": 1.9799196787148594, "no_speech_prob": 0.4261671304702759}, {"id": 73, "seek": 39900, "start": 406.84, "end": 412.0, "text": " y traducir palabra palabra con poca informaci\u00f3n m\u00e1s entonces eso casi no necesita ning\u00fan tipo", "tokens": [50756, 288, 2479, 1311, 347, 31702, 31702, 416, 714, 496, 21660, 3573, 13003, 7287, 22567, 572, 45485, 30394, 9746, 51014], "temperature": 0.0, "avg_logprob": -0.12944409847259522, "compression_ratio": 1.9799196787148594, "no_speech_prob": 0.4261671304702759}, {"id": 74, "seek": 39900, "start": 412.0, "end": 417.08, "text": " de an\u00e1lisis y casi no necesita generaci\u00f3n pero para que son de bien yo necesito ponerle muchas", "tokens": [51014, 368, 44113, 28436, 288, 22567, 572, 45485, 1337, 3482, 4768, 1690, 631, 1872, 368, 3610, 5290, 11909, 3528, 19149, 306, 16072, 51268], "temperature": 0.0, "avg_logprob": -0.12944409847259522, "compression_ratio": 1.9799196787148594, "no_speech_prob": 0.4261671304702759}, {"id": 75, "seek": 39900, "start": 417.08, "end": 422.28, "text": " ganas a las reglas o sea las reglas de traducci\u00f3n tienen que ser muy buenas y tienen que tomar en", "tokens": [51268, 7574, 296, 257, 2439, 1121, 7743, 277, 4158, 2439, 1121, 7743, 368, 2479, 1311, 5687, 12536, 631, 816, 5323, 43852, 288, 12536, 631, 22048, 465, 51528], "temperature": 0.0, "avg_logprob": -0.12944409847259522, "compression_ratio": 1.9799196787148594, "no_speech_prob": 0.4261671304702759}, {"id": 76, "seek": 39900, "start": 422.28, "end": 427.08, "text": " cuenta muchos casos para que esa traducci\u00f3n llegue a ser buena entonces es como que la flecha de la", "tokens": [51528, 17868, 17061, 25135, 1690, 631, 11342, 2479, 1311, 5687, 11234, 622, 257, 816, 25710, 13003, 785, 2617, 631, 635, 7025, 4413, 368, 635, 51768], "temperature": 0.0, "avg_logprob": -0.12944409847259522, "compression_ratio": 1.9799196787148594, "no_speech_prob": 0.4261671304702759}, {"id": 77, "seek": 42708, "start": 427.08, "end": 431.52, "text": " transferencia la flecha de la traducci\u00f3n es mucho m\u00e1s larga en cambio si yo hago un poco de an\u00e1lisis", "tokens": [50364, 5003, 10974, 635, 7025, 4413, 368, 635, 2479, 1311, 5687, 785, 9824, 3573, 1613, 3680, 465, 28731, 1511, 5290, 38721, 517, 10639, 368, 44113, 28436, 50586], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 78, "seek": 42708, "start": 431.52, "end": 436.24, "text": " por ejemplo lleg\u00f3 hasta el nivel de an\u00e1lisis intactico tengo un parcer puedo escribir otro", "tokens": [50586, 1515, 13358, 46182, 10764, 806, 24423, 368, 44113, 28436, 23493, 2789, 13989, 517, 971, 1776, 21612, 30598, 10119, 11921, 50822], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 79, "seek": 42708, "start": 436.24, "end": 440.71999999999997, "text": " tipo de reglas que pueden ser un poco m\u00e1s expresivas me resulta un poco m\u00e1s f\u00e1cil y despu\u00e9s si tengo", "tokens": [50822, 9746, 368, 1121, 7743, 631, 14714, 816, 517, 10639, 3573, 33397, 24759, 385, 1874, 64, 517, 10639, 3573, 17474, 288, 15283, 1511, 13989, 51046], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 80, "seek": 42708, "start": 440.71999999999997, "end": 446.32, "text": " un generador puedo llegar a traducir entonces si sigo subiendo de vuelta voy a necesitar mayor", "tokens": [51046, 517, 1337, 5409, 21612, 24892, 257, 2479, 1311, 347, 13003, 1511, 4556, 78, 1422, 7304, 368, 41542, 7552, 257, 11909, 3981, 10120, 51326], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 81, "seek": 42708, "start": 446.32, "end": 449.88, "text": " esfuerzo de an\u00e1lisis de generaci\u00f3n pero las reglas pueden ser m\u00e1s expresivas y m\u00e1s f\u00e1cil de", "tokens": [51326, 49213, 4765, 368, 44113, 28436, 368, 1337, 3482, 4768, 2439, 1121, 7743, 14714, 816, 3573, 33397, 24759, 288, 3573, 17474, 368, 51504], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 82, "seek": 42708, "start": 449.88, "end": 455.47999999999996, "text": " escribir y probablemente la traducci\u00f3n sea mejor hasta que si llegamos al al v\u00e9rtice del", "tokens": [51504, 30598, 10119, 288, 21759, 4082, 635, 2479, 1311, 5687, 4158, 11479, 10764, 631, 1511, 11234, 2151, 419, 419, 371, 33672, 573, 1103, 51784], "temperature": 0.0, "avg_logprob": -0.1352191689896257, "compression_ratio": 1.9147540983606557, "no_speech_prob": 0.031352393329143524}, {"id": 83, "seek": 45548, "start": 455.48, "end": 460.88, "text": " tri\u00e1ngulo llegamos a la interlingua que es una especie de noci\u00f3n en la cual no necesito ning\u00fan", "tokens": [50364, 1376, 30344, 13455, 11234, 2151, 257, 635, 728, 1688, 4398, 631, 785, 2002, 49368, 368, 572, 5687, 465, 635, 10911, 572, 11909, 3528, 30394, 50634], "temperature": 0.0, "avg_logprob": -0.1497513477067302, "compression_ratio": 1.8609022556390977, "no_speech_prob": 0.004304412752389908}, {"id": 84, "seek": 45548, "start": 460.88, "end": 467.0, "text": " tipo de transferencia vamos a ver un poco dentro de un rato de que se trata eso pero bueno empecemos", "tokens": [50634, 9746, 368, 5003, 10974, 5295, 257, 1306, 517, 10639, 10856, 368, 517, 367, 2513, 368, 631, 369, 31920, 7287, 4768, 11974, 846, 494, 38173, 50940], "temperature": 0.0, "avg_logprob": -0.1497513477067302, "compression_ratio": 1.8609022556390977, "no_speech_prob": 0.004304412752389908}, {"id": 85, "seek": 45548, "start": 467.0, "end": 471.72, "text": " a ver los distintos niveles de este tri\u00e1ngulo de bocua el de m\u00e1s abajo era la traducci\u00f3n directa", "tokens": [50940, 257, 1306, 1750, 49337, 11461, 904, 368, 4065, 1376, 30344, 13455, 368, 748, 66, 4398, 806, 368, 3573, 30613, 4249, 635, 2479, 1311, 5687, 2047, 64, 51176], "temperature": 0.0, "avg_logprob": -0.1497513477067302, "compression_ratio": 1.8609022556390977, "no_speech_prob": 0.004304412752389908}, {"id": 86, "seek": 45548, "start": 471.72, "end": 476.72, "text": " es el enfoque m\u00e1s simple lo \u00fanico que necesito para este para este enfoque es un diccionario", "tokens": [51176, 785, 806, 10667, 29743, 3573, 2199, 450, 26113, 631, 11909, 3528, 1690, 4065, 1690, 4065, 10667, 29743, 785, 517, 14285, 10015, 4912, 51426], "temperature": 0.0, "avg_logprob": -0.1497513477067302, "compression_ratio": 1.8609022556390977, "no_speech_prob": 0.004304412752389908}, {"id": 87, "seek": 45548, "start": 476.72, "end": 481.76, "text": " biling\u00fce yo quiero traducir entre los idiomas y necesito un diccionario que tenga la correspondencia", "tokens": [51426, 272, 4883, 774, 68, 5290, 16811, 2479, 1311, 347, 3962, 1750, 18014, 7092, 288, 11909, 3528, 517, 14285, 10015, 4912, 631, 36031, 635, 6805, 10974, 51678], "temperature": 0.0, "avg_logprob": -0.1497513477067302, "compression_ratio": 1.8609022556390977, "no_speech_prob": 0.004304412752389908}, {"id": 88, "seek": 48176, "start": 481.76, "end": 486.15999999999997, "text": " entre palabras de un idioma y palabras del otro y lo que voy a hacer es traducir palabra-palabra", "tokens": [50364, 3962, 35240, 368, 517, 18014, 6440, 288, 35240, 1103, 11921, 288, 450, 631, 7552, 257, 6720, 785, 2479, 1311, 347, 31702, 12, 31862, 455, 424, 50584], "temperature": 0.0, "avg_logprob": -0.1702010302039666, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.05138275772333145}, {"id": 89, "seek": 48176, "start": 486.15999999999997, "end": 491.68, "text": " o sea puedo agregarle alguna cosa extra como por ejemplo alg\u00fan reordenamiento local yo que", "tokens": [50584, 277, 4158, 21612, 4554, 2976, 306, 20651, 10163, 2857, 2617, 1515, 13358, 26300, 319, 19058, 16971, 2654, 5290, 631, 50860], "temperature": 0.0, "avg_logprob": -0.1702010302039666, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.05138275772333145}, {"id": 90, "seek": 48176, "start": 491.68, "end": 496.32, "text": " s\u00e9 para traducir entre espa\u00f1ol ingl\u00e9s yo dir\u00eda que en espa\u00f1ol el nombre se sigue al adjetivo y", "tokens": [50860, 7910, 1690, 2479, 1311, 347, 3962, 31177, 49766, 5290, 4746, 2686, 631, 465, 31177, 806, 13000, 369, 34532, 419, 614, 7108, 6340, 288, 51092], "temperature": 0.0, "avg_logprob": -0.1702010302039666, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.05138275772333145}, {"id": 91, "seek": 48176, "start": 496.32, "end": 499.88, "text": " en ingl\u00e9s en realidad lo hacen al rev\u00e9s ponen el adjetivo seguido el nombre entonces ese tipo de", "tokens": [51092, 465, 49766, 465, 25635, 450, 27434, 419, 3698, 2191, 9224, 268, 806, 614, 7108, 6340, 8878, 2925, 806, 13000, 13003, 10167, 9746, 368, 51270], "temperature": 0.0, "avg_logprob": -0.1702010302039666, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.05138275772333145}, {"id": 92, "seek": 48176, "start": 499.88, "end": 507.08, "text": " reglas simples se las puedo agregar al sistema y bueno el sistema funcionar\u00eda un poco as\u00ed yo tengo", "tokens": [51270, 1121, 7743, 21730, 369, 2439, 21612, 4554, 2976, 419, 13245, 288, 11974, 806, 13245, 14186, 21178, 517, 10639, 8582, 5290, 13989, 51630], "temperature": 0.0, "avg_logprob": -0.1702010302039666, "compression_ratio": 1.7875457875457876, "no_speech_prob": 0.05138275772333145}, {"id": 93, "seek": 50708, "start": 507.08, "end": 512.1999999999999, "text": " una oraci\u00f3n de entrada en el idioma origen mary didn't slap de greenwich le pasa un analizador", "tokens": [50364, 2002, 420, 3482, 368, 37119, 465, 806, 18014, 6440, 2349, 268, 275, 822, 994, 380, 21075, 368, 3092, 9669, 476, 20260, 517, 2624, 590, 5409, 50620], "temperature": 0.0, "avg_logprob": -0.17549785490958922, "compression_ratio": 1.697594501718213, "no_speech_prob": 0.291759192943573}, {"id": 94, "seek": 50708, "start": 512.1999999999999, "end": 517.1999999999999, "text": " morfol\u00f3gico bastante de superficie que no hace mucho en realidad simplemente me dice que esto era", "tokens": [50620, 1896, 7082, 14047, 2789, 14651, 368, 23881, 414, 631, 572, 10032, 9824, 465, 25635, 33190, 385, 10313, 631, 7433, 4249, 50870], "temperature": 0.0, "avg_logprob": -0.17549785490958922, "compression_ratio": 1.697594501718213, "no_speech_prob": 0.291759192943573}, {"id": 95, "seek": 50708, "start": 517.1999999999999, "end": 523.52, "text": " el verbo du en pasado y seguido por un not y bueno el resto de los tokens siguen igual y ac\u00e1 viene", "tokens": [50870, 806, 1306, 1763, 1581, 465, 24794, 288, 8878, 2925, 1515, 517, 406, 288, 11974, 806, 28247, 368, 1750, 22667, 4556, 7801, 10953, 288, 23496, 19561, 51186], "temperature": 0.0, "avg_logprob": -0.17549785490958922, "compression_ratio": 1.697594501718213, "no_speech_prob": 0.291759192943573}, {"id": 96, "seek": 50708, "start": 523.52, "end": 527.92, "text": " la parte de diccionario digamos lo siguiente que tengo que hacer es buscar en mi diccionario cada", "tokens": [51186, 635, 6975, 368, 14285, 10015, 4912, 36430, 450, 25666, 631, 13989, 631, 6720, 785, 26170, 465, 2752, 14285, 10015, 4912, 8411, 51406], "temperature": 0.0, "avg_logprob": -0.17549785490958922, "compression_ratio": 1.697594501718213, "no_speech_prob": 0.291759192943573}, {"id": 97, "seek": 50708, "start": 527.92, "end": 532.76, "text": " una de las palabras y poner la palabra correspondiente del otro lado entonces mary queda mar\u00eda du en", "tokens": [51406, 2002, 368, 2439, 35240, 288, 19149, 635, 31702, 6805, 8413, 1103, 11921, 11631, 13003, 275, 822, 23314, 1849, 2686, 1581, 465, 51648], "temperature": 0.0, "avg_logprob": -0.17549785490958922, "compression_ratio": 1.697594501718213, "no_speech_prob": 0.291759192943573}, {"id": 98, "seek": 53276, "start": 532.76, "end": 538.08, "text": " pasado como en espa\u00f1ol no se usa el du usamos simplemente el marcador de pasado no es no slap es", "tokens": [50364, 24794, 2617, 465, 31177, 572, 369, 29909, 806, 1581, 505, 2151, 33190, 806, 42365, 5409, 368, 24794, 572, 785, 572, 21075, 785, 50630], "temperature": 0.0, "avg_logprob": -0.19663313293457033, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.07511857151985168}, {"id": 99, "seek": 53276, "start": 538.08, "end": 545.76, "text": " dar una ufetada de es la green es verde witch es bruja con el diccionario voy poniendo todas las", "tokens": [50630, 4072, 2002, 344, 69, 302, 1538, 368, 785, 635, 3092, 785, 29653, 14867, 785, 25267, 2938, 416, 806, 14285, 10015, 4912, 7552, 9224, 7304, 10906, 2439, 51014], "temperature": 0.0, "avg_logprob": -0.19663313293457033, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.07511857151985168}, {"id": 100, "seek": 53276, "start": 545.76, "end": 552.0, "text": " traducciones y despu\u00e9s puedo usar mis reglas de reordenamiento local reordenamiento simple como", "tokens": [51014, 2479, 1311, 23469, 288, 15283, 21612, 14745, 3346, 1121, 7743, 368, 319, 19058, 16971, 2654, 319, 19058, 16971, 2199, 2617, 51326], "temperature": 0.0, "avg_logprob": -0.19663313293457033, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.07511857151985168}, {"id": 101, "seek": 53276, "start": 552.0, "end": 557.08, "text": " por ejemplo que el adjetivo seguido en nombre en ingl\u00e9s en realidad en espa\u00f1ol se corresponde con", "tokens": [51326, 1515, 13358, 631, 806, 614, 7108, 6340, 8878, 2925, 465, 13000, 465, 49766, 465, 25635, 465, 31177, 369, 6805, 68, 416, 51580], "temperature": 0.0, "avg_logprob": -0.19663313293457033, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.07511857151985168}, {"id": 102, "seek": 53276, "start": 557.08, "end": 561.52, "text": " nombre seguido adjetivo entonces verdad de bruja lo cambi\u00f3 por bruja verde ac\u00e1 hay otro reordenamiento", "tokens": [51580, 13000, 8878, 2925, 614, 7108, 6340, 13003, 13692, 368, 25267, 2938, 450, 19569, 812, 1515, 25267, 2938, 29653, 23496, 4842, 11921, 319, 19058, 16971, 51802], "temperature": 0.0, "avg_logprob": -0.19663313293457033, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.07511857151985168}, {"id": 103, "seek": 56152, "start": 561.52, "end": 567.0799999999999, "text": " digamos donde tengo una marca de pasado y se la pas\u00f3 para adelante a lo largo y finalmente lo que", "tokens": [50364, 36430, 10488, 13989, 2002, 30582, 368, 24794, 288, 369, 635, 41382, 1690, 40214, 257, 450, 31245, 288, 35577, 450, 631, 50642], "temperature": 0.0, "avg_logprob": -0.16795450448989868, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0013203286798670888}, {"id": 104, "seek": 56152, "start": 567.0799999999999, "end": 573.48, "text": " hago es una peque\u00f1a generaci\u00f3n morfol\u00f3gica con estas marcas y digo bueno este dar en pasado se", "tokens": [50642, 38721, 785, 2002, 47177, 1337, 3482, 1896, 7082, 14047, 2262, 416, 13897, 1849, 16369, 288, 22990, 11974, 4065, 4072, 465, 24794, 369, 50962], "temperature": 0.0, "avg_logprob": -0.16795450448989868, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0013203286798670888}, {"id": 105, "seek": 56152, "start": 573.48, "end": 579.72, "text": " transforma en dio entonces me queda mar\u00eda no dio una ufetada a la bruja verde as\u00ed que part\u00ed de", "tokens": [50962, 4088, 64, 465, 31965, 13003, 385, 23314, 1849, 2686, 572, 31965, 2002, 344, 69, 302, 1538, 257, 635, 25267, 2938, 29653, 8582, 631, 644, 870, 368, 51274], "temperature": 0.0, "avg_logprob": -0.16795450448989868, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0013203286798670888}, {"id": 106, "seek": 56152, "start": 579.72, "end": 585.68, "text": " el texto en el idioma origen merited en slap de green witch y llegu\u00e9 a una oraci\u00f3n en el idioma", "tokens": [51274, 806, 35503, 465, 806, 18014, 6440, 2349, 268, 3551, 1226, 465, 21075, 368, 3092, 14867, 288, 11234, 42423, 257, 2002, 420, 3482, 465, 806, 18014, 6440, 51572], "temperature": 0.0, "avg_logprob": -0.16795450448989868, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0013203286798670888}, {"id": 107, "seek": 56152, "start": 585.68, "end": 589.92, "text": " estino mar\u00eda no dio una ufetada la bruja verde que parece est\u00e1 bastante bien digamos bastante", "tokens": [51572, 871, 2982, 1849, 2686, 572, 31965, 2002, 344, 69, 302, 1538, 635, 25267, 2938, 29653, 631, 14120, 3192, 14651, 3610, 36430, 14651, 51784], "temperature": 0.0, "avg_logprob": -0.16795450448989868, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0013203286798670888}, {"id": 108, "seek": 58992, "start": 589.92, "end": 595.4799999999999, "text": " bien la traducci\u00f3n entonces as\u00ed es como funcionar\u00eda un poco un sistema de traducci\u00f3n directa como les", "tokens": [50364, 3610, 635, 2479, 1311, 5687, 13003, 8582, 785, 2617, 14186, 21178, 517, 10639, 517, 13245, 368, 2479, 1311, 5687, 2047, 64, 2617, 1512, 50642], "temperature": 0.0, "avg_logprob": -0.20677136683809585, "compression_ratio": 1.7118644067796611, "no_speech_prob": 0.02851179987192154}, {"id": 109, "seek": 58992, "start": 595.4799999999999, "end": 600.4, "text": " parece que funcionan estos sistemas en la pr\u00e1ctica digamos que tambi\u00e9n se comportan en la pr\u00e1ctica", "tokens": [50642, 14120, 631, 14186, 282, 12585, 48720, 465, 635, 27300, 29041, 36430, 631, 6407, 369, 25883, 282, 465, 635, 27300, 29041, 50888], "temperature": 0.0, "avg_logprob": -0.20677136683809585, "compression_ratio": 1.7118644067796611, "no_speech_prob": 0.02851179987192154}, {"id": 110, "seek": 58992, "start": 600.4, "end": 605.4799999999999, "text": " este tipo de sistemas pues ac\u00e1 vimos un ejemplo que anda bastante bien digamos pero no s\u00e9 que", "tokens": [50888, 4065, 9746, 368, 48720, 11059, 23496, 49266, 517, 13358, 631, 21851, 14651, 3610, 36430, 4768, 572, 7910, 631, 51142], "temperature": 0.0, "avg_logprob": -0.20677136683809585, "compression_ratio": 1.7118644067796611, "no_speech_prob": 0.02851179987192154}, {"id": 111, "seek": 60548, "start": 605.48, "end": 615.84, "text": " claro y hay otro problema m\u00e1s y es", "tokens": [50364, 16742, 288, 4842, 11921, 12395, 3573, 288, 785, 50882], "temperature": 0.0, "avg_logprob": -0.23418421494333366, "compression_ratio": 1.6, "no_speech_prob": 0.020681502297520638}, {"id": 112, "seek": 60548, "start": 618.6800000000001, "end": 621.8000000000001, "text": " que no tenga todas las palabras pero adem\u00e1s que palabras que se pueden traducir de m\u00e1s de", "tokens": [51024, 631, 572, 36031, 10906, 2439, 35240, 4768, 21251, 631, 35240, 631, 369, 14714, 2479, 1311, 347, 368, 3573, 368, 51180], "temperature": 0.0, "avg_logprob": -0.23418421494333366, "compression_ratio": 1.6, "no_speech_prob": 0.020681502297520638}, {"id": 113, "seek": 60548, "start": 621.8000000000001, "end": 627.12, "text": " una manera entonces necesitas saber qu\u00e9 palabra ten\u00e9s que usar entonces bueno", "tokens": [51180, 2002, 13913, 13003, 11909, 14182, 12489, 8057, 31702, 2064, 2191, 631, 14745, 13003, 11974, 51446], "temperature": 0.0, "avg_logprob": -0.23418421494333366, "compression_ratio": 1.6, "no_speech_prob": 0.020681502297520638}, {"id": 114, "seek": 60548, "start": 628.28, "end": 633.16, "text": " la web est\u00e1 llena de ejemplos de lo que puede salir mal si yo utilizo un sistema de traducci\u00f3n", "tokens": [51504, 635, 3670, 3192, 4849, 4118, 368, 10012, 5895, 329, 368, 450, 631, 8919, 31514, 2806, 1511, 5290, 4976, 19055, 517, 13245, 368, 2479, 1311, 5687, 51748], "temperature": 0.0, "avg_logprob": -0.23418421494333366, "compression_ratio": 1.6, "no_speech_prob": 0.020681502297520638}, {"id": 115, "seek": 63316, "start": 633.16, "end": 638.8, "text": " directa como \u00e9ste entonces lo que est\u00e1bamos viendo reci\u00e9n era los sistemas de traducci\u00f3n directa", "tokens": [50364, 2047, 64, 2617, 1136, 2941, 13003, 450, 631, 3192, 65, 2151, 34506, 4214, 3516, 4249, 1750, 48720, 368, 2479, 1311, 5687, 2047, 64, 50646], "temperature": 0.0, "avg_logprob": -0.13979786060474536, "compression_ratio": 1.9798387096774193, "no_speech_prob": 0.017621399834752083}, {"id": 116, "seek": 63316, "start": 638.8, "end": 644.68, "text": " vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sint\u00e1ctica", "tokens": [50646, 5295, 257, 34785, 517, 10639, 465, 635, 44424, 73, 4580, 368, 1750, 48720, 288, 24892, 257, 635, 5003, 10974, 41259, 842, 29041, 50940], "temperature": 0.0, "avg_logprob": -0.13979786060474536, "compression_ratio": 1.9798387096774193, "no_speech_prob": 0.017621399834752083}, {"id": 117, "seek": 63316, "start": 644.68, "end": 650.4, "text": " entonces para transferencia sint\u00e1ctica yo lo que voy a necesitar primero es tener un p\u00e1rsar del", "tokens": [50940, 13003, 1690, 5003, 10974, 41259, 842, 29041, 5290, 450, 631, 7552, 257, 11909, 3981, 21289, 785, 11640, 517, 280, 20335, 82, 289, 1103, 51226], "temperature": 0.0, "avg_logprob": -0.13979786060474536, "compression_ratio": 1.9798387096774193, "no_speech_prob": 0.017621399834752083}, {"id": 118, "seek": 63316, "start": 650.4, "end": 656.56, "text": " lenguaje origen que me lleva a una una an\u00e1lisis sint\u00e1ctico y adem\u00e1s voy a necesitar un generador", "tokens": [51226, 35044, 84, 11153, 2349, 268, 631, 385, 37681, 257, 2002, 2002, 44113, 28436, 41259, 842, 349, 2789, 288, 21251, 7552, 257, 11909, 3981, 517, 1337, 5409, 51534], "temperature": 0.0, "avg_logprob": -0.13979786060474536, "compression_ratio": 1.9798387096774193, "no_speech_prob": 0.017621399834752083}, {"id": 119, "seek": 63316, "start": 656.56, "end": 660.72, "text": " del lenguaje destino que agarra un \u00e1rbol sint\u00e1ctico del lenguaje destino y genera una oraci\u00f3n", "tokens": [51534, 1103, 35044, 84, 11153, 2677, 2982, 631, 623, 289, 424, 517, 35349, 17460, 41259, 842, 349, 2789, 1103, 35044, 84, 11153, 2677, 2982, 288, 1337, 64, 2002, 420, 3482, 51742], "temperature": 0.0, "avg_logprob": -0.13979786060474536, "compression_ratio": 1.9798387096774193, "no_speech_prob": 0.017621399834752083}, {"id": 120, "seek": 66072, "start": 661.48, "end": 667.64, "text": " entonces yo lo que puedo hacer es escribir reglas que transforma un \u00e1rbol en el otro y esas reglas", "tokens": [50402, 13003, 5290, 450, 631, 21612, 6720, 785, 30598, 10119, 1121, 7743, 631, 4088, 64, 517, 35349, 17460, 465, 806, 11921, 288, 23388, 1121, 7743, 50710], "temperature": 0.0, "avg_logprob": -0.18124656989926197, "compression_ratio": 1.8875968992248062, "no_speech_prob": 0.004977756179869175}, {"id": 121, "seek": 66072, "start": 667.64, "end": 671.32, "text": " son un poco m\u00e1s f\u00e1ciles digamos que lo que necesitar\u00eda para un sistema de traducci\u00f3n directa", "tokens": [50710, 1872, 517, 10639, 3573, 17474, 279, 36430, 631, 450, 631, 11909, 3981, 2686, 1690, 517, 13245, 368, 2479, 1311, 5687, 2047, 64, 50894], "temperature": 0.0, "avg_logprob": -0.18124656989926197, "compression_ratio": 1.8875968992248062, "no_speech_prob": 0.004977756179869175}, {"id": 122, "seek": 66072, "start": 671.32, "end": 674.84, "text": " entonces para el ingl\u00e9s por ejemplo para tu siguiente el ingl\u00e9s y el espa\u00f1ol yo dir\u00eda que", "tokens": [50894, 13003, 1690, 806, 49766, 1515, 13358, 1690, 2604, 25666, 806, 49766, 288, 806, 31177, 5290, 4746, 2686, 631, 51070], "temperature": 0.0, "avg_logprob": -0.18124656989926197, "compression_ratio": 1.8875968992248062, "no_speech_prob": 0.004977756179869175}, {"id": 123, "seek": 66072, "start": 674.84, "end": 679.5600000000001, "text": " si tengo un nominal que es un adjetivo nombre un adjetivo ser\u00eda un nombre en ingl\u00e9s lo transformar\u00eda", "tokens": [51070, 1511, 13989, 517, 41641, 631, 785, 517, 614, 7108, 6340, 13000, 517, 614, 7108, 6340, 23679, 517, 13000, 465, 49766, 450, 4088, 21178, 51306], "temperature": 0.0, "avg_logprob": -0.18124656989926197, "compression_ratio": 1.8875968992248062, "no_speech_prob": 0.004977756179869175}, {"id": 124, "seek": 66072, "start": 679.5600000000001, "end": 685.88, "text": " en un nombre seguir un adjetivo en espa\u00f1ol y la regla se escribir\u00eda algo as\u00ed dir\u00eda tengo", "tokens": [51306, 465, 517, 13000, 18584, 517, 614, 7108, 6340, 465, 31177, 288, 635, 1121, 875, 369, 30598, 10119, 2686, 8655, 8582, 4746, 2686, 13989, 51622], "temperature": 0.0, "avg_logprob": -0.18124656989926197, "compression_ratio": 1.8875968992248062, "no_speech_prob": 0.004977756179869175}, {"id": 125, "seek": 68588, "start": 685.88, "end": 689.32, "text": " un nominal adjetivo nombre entonces lo cambio por nominal nombre adjetivo", "tokens": [50364, 517, 41641, 614, 7108, 6340, 13000, 13003, 450, 28731, 1515, 41641, 13000, 614, 7108, 6340, 50536], "temperature": 0.0, "avg_logprob": -0.28659489814271316, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.009107043035328388}, {"id": 126, "seek": 68588, "start": 691.64, "end": 698.0, "text": " entonces ahora que sabemos c\u00f3mo funciona esto tratemos de hacer el ejemplo en japon\u00e9s digamos", "tokens": [50652, 13003, 9923, 631, 27200, 12826, 26210, 7433, 21507, 4485, 368, 6720, 806, 13358, 465, 361, 21319, 2191, 36430, 50970], "temperature": 0.0, "avg_logprob": -0.28659489814271316, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.009107043035328388}, {"id": 127, "seek": 68588, "start": 698.0, "end": 703.24, "text": " c\u00f3mo ser\u00edan las reglas para transformar el \u00e1rbol en ingl\u00e9s de giador soliciendo music a el", "tokens": [50970, 12826, 816, 11084, 2439, 1121, 7743, 1690, 4088, 289, 806, 35349, 17460, 465, 49766, 368, 1735, 5409, 23665, 7304, 1318, 257, 806, 51232], "temperature": 0.0, "avg_logprob": -0.28659489814271316, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.009107043035328388}, {"id": 128, "seek": 68588, "start": 703.24, "end": 710.0, "text": " japon\u00e9s kareha ongaku uokiku no kadaizuki desu donde est\u00e1 tenemos la correspondencia de cada una de", "tokens": [51232, 361, 21319, 2191, 350, 543, 1641, 322, 70, 15803, 344, 453, 24320, 572, 350, 1538, 590, 11788, 730, 84, 10488, 3192, 9914, 635, 6805, 10974, 368, 8411, 2002, 368, 51570], "temperature": 0.0, "avg_logprob": -0.28659489814271316, "compression_ratio": 1.6636363636363636, "no_speech_prob": 0.009107043035328388}, {"id": 129, "seek": 71000, "start": 710.0, "end": 717.2, "text": " las palabras pero claro los \u00e1rboles son un poco distintos el ingl\u00e9s y el espa\u00f1ol se caracterizan", "tokens": [50364, 2439, 35240, 4768, 16742, 1750, 35349, 65, 7456, 1872, 517, 10639, 49337, 806, 49766, 288, 806, 31177, 369, 28760, 590, 282, 50724], "temperature": 0.0, "avg_logprob": -0.16673410855806792, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.22449754178524017}, {"id": 130, "seek": 71000, "start": 717.2, "end": 722.32, "text": " por ser lenguajes de tipo no s\u00e9 si esto lo hemos visto ya en el curso pero son lenguajes de tipo", "tokens": [50724, 1515, 816, 35044, 84, 29362, 368, 9746, 572, 7910, 1511, 7433, 450, 15396, 17558, 2478, 465, 806, 31085, 4768, 1872, 35044, 84, 29362, 368, 9746, 50980], "temperature": 0.0, "avg_logprob": -0.16673410855806792, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.22449754178524017}, {"id": 131, "seek": 71000, "start": 722.32, "end": 727.16, "text": " sbo que significa que habitualmente yo suelo escribir un sujeto se dio un verbo seguido de", "tokens": [50980, 262, 1763, 631, 19957, 631, 46883, 4082, 5290, 459, 10590, 30598, 10119, 517, 23634, 78, 369, 31965, 517, 1306, 1763, 8878, 2925, 368, 51222], "temperature": 0.0, "avg_logprob": -0.16673410855806792, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.22449754178524017}, {"id": 132, "seek": 71000, "start": 727.16, "end": 732.32, "text": " un objeto el japon\u00e9s en cambio es un lenguaje de tipo sb porque habitualmente se escribi\u00f3", "tokens": [51222, 517, 40438, 806, 361, 21319, 2191, 465, 28731, 785, 517, 35044, 84, 11153, 368, 9746, 262, 65, 4021, 46883, 4082, 369, 30598, 5614, 812, 51480], "temperature": 0.0, "avg_logprob": -0.16673410855806792, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.22449754178524017}, {"id": 133, "seek": 71000, "start": 732.32, "end": 736.52, "text": " el sujeto seguido del objeto seguido del verbo hay muchos lenguajes que pertenecen a esta otra", "tokens": [51480, 806, 23634, 78, 8878, 2925, 1103, 40438, 8878, 2925, 1103, 1306, 1763, 4842, 17061, 35044, 84, 29362, 631, 680, 1147, 3045, 268, 257, 5283, 13623, 51690], "temperature": 0.0, "avg_logprob": -0.16673410855806792, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.22449754178524017}, {"id": 134, "seek": 73652, "start": 736.52, "end": 743.56, "text": " categor\u00eda entonces bueno queremos escribir reglas de transferencia para transformar este \u00e1rbol en", "tokens": [50364, 19250, 2686, 13003, 11974, 26813, 30598, 10119, 1121, 7743, 368, 5003, 10974, 1690, 4088, 289, 4065, 35349, 17460, 465, 50716], "temperature": 0.0, "avg_logprob": -0.16773971598199072, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.004602416418492794}, {"id": 135, "seek": 73652, "start": 743.56, "end": 751.1999999999999, "text": " aquel otro \u00e1rbol c\u00f3mo escribir\u00edamos esas reglas que les parece que reglas utilizar\u00eda yo para", "tokens": [50716, 2373, 338, 11921, 35349, 17460, 12826, 30598, 10119, 16275, 23388, 1121, 7743, 631, 1512, 14120, 631, 1121, 7743, 24060, 2686, 5290, 1690, 51098], "temperature": 0.0, "avg_logprob": -0.16773971598199072, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.004602416418492794}, {"id": 136, "seek": 75120, "start": 751.2, "end": 765.4000000000001, "text": " transformar un \u00e1rbol en el otro ah\u00ed est\u00e1 una de esas en ingl\u00e9s yo escribo", "tokens": [50364, 4088, 289, 517, 35349, 17460, 465, 806, 11921, 12571, 3192, 2002, 368, 23388, 465, 49766, 5290, 30598, 1763, 51074], "temperature": 0.0, "avg_logprob": -0.31281149905660877, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.010325523093342781}, {"id": 137, "seek": 75120, "start": 770.4000000000001, "end": 776.2800000000001, "text": " una frase verbal un grupo verbal como un verbo seguido de un grupo precaucional esta es la que", "tokens": [51324, 2002, 38406, 24781, 517, 20190, 24781, 2617, 517, 1306, 1763, 8878, 2925, 368, 517, 20190, 25651, 1311, 1966, 5283, 785, 635, 631, 51618], "temperature": 0.0, "avg_logprob": -0.31281149905660877, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.010325523093342781}, {"id": 138, "seek": 77628, "start": 777.0, "end": 779.28, "text": " est\u00e1 y la cambio por qu\u00e9 otra cosa", "tokens": [50400, 3192, 288, 635, 28731, 1515, 8057, 13623, 10163, 50514], "temperature": 0.0, "avg_logprob": -0.3592838028729972, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.021016674116253853}, {"id": 139, "seek": 77628, "start": 784.8399999999999, "end": 793.0, "text": " la cambio por un grupo preposicional que sigue un verbo esa es una qu\u00e9 otra regla tendr\u00eda que", "tokens": [50792, 635, 28731, 1515, 517, 20190, 2666, 329, 33010, 631, 34532, 517, 1306, 1763, 11342, 785, 2002, 8057, 13623, 1121, 875, 3928, 37183, 631, 51200], "temperature": 0.0, "avg_logprob": -0.3592838028729972, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.021016674116253853}, {"id": 140, "seek": 77628, "start": 793.0, "end": 801.4399999999999, "text": " agregar cu\u00e1l la elaboraci\u00f3n que tiene la operaci\u00f3n la operaci\u00f3n seg\u00fan esto en ingl\u00e9s es un", "tokens": [51200, 4554, 2976, 44318, 635, 16298, 3482, 631, 7066, 635, 2208, 3482, 635, 2208, 3482, 36570, 7433, 465, 49766, 785, 517, 51622], "temperature": 0.0, "avg_logprob": -0.3592838028729972, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.021016674116253853}, {"id": 141, "seek": 80144, "start": 801.44, "end": 808.9200000000001, "text": " pronombre seguido de un verbo seguido de un grupo verbal por qu\u00e9 tendr\u00eda a cambiarlo", "tokens": [50364, 7569, 298, 2672, 8878, 2925, 368, 517, 1306, 1763, 8878, 2925, 368, 517, 20190, 24781, 1515, 8057, 3928, 37183, 257, 19569, 19457, 50738], "temperature": 0.0, "avg_logprob": -0.24265572963616786, "compression_ratio": 1.720496894409938, "no_speech_prob": 0.007167479954659939}, {"id": 142, "seek": 80144, "start": 810.72, "end": 818.6800000000001, "text": " ahora en japon\u00e9s la operaci\u00f3n va a ser el pronombre seguido del verse seguido del verbo", "tokens": [50828, 9923, 465, 361, 21319, 2191, 635, 2208, 3482, 2773, 257, 816, 806, 7569, 298, 2672, 8878, 2925, 1103, 7996, 8878, 2925, 1103, 1306, 1763, 51226], "temperature": 0.0, "avg_logprob": -0.24265572963616786, "compression_ratio": 1.720496894409938, "no_speech_prob": 0.007167479954659939}, {"id": 143, "seek": 80144, "start": 818.6800000000001, "end": 820.0, "text": " bien alguna otra", "tokens": [51226, 3610, 20651, 13623, 51292], "temperature": 0.0, "avg_logprob": -0.24265572963616786, "compression_ratio": 1.720496894409938, "no_speech_prob": 0.007167479954659939}, {"id": 144, "seek": 80144, "start": 822.44, "end": 827.84, "text": " ah\u00ed est\u00e1 el grupo preposicional que est\u00e1 formado por un t\u00fa seguido de un nombre", "tokens": [51414, 12571, 3192, 806, 20190, 2666, 329, 33010, 631, 3192, 1254, 1573, 1515, 517, 15056, 8878, 2925, 368, 517, 13000, 51684], "temperature": 0.0, "avg_logprob": -0.24265572963616786, "compression_ratio": 1.720496894409938, "no_speech_prob": 0.007167479954659939}, {"id": 145, "seek": 82784, "start": 827.84, "end": 835.1600000000001, "text": " eso es en ingl\u00e9s y en japon\u00e9s que va a pasar voy a tener un grupo preposicional que es un nombre", "tokens": [50364, 7287, 785, 465, 49766, 288, 465, 361, 21319, 2191, 631, 2773, 257, 25344, 7552, 257, 11640, 517, 20190, 2666, 329, 33010, 631, 785, 517, 13000, 50730], "temperature": 0.0, "avg_logprob": -0.2050542936220274, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0015288875438272953}, {"id": 146, "seek": 82784, "start": 835.1600000000001, "end": 841.72, "text": " seguido de t\u00fa bien entonces con eso m\u00e1s o menos creo que tendr\u00eda las reglas suficientes para", "tokens": [50730, 8878, 2925, 368, 15056, 3610, 13003, 416, 7287, 3573, 277, 8902, 14336, 631, 3928, 37183, 2439, 1121, 7743, 459, 1786, 20135, 1690, 51058], "temperature": 0.0, "avg_logprob": -0.2050542936220274, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0015288875438272953}, {"id": 147, "seek": 82784, "start": 841.72, "end": 845.76, "text": " transformar un \u00e1rbol en el otro los sistemas de traducci\u00f3n vamos a ver si est\u00e1 bien", "tokens": [51058, 4088, 289, 517, 35349, 17460, 465, 806, 11921, 1750, 48720, 368, 2479, 1311, 5687, 5295, 257, 1306, 1511, 3192, 3610, 51260], "temperature": 0.0, "avg_logprob": -0.2050542936220274, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0015288875438272953}, {"id": 148, "seek": 82784, "start": 847.76, "end": 850.84, "text": " son los que escribimos esta es la soluci\u00f3n del ejercicio", "tokens": [51360, 1872, 1750, 631, 30598, 65, 8372, 5283, 785, 635, 24807, 5687, 1103, 39151, 18322, 51514], "temperature": 0.0, "avg_logprob": -0.2050542936220274, "compression_ratio": 1.5694444444444444, "no_speech_prob": 0.0015288875438272953}, {"id": 149, "seek": 85084, "start": 851.84, "end": 858.52, "text": " los sistemas de traducci\u00f3n basados en sintaxis en realidad los sistemas de reglas basados en", "tokens": [50414, 1750, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 41259, 24633, 465, 25635, 1750, 48720, 368, 1121, 7743, 987, 4181, 465, 50748], "temperature": 0.0, "avg_logprob": -0.16880268297697368, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.036054473370313644}, {"id": 150, "seek": 85084, "start": 858.52, "end": 863.72, "text": " sintaxis hacen esto a alto nivel digamos tienen un mont\u00f3n de pares de \u00e1rboles hay gente que", "tokens": [50748, 41259, 24633, 27434, 7433, 257, 21275, 24423, 36430, 12536, 517, 45259, 368, 2502, 495, 368, 35349, 65, 7456, 4842, 3788, 631, 51008], "temperature": 0.0, "avg_logprob": -0.16880268297697368, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.036054473370313644}, {"id": 151, "seek": 85084, "start": 863.72, "end": 868.64, "text": " los analiza y escribe reglas de c\u00f3mo se transforma uno en el otro a veces las reglas son complicadas", "tokens": [51008, 1750, 2624, 13427, 288, 785, 8056, 1121, 7743, 368, 12826, 369, 4088, 64, 8526, 465, 806, 11921, 257, 17054, 2439, 1121, 7743, 1872, 16060, 6872, 51254], "temperature": 0.0, "avg_logprob": -0.16880268297697368, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.036054473370313644}, {"id": 152, "seek": 85084, "start": 868.64, "end": 875.32, "text": " porque se pueden super poner entonces hay que definir prioridades y ese tipo de cosas bueno", "tokens": [51254, 4021, 369, 14714, 1687, 19149, 13003, 4842, 631, 1561, 347, 4059, 10284, 288, 10167, 9746, 368, 12218, 11974, 51588], "temperature": 0.0, "avg_logprob": -0.16880268297697368, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.036054473370313644}, {"id": 153, "seek": 87532, "start": 875.32, "end": 880.5200000000001, "text": " esos transferencias sint\u00e1cticas si seguimos subiendo en la en el tri\u00e1ngulo de bocua llegamos", "tokens": [50364, 22411, 5003, 37246, 41259, 842, 349, 9150, 1511, 8878, 8372, 1422, 7304, 465, 635, 465, 806, 1376, 30344, 13455, 368, 748, 66, 4398, 11234, 2151, 50624], "temperature": 0.0, "avg_logprob": -0.16962560966833315, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.09507009387016296}, {"id": 154, "seek": 87532, "start": 880.5200000000001, "end": 885.48, "text": " a lo que es la transferencia sem\u00e1ntica transferencia sem\u00e1ntica uno puede pensarla un poco como lo", "tokens": [50624, 257, 450, 631, 785, 635, 5003, 10974, 4361, 27525, 2262, 5003, 10974, 4361, 27525, 2262, 8526, 8919, 18321, 875, 517, 10639, 2617, 450, 50872], "temperature": 0.0, "avg_logprob": -0.16962560966833315, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.09507009387016296}, {"id": 155, "seek": 87532, "start": 885.48, "end": 889.72, "text": " que hab\u00edamos en la clase pasada utilizando roles sem\u00e1nticos yo tengo un etiquetador de", "tokens": [50872, 631, 3025, 16275, 465, 635, 44578, 1736, 1538, 19906, 1806, 9604, 4361, 27525, 9940, 5290, 13989, 517, 42177, 302, 5409, 368, 51084], "temperature": 0.0, "avg_logprob": -0.16962560966833315, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.09507009387016296}, {"id": 156, "seek": 87532, "start": 889.72, "end": 895.0, "text": " roles sem\u00e1nticos que agarra la oraci\u00f3n juan fue a la tienda y me devuelve los roles de los", "tokens": [51084, 9604, 4361, 27525, 9940, 631, 623, 289, 424, 635, 420, 3482, 3649, 282, 9248, 257, 635, 256, 30498, 288, 385, 1905, 3483, 303, 1750, 9604, 368, 1750, 51348], "temperature": 0.0, "avg_logprob": -0.16962560966833315, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.09507009387016296}, {"id": 157, "seek": 87532, "start": 895.0, "end": 900.6800000000001, "text": " constituyentes me dice que juan es el agente y a la tienda es el objetivo o gol digamos es el nombre", "tokens": [51348, 16085, 88, 9240, 385, 10313, 631, 3649, 282, 785, 806, 623, 1576, 288, 257, 635, 256, 30498, 785, 806, 29809, 277, 9988, 36430, 785, 806, 13000, 51632], "temperature": 0.0, "avg_logprob": -0.16962560966833315, "compression_ratio": 1.8853754940711462, "no_speech_prob": 0.09507009387016296}, {"id": 158, "seek": 90068, "start": 900.68, "end": 907.0, "text": " del rol entonces yo para ciertos idiomas podr\u00eda escribir reglas m\u00e1s espec\u00edficas por ejemplo en", "tokens": [50364, 1103, 34109, 13003, 5290, 1690, 49252, 329, 18014, 7092, 27246, 30598, 10119, 1121, 7743, 3573, 32741, 296, 1515, 13358, 465, 50680], "temperature": 0.0, "avg_logprob": -0.1262806538612612, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.11966484040021896}, {"id": 159, "seek": 90068, "start": 907.0, "end": 912.1999999999999, "text": " chino ocurre que los sintamas preposicionales que son de tipo objetivo se escriben antes del verbo", "tokens": [50680, 417, 2982, 26430, 265, 631, 1750, 41259, 19473, 2666, 329, 33010, 279, 631, 1872, 368, 9746, 29809, 369, 30598, 1799, 11014, 1103, 1306, 1763, 50940], "temperature": 0.0, "avg_logprob": -0.1262806538612612, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.11966484040021896}, {"id": 160, "seek": 90068, "start": 912.1999999999999, "end": 916.3599999999999, "text": " pero los dem\u00e1s sintamas preposicionales escriben despu\u00e9s o sea el chino es un lenguaje de tipo", "tokens": [50940, 4768, 1750, 34682, 41259, 19473, 2666, 329, 33010, 279, 30598, 1799, 15283, 277, 4158, 806, 417, 2982, 785, 517, 35044, 84, 11153, 368, 9746, 51148], "temperature": 0.0, "avg_logprob": -0.1262806538612612, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.11966484040021896}, {"id": 161, "seek": 90068, "start": 916.3599999999999, "end": 923.8, "text": " sbo igual que el ingl\u00e9s o el espa\u00f1ol pero cuando el objeto es de tipo gol lo que hacen es ponerlo", "tokens": [51148, 262, 1763, 10953, 631, 806, 49766, 277, 806, 31177, 4768, 7767, 806, 40438, 785, 368, 9746, 9988, 450, 631, 27434, 785, 19149, 752, 51520], "temperature": 0.0, "avg_logprob": -0.1262806538612612, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.11966484040021896}, {"id": 162, "seek": 90068, "start": 923.8, "end": 930.28, "text": " antes del verbo entonces yo podr\u00eda escribir una regla un poco m\u00e1s expresiva para este caso del", "tokens": [51520, 11014, 1103, 1306, 1763, 13003, 5290, 27246, 30598, 10119, 2002, 1121, 875, 517, 10639, 3573, 33397, 5931, 1690, 4065, 9666, 1103, 51844], "temperature": 0.0, "avg_logprob": -0.1262806538612612, "compression_ratio": 1.8992248062015504, "no_speech_prob": 0.11966484040021896}, {"id": 163, "seek": 93028, "start": 930.28, "end": 937.48, "text": " chino si yo tuviera los roles sem\u00e1nticos yo dir\u00eda que un grupo verbal es un verbo seguido de esto no", "tokens": [50364, 417, 2982, 1511, 5290, 38177, 10609, 1750, 9604, 4361, 27525, 9940, 5290, 4746, 2686, 631, 517, 20190, 24781, 785, 517, 1306, 1763, 8878, 2925, 368, 7433, 572, 50724], "temperature": 0.0, "avg_logprob": -0.1919973387972999, "compression_ratio": 1.9554655870445343, "no_speech_prob": 0.004914280958473682}, {"id": 164, "seek": 93028, "start": 937.48, "end": 942.72, "text": " est\u00e1 tachado sino que era la barrita que qued\u00f3 arriba es un verbo seguido de una de un grupo", "tokens": [50724, 3192, 256, 608, 1573, 18108, 631, 4249, 635, 2159, 81, 2786, 631, 13617, 812, 28469, 785, 517, 1306, 1763, 8878, 2925, 368, 2002, 368, 517, 20190, 50986], "temperature": 0.0, "avg_logprob": -0.1919973387972999, "compression_ratio": 1.9554655870445343, "no_speech_prob": 0.004914280958473682}, {"id": 165, "seek": 93028, "start": 942.72, "end": 948.4399999999999, "text": " preposicional de tipo gol en chino lo cambiar\u00eda por un verbo seguido de perd\u00f3n por un grupo", "tokens": [50986, 2666, 329, 33010, 368, 9746, 9988, 465, 417, 2982, 450, 19569, 21178, 1515, 517, 1306, 1763, 8878, 2925, 368, 12611, 1801, 1515, 517, 20190, 51272], "temperature": 0.0, "avg_logprob": -0.1919973387972999, "compression_ratio": 1.9554655870445343, "no_speech_prob": 0.004914280958473682}, {"id": 166, "seek": 93028, "start": 948.4399999999999, "end": 955.1999999999999, "text": " producci\u00f3n de tipo gol seguido de un verbo es m\u00e1s costoso para generar y para parcer digamos", "tokens": [51272, 48586, 368, 9746, 9988, 8878, 2925, 368, 517, 1306, 1763, 785, 3573, 2063, 9869, 1690, 1337, 289, 288, 1690, 971, 1776, 36430, 51610], "temperature": 0.0, "avg_logprob": -0.1919973387972999, "compression_ratio": 1.9554655870445343, "no_speech_prob": 0.004914280958473682}, {"id": 167, "seek": 93028, "start": 955.1999999999999, "end": 958.9599999999999, "text": " necesito tener m\u00e1s esfuerzo de par sin m\u00e1s esfuerzo de generaci\u00f3n pero puede escribir mejores", "tokens": [51610, 11909, 3528, 11640, 3573, 49213, 4765, 368, 971, 3343, 3573, 49213, 4765, 368, 1337, 3482, 4768, 8919, 30598, 10119, 42284, 51798], "temperature": 0.0, "avg_logprob": -0.1919973387972999, "compression_ratio": 1.9554655870445343, "no_speech_prob": 0.004914280958473682}, {"id": 168, "seek": 95896, "start": 958.96, "end": 965.5600000000001, "text": " reglas que capturan ciertas particularidades de los lenguajes y si yo sigo subiendo en el", "tokens": [50364, 1121, 7743, 631, 3770, 12125, 49252, 296, 1729, 10284, 368, 1750, 35044, 84, 29362, 288, 1511, 5290, 4556, 78, 1422, 7304, 465, 806, 50694], "temperature": 0.0, "avg_logprob": -0.12458276360984741, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0396893285214901}, {"id": 169, "seek": 95896, "start": 965.5600000000001, "end": 969.6800000000001, "text": " tri\u00e1ngulo llego a lo que se conoce como interlingua cu\u00e1l es la gracia del interlingua cu\u00e1l es la", "tokens": [50694, 1376, 30344, 13455, 4849, 6308, 257, 450, 631, 369, 33029, 384, 2617, 728, 1688, 4398, 44318, 785, 635, 11625, 654, 1103, 728, 1688, 4398, 44318, 785, 635, 50900], "temperature": 0.0, "avg_logprob": -0.12458276360984741, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0396893285214901}, {"id": 170, "seek": 95896, "start": 969.6800000000001, "end": 974.0, "text": " idea estos sirve si nosotros estamos en un contexto multicultural estamos trabajando por", "tokens": [50900, 1558, 12585, 4735, 303, 1511, 13863, 10382, 465, 517, 47685, 47684, 10382, 40473, 1515, 51116], "temperature": 0.0, "avg_logprob": -0.12458276360984741, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0396893285214901}, {"id": 171, "seek": 95896, "start": 974.0, "end": 979.96, "text": " ejemplo en la ONU o en el parlamento europeo o algo de eso donde se hablan muchos idiomas si", "tokens": [51116, 13358, 465, 635, 9299, 52, 277, 465, 806, 13734, 8824, 27207, 78, 277, 8655, 368, 7287, 10488, 369, 3025, 8658, 17061, 18014, 7092, 1511, 51414], "temperature": 0.0, "avg_logprob": -0.12458276360984741, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0396893285214901}, {"id": 172, "seek": 95896, "start": 979.96, "end": 984.72, "text": " yo quiero mantener un mont\u00f3n de documentos que est\u00e9n en todos los idiomas a la vez voy a necesitar", "tokens": [51414, 5290, 16811, 42759, 517, 45259, 368, 4166, 329, 631, 871, 3516, 465, 6321, 1750, 18014, 7092, 257, 635, 5715, 7552, 257, 11909, 3981, 51652], "temperature": 0.0, "avg_logprob": -0.12458276360984741, "compression_ratio": 1.7163636363636363, "no_speech_prob": 0.0396893285214901}, {"id": 173, "seek": 98472, "start": 984.88, "end": 988.84, "text": " para los sistemas que estuve viendo hasta el momento voy a necesitar tener n parsers uno", "tokens": [50372, 1690, 1750, 48720, 631, 871, 31564, 34506, 10764, 806, 9333, 7552, 257, 11909, 3981, 11640, 297, 21156, 433, 8526, 50570], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 174, "seek": 98472, "start": 988.84, "end": 993.44, "text": " para ac\u00e1 de idioma n generadores tambi\u00e9n uno para ac\u00e1 de idioma y despu\u00e9s para cada", "tokens": [50570, 1690, 23496, 368, 18014, 6440, 297, 1337, 11856, 6407, 8526, 1690, 23496, 368, 18014, 6440, 288, 15283, 1690, 8411, 50800], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 175, "seek": 98472, "start": 993.44, "end": 997.72, "text": " parte de idiomas voy a necesitar reglas de transferencia entonces voy a necesitar tener", "tokens": [50800, 6975, 368, 18014, 7092, 7552, 257, 11909, 3981, 1121, 7743, 368, 5003, 10974, 13003, 7552, 257, 11909, 3981, 11640, 51014], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 176, "seek": 98472, "start": 997.72, "end": 1003.9200000000001, "text": " en total n por n menos un set de transferencia yo tengo 20 idiomas voy a necesitar 380 conjuntos", "tokens": [51014, 465, 3217, 297, 1515, 297, 8902, 517, 992, 368, 5003, 10974, 5290, 13989, 945, 18014, 7092, 7552, 257, 11909, 3981, 805, 4702, 20295, 2760, 329, 51324], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 177, "seek": 98472, "start": 1003.9200000000001, "end": 1008.32, "text": " de reglas de transferencia y esos conjuntos de referencia son largos son grandes son complejos", "tokens": [51324, 368, 1121, 7743, 368, 5003, 10974, 288, 22411, 20295, 2760, 329, 368, 2864, 10974, 1872, 11034, 329, 1872, 16640, 1872, 44424, 19136, 51544], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 178, "seek": 98472, "start": 1008.32, "end": 1013.64, "text": " hay que mantenerlos pueden tener errores entonces esto claramente no escala es como muy dif\u00edcil", "tokens": [51544, 4842, 631, 42759, 9389, 14714, 11640, 45935, 495, 13003, 7433, 6093, 3439, 572, 4721, 5159, 785, 2617, 5323, 17258, 51810], "temperature": 0.0, "avg_logprob": -0.14602616581603559, "compression_ratio": 2.0634328358208953, "no_speech_prob": 0.33955636620521545}, {"id": 179, "seek": 101364, "start": 1014.08, "end": 1018.48, "text": " poder mantener un entorno de todos esos idiomas y poder mantener la traducci\u00f3n en base a reglas", "tokens": [50386, 8152, 42759, 517, 948, 21998, 368, 6321, 22411, 18014, 7092, 288, 8152, 42759, 635, 2479, 1311, 5687, 465, 3096, 257, 1121, 7743, 50606], "temperature": 0.0, "avg_logprob": -0.13831286785031152, "compression_ratio": 1.9877551020408164, "no_speech_prob": 0.0053570163436234}, {"id": 180, "seek": 101364, "start": 1018.48, "end": 1025.8, "text": " entonces la idea del interlingua es decir qu\u00e9 tal si pudi\u00e9ramos parsear lo suficiente o analizarlo", "tokens": [50606, 13003, 635, 1558, 1103, 728, 1688, 4398, 785, 10235, 8057, 4023, 1511, 14166, 72, 4198, 2151, 971, 405, 289, 450, 33958, 277, 2624, 9736, 752, 50972], "temperature": 0.0, "avg_logprob": -0.13831286785031152, "compression_ratio": 1.9877551020408164, "no_speech_prob": 0.0053570163436234}, {"id": 181, "seek": 101364, "start": 1025.8, "end": 1030.0, "text": " lo suficiente como para llevar a una representaci\u00f3n com\u00fan una representaci\u00f3n que capture el", "tokens": [50972, 450, 33958, 2617, 1690, 30374, 257, 2002, 2906, 3482, 45448, 2002, 2906, 3482, 631, 7983, 806, 51182], "temperature": 0.0, "avg_logprob": -0.13831286785031152, "compression_ratio": 1.9877551020408164, "no_speech_prob": 0.0053570163436234}, {"id": 182, "seek": 101364, "start": 1030.0, "end": 1034.52, "text": " significado de todos los idiomas a la vez y adem\u00e1s tuvi\u00e9ramos un generador para cada uno de los", "tokens": [51182, 3350, 1573, 368, 6321, 1750, 18014, 7092, 257, 635, 5715, 288, 21251, 2604, 4917, 4198, 2151, 517, 1337, 5409, 1690, 8411, 8526, 368, 1750, 51408], "temperature": 0.0, "avg_logprob": -0.13831286785031152, "compression_ratio": 1.9877551020408164, "no_speech_prob": 0.0053570163436234}, {"id": 183, "seek": 101364, "start": 1034.52, "end": 1040.6399999999999, "text": " idiomas si eso pasara si nosotros pudi\u00e9ramos capturar con una representaci\u00f3n el significado de", "tokens": [51408, 18014, 7092, 1511, 7287, 1736, 2419, 1511, 13863, 14166, 72, 4198, 2151, 3770, 28586, 416, 2002, 2906, 3482, 806, 3350, 1573, 368, 51714], "temperature": 0.0, "avg_logprob": -0.13831286785031152, "compression_ratio": 1.9877551020408164, "no_speech_prob": 0.0053570163436234}, {"id": 184, "seek": 104064, "start": 1040.64, "end": 1045.6000000000001, "text": " los idiomas a la vez no necesitar\u00edamos transferencia simplemente parseamos y llevamos a esa interlingua", "tokens": [50364, 1750, 18014, 7092, 257, 635, 5715, 572, 11909, 3981, 16275, 5003, 10974, 33190, 971, 405, 2151, 288, 27124, 2151, 257, 11342, 728, 1688, 4398, 50612], "temperature": 0.0, "avg_logprob": -0.15859663291055648, "compression_ratio": 1.8224637681159421, "no_speech_prob": 0.004478742368519306}, {"id": 185, "seek": 104064, "start": 1045.6000000000001, "end": 1052.8400000000001, "text": " y despu\u00e9s generamos en el otro idioma esto est\u00e1 muy bien digamos del punto de vista ideal pero es", "tokens": [50612, 288, 15283, 1337, 2151, 465, 806, 11921, 18014, 6440, 7433, 3192, 5323, 3610, 36430, 1103, 14326, 368, 22553, 7157, 4768, 785, 50974], "temperature": 0.0, "avg_logprob": -0.15859663291055648, "compression_ratio": 1.8224637681159421, "no_speech_prob": 0.004478742368519306}, {"id": 186, "seek": 104064, "start": 1052.8400000000001, "end": 1058.72, "text": " muy dif\u00edcil de obtener en la pr\u00e1ctica que se podr\u00eda usar como representaci\u00f3n de interlingua que", "tokens": [50974, 5323, 17258, 368, 28326, 260, 465, 635, 27300, 29041, 631, 369, 27246, 14745, 2617, 2906, 3482, 368, 728, 1688, 4398, 631, 51268], "temperature": 0.0, "avg_logprob": -0.15859663291055648, "compression_ratio": 1.8224637681159421, "no_speech_prob": 0.004478742368519306}, {"id": 187, "seek": 104064, "start": 1058.72, "end": 1063.5200000000002, "text": " podr\u00eda ser un candidato bueno podr\u00edamos usar la l\u00f3gica de primer orden que era lo que ve\u00edamos", "tokens": [51268, 27246, 816, 517, 6268, 2513, 11974, 15305, 16275, 14745, 635, 48475, 2262, 368, 12595, 28615, 631, 4249, 450, 631, 1241, 16275, 51508], "temperature": 0.0, "avg_logprob": -0.15859663291055648, "compression_ratio": 1.8224637681159421, "no_speech_prob": 0.004478742368519306}, {"id": 188, "seek": 104064, "start": 1063.5200000000002, "end": 1067.68, "text": " en las primeras clases de sem\u00e1ntica como representar veraciones en los primer orden o alguna de sus", "tokens": [51508, 465, 2439, 2886, 6985, 596, 1957, 368, 4361, 27525, 2262, 2617, 2906, 289, 1306, 9188, 465, 1750, 12595, 28615, 277, 20651, 368, 3291, 51716], "temperature": 0.0, "avg_logprob": -0.15859663291055648, "compression_ratio": 1.8224637681159421, "no_speech_prob": 0.004478742368519306}, {"id": 189, "seek": 106768, "start": 1067.68, "end": 1072.3200000000002, "text": " variantes que dan cuenta mejor de lo que es la l\u00f3gica del lenguaje natural como la m\u00ednima", "tokens": [50364, 3034, 9327, 631, 3277, 17868, 11479, 368, 450, 631, 785, 635, 48475, 2262, 1103, 35044, 84, 11153, 3303, 2617, 635, 33656, 4775, 50596], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 190, "seek": 106768, "start": 1072.3200000000002, "end": 1077.1200000000001, "text": " recurso sem\u00e1nticos o la whole sem\u00e1ntics o si no algo m\u00e1s parecido lo que ve\u00edamos en la clase", "tokens": [50596, 18680, 539, 4361, 27525, 9940, 277, 635, 1379, 4361, 27525, 1167, 277, 1511, 572, 8655, 3573, 7448, 17994, 450, 631, 1241, 16275, 465, 635, 44578, 50836], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 191, "seek": 106768, "start": 1077.1200000000001, "end": 1081.88, "text": " anterior de frames construirme frames con el estado de las cosas como por ejemplo esta era la", "tokens": [50836, 22272, 368, 12083, 12946, 347, 1398, 12083, 416, 806, 18372, 368, 2439, 12218, 2617, 1515, 13358, 5283, 4249, 635, 51074], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 192, "seek": 106768, "start": 1081.88, "end": 1086.16, "text": " misma oraci\u00f3n de hoy mary didn't slap de green wish pero escrita como un frame es hay un evento de", "tokens": [51074, 24946, 420, 3482, 368, 13775, 275, 822, 994, 380, 21075, 368, 3092, 3172, 4768, 49865, 2786, 2617, 517, 3920, 785, 4842, 517, 40655, 368, 51288], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 193, "seek": 106768, "start": 1086.16, "end": 1092.48, "text": " slapping el agente es mary ocurre en pasado la polaridad negativa el tema de ese evento es la", "tokens": [51288, 8039, 3759, 806, 623, 1576, 785, 275, 822, 26430, 265, 465, 24794, 635, 12367, 4580, 2485, 18740, 806, 15854, 368, 10167, 40655, 785, 635, 51604], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 194, "seek": 106768, "start": 1092.48, "end": 1096.64, "text": " bruja y la bruja de m\u00e1s es verde yo podr\u00eda construirme este tipo de frames y usarlos como", "tokens": [51604, 25267, 2938, 288, 635, 25267, 2938, 368, 3573, 785, 29653, 5290, 27246, 38445, 1398, 4065, 9746, 368, 12083, 288, 505, 39734, 2617, 51812], "temperature": 0.0, "avg_logprob": -0.22199246724446614, "compression_ratio": 1.8031746031746032, "no_speech_prob": 0.03393399342894554}, {"id": 195, "seek": 109664, "start": 1096.64, "end": 1106.3200000000002, "text": " representaciones pero bueno el problema que tiene crear o pensar en crear una interlingua es que", "tokens": [50364, 2906, 9188, 4768, 11974, 806, 12395, 631, 7066, 31984, 277, 18321, 465, 31984, 2002, 728, 1688, 4398, 785, 631, 50848], "temperature": 0.0, "avg_logprob": -0.13064155578613282, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0007472089491784573}, {"id": 196, "seek": 109664, "start": 1106.3200000000002, "end": 1111.4, "text": " esa interlingua seguro que va a ser muy compleja y seguro que va a tener que modelar las caracter\u00edsticas", "tokens": [50848, 11342, 728, 1688, 4398, 31424, 631, 2773, 257, 816, 5323, 44424, 2938, 288, 31424, 631, 2773, 257, 11640, 631, 2316, 289, 2439, 47990, 51102], "temperature": 0.0, "avg_logprob": -0.13064155578613282, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0007472089491784573}, {"id": 197, "seek": 109664, "start": 1111.4, "end": 1117.64, "text": " de todos los idiomas al mismo tiempo y hay caracter\u00edsticas que son complicadas en los", "tokens": [51102, 368, 6321, 1750, 18014, 7092, 419, 12461, 11772, 288, 4842, 47990, 631, 1872, 16060, 6872, 465, 1750, 51414], "temperature": 0.0, "avg_logprob": -0.13064155578613282, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0007472089491784573}, {"id": 198, "seek": 109664, "start": 1117.64, "end": 1124.0, "text": " distintos idiomas y algunas que ni nos ni nos imaginamos o sea por ejemplo en chino existen", "tokens": [51414, 49337, 18014, 7092, 288, 27316, 631, 3867, 3269, 3867, 3269, 23427, 2151, 277, 4158, 1515, 13358, 465, 417, 2982, 2514, 268, 51732], "temperature": 0.0, "avg_logprob": -0.13064155578613282, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0007472089491784573}, {"id": 199, "seek": 112400, "start": 1124.0, "end": 1127.28, "text": " palabras distintas para decir hermano mayor y hermano menor y no hay una palabra para decir", "tokens": [50364, 35240, 31489, 296, 1690, 10235, 39458, 78, 10120, 288, 39458, 78, 26343, 288, 572, 4842, 2002, 31702, 1690, 10235, 50528], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 200, "seek": 112400, "start": 1127.28, "end": 1131.84, "text": " hermano o sea no hay una palabra que quiere decir solamente hermano en espa\u00f1ol si y en ingl\u00e9s", "tokens": [50528, 39458, 78, 277, 4158, 572, 4842, 2002, 31702, 631, 23877, 10235, 27814, 39458, 78, 465, 31177, 1511, 288, 465, 49766, 50756], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 201, "seek": 112400, "start": 1131.84, "end": 1136.64, "text": " tambi\u00e9n en ingl\u00e9s puede decir brother pero en chino no en chino ten\u00e9s que elegir cuando vas a decir", "tokens": [50756, 6407, 465, 49766, 8919, 10235, 3708, 4768, 465, 417, 2982, 572, 465, 417, 2982, 2064, 2191, 631, 14459, 347, 7767, 11481, 257, 10235, 50996], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 202, "seek": 112400, "start": 1136.64, "end": 1141.56, "text": " hermano si es hermano mayor o hermano menor entonces imag\u00ednense que si yo estoy traduciendo del espa\u00f1ol", "tokens": [50996, 39458, 78, 1511, 785, 39458, 78, 10120, 277, 39458, 78, 26343, 13003, 2576, 10973, 1288, 631, 1511, 5290, 15796, 2479, 84, 16830, 1103, 31177, 51242], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 203, "seek": 112400, "start": 1141.56, "end": 1147.72, "text": " al ingl\u00e9s y estoy utilizando una interlingua la interlingua en su parcer necesita poder distinguir", "tokens": [51242, 419, 49766, 288, 15796, 19906, 1806, 2002, 728, 1688, 4398, 635, 728, 1688, 4398, 465, 459, 971, 1776, 45485, 8152, 11365, 347, 51550], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 204, "seek": 112400, "start": 1147.72, "end": 1151.6, "text": " en alg\u00fan momento si estoy hablando de un hermano mayor o un hermano menor porque tiene que lograr", "tokens": [51550, 465, 26300, 9333, 1511, 15796, 29369, 368, 517, 39458, 78, 10120, 277, 517, 39458, 78, 26343, 4021, 7066, 631, 31013, 289, 51744], "temperature": 0.0, "avg_logprob": -0.1362134493314303, "compression_ratio": 2.1402877697841727, "no_speech_prob": 0.07447363436222076}, {"id": 205, "seek": 115160, "start": 1151.6, "end": 1156.36, "text": " la representaci\u00f3n suficiente como para poder traducir al chino entonces necesita esa informaci\u00f3n y", "tokens": [50364, 635, 2906, 3482, 33958, 2617, 1690, 8152, 2479, 1311, 347, 419, 417, 2982, 13003, 45485, 11342, 21660, 288, 50602], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 206, "seek": 115160, "start": 1156.36, "end": 1160.0, "text": " no s\u00e9 d\u00f3nde la va a sacar la puede sacar de contexto lo puede sacar inventar de alg\u00fan lado", "tokens": [50602, 572, 7910, 34264, 635, 2773, 257, 43823, 635, 8919, 43823, 368, 47685, 450, 8919, 43823, 7962, 289, 368, 26300, 11631, 50784], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 207, "seek": 115160, "start": 1160.0, "end": 1164.48, "text": " pero en alg\u00fan momento va a tener que averiguar el hermano que se est\u00e1 hablando en espa\u00f1ol si es un", "tokens": [50784, 4768, 465, 26300, 9333, 2773, 257, 11640, 631, 18247, 16397, 289, 806, 39458, 78, 631, 369, 3192, 29369, 465, 31177, 1511, 785, 517, 51008], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 208, "seek": 115160, "start": 1164.48, "end": 1168.6799999999998, "text": " hermano mayor o menor como para poder tener la representaci\u00f3n y despu\u00e9s de informaci\u00f3n se va", "tokens": [51008, 39458, 78, 10120, 277, 26343, 2617, 1690, 8152, 11640, 635, 2906, 3482, 288, 15283, 368, 21660, 369, 2773, 51218], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 209, "seek": 115160, "start": 1168.6799999999998, "end": 1173.32, "text": " a perder porque cuando baja de vuelta al lado del ingl\u00e9s de vuelta vuelve a ser brother y no importa si", "tokens": [51218, 257, 26971, 4021, 7767, 49427, 368, 41542, 419, 11631, 1103, 49766, 368, 41542, 20126, 303, 257, 816, 3708, 288, 572, 33218, 1511, 51450], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 210, "seek": 115160, "start": 1173.32, "end": 1178.6, "text": " es mayor o menor y esto solamente un caso de un fen\u00f3meno que ocurre en chino pero digamos imag\u00ednense", "tokens": [51450, 785, 10120, 277, 26343, 288, 7433, 27814, 517, 9666, 368, 517, 26830, 812, 43232, 631, 26430, 265, 465, 417, 2982, 4768, 36430, 2576, 10973, 1288, 51714], "temperature": 0.0, "avg_logprob": -0.1486476080758231, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.02983950264751911}, {"id": 211, "seek": 117860, "start": 1178.6, "end": 1183.6, "text": " los fen\u00f3menos que ocurren en el idioma en en en todo el tiempo digamos y todas las peque\u00f1as", "tokens": [50364, 1750, 26830, 812, 2558, 329, 631, 26430, 1095, 465, 806, 18014, 6440, 465, 465, 465, 5149, 806, 11772, 36430, 288, 10906, 2439, 19132, 32448, 50614], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 212, "seek": 117860, "start": 1183.6, "end": 1190.12, "text": " variantes que hay y como en realidad no es cierto que podamos traducir exactamente los mismos conceptos", "tokens": [50614, 3034, 9327, 631, 4842, 288, 2617, 465, 25635, 572, 785, 28558, 631, 2497, 2151, 2479, 1311, 347, 48686, 1750, 47458, 3410, 329, 50940], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 213, "seek": 117860, "start": 1190.12, "end": 1193.9199999999998, "text": " como que es muy dif\u00edcil encontrar conceptos que se correspondan 100 por ciento de un idioma y otro", "tokens": [50940, 2617, 631, 785, 5323, 17258, 17525, 3410, 329, 631, 369, 6805, 282, 2319, 1515, 47361, 368, 517, 18014, 6440, 288, 11921, 51130], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 214, "seek": 117860, "start": 1193.9199999999998, "end": 1198.36, "text": " hay una cosa que llama el principio de incertidumbre la traducci\u00f3n y dice eso que en realidad cuando", "tokens": [51130, 4842, 2002, 10163, 631, 23272, 806, 34308, 368, 834, 911, 327, 449, 2672, 635, 2479, 1311, 5687, 288, 10313, 7287, 631, 465, 25635, 7767, 51352], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 215, "seek": 117860, "start": 1198.36, "end": 1202.52, "text": " yo tengo un idioma y otro los conceptos no siempre se van a traducir 100 por ciento bien o sea no", "tokens": [51352, 5290, 13989, 517, 18014, 6440, 288, 11921, 1750, 3410, 329, 572, 12758, 369, 3161, 257, 2479, 1311, 347, 2319, 1515, 47361, 3610, 277, 4158, 572, 51560], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 216, "seek": 117860, "start": 1202.52, "end": 1207.3999999999999, "text": " siempre la traducci\u00f3n es exacta sino que hay cierto solopamiento y a veces va a funcionar y a veces", "tokens": [51560, 12758, 635, 2479, 1311, 5687, 785, 1900, 64, 18108, 631, 4842, 28558, 1404, 404, 16971, 288, 257, 17054, 2773, 257, 14186, 289, 288, 257, 17054, 51804], "temperature": 0.0, "avg_logprob": -0.1346572506812311, "compression_ratio": 1.9671052631578947, "no_speech_prob": 0.15138864517211914}, {"id": 217, "seek": 120740, "start": 1207.4, "end": 1216.6000000000001, "text": " no bien pero a pesar de que es una utop\u00eda tener una interlingua que funcione para todo para todos", "tokens": [50364, 572, 3610, 4768, 257, 41951, 368, 631, 785, 2002, 2839, 404, 2686, 11640, 2002, 728, 1688, 4398, 631, 1019, 66, 5328, 1690, 5149, 1690, 6321, 50824], "temperature": 0.0, "avg_logprob": -0.1751154468905541, "compression_ratio": 1.7624113475177305, "no_speech_prob": 0.0015416548121720552}, {"id": 218, "seek": 120740, "start": 1216.6000000000001, "end": 1221.24, "text": " los lenguajes bien este tipo de tecnolog\u00eda si se utilizan para dominios m\u00e1s acotados para dominios", "tokens": [50824, 1750, 35044, 84, 29362, 3610, 4065, 9746, 368, 48055, 1511, 369, 19906, 282, 1690, 8859, 2717, 3573, 696, 310, 4181, 1690, 8859, 2717, 51056], "temperature": 0.0, "avg_logprob": -0.1751154468905541, "compression_ratio": 1.7624113475177305, "no_speech_prob": 0.0015416548121720552}, {"id": 219, "seek": 120740, "start": 1221.24, "end": 1226.96, "text": " peque\u00f1os como por ejemplo el de meteorolog\u00eda yo puedo escribir perfectamente puedo construir una", "tokens": [51056, 19132, 8242, 2617, 1515, 13358, 806, 368, 25313, 29987, 5290, 21612, 30598, 10119, 2176, 3439, 21612, 38445, 2002, 51342], "temperature": 0.0, "avg_logprob": -0.1751154468905541, "compression_ratio": 1.7624113475177305, "no_speech_prob": 0.0015416548121720552}, {"id": 220, "seek": 120740, "start": 1226.96, "end": 1230.6000000000001, "text": " representaci\u00f3n de todos los estados meteorol\u00f3gicos que hay si hay viento si hay lluvias y nieve hacia", "tokens": [51342, 2906, 3482, 368, 6321, 1750, 871, 4181, 25313, 27629, 9940, 631, 4842, 1511, 4842, 371, 7814, 1511, 4842, 4849, 9350, 4609, 288, 2838, 303, 21365, 51524], "temperature": 0.0, "avg_logprob": -0.1751154468905541, "compression_ratio": 1.7624113475177305, "no_speech_prob": 0.0015416548121720552}, {"id": 221, "seek": 120740, "start": 1230.6000000000001, "end": 1236.0800000000002, "text": " y granizo la temperatura la presi\u00f3n etc\u00e9tera y traducir los distintos las distintas palabras", "tokens": [51524, 288, 9370, 19055, 635, 36903, 635, 1183, 2560, 5183, 526, 23833, 288, 2479, 1311, 347, 1750, 49337, 2439, 31489, 296, 35240, 51798], "temperature": 0.0, "avg_logprob": -0.1751154468905541, "compression_ratio": 1.7624113475177305, "no_speech_prob": 0.0015416548121720552}, {"id": 222, "seek": 123608, "start": 1236.08, "end": 1240.4399999999998, "text": " que se usan los distintos idiomas para dar cuenta de estos conceptos entonces ese dominio acotado", "tokens": [50364, 631, 369, 505, 282, 1750, 49337, 18014, 7092, 1690, 4072, 17868, 368, 12585, 3410, 329, 13003, 10167, 8859, 1004, 696, 310, 1573, 50582], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 223, "seek": 123608, "start": 1240.4399999999998, "end": 1246.6, "text": " es bastante bien manejable con una interlingua y otro ejemplo son los manuales t\u00e9cnicos hay empresas", "tokens": [50582, 785, 14651, 3610, 12743, 73, 712, 416, 2002, 728, 1688, 4398, 288, 11921, 13358, 1872, 1750, 9688, 279, 25564, 48674, 4842, 26433, 50890], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 224, "seek": 123608, "start": 1246.6, "end": 1252.48, "text": " que tienen un mont\u00f3n de documentaci\u00f3n t\u00e9cnica o describen las apis de sus productos etc\u00e9tera y", "tokens": [50890, 631, 12536, 517, 45259, 368, 4166, 3482, 45411, 277, 2189, 1799, 2439, 1882, 271, 368, 3291, 46363, 5183, 526, 23833, 288, 51184], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 225, "seek": 123608, "start": 1252.48, "end": 1257.8, "text": " uno suele dar cuando cuando mira la p\u00e1gina web digamos que aparece como que con su fijo es porque", "tokens": [51184, 8526, 459, 16884, 4072, 7767, 7767, 30286, 635, 36960, 3670, 36430, 631, 37863, 2617, 631, 416, 459, 283, 24510, 785, 4021, 51450], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 226, "seek": 123608, "start": 1257.8, "end": 1261.6799999999998, "text": " est\u00e1 en espa\u00f1ol pero si se lo cambia por n autom\u00e1ticamente te genera otra p\u00e1gina exactamente", "tokens": [51450, 3192, 465, 31177, 4768, 1511, 369, 450, 18751, 654, 1515, 297, 3553, 7656, 23653, 535, 1337, 64, 13623, 36960, 48686, 51644], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 227, "seek": 123608, "start": 1261.6799999999998, "end": 1265.76, "text": " igual pero en ingl\u00e9s en realidad lo que hacen es como mantener una representaci\u00f3n abstracta de", "tokens": [51644, 10953, 4768, 465, 49766, 465, 25635, 450, 631, 27434, 785, 2617, 42759, 2002, 2906, 3482, 12649, 64, 368, 51848], "temperature": 0.0, "avg_logprob": -0.15000876827516418, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.008943037129938602}, {"id": 228, "seek": 126576, "start": 1265.76, "end": 1268.2, "text": " lo que est\u00e1n escribiendo y generarla en los distintos idiomas", "tokens": [50364, 450, 631, 10368, 30598, 65, 7304, 288, 1337, 34148, 465, 1750, 49337, 18014, 7092, 50486], "temperature": 0.0, "avg_logprob": -0.19383213209069294, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0010211680782958865}, {"id": 229, "seek": 126576, "start": 1271.4, "end": 1275.24, "text": " bien entonces hasta ah\u00ed lo que vimos era como un paneo de lo que son los distintos", "tokens": [50646, 3610, 13003, 10764, 12571, 450, 631, 49266, 4249, 2617, 517, 32605, 78, 368, 450, 631, 1872, 1750, 49337, 50838], "temperature": 0.0, "avg_logprob": -0.19383213209069294, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0010211680782958865}, {"id": 230, "seek": 126576, "start": 1275.24, "end": 1280.08, "text": " sistemas basados en reglas ahora vamos a pasar a hablar de lo que es la traducci\u00f3n estad\u00edstica", "tokens": [50838, 48720, 987, 4181, 465, 1121, 7743, 9923, 5295, 257, 25344, 257, 21014, 368, 450, 631, 785, 635, 2479, 1311, 5687, 39160, 19512, 2262, 51080], "temperature": 0.0, "avg_logprob": -0.19383213209069294, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0010211680782958865}, {"id": 231, "seek": 126576, "start": 1280.08, "end": 1285.84, "text": " que es el estado del arte hoy en d\u00eda y vamos a empezar con un ejemplo un ejemplo de una frase", "tokens": [51080, 631, 785, 806, 18372, 1103, 29159, 13775, 465, 12271, 288, 5295, 257, 31168, 416, 517, 13358, 517, 13358, 368, 2002, 38406, 51368], "temperature": 0.0, "avg_logprob": -0.19383213209069294, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0010211680782958865}, {"id": 232, "seek": 126576, "start": 1285.84, "end": 1292.16, "text": " en hebreo que es adona y roi que la traducci\u00f3n ser\u00eda el se\u00f1or es mi pastor o del or y es", "tokens": [51368, 465, 415, 2672, 78, 631, 785, 614, 4037, 288, 744, 72, 631, 635, 2479, 1311, 5687, 23679, 806, 22188, 785, 2752, 21193, 277, 1103, 420, 288, 785, 51684], "temperature": 0.0, "avg_logprob": -0.19383213209069294, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0010211680782958865}, {"id": 233, "seek": 129216, "start": 1292.16, "end": 1299.2, "text": " my shepherd y esta frase en realidad funciona bien porque nosotros conocemos que son las ovejas", "tokens": [50364, 452, 40317, 288, 5283, 38406, 465, 25635, 26210, 3610, 4021, 13863, 33029, 38173, 631, 1872, 2439, 277, 303, 19221, 50716], "temperature": 0.0, "avg_logprob": -0.16445735295613606, "compression_ratio": 1.8661417322834646, "no_speech_prob": 0.008370297029614449}, {"id": 234, "seek": 129216, "start": 1299.2, "end": 1304.16, "text": " digamos la cultura en la que surgi\u00f3 esta frase conoc\u00eda que eran las ovejas ten\u00edan pastores", "tokens": [50716, 36430, 635, 30576, 465, 635, 631, 19560, 7138, 5283, 38406, 15871, 2686, 631, 32762, 2439, 277, 303, 19221, 47596, 1791, 2706, 50964], "temperature": 0.0, "avg_logprob": -0.16445735295613606, "compression_ratio": 1.8661417322834646, "no_speech_prob": 0.008370297029614449}, {"id": 235, "seek": 129216, "start": 1304.16, "end": 1307.8000000000002, "text": " los pastores este cuidaban las ovejas la llevaban a donde estaban los mejores pastos etc\u00e9tera", "tokens": [50964, 1750, 1791, 2706, 4065, 20770, 18165, 2439, 277, 303, 19221, 635, 27124, 18165, 257, 10488, 36713, 1750, 42284, 1791, 329, 5183, 526, 23833, 51146], "temperature": 0.0, "avg_logprob": -0.16445735295613606, "compression_ratio": 1.8661417322834646, "no_speech_prob": 0.008370297029614449}, {"id": 236, "seek": 129216, "start": 1307.8000000000002, "end": 1314.6000000000001, "text": " entonces esta esta met\u00e1fora funcionaba bien digamos la gente describ\u00eda como se sent\u00eda", "tokens": [51146, 13003, 5283, 5283, 1131, 842, 2994, 64, 14186, 5509, 3610, 36430, 635, 3788, 2189, 65, 2686, 2617, 369, 2279, 2686, 51486], "temperature": 0.0, "avg_logprob": -0.16445735295613606, "compression_ratio": 1.8661417322834646, "no_speech_prob": 0.008370297029614449}, {"id": 237, "seek": 129216, "start": 1314.6000000000001, "end": 1320.72, "text": " en respecto a dios utilizando esta met\u00e1fora pero qu\u00e9 tal si quisi\u00e9ramos expresar esta misma frase", "tokens": [51486, 465, 35694, 257, 1026, 329, 19906, 1806, 5283, 1131, 842, 2994, 64, 4768, 8057, 4023, 1511, 421, 8021, 4198, 2151, 33397, 289, 5283, 24946, 38406, 51792], "temperature": 0.0, "avg_logprob": -0.16445735295613606, "compression_ratio": 1.8661417322834646, "no_speech_prob": 0.008370297029614449}, {"id": 238, "seek": 132072, "start": 1321.2, "end": 1326.28, "text": " a una cultura que no conoce a las ovejas como por ejemplo los primeros misioneros que vendr\u00edan", "tokens": [50388, 257, 2002, 30576, 631, 572, 33029, 384, 257, 2439, 277, 303, 19221, 2617, 1515, 13358, 1750, 12595, 329, 275, 1991, 16771, 631, 10169, 81, 11084, 50642], "temperature": 0.0, "avg_logprob": -0.12342993121280849, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.009548299014568329}, {"id": 239, "seek": 132072, "start": 1326.28, "end": 1333.1200000000001, "text": " de europa y tendr\u00edan contacto con los ind\u00edgenas americanos no conoc\u00edan ovejas entonces c\u00f3mo", "tokens": [50642, 368, 22139, 64, 288, 3928, 81, 11084, 3385, 78, 416, 1750, 1016, 36492, 296, 31229, 329, 572, 15871, 11084, 277, 303, 19221, 13003, 12826, 50984], "temperature": 0.0, "avg_logprob": -0.12342993121280849, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.009548299014568329}, {"id": 240, "seek": 132072, "start": 1333.1200000000001, "end": 1340.72, "text": " hacemos para expresarles el concepto de adona y roi una forma de expresarlo es decir bueno", "tokens": [50984, 33839, 1690, 33397, 289, 904, 806, 3410, 78, 368, 614, 4037, 288, 744, 72, 2002, 8366, 368, 33397, 19457, 785, 10235, 11974, 51364], "temperature": 0.0, "avg_logprob": -0.12342993121280849, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.009548299014568329}, {"id": 241, "seek": 132072, "start": 1340.72, "end": 1346.2, "text": " traduzco la met\u00e1fora el significado de la met\u00e1fora digo significa el se\u00f1or me cuidar\u00e1 que en", "tokens": [51364, 2479, 3334, 1291, 635, 1131, 842, 2994, 64, 806, 3350, 1573, 368, 635, 1131, 842, 2994, 64, 22990, 19957, 806, 22188, 385, 20770, 21534, 631, 465, 51638], "temperature": 0.0, "avg_logprob": -0.12342993121280849, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.009548299014568329}, {"id": 242, "seek": 134620, "start": 1346.2, "end": 1351.68, "text": " definitiva es un poco la met\u00e1fora quiere decir eso aunque pierda un poco del contenido o si no lo", "tokens": [50364, 28781, 5931, 785, 517, 10639, 635, 1131, 842, 2994, 64, 23877, 10235, 7287, 21962, 9766, 2675, 517, 10639, 1103, 47117, 277, 1511, 572, 450, 50638], "temperature": 0.0, "avg_logprob": -0.13597943523142597, "compression_ratio": 1.6875, "no_speech_prob": 0.056586455553770065}, {"id": 243, "seek": 134620, "start": 1351.68, "end": 1357.1200000000001, "text": " que lo otro que puedo hacer es tratar de ser m\u00e1s fiel al significado original y tratar de traducirlo", "tokens": [50638, 631, 450, 11921, 631, 21612, 6720, 785, 42549, 368, 816, 3573, 283, 1187, 419, 3350, 1573, 3380, 288, 42549, 368, 2479, 1311, 347, 752, 50910], "temperature": 0.0, "avg_logprob": -0.13597943523142597, "compression_ratio": 1.6875, "no_speech_prob": 0.056586455553770065}, {"id": 244, "seek": 134620, "start": 1357.1200000000001, "end": 1361.32, "text": " m\u00e1s literalmente y decir bueno el se\u00f1or ser\u00e1 para m\u00ed como un hombre que cuida de animales que tiene", "tokens": [50910, 3573, 20411, 4082, 288, 10235, 11974, 806, 22188, 16502, 1690, 14692, 2617, 517, 26102, 631, 2702, 2887, 368, 45102, 631, 7066, 51120], "temperature": 0.0, "avg_logprob": -0.13597943523142597, "compression_ratio": 1.6875, "no_speech_prob": 0.056586455553770065}, {"id": 245, "seek": 134620, "start": 1361.32, "end": 1369.56, "text": " el pelo como algod\u00f3n que es bastante m\u00e1s fiel al original pero sin embargo se entiende mucho menos", "tokens": [51120, 806, 12167, 2617, 3501, 378, 1801, 631, 785, 14651, 3573, 283, 1187, 419, 3380, 4768, 3343, 23955, 369, 948, 45816, 9824, 8902, 51532], "temperature": 0.0, "avg_logprob": -0.13597943523142597, "compression_ratio": 1.6875, "no_speech_prob": 0.056586455553770065}, {"id": 246, "seek": 136956, "start": 1369.56, "end": 1376.36, "text": " como que te van a mirar y decirte qu\u00e9 me est\u00e1s hablando y bueno un poco este es el problema que", "tokens": [50364, 2617, 631, 535, 3161, 257, 3149, 289, 288, 10235, 975, 8057, 385, 24389, 29369, 288, 11974, 517, 10639, 4065, 785, 806, 12395, 631, 50704], "temperature": 0.0, "avg_logprob": -0.14680473388187468, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.014462786726653576}, {"id": 247, "seek": 136956, "start": 1376.36, "end": 1382.9199999999998, "text": " hay que se enfrentan los traductores humanos todos los d\u00edas o sea es muy dif\u00edcil tener las dos", "tokens": [50704, 4842, 631, 369, 33771, 282, 1750, 2479, 84, 1672, 279, 34555, 6321, 1750, 19527, 277, 4158, 785, 5323, 17258, 11640, 2439, 4491, 51032], "temperature": 0.0, "avg_logprob": -0.14680473388187468, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.014462786726653576}, {"id": 248, "seek": 136956, "start": 1382.9199999999998, "end": 1389.36, "text": " cosas ser fiel al original y sonar natural que suene bien en el lenguaje destino una traducci\u00f3n", "tokens": [51032, 12218, 816, 283, 1187, 419, 3380, 288, 1872, 289, 3303, 631, 459, 1450, 3610, 465, 806, 35044, 84, 11153, 2677, 2982, 2002, 2479, 1311, 5687, 51354], "temperature": 0.0, "avg_logprob": -0.14680473388187468, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.014462786726653576}, {"id": 249, "seek": 136956, "start": 1389.36, "end": 1394.36, "text": " queremos que tenga esas dos propiedades pero muy dif\u00edcil lograrlo a la vez entonces los traductores", "tokens": [51354, 26813, 631, 36031, 23388, 4491, 2365, 1091, 2977, 4768, 5323, 17258, 31013, 19457, 257, 635, 5715, 13003, 1750, 2479, 84, 1672, 279, 51604], "temperature": 0.0, "avg_logprob": -0.14680473388187468, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.014462786726653576}, {"id": 250, "seek": 136956, "start": 1394.36, "end": 1399.32, "text": " humanos saben que esto es imposible en la pr\u00e1ctica lo que hacen es tratar de traducir de manera", "tokens": [51604, 34555, 36670, 631, 7433, 785, 38396, 964, 465, 635, 27300, 29041, 450, 631, 27434, 785, 42549, 368, 2479, 1311, 347, 368, 13913, 51852], "temperature": 0.0, "avg_logprob": -0.14680473388187468, "compression_ratio": 1.7589928057553956, "no_speech_prob": 0.014462786726653576}, {"id": 251, "seek": 139932, "start": 1399.32, "end": 1403.96, "text": " de encontrar un punto intermedio en el cual bueno suene bastante bien pero adem\u00e1s sea fiel al", "tokens": [50364, 368, 17525, 517, 14326, 728, 1912, 1004, 465, 806, 10911, 11974, 459, 1450, 14651, 3610, 4768, 21251, 4158, 283, 1187, 419, 50596], "temperature": 0.0, "avg_logprob": -0.10902494192123413, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.0004048106202390045}, {"id": 252, "seek": 139932, "start": 1403.96, "end": 1412.12, "text": " significado original entonces esto significa que lo que estamos tratando de hacer al traducir es que", "tokens": [50596, 3350, 1573, 3380, 13003, 7433, 19957, 631, 450, 631, 10382, 21507, 1806, 368, 6720, 419, 2479, 1311, 347, 785, 631, 51004], "temperature": 0.0, "avg_logprob": -0.10902494192123413, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.0004048106202390045}, {"id": 253, "seek": 139932, "start": 1412.12, "end": 1418.36, "text": " estamos tratando de maximizar dos cosas a la vez como dos medidas que queremos maximizar una medida", "tokens": [51004, 10382, 21507, 1806, 368, 5138, 9736, 4491, 12218, 257, 635, 5715, 2617, 4491, 37295, 631, 26813, 5138, 9736, 2002, 32984, 51316], "temperature": 0.0, "avg_logprob": -0.10902494192123413, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.0004048106202390045}, {"id": 254, "seek": 139932, "start": 1418.36, "end": 1422.96, "text": " es que tan fiel es mi oraci\u00f3n traducida a la oraci\u00f3n original a esa medida le vamos a llamar", "tokens": [51316, 785, 631, 7603, 283, 1187, 785, 2752, 420, 3482, 2479, 1311, 2887, 257, 635, 420, 3482, 3380, 257, 11342, 32984, 476, 5295, 257, 16848, 289, 51546], "temperature": 0.0, "avg_logprob": -0.10902494192123413, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.0004048106202390045}, {"id": 255, "seek": 142296, "start": 1422.96, "end": 1430.8400000000001, "text": " adecuaci\u00f3n o fidelidad y en ingl\u00e9s es adecuaci\u00f3n fidelidad y la otra medida es que tan natural suena", "tokens": [50364, 614, 3045, 84, 3482, 277, 283, 16189, 4580, 288, 465, 49766, 785, 614, 3045, 84, 3482, 283, 16189, 4580, 288, 635, 13623, 32984, 785, 631, 7603, 3303, 459, 4118, 50758], "temperature": 0.0, "avg_logprob": -0.16231552759806314, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.009028369560837746}, {"id": 256, "seek": 142296, "start": 1430.8400000000001, "end": 1435.3600000000001, "text": " la oraci\u00f3n que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en ingl\u00e9s", "tokens": [50758, 635, 420, 3482, 631, 5290, 2479, 13008, 465, 806, 35044, 84, 11153, 2677, 2982, 288, 257, 11342, 32984, 476, 7552, 257, 16848, 289, 5029, 45170, 277, 465, 49766, 50984], "temperature": 0.0, "avg_logprob": -0.16231552759806314, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.009028369560837746}, {"id": 257, "seek": 142296, "start": 1435.3600000000001, "end": 1443.48, "text": " fluency entonces esta idea de que estoy tratando de maximizar dos medidas a la vez despu\u00e9s vamos a", "tokens": [50984, 5029, 3020, 13003, 5283, 1558, 368, 631, 15796, 21507, 1806, 368, 5138, 9736, 4491, 37295, 257, 635, 5715, 15283, 5295, 257, 51390], "temperature": 0.0, "avg_logprob": -0.16231552759806314, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.009028369560837746}, {"id": 258, "seek": 142296, "start": 1443.48, "end": 1446.72, "text": " ver que en realidad lo que vamos a total maximizar es el producto de las dos medidas porque eso", "tokens": [51390, 1306, 631, 465, 25635, 450, 631, 5295, 257, 3217, 5138, 9736, 785, 806, 47583, 368, 2439, 4491, 37295, 4021, 7287, 51552], "temperature": 0.0, "avg_logprob": -0.16231552759806314, "compression_ratio": 1.8738317757009346, "no_speech_prob": 0.009028369560837746}, {"id": 259, "seek": 144672, "start": 1446.72, "end": 1453.44, "text": " significa maximizar ambas al mismo tiempo es una idea que sirve para poder inferir o para poder", "tokens": [50364, 19957, 5138, 9736, 3913, 296, 419, 12461, 11772, 785, 2002, 1558, 631, 4735, 303, 1690, 8152, 13596, 347, 277, 1690, 8152, 50700], "temperature": 0.0, "avg_logprob": -0.14561447294631807, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.058153726160526276}, {"id": 260, "seek": 144672, "start": 1453.44, "end": 1457.88, "text": " construir mecanismos para crear los traductores autom\u00e1ticos y tambi\u00e9n mecanismo para testarlos", "tokens": [50700, 38445, 385, 7035, 1434, 329, 1690, 31984, 1750, 2479, 11130, 2706, 3553, 7656, 9940, 288, 6407, 385, 7035, 6882, 1690, 1500, 39734, 50922], "temperature": 0.0, "avg_logprob": -0.14561447294631807, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.058153726160526276}, {"id": 261, "seek": 144672, "start": 1457.88, "end": 1465.1200000000001, "text": " y vamos a ver un poco c\u00f3mo es que funciona eso yo voy a intentar traducir a partir de ahora del", "tokens": [50922, 288, 5295, 257, 1306, 517, 10639, 12826, 785, 631, 26210, 7287, 5290, 7552, 257, 46596, 2479, 1311, 347, 257, 13906, 368, 9923, 1103, 51284], "temperature": 0.0, "avg_logprob": -0.14561447294631807, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.058153726160526276}, {"id": 262, "seek": 144672, "start": 1465.1200000000001, "end": 1469.0, "text": " resto de la clase y la clase que viene vamos a hablar siempre de que voy a traducir de un lenguaje", "tokens": [51284, 28247, 368, 635, 44578, 288, 635, 44578, 631, 19561, 5295, 257, 21014, 12758, 368, 631, 7552, 257, 2479, 1311, 347, 368, 517, 35044, 84, 11153, 51478], "temperature": 0.0, "avg_logprob": -0.14561447294631807, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.058153726160526276}, {"id": 263, "seek": 146900, "start": 1469.0, "end": 1475.16, "text": " origen f a un lenguaje destino e vamos a ponerlo ac\u00e1 si no nos olvidamos", "tokens": [50364, 2349, 268, 283, 257, 517, 35044, 84, 11153, 2677, 2982, 308, 5295, 257, 19149, 752, 23496, 1511, 572, 3269, 43194, 2151, 50672], "temperature": 0.0, "avg_logprob": -0.417589357164171, "compression_ratio": 1.4186046511627908, "no_speech_prob": 0.07336464524269104}, {"id": 264, "seek": 146900, "start": 1481.6, "end": 1483.48, "text": " f es el lenguaje origen", "tokens": [50994, 283, 785, 806, 35044, 84, 11153, 2349, 268, 51088], "temperature": 0.0, "avg_logprob": -0.417589357164171, "compression_ratio": 1.4186046511627908, "no_speech_prob": 0.07336464524269104}, {"id": 265, "seek": 146900, "start": 1488.48, "end": 1490.52, "text": " y es el lenguaje destino", "tokens": [51338, 288, 785, 806, 35044, 84, 11153, 2677, 2982, 51440], "temperature": 0.0, "avg_logprob": -0.417589357164171, "compression_ratio": 1.4186046511627908, "no_speech_prob": 0.07336464524269104}, {"id": 266, "seek": 149052, "start": 1491.0, "end": 1500.4, "text": " esos nombres surgen porque el paper inicial en donde se empez\u00f3 a hablar de estas cosas", "tokens": [50388, 22411, 297, 29947, 1022, 1766, 4021, 806, 3035, 44076, 465, 10488, 369, 18730, 812, 257, 21014, 368, 13897, 12218, 50858], "temperature": 0.0, "avg_logprob": -0.21912002563476562, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.0019533950835466385}, {"id": 267, "seek": 149052, "start": 1500.4, "end": 1503.72, "text": " de los m\u00e9todos estad\u00edsticos traduc\u00eda del franc\u00e9s al ingl\u00e9s entonces sac\u00f3 los nombres", "tokens": [50858, 368, 1750, 20275, 378, 329, 39160, 19512, 9940, 2479, 1311, 2686, 1103, 30514, 2191, 419, 49766, 13003, 4899, 812, 1750, 297, 29947, 51024], "temperature": 0.0, "avg_logprob": -0.21912002563476562, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.0019533950835466385}, {"id": 268, "seek": 149052, "start": 1503.72, "end": 1510.2, "text": " ah\u00ed dijo en franc\u00e9s f el ingl\u00e9s e entonces traducimos del origen al destino bueno yo quiero", "tokens": [51024, 12571, 27024, 465, 30514, 2191, 283, 806, 49766, 308, 13003, 2479, 1311, 8372, 1103, 2349, 268, 419, 2677, 2982, 11974, 5290, 16811, 51348], "temperature": 0.0, "avg_logprob": -0.21912002563476562, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.0019533950835466385}, {"id": 269, "seek": 149052, "start": 1510.2, "end": 1516.6, "text": " traducir una frase del idioma f a otra frase del idioma e lo que quiero tratar de encontrar es el mejor", "tokens": [51348, 2479, 1311, 347, 2002, 38406, 1103, 18014, 6440, 283, 257, 13623, 38406, 1103, 18014, 6440, 308, 450, 631, 16811, 42549, 368, 17525, 785, 806, 11479, 51668], "temperature": 0.0, "avg_logprob": -0.21912002563476562, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.0019533950835466385}, {"id": 270, "seek": 151660, "start": 1516.6, "end": 1523.0, "text": " etecho que maximice a la vez la adecuaci\u00f3n y la fluidez o sea de todos los e posibles del lenguaje", "tokens": [50364, 1030, 5023, 78, 631, 5138, 573, 257, 635, 5715, 635, 614, 3045, 84, 3482, 288, 635, 5029, 45170, 277, 4158, 368, 6321, 1750, 308, 1366, 14428, 1103, 35044, 84, 11153, 50684], "temperature": 0.0, "avg_logprob": -0.18027619962339048, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009265357628464699}, {"id": 271, "seek": 151660, "start": 1523.0, "end": 1528.6399999999999, "text": " destino quiero encontrar el que maximice la fluidez de o sea que suene natural y adem\u00e1s la", "tokens": [50684, 2677, 2982, 16811, 17525, 806, 631, 5138, 573, 635, 5029, 45170, 368, 277, 4158, 631, 459, 1450, 3303, 288, 21251, 635, 50966], "temperature": 0.0, "avg_logprob": -0.18027619962339048, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009265357628464699}, {"id": 272, "seek": 151660, "start": 1528.6399999999999, "end": 1537.4399999999998, "text": " adecuaci\u00f3n entre la oraci\u00f3n origen f y ese que estoy buscando esto esta f\u00f3rmula as\u00ed escrita", "tokens": [50966, 614, 3045, 84, 3482, 3962, 635, 420, 3482, 2349, 268, 283, 288, 10167, 631, 15796, 46804, 7433, 5283, 283, 15614, 76, 3780, 8582, 49865, 2786, 51406], "temperature": 0.0, "avg_logprob": -0.18027619962339048, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009265357628464699}, {"id": 273, "seek": 151660, "start": 1537.4399999999998, "end": 1541.4399999999998, "text": " de esa manera est\u00e1s a acordar algo que hayamos visto ya en el curso en alg\u00fan momento les suena", "tokens": [51406, 368, 11342, 13913, 24389, 257, 38077, 289, 8655, 631, 4842, 2151, 17558, 2478, 465, 806, 31085, 465, 26300, 9333, 1512, 459, 4118, 51606], "temperature": 0.0, "avg_logprob": -0.18027619962339048, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.009265357628464699}, {"id": 274, "seek": 154144, "start": 1541.44, "end": 1544.56, "text": " a alg\u00fan lado entrop\u00eda si", "tokens": [50364, 257, 26300, 11631, 948, 1513, 2686, 1511, 50520], "temperature": 0.0, "avg_logprob": -0.2186005970217147, "compression_ratio": 1.8533333333333333, "no_speech_prob": 0.024003762751817703}, {"id": 275, "seek": 154144, "start": 1547.28, "end": 1552.6000000000001, "text": " valles si o sea viene por ese lado se parece al modelo de valles porque esto es otra aplicaci\u00f3n", "tokens": [50656, 371, 37927, 1511, 277, 4158, 19561, 1515, 10167, 11631, 369, 14120, 419, 27825, 368, 371, 37927, 4021, 7433, 785, 13623, 18221, 3482, 50922], "temperature": 0.0, "avg_logprob": -0.2186005970217147, "compression_ratio": 1.8533333333333333, "no_speech_prob": 0.024003762751817703}, {"id": 276, "seek": 154144, "start": 1552.6000000000001, "end": 1556.1200000000001, "text": " del modelo de canal ruidoso el modelo de canal ruidoso lo hab\u00edamos visto en el curso cuando", "tokens": [50922, 1103, 27825, 368, 9911, 5420, 7895, 78, 806, 27825, 368, 9911, 5420, 7895, 78, 450, 3025, 16275, 17558, 465, 806, 31085, 7767, 51098], "temperature": 0.0, "avg_logprob": -0.2186005970217147, "compression_ratio": 1.8533333333333333, "no_speech_prob": 0.024003762751817703}, {"id": 277, "seek": 154144, "start": 1556.1200000000001, "end": 1560.96, "text": " vimos correcciones de errores hace ya bastante tiempo y tambi\u00e9n es una aplicaci\u00f3n de lo que es la", "tokens": [51098, 49266, 29731, 35560, 368, 45935, 495, 10032, 2478, 14651, 11772, 288, 6407, 785, 2002, 18221, 3482, 368, 450, 631, 785, 635, 51340], "temperature": 0.0, "avg_logprob": -0.2186005970217147, "compression_ratio": 1.8533333333333333, "no_speech_prob": 0.024003762751817703}, {"id": 278, "seek": 154144, "start": 1560.96, "end": 1567.28, "text": " regla de valles entonces el modelo de canal ruidoso aplicado ac\u00e1 funciona de la siguiente manera yo", "tokens": [51340, 1121, 875, 368, 371, 37927, 13003, 806, 27825, 368, 9911, 5420, 7895, 78, 18221, 1573, 23496, 26210, 368, 635, 25666, 13913, 5290, 51656], "temperature": 0.0, "avg_logprob": -0.2186005970217147, "compression_ratio": 1.8533333333333333, "no_speech_prob": 0.024003762751817703}, {"id": 279, "seek": 156728, "start": 1567.28, "end": 1573.6399999999999, "text": " tengo una oraci\u00f3n origen en el lenguaje f que es f chica que tiene m palabras y es bueno f sub 1", "tokens": [50364, 13989, 2002, 420, 3482, 2349, 268, 465, 806, 35044, 84, 11153, 283, 631, 785, 283, 417, 2262, 631, 7066, 275, 35240, 288, 785, 11974, 283, 1422, 502, 50682], "temperature": 0.0, "avg_logprob": -0.25281614627478255, "compression_ratio": 1.8899521531100478, "no_speech_prob": 0.2191283255815506}, {"id": 280, "seek": 156728, "start": 1573.6399999999999, "end": 1579.92, "text": " f sub 2 hasta f sub m y quiero encontrar la mejor oraci\u00f3n en el lenguaje destino etecho que es", "tokens": [50682, 283, 1422, 568, 10764, 283, 1422, 275, 288, 16811, 17525, 635, 11479, 420, 3482, 465, 806, 35044, 84, 11153, 2677, 2982, 1030, 5023, 78, 631, 785, 50996], "temperature": 0.0, "avg_logprob": -0.25281614627478255, "compression_ratio": 1.8899521531100478, "no_speech_prob": 0.2191283255815506}, {"id": 281, "seek": 156728, "start": 1579.92, "end": 1586.44, "text": " es sub 1 hasta vez es su bene hasta es su bene que maximiza y en realidad lo que yo quiero maximizar", "tokens": [50996, 785, 1422, 502, 10764, 5715, 785, 459, 2537, 10764, 785, 459, 2537, 631, 5138, 13427, 288, 465, 25635, 450, 631, 5290, 16811, 5138, 9736, 51322], "temperature": 0.0, "avg_logprob": -0.25281614627478255, "compression_ratio": 1.8899521531100478, "no_speech_prob": 0.2191283255815506}, {"id": 282, "seek": 156728, "start": 1586.44, "end": 1592.3999999999999, "text": " originalmente como todos esperar\u00edamos es decir bueno yo quiero encontrar la oraci\u00f3n e que maximice", "tokens": [51322, 3380, 4082, 2617, 6321, 37577, 16275, 785, 10235, 11974, 5290, 16811, 17525, 635, 420, 3482, 308, 631, 5138, 573, 51620], "temperature": 0.0, "avg_logprob": -0.25281614627478255, "compression_ratio": 1.8899521531100478, "no_speech_prob": 0.2191283255815506}, {"id": 283, "seek": 159240, "start": 1592.4, "end": 1596.88, "text": " la probabilidad de e dado f digamos eso es lo que uno se le ocurrir\u00eda primero dir\u00eda bueno yo quiero", "tokens": [50364, 635, 31959, 4580, 368, 308, 29568, 283, 36430, 7287, 785, 450, 631, 8526, 369, 476, 26430, 10949, 2686, 21289, 4746, 2686, 11974, 5290, 16811, 50588], "temperature": 0.0, "avg_logprob": -0.2059209763057648, "compression_ratio": 2.1904761904761907, "no_speech_prob": 0.10041527450084686}, {"id": 284, "seek": 159240, "start": 1596.88, "end": 1601.48, "text": " estoy traduciendo la oraci\u00f3n f quiero encontrar la e que me de m\u00e1ximo la probabilidad de e dado", "tokens": [50588, 15796, 2479, 1311, 7304, 635, 420, 3482, 283, 16811, 17525, 635, 308, 631, 385, 368, 38876, 635, 31959, 4580, 368, 308, 29568, 50818], "temperature": 0.0, "avg_logprob": -0.2059209763057648, "compression_ratio": 2.1904761904761907, "no_speech_prob": 0.10041527450084686}, {"id": 285, "seek": 159240, "start": 1601.48, "end": 1607.52, "text": " f bien pero en realidad yo esto lo puedo descomponer por valles digamos y por definici\u00f3n de probabilidad", "tokens": [50818, 283, 3610, 4768, 465, 25635, 5290, 7433, 450, 21612, 730, 21541, 32949, 1515, 371, 37927, 36430, 288, 1515, 1561, 15534, 368, 31959, 4580, 51120], "temperature": 0.0, "avg_logprob": -0.2059209763057648, "compression_ratio": 2.1904761904761907, "no_speech_prob": 0.10041527450084686}, {"id": 286, "seek": 159240, "start": 1607.52, "end": 1612.6000000000001, "text": " condicional puede decir que la probabilidad de e dado f es igual a la probabilidad de f dado e por la", "tokens": [51120, 2224, 33010, 8919, 10235, 631, 635, 31959, 4580, 368, 308, 29568, 283, 785, 10953, 257, 635, 31959, 4580, 368, 283, 29568, 308, 1515, 635, 51374], "temperature": 0.0, "avg_logprob": -0.2059209763057648, "compression_ratio": 2.1904761904761907, "no_speech_prob": 0.10041527450084686}, {"id": 287, "seek": 159240, "start": 1612.6000000000001, "end": 1619.3600000000001, "text": " probabilidad de divido la probabilidad de f digamos esa equivalencia es directa por definici\u00f3n de", "tokens": [51374, 31959, 4580, 368, 4996, 78, 635, 31959, 4580, 368, 283, 36430, 11342, 9052, 10974, 785, 2047, 64, 1515, 1561, 15534, 368, 51712], "temperature": 0.0, "avg_logprob": -0.2059209763057648, "compression_ratio": 2.1904761904761907, "no_speech_prob": 0.10041527450084686}, {"id": 288, "seek": 161936, "start": 1619.36, "end": 1625.12, "text": " probabilidad condicional y adem\u00e1s como estoy maximizando en e esta f se mantiene constante porque", "tokens": [50364, 31959, 4580, 2224, 33010, 288, 21251, 2617, 15796, 5138, 590, 1806, 465, 308, 5283, 283, 369, 10845, 10174, 47343, 4021, 50652], "temperature": 0.0, "avg_logprob": -0.17300785064697266, "compression_ratio": 1.8009049773755657, "no_speech_prob": 0.0753520205616951}, {"id": 289, "seek": 161936, "start": 1625.12, "end": 1631.4799999999998, "text": " lo que voy variando es la e entonces la tacho o sea maximizar sobre una constante no no hace ning\u00fan", "tokens": [50652, 450, 631, 7552, 3034, 1806, 785, 635, 308, 13003, 635, 256, 46574, 277, 4158, 5138, 9736, 5473, 2002, 47343, 572, 572, 10032, 30394, 50970], "temperature": 0.0, "avg_logprob": -0.17300785064697266, "compression_ratio": 1.8009049773755657, "no_speech_prob": 0.0753520205616951}, {"id": 290, "seek": 161936, "start": 1631.4799999999998, "end": 1638.9599999999998, "text": " cambio entonces lo que me queda el final es que yo busco un etecho que es el e que hace m\u00e1ximo la", "tokens": [50970, 28731, 13003, 450, 631, 385, 23314, 806, 2572, 785, 631, 5290, 1255, 1291, 517, 1030, 5023, 78, 631, 785, 806, 308, 631, 10032, 38876, 635, 51344], "temperature": 0.0, "avg_logprob": -0.17300785064697266, "compression_ratio": 1.8009049773755657, "no_speech_prob": 0.0753520205616951}, {"id": 291, "seek": 161936, "start": 1638.9599999999998, "end": 1646.1599999999999, "text": " probabilidad de f dado e por la probabilidad de y eso que tenemos escrito ah\u00ed se parece mucho a la", "tokens": [51344, 31959, 4580, 368, 283, 29568, 308, 1515, 635, 31959, 4580, 368, 288, 7287, 631, 9914, 49451, 12571, 369, 14120, 9824, 257, 635, 51704], "temperature": 0.0, "avg_logprob": -0.17300785064697266, "compression_ratio": 1.8009049773755657, "no_speech_prob": 0.0753520205616951}, {"id": 292, "seek": 164616, "start": 1646.16, "end": 1652.68, "text": " otra ecuaci\u00f3n que ten\u00edamos antes digamos se parece mucho a esta ecuaci\u00f3n de adecuaci\u00f3n de f e y", "tokens": [50364, 13623, 11437, 84, 3482, 631, 2064, 16275, 11014, 36430, 369, 14120, 9824, 257, 5283, 11437, 84, 3482, 368, 614, 3045, 84, 3482, 368, 283, 308, 288, 50690], "temperature": 0.0, "avg_logprob": -0.14664798106962038, "compression_ratio": 1.7621145374449338, "no_speech_prob": 0.0017031367169693112}, {"id": 293, "seek": 164616, "start": 1652.68, "end": 1663.0800000000002, "text": " fluidez de entonces esto se conoce como la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica", "tokens": [50690, 5029, 45170, 368, 13003, 7433, 369, 33029, 384, 2617, 635, 11437, 84, 3482, 8088, 368, 635, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 51210], "temperature": 0.0, "avg_logprob": -0.14664798106962038, "compression_ratio": 1.7621145374449338, "no_speech_prob": 0.0017031367169693112}, {"id": 294, "seek": 164616, "start": 1663.0800000000002, "end": 1669.64, "text": " la vamos a ver unas cuantas veces en estas dos clases la vamos a estar refrescando y funciona", "tokens": [51210, 635, 5295, 257, 1306, 25405, 2702, 49153, 17054, 465, 13897, 4491, 596, 1957, 635, 5295, 257, 8755, 17368, 29585, 288, 26210, 51538], "temperature": 0.0, "avg_logprob": -0.14664798106962038, "compression_ratio": 1.7621145374449338, "no_speech_prob": 0.0017031367169693112}, {"id": 295, "seek": 164616, "start": 1669.64, "end": 1675.2, "text": " de la siguiente manera yo quiero encontrar el etecho que es el e que maximiza el producto de estas", "tokens": [51538, 368, 635, 25666, 13913, 5290, 16811, 17525, 806, 1030, 5023, 78, 631, 785, 806, 308, 631, 5138, 13427, 806, 47583, 368, 13897, 51816], "temperature": 0.0, "avg_logprob": -0.14664798106962038, "compression_ratio": 1.7621145374449338, "no_speech_prob": 0.0017031367169693112}, {"id": 296, "seek": 167520, "start": 1675.2, "end": 1680.48, "text": " dos probabilidades la primera probabilidad pdf dado e es la que se encarga de medir qu\u00e9 tal la", "tokens": [50364, 4491, 31959, 10284, 635, 17382, 31959, 4580, 280, 45953, 29568, 308, 785, 635, 631, 369, 2058, 289, 3680, 368, 1205, 347, 8057, 4023, 635, 50628], "temperature": 0.0, "avg_logprob": -0.1291283062526158, "compression_ratio": 2.219730941704036, "no_speech_prob": 0.004589653108268976}, {"id": 297, "seek": 167520, "start": 1680.48, "end": 1685.96, "text": " adecuaci\u00f3n digamos de la frase que tan adecuada es la frase f para la frase e la segunda probabilidad", "tokens": [50628, 614, 3045, 84, 3482, 36430, 368, 635, 38406, 631, 7603, 614, 3045, 84, 1538, 785, 635, 38406, 283, 1690, 635, 38406, 308, 635, 21978, 31959, 4580, 50902], "temperature": 0.0, "avg_logprob": -0.1291283062526158, "compression_ratio": 2.219730941704036, "no_speech_prob": 0.004589653108268976}, {"id": 298, "seek": 167520, "start": 1685.96, "end": 1692.6000000000001, "text": " la pd es la que se encarga de la fluidez que tan natural suena esa frase en el lenguaje destino", "tokens": [50902, 635, 280, 67, 785, 635, 631, 369, 2058, 289, 3680, 368, 635, 5029, 45170, 631, 7603, 3303, 459, 4118, 11342, 38406, 465, 806, 35044, 84, 11153, 2677, 2982, 51234], "temperature": 0.0, "avg_logprob": -0.1291283062526158, "compression_ratio": 2.219730941704036, "no_speech_prob": 0.004589653108268976}, {"id": 299, "seek": 167520, "start": 1692.6000000000001, "end": 1698.0800000000002, "text": " y se calculan con modelos distintos la primera se calcula con lo que se conoce como modelo de traducci\u00f3n", "tokens": [51234, 288, 369, 4322, 282, 416, 2316, 329, 49337, 635, 17382, 369, 4322, 64, 416, 450, 631, 369, 33029, 384, 2617, 27825, 368, 2479, 1311, 5687, 51508], "temperature": 0.0, "avg_logprob": -0.1291283062526158, "compression_ratio": 2.219730941704036, "no_speech_prob": 0.004589653108268976}, {"id": 300, "seek": 167520, "start": 1698.0800000000002, "end": 1702.44, "text": " y la segunda con lo que se conoce como modelo de lenguaje de hecho los modelos del lenguaje ya", "tokens": [51508, 288, 635, 21978, 416, 450, 631, 369, 33029, 384, 2617, 27825, 368, 35044, 84, 11153, 368, 13064, 1750, 2316, 329, 1103, 35044, 84, 11153, 2478, 51726], "temperature": 0.0, "avg_logprob": -0.1291283062526158, "compression_ratio": 2.219730941704036, "no_speech_prob": 0.004589653108268976}, {"id": 301, "seek": 170244, "start": 1702.44, "end": 1708.96, "text": " los hemos visto en el curso vamos a dar un breve repaso de qu\u00e9 se trataba bueno porque esto es", "tokens": [50364, 1750, 15396, 17558, 465, 806, 31085, 5295, 257, 4072, 517, 48517, 1085, 35281, 368, 8057, 369, 21507, 5509, 11974, 4021, 7433, 785, 50690], "temperature": 0.0, "avg_logprob": -0.13811423173591272, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004601951222866774}, {"id": 302, "seek": 170244, "start": 1708.96, "end": 1714.48, "text": " una aplicaci\u00f3n de canal ruidoso es una aplicaci\u00f3n de canal ruidoso por lo siguiente nosotros estamos", "tokens": [50690, 2002, 18221, 3482, 368, 9911, 5420, 7895, 78, 785, 2002, 18221, 3482, 368, 9911, 5420, 7895, 78, 1515, 450, 25666, 13863, 10382, 50966], "temperature": 0.0, "avg_logprob": -0.13811423173591272, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004601951222866774}, {"id": 303, "seek": 170244, "start": 1714.48, "end": 1720.3200000000002, "text": " tratando de traducir del lenguaje f efe la lenguaje origen al lenguaje que es el lenguaje destino y lo", "tokens": [50966, 21507, 1806, 368, 2479, 1311, 347, 1103, 35044, 84, 11153, 283, 308, 2106, 635, 35044, 84, 11153, 2349, 268, 419, 35044, 84, 11153, 631, 785, 806, 35044, 84, 11153, 2677, 2982, 288, 450, 51258], "temperature": 0.0, "avg_logprob": -0.13811423173591272, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004601951222866774}, {"id": 304, "seek": 170244, "start": 1720.3200000000002, "end": 1725.24, "text": " estamos pensando al rev\u00e9s estamos pensando como que alguien emiti\u00f3 los sonidos de la oraci\u00f3n e", "tokens": [51258, 10382, 34525, 419, 3698, 2191, 10382, 34525, 2617, 631, 25814, 32084, 7138, 1750, 1872, 7895, 368, 635, 420, 3482, 308, 51504], "temperature": 0.0, "avg_logprob": -0.13811423173591272, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004601951222866774}, {"id": 305, "seek": 170244, "start": 1725.24, "end": 1730.4, "text": " la oraci\u00f3n del lenguaje destino eso pas\u00f3 a trav\u00e9s de un canal ruidoso y cuando lleg\u00f3 hasta m\u00ed yo", "tokens": [51504, 635, 420, 3482, 1103, 35044, 84, 11153, 2677, 2982, 7287, 41382, 257, 24463, 368, 517, 9911, 5420, 7895, 78, 288, 7767, 46182, 10764, 14692, 5290, 51762], "temperature": 0.0, "avg_logprob": -0.13811423173591272, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004601951222866774}, {"id": 306, "seek": 173040, "start": 1730.4, "end": 1735.48, "text": " escuch\u00e9 los sonidos de la oraci\u00f3n efe estoy pensando como esa especie de met\u00e1fora alguien emiti\u00f3", "tokens": [50364, 22483, 526, 1750, 1872, 7895, 368, 635, 420, 3482, 308, 2106, 15796, 34525, 2617, 11342, 49368, 368, 1131, 842, 2994, 64, 25814, 32084, 7138, 50618], "temperature": 0.0, "avg_logprob": -0.15237684547901154, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.013728531077504158}, {"id": 307, "seek": 173040, "start": 1735.48, "end": 1740.1200000000001, "text": " e pas\u00f3 por un canal ruidoso y llegaron los ruidos de efe entonces lo que yo trato de hacer como", "tokens": [50618, 308, 41382, 1515, 517, 9911, 5420, 7895, 78, 288, 11234, 6372, 1750, 5420, 7895, 368, 308, 2106, 13003, 450, 631, 5290, 504, 2513, 368, 6720, 2617, 50850], "temperature": 0.0, "avg_logprob": -0.15237684547901154, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.013728531077504158}, {"id": 308, "seek": 173040, "start": 1740.1200000000001, "end": 1745.1200000000001, "text": " proceso de traducci\u00f3n es encontrar cu\u00e1l tiene que haber sido esa e original para que yo haya", "tokens": [50850, 29314, 368, 2479, 1311, 5687, 785, 17525, 44318, 7066, 631, 15811, 14444, 11342, 308, 3380, 1690, 631, 5290, 24693, 51100], "temperature": 0.0, "avg_logprob": -0.15237684547901154, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.013728531077504158}, {"id": 309, "seek": 173040, "start": 1745.1200000000001, "end": 1750.2800000000002, "text": " escuchado la efe cu\u00e1l es la e original que me da probabilidad m\u00e1xima de que yo haya escuchado esta efe", "tokens": [51100, 22483, 1573, 635, 308, 2106, 44318, 785, 635, 308, 3380, 631, 385, 1120, 31959, 4580, 31031, 64, 368, 631, 5290, 24693, 22483, 1573, 5283, 308, 2106, 51358], "temperature": 0.0, "avg_logprob": -0.15237684547901154, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.013728531077504158}, {"id": 310, "seek": 173040, "start": 1753.0, "end": 1757.92, "text": " y bueno por eso es una aplicaci\u00f3n de canal ruidoso y bueno la realidad es que en realidad", "tokens": [51494, 288, 11974, 1515, 7287, 785, 2002, 18221, 3482, 368, 9911, 5420, 7895, 78, 288, 11974, 635, 25635, 785, 631, 465, 25635, 51740], "temperature": 0.0, "avg_logprob": -0.15237684547901154, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.013728531077504158}, {"id": 311, "seek": 175792, "start": 1757.92, "end": 1762.6000000000001, "text": " damos vuelta esta probabilidad porque nos da toda otra forma de calcular lo que no podr\u00edamos", "tokens": [50364, 274, 2151, 41542, 5283, 31959, 4580, 4021, 3269, 1120, 11687, 13623, 8366, 368, 2104, 17792, 450, 631, 572, 15305, 16275, 50598], "temperature": 0.0, "avg_logprob": -0.1422071857612674, "compression_ratio": 1.9130434782608696, "no_speech_prob": 0.014196008443832397}, {"id": 312, "seek": 175792, "start": 1762.6000000000001, "end": 1767.88, "text": " hacerlo si calculamos la probabilidad directa es como que hay mejores herramientas para hacer eso", "tokens": [50598, 32039, 1511, 4322, 2151, 635, 31959, 4580, 2047, 64, 785, 2617, 631, 4842, 42284, 38271, 296, 1690, 6720, 7287, 50862], "temperature": 0.0, "avg_logprob": -0.1422071857612674, "compression_ratio": 1.9130434782608696, "no_speech_prob": 0.014196008443832397}, {"id": 313, "seek": 175792, "start": 1767.88, "end": 1772.3200000000002, "text": " bueno de vuelta esto es la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica e", "tokens": [50862, 11974, 368, 41542, 7433, 785, 635, 11437, 84, 3482, 8088, 368, 635, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 308, 51084], "temperature": 0.0, "avg_logprob": -0.1422071857612674, "compression_ratio": 1.9130434782608696, "no_speech_prob": 0.014196008443832397}, {"id": 314, "seek": 175792, "start": 1772.3200000000002, "end": 1779.2, "text": " techo es el argumento que hace m\u00e1ximo la probabilidad de efe dado e por la probabilidad e y para poder", "tokens": [51084, 535, 5738, 785, 806, 6770, 78, 631, 10032, 38876, 635, 31959, 4580, 368, 308, 2106, 29568, 308, 1515, 635, 31959, 4580, 308, 288, 1690, 8152, 51428], "temperature": 0.0, "avg_logprob": -0.1422071857612674, "compression_ratio": 1.9130434782608696, "no_speech_prob": 0.014196008443832397}, {"id": 315, "seek": 175792, "start": 1779.2, "end": 1784.16, "text": " resolver esta ecuaci\u00f3n necesitamos tres cosas necesitamos un modelo de lenguaje pde que es el", "tokens": [51428, 34480, 5283, 11437, 84, 3482, 38661, 2151, 15890, 12218, 38661, 2151, 517, 27825, 368, 35044, 84, 11153, 280, 1479, 631, 785, 806, 51676], "temperature": 0.0, "avg_logprob": -0.1422071857612674, "compression_ratio": 1.9130434782608696, "no_speech_prob": 0.014196008443832397}, {"id": 316, "seek": 178416, "start": 1784.16, "end": 1792.0, "text": " que se va a encargar de la fluidez esto se calcula mediante la t\u00e9cnica de negramas en general", "tokens": [50364, 631, 369, 2773, 257, 2058, 289, 2976, 368, 635, 5029, 45170, 7433, 369, 4322, 64, 17269, 2879, 635, 45411, 368, 408, 861, 19473, 465, 2674, 50756], "temperature": 0.0, "avg_logprob": -0.14631003141403198, "compression_ratio": 1.9372384937238494, "no_speech_prob": 0.004343437030911446}, {"id": 317, "seek": 178416, "start": 1793.72, "end": 1797.6000000000001, "text": " los engramas son bastante f\u00e1ciles de construir digamos porque yo necesito texto en un solo", "tokens": [50842, 1750, 465, 1342, 296, 1872, 14651, 17474, 279, 368, 38445, 36430, 4021, 5290, 11909, 3528, 35503, 465, 517, 6944, 51036], "temperature": 0.0, "avg_logprob": -0.14631003141403198, "compression_ratio": 1.9372384937238494, "no_speech_prob": 0.004343437030911446}, {"id": 318, "seek": 178416, "start": 1797.6000000000001, "end": 1805.88, "text": " idioma solo en el idioma destino pdf dado e es la componente que se encarga de la adecuaci\u00f3n y", "tokens": [51036, 18014, 6440, 6944, 465, 806, 18014, 6440, 2677, 2982, 280, 45953, 29568, 308, 785, 635, 4026, 1576, 631, 369, 2058, 289, 3680, 368, 635, 614, 3045, 84, 3482, 288, 51450], "temperature": 0.0, "avg_logprob": -0.14631003141403198, "compression_ratio": 1.9372384937238494, "no_speech_prob": 0.004343437030911446}, {"id": 319, "seek": 178416, "start": 1805.88, "end": 1809.64, "text": " se resuelve mediante el modelo de traducci\u00f3n el modelo de traducci\u00f3n no es tan f\u00e1cil de", "tokens": [51450, 369, 725, 3483, 303, 17269, 2879, 806, 27825, 368, 2479, 1311, 5687, 806, 27825, 368, 2479, 1311, 5687, 572, 785, 7603, 17474, 368, 51638], "temperature": 0.0, "avg_logprob": -0.14631003141403198, "compression_ratio": 1.9372384937238494, "no_speech_prob": 0.004343437030911446}, {"id": 320, "seek": 178416, "start": 1809.64, "end": 1812.88, "text": " construir como el modelo de lenguaje porque para el modelo de traducci\u00f3n voy a necesitar", "tokens": [51638, 38445, 2617, 806, 27825, 368, 35044, 84, 11153, 4021, 1690, 806, 27825, 368, 2479, 1311, 5687, 7552, 257, 11909, 3981, 51800], "temperature": 0.0, "avg_logprob": -0.14631003141403198, "compression_ratio": 1.9372384937238494, "no_speech_prob": 0.004343437030911446}, {"id": 321, "seek": 181288, "start": 1812.88, "end": 1817.2800000000002, "text": " texto biling\u00fce de hecho voy a necesitar un corpus paralelo que sea texto en dos idiomas que adem\u00e1s", "tokens": [50364, 35503, 272, 4883, 774, 68, 368, 13064, 7552, 257, 11909, 3981, 517, 1181, 31624, 26009, 10590, 631, 4158, 35503, 465, 4491, 18014, 7092, 631, 21251, 50584], "temperature": 0.0, "avg_logprob": -0.1615181121826172, "compression_ratio": 1.8, "no_speech_prob": 0.006589286960661411}, {"id": 322, "seek": 181288, "start": 1817.2800000000002, "end": 1822.96, "text": " tengan su correspondencia y adem\u00e1s necesito una tercera componente esta tercera componente se", "tokens": [50584, 46874, 459, 6805, 10974, 288, 21251, 11909, 3528, 2002, 1796, 41034, 4026, 1576, 5283, 1796, 41034, 4026, 1576, 369, 50868], "temperature": 0.0, "avg_logprob": -0.1615181121826172, "compression_ratio": 1.8, "no_speech_prob": 0.006589286960661411}, {"id": 323, "seek": 181288, "start": 1822.96, "end": 1828.3200000000002, "text": " llama decodificador y se trata de lo siguiente yo cuando estoy buscando cuando se resuelve esta", "tokens": [50868, 23272, 979, 378, 1089, 5409, 288, 369, 31920, 368, 450, 25666, 5290, 7767, 15796, 46804, 7767, 369, 725, 3483, 303, 5283, 51136], "temperature": 0.0, "avg_logprob": -0.1615181121826172, "compression_ratio": 1.8, "no_speech_prob": 0.006589286960661411}, {"id": 324, "seek": 181288, "start": 1828.3200000000002, "end": 1834.0, "text": " ecuaci\u00f3n yo veo la oraci\u00f3n efe y quiero buscar la mejor e que maximice esa ecuaci\u00f3n pero en", "tokens": [51136, 11437, 84, 3482, 5290, 41319, 635, 420, 3482, 308, 2106, 288, 16811, 26170, 635, 11479, 308, 631, 5138, 573, 11342, 11437, 84, 3482, 4768, 465, 51420], "temperature": 0.0, "avg_logprob": -0.1615181121826172, "compression_ratio": 1.8, "no_speech_prob": 0.006589286960661411}, {"id": 325, "seek": 181288, "start": 1834.0, "end": 1838.4, "text": " realidad lo que tendr\u00eda que hacer es probar con todas las oraciones e del idioma destino todas las", "tokens": [51420, 25635, 450, 631, 3928, 37183, 631, 6720, 785, 1239, 289, 416, 10906, 2439, 420, 9188, 308, 1103, 18014, 6440, 2677, 2982, 10906, 2439, 51640], "temperature": 0.0, "avg_logprob": -0.1615181121826172, "compression_ratio": 1.8, "no_speech_prob": 0.006589286960661411}, {"id": 326, "seek": 183840, "start": 1838.4, "end": 1844.72, "text": " oraciones posibles que cu\u00e1ntas son las oraciones del idioma estino son infinitas oraciones posibles", "tokens": [50364, 420, 9188, 1366, 14428, 631, 44256, 296, 1872, 2439, 420, 9188, 1103, 18014, 6440, 871, 2982, 1872, 7193, 14182, 420, 9188, 1366, 14428, 50680], "temperature": 0.0, "avg_logprob": -0.12203536356302132, "compression_ratio": 2.06198347107438, "no_speech_prob": 0.03287367895245552}, {"id": 327, "seek": 183840, "start": 1844.72, "end": 1848.68, "text": " en el idioma estino entonces yo estar\u00eda probando con infinitas oraciones hasta que una de ellas me", "tokens": [50680, 465, 806, 18014, 6440, 871, 2982, 13003, 5290, 8755, 2686, 1239, 1806, 416, 7193, 14182, 420, 9188, 10764, 631, 2002, 368, 38397, 385, 50878], "temperature": 0.0, "avg_logprob": -0.12203536356302132, "compression_ratio": 2.06198347107438, "no_speech_prob": 0.03287367895245552}, {"id": 328, "seek": 183840, "start": 1848.68, "end": 1852.8400000000001, "text": " d\u00e9 el m\u00e1ximo obviamente esto no es un problema tratable yo no puedo probar con infinitas oraciones", "tokens": [50878, 2795, 806, 38876, 36325, 7433, 572, 785, 517, 12395, 21507, 712, 5290, 572, 21612, 1239, 289, 416, 7193, 14182, 420, 9188, 51086], "temperature": 0.0, "avg_logprob": -0.12203536356302132, "compression_ratio": 2.06198347107438, "no_speech_prob": 0.03287367895245552}, {"id": 329, "seek": 183840, "start": 1852.8400000000001, "end": 1858.0800000000002, "text": " lo que necesito es un proceso que me limites a cantidad de b\u00fasqueda de infinitas oraciones a", "tokens": [51086, 450, 631, 11909, 3528, 785, 517, 29314, 631, 385, 2364, 3324, 257, 33757, 368, 272, 10227, 358, 8801, 368, 7193, 14182, 420, 9188, 257, 51348], "temperature": 0.0, "avg_logprob": -0.12203536356302132, "compression_ratio": 2.06198347107438, "no_speech_prob": 0.03287367895245552}, {"id": 330, "seek": 183840, "start": 1858.0800000000002, "end": 1864.24, "text": " algo tratable entonces el decodificador va a ser un algoritmo de b\u00fasqueda que va a agarrar la oraci\u00f3n", "tokens": [51348, 8655, 21507, 712, 13003, 806, 979, 378, 1089, 5409, 2773, 257, 816, 517, 3501, 50017, 3280, 368, 272, 10227, 358, 8801, 631, 2773, 257, 623, 2284, 289, 635, 420, 3482, 51656], "temperature": 0.0, "avg_logprob": -0.12203536356302132, "compression_ratio": 2.06198347107438, "no_speech_prob": 0.03287367895245552}, {"id": 331, "seek": 186424, "start": 1864.24, "end": 1871.04, "text": " en origen y va me va a devolver las 100 200 mil oraciones destino candidatas m\u00e1s probable que", "tokens": [50364, 465, 2349, 268, 288, 2773, 385, 2773, 257, 1905, 401, 331, 2439, 2319, 2331, 1962, 420, 9188, 2677, 2982, 6268, 37892, 3573, 21759, 631, 50704], "temperature": 0.0, "avg_logprob": -0.18196385177140384, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.006043384782969952}, {"id": 332, "seek": 186424, "start": 1871.04, "end": 1876.56, "text": " a veces lo ocurra para que yo pueda resolver y calcular esa ecuaci\u00f3n para esas para esas oraciones", "tokens": [50704, 257, 17054, 450, 26430, 424, 1690, 631, 5290, 31907, 34480, 288, 2104, 17792, 11342, 11437, 84, 3482, 1690, 23388, 1690, 23388, 420, 9188, 50980], "temperature": 0.0, "avg_logprob": -0.18196385177140384, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.006043384782969952}, {"id": 333, "seek": 186424, "start": 1876.56, "end": 1881.44, "text": " en vez de para todas las posibles entonces lo que hace es volver este problema tratable vamos a ver", "tokens": [50980, 465, 5715, 368, 1690, 10906, 2439, 1366, 14428, 13003, 450, 631, 10032, 785, 33998, 4065, 12395, 21507, 712, 5295, 257, 1306, 51224], "temperature": 0.0, "avg_logprob": -0.18196385177140384, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.006043384782969952}, {"id": 334, "seek": 186424, "start": 1881.44, "end": 1890.48, "text": " tambi\u00e9n un algoritmo de codificaci\u00f3n que se llama beam search bueno entonces un poco m\u00e1s sobre", "tokens": [51224, 6407, 517, 3501, 50017, 3280, 368, 17656, 40802, 631, 369, 23272, 14269, 3164, 11974, 13003, 517, 10639, 3573, 5473, 51676], "temperature": 0.0, "avg_logprob": -0.18196385177140384, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.006043384782969952}, {"id": 335, "seek": 189048, "start": 1890.48, "end": 1895.1200000000001, "text": " modelos de lenguaje la componente pde de la ecuaci\u00f3n era la que medida la fluidez y se", "tokens": [50364, 2316, 329, 368, 35044, 84, 11153, 635, 4026, 1576, 280, 1479, 368, 635, 11437, 84, 3482, 4249, 635, 631, 32984, 635, 5029, 45170, 288, 369, 50596], "temperature": 0.0, "avg_logprob": -0.1847465942645895, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.288056343793869}, {"id": 336, "seek": 189048, "start": 1895.1200000000001, "end": 1899.0, "text": " calculaba mediante un modelo de lenguaje los modelos de lenguaje son relativamente f\u00e1ciles de", "tokens": [50596, 4322, 5509, 17269, 2879, 517, 27825, 368, 35044, 84, 11153, 1750, 2316, 329, 368, 35044, 84, 11153, 1872, 21960, 3439, 17474, 279, 368, 50790], "temperature": 0.0, "avg_logprob": -0.1847465942645895, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.288056343793869}, {"id": 337, "seek": 189048, "start": 1899.0, "end": 1903.44, "text": " construir porque necesitamos informaci\u00f3n monolingua informaci\u00f3n solamente en el lenguaje destino", "tokens": [50790, 38445, 4021, 38661, 2151, 21660, 1108, 401, 278, 4398, 21660, 27814, 465, 806, 35044, 84, 11153, 2677, 2982, 51012], "temperature": 0.0, "avg_logprob": -0.1847465942645895, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.288056343793869}, {"id": 338, "seek": 189048, "start": 1903.44, "end": 1909.84, "text": " entonces en la web tenemos mont\u00f3n toneladas informaci\u00f3n de muchos idiomas entonces como", "tokens": [51012, 13003, 465, 635, 3670, 9914, 45259, 2952, 338, 6872, 21660, 368, 17061, 18014, 7092, 13003, 2617, 51332], "temperature": 0.0, "avg_logprob": -0.1847465942645895, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.288056343793869}, {"id": 339, "seek": 189048, "start": 1909.84, "end": 1915.48, "text": " solo necesitamos informaci\u00f3n idiomas sacamos texto web noticias blogs etc\u00e9tera y compilamos un gran", "tokens": [51332, 6944, 38661, 2151, 21660, 18014, 7092, 4899, 2151, 35503, 3670, 406, 48042, 31038, 5183, 526, 23833, 288, 715, 388, 2151, 517, 9370, 51614], "temperature": 0.0, "avg_logprob": -0.1847465942645895, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.288056343793869}, {"id": 340, "seek": 191548, "start": 1915.48, "end": 1921.64, "text": " corpus del lenguaje destino los modelos que se utilizan para traducci\u00f3n autom\u00e1tica en general", "tokens": [50364, 1181, 31624, 1103, 35044, 84, 11153, 2677, 2982, 1750, 2316, 329, 631, 369, 19906, 282, 1690, 2479, 1311, 5687, 3553, 23432, 465, 2674, 50672], "temperature": 0.0, "avg_logprob": -0.13544486639067882, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.22771872580051422}, {"id": 341, "seek": 191548, "start": 1921.64, "end": 1926.2, "text": " son modelos basados en engramas que ya hemos visto en el curso c\u00f3mo funcionaban se suele usar orden", "tokens": [50672, 1872, 2316, 329, 987, 4181, 465, 465, 1342, 296, 631, 2478, 15396, 17558, 465, 806, 31085, 12826, 14186, 18165, 369, 459, 16884, 14745, 28615, 50900], "temperature": 0.0, "avg_logprob": -0.13544486639067882, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.22771872580051422}, {"id": 342, "seek": 191548, "start": 1926.2, "end": 1932.88, "text": " de 4 o 5 en otras tareas de pdn se suelen usar \u00f3rdenes m\u00e1s chicos pero para ac\u00e1 da buenos", "tokens": [50900, 368, 1017, 277, 1025, 465, 20244, 49423, 296, 368, 280, 67, 77, 369, 459, 14818, 14745, 44083, 1556, 279, 3573, 46070, 4768, 1690, 23496, 1120, 49617, 51234], "temperature": 0.0, "avg_logprob": -0.13544486639067882, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.22771872580051422}, {"id": 343, "seek": 191548, "start": 1932.88, "end": 1938.1200000000001, "text": " resultados en 4 o 5 y bueno lo importante es tener una gran cantidad de material de entrenamiento o", "tokens": [51234, 36796, 465, 1017, 277, 1025, 288, 11974, 450, 9416, 785, 11640, 2002, 9370, 33757, 368, 2527, 368, 45069, 16971, 277, 51496], "temperature": 0.0, "avg_logprob": -0.13544486639067882, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.22771872580051422}, {"id": 344, "seek": 191548, "start": 1938.1200000000001, "end": 1944.3600000000001, "text": " sea los mejores modelos que usan google translate y otras empresas usan trillones de palabras y bueno", "tokens": [51496, 4158, 1750, 42284, 2316, 329, 631, 505, 282, 20742, 13799, 288, 20244, 26433, 505, 282, 504, 373, 2213, 368, 35240, 288, 11974, 51808], "temperature": 0.0, "avg_logprob": -0.13544486639067882, "compression_ratio": 1.7411347517730495, "no_speech_prob": 0.22771872580051422}, {"id": 345, "seek": 194436, "start": 1944.36, "end": 1949.8, "text": " son necesitan hardware especial especialmente dise\u00f1ado para poder ir r\u00e1pido y recuperar la", "tokens": [50364, 1872, 11909, 9670, 8837, 15342, 41546, 3814, 2791, 1573, 1690, 8152, 3418, 24893, 288, 25692, 289, 635, 50636], "temperature": 0.0, "avg_logprob": -0.2017668088277181, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.0065755597315728664}, {"id": 346, "seek": 194436, "start": 1949.8, "end": 1955.04, "text": " informaci\u00f3n o si no bueno si estoy hablando un dominio acotado puedo usar datos de dominio para", "tokens": [50636, 21660, 277, 1511, 572, 11974, 1511, 15796, 29369, 517, 8859, 1004, 696, 310, 1573, 21612, 14745, 27721, 368, 8859, 1004, 1690, 50898], "temperature": 0.0, "avg_logprob": -0.2017668088277181, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.0065755597315728664}, {"id": 347, "seek": 194436, "start": 1955.04, "end": 1962.8, "text": " entrenar que tambi\u00e9n va a ser buenos resultados las t\u00e9cnicas de mutin es cuando vos haya alguna", "tokens": [50898, 45069, 289, 631, 6407, 2773, 257, 816, 49617, 36796, 2439, 25564, 40672, 368, 5839, 259, 785, 7767, 13845, 24693, 20651, 51286], "temperature": 0.0, "avg_logprob": -0.2017668088277181, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.0065755597315728664}, {"id": 348, "seek": 194436, "start": 1962.8, "end": 1967.36, "text": " engrama que no viste lo que te va a pasar es que la probabilidad cero y ah\u00ed te va a dar todo cero", "tokens": [51286, 465, 1342, 64, 631, 572, 371, 8375, 450, 631, 535, 2773, 257, 25344, 785, 631, 635, 31959, 4580, 269, 2032, 288, 12571, 535, 2773, 257, 4072, 5149, 269, 2032, 51514], "temperature": 0.0, "avg_logprob": -0.2017668088277181, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.0065755597315728664}, {"id": 349, "seek": 194436, "start": 1967.36, "end": 1971.36, "text": " en realidad las mejores t\u00e9cnicas de mutin significa darle una buena probabilidad a eso a pesar de que", "tokens": [51514, 465, 25635, 2439, 42284, 25564, 40672, 368, 5839, 259, 19957, 37666, 2002, 25710, 31959, 4580, 257, 7287, 257, 41951, 368, 631, 51714], "temperature": 0.0, "avg_logprob": -0.2017668088277181, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.0065755597315728664}, {"id": 350, "seek": 197136, "start": 1971.36, "end": 1977.36, "text": " nunca lo has visto se dice que las mejores mejoras digamos las m\u00e1s grandes mejoras en los modelos", "tokens": [50364, 13768, 450, 575, 17558, 369, 10313, 631, 2439, 42284, 11479, 296, 36430, 2439, 3573, 16640, 11479, 296, 465, 1750, 2316, 329, 50664], "temperature": 0.0, "avg_logprob": -0.14091318448384602, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.07157599180936813}, {"id": 351, "seek": 197136, "start": 1977.36, "end": 1981.12, "text": " en la traducci\u00f3n autom\u00e1tica de los \u00faltimos a\u00f1os se han dado porque hay mejor en modelo", "tokens": [50664, 465, 635, 2479, 1311, 5687, 3553, 23432, 368, 1750, 33013, 11424, 369, 7276, 29568, 4021, 4842, 11479, 465, 27825, 50852], "temperature": 0.0, "avg_logprob": -0.14091318448384602, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.07157599180936813}, {"id": 352, "seek": 197136, "start": 1981.12, "end": 1987.32, "text": " el lenguaje que me dan traducciones que son m\u00e1s fluidas y y bueno y usualmente hay como", "tokens": [50852, 806, 35044, 84, 11153, 631, 385, 3277, 2479, 1311, 23469, 631, 1872, 3573, 5029, 11382, 288, 288, 11974, 288, 7713, 4082, 4842, 2617, 51162], "temperature": 0.0, "avg_logprob": -0.14091318448384602, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.07157599180936813}, {"id": 353, "seek": 197136, "start": 1987.32, "end": 1992.84, "text": " cierta cierta correlaci\u00f3n o cierta inclinaci\u00f3n hacia las fluidez la gente prefiere cuando las", "tokens": [51162, 39769, 1328, 39769, 1328, 13983, 3482, 277, 39769, 1328, 834, 5045, 3482, 21365, 2439, 5029, 45170, 635, 3788, 659, 13325, 323, 7767, 2439, 51438], "temperature": 0.0, "avg_logprob": -0.14091318448384602, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.07157599180936813}, {"id": 354, "seek": 197136, "start": 1992.84, "end": 1998.4799999999998, "text": " oraciones son sonan m\u00e1s naturales ac\u00e1 un ejemplo esto era sacado un sistema de traducci\u00f3n del", "tokens": [51438, 420, 9188, 1872, 1872, 282, 3573, 3303, 279, 23496, 517, 13358, 7433, 4249, 4899, 1573, 517, 13245, 368, 2479, 1311, 5687, 1103, 51720], "temperature": 0.0, "avg_logprob": -0.14091318448384602, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.07157599180936813}, {"id": 355, "seek": 199848, "start": 1998.48, "end": 2004.4, "text": " chino al ingl\u00e9s el sistema estad\u00edstico basado en sintaxis que cuando no utilizaba modelo", "tokens": [50364, 417, 2982, 419, 49766, 806, 13245, 39160, 19512, 2789, 987, 1573, 465, 41259, 24633, 631, 7767, 572, 19906, 5509, 27825, 50660], "temperature": 0.0, "avg_logprob": -0.14598391236377364, "compression_ratio": 1.728624535315985, "no_speech_prob": 0.02530805952847004}, {"id": 356, "seek": 199848, "start": 2004.4, "end": 2010.1200000000001, "text": " lenguaje ten\u00eda un puntaje de 25 con 2 al incorporar modelo lenguaje subi\u00f3 como un 20", "tokens": [50660, 35044, 84, 11153, 23718, 517, 4468, 1328, 2884, 368, 3552, 416, 568, 419, 8788, 289, 27825, 35044, 84, 11153, 1422, 7138, 2617, 517, 945, 50946], "temperature": 0.0, "avg_logprob": -0.14598391236377364, "compression_ratio": 1.728624535315985, "no_speech_prob": 0.02530805952847004}, {"id": 357, "seek": 199848, "start": 2010.1200000000001, "end": 2016.1200000000001, "text": " por ciento su su performance y lleg\u00f3 a 31 con 2 como 6 puntos esos puntos corresponden a una", "tokens": [50946, 1515, 47361, 459, 459, 3389, 288, 46182, 257, 10353, 416, 568, 2617, 1386, 34375, 22411, 34375, 6805, 268, 257, 2002, 51246], "temperature": 0.0, "avg_logprob": -0.14598391236377364, "compression_ratio": 1.728624535315985, "no_speech_prob": 0.02530805952847004}, {"id": 358, "seek": 199848, "start": 2016.1200000000001, "end": 2020.04, "text": " medida que vamos a ver dentro un rato que se llama medida blu que es una medida muy utilizada en lo", "tokens": [51246, 32984, 631, 5295, 257, 1306, 10856, 517, 367, 2513, 631, 369, 23272, 32984, 888, 84, 631, 785, 2002, 32984, 5323, 19906, 1538, 465, 450, 51442], "temperature": 0.0, "avg_logprob": -0.14598391236377364, "compression_ratio": 1.728624535315985, "no_speech_prob": 0.02530805952847004}, {"id": 359, "seek": 199848, "start": 2020.04, "end": 2027.88, "text": " que es traducci\u00f3n estad\u00edstica traducci\u00f3n autom\u00e1tica en general pero bueno ahora solamente", "tokens": [51442, 631, 785, 2479, 1311, 5687, 39160, 19512, 2262, 2479, 1311, 5687, 3553, 23432, 465, 2674, 4768, 11974, 9923, 27814, 51834], "temperature": 0.0, "avg_logprob": -0.14598391236377364, "compression_ratio": 1.728624535315985, "no_speech_prob": 0.02530805952847004}, {"id": 360, "seek": 202788, "start": 2027.88, "end": 2034.72, "text": " saber que 6 puntos es una mejora que es much\u00edsimo y como es que mejora esto mejora haciendo que", "tokens": [50364, 12489, 631, 1386, 34375, 785, 2002, 11479, 64, 631, 785, 44722, 288, 2617, 785, 631, 11479, 64, 7433, 11479, 64, 20509, 631, 50706], "temperature": 0.0, "avg_logprob": -0.16957478369435958, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0003338077221997082}, {"id": 361, "seek": 202788, "start": 2034.72, "end": 2039.3200000000002, "text": " las traducciones que devuelve en general sean m\u00e1s fluidas son m\u00e1s natural en el lenguaje", "tokens": [50706, 2439, 2479, 1311, 23469, 631, 1905, 3483, 303, 465, 2674, 37670, 3573, 5029, 11382, 1872, 3573, 3303, 465, 806, 35044, 84, 11153, 50936], "temperature": 0.0, "avg_logprob": -0.16957478369435958, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0003338077221997082}, {"id": 362, "seek": 202788, "start": 2039.3200000000002, "end": 2044.0, "text": " destino y ac\u00e1 hay un ejemplo de traducciones de ese mismo sistema yo ten\u00eda una traducci\u00f3n de", "tokens": [50936, 2677, 2982, 288, 23496, 4842, 517, 13358, 368, 2479, 1311, 23469, 368, 10167, 12461, 13245, 5290, 23718, 2002, 2479, 1311, 5687, 368, 51170], "temperature": 0.0, "avg_logprob": -0.16957478369435958, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0003338077221997082}, {"id": 363, "seek": 202788, "start": 2044.0, "end": 2049.76, "text": " referencia que era I don't have enough money with me to buy a new airplane ticket el sistema sin el", "tokens": [51170, 2864, 10974, 631, 4249, 286, 500, 380, 362, 1547, 1460, 365, 385, 281, 2256, 257, 777, 17130, 10550, 806, 13245, 3343, 806, 51458], "temperature": 0.0, "avg_logprob": -0.16957478369435958, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0003338077221997082}, {"id": 364, "seek": 202788, "start": 2049.76, "end": 2054.6800000000003, "text": " modelo lenguaje devolv\u00eda esta traducci\u00f3n dec\u00eda don't have enough bag on me change please go a", "tokens": [51458, 27825, 35044, 84, 11153, 1905, 401, 85, 2686, 5283, 2479, 1311, 5687, 37599, 500, 380, 362, 1547, 3411, 322, 385, 1319, 1767, 352, 257, 51704], "temperature": 0.0, "avg_logprob": -0.16957478369435958, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0003338077221997082}, {"id": 365, "seek": 205468, "start": 2054.68, "end": 2060.6, "text": " new by plane que no nos entiende mucho que lo que dice no es gramatical pero al agregar el modelo", "tokens": [50364, 777, 538, 5720, 631, 572, 3269, 948, 45816, 9824, 631, 450, 631, 10313, 572, 785, 21353, 267, 804, 4768, 419, 4554, 2976, 806, 27825, 50660], "temperature": 0.0, "avg_logprob": -0.18422754349247103, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.004527103155851364}, {"id": 366, "seek": 205468, "start": 2060.6, "end": 2065.7999999999997, "text": " de traducci\u00f3n su traducci\u00f3n es la siguiente I have enough money to buy a new one by air que", "tokens": [50660, 368, 2479, 1311, 5687, 459, 2479, 1311, 5687, 785, 635, 25666, 286, 362, 1547, 1460, 281, 2256, 257, 777, 472, 538, 1988, 631, 50920], "temperature": 0.0, "avg_logprob": -0.18422754349247103, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.004527103155851364}, {"id": 367, "seek": 205468, "start": 2065.7999999999997, "end": 2076.3199999999997, "text": " suena mucho mejor que les parece acerca del significado el significado se lo puesto digamos", "tokens": [50920, 459, 4118, 9824, 11479, 631, 1512, 14120, 46321, 1103, 3350, 1573, 806, 3350, 1573, 369, 450, 35136, 36430, 51446], "temperature": 0.0, "avg_logprob": -0.18422754349247103, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.004527103155851364}, {"id": 368, "seek": 205468, "start": 2076.3199999999997, "end": 2080.08, "text": " ac\u00e1 est\u00e1 diciendo que tiene suficiente plata para comprar uno por aire y ac\u00e1 dice que no tiene", "tokens": [51446, 23496, 3192, 42797, 631, 7066, 33958, 30780, 1690, 22077, 8526, 1515, 42885, 288, 23496, 10313, 631, 572, 7066, 51634], "temperature": 0.0, "avg_logprob": -0.18422754349247103, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.004527103155851364}, {"id": 369, "seek": 208008, "start": 2080.08, "end": 2085.2799999999997, "text": " suficiente plata para comprar un pasaje de avi\u00f3n o sea este suena much\u00edsimo mejor porque", "tokens": [50364, 33958, 30780, 1690, 22077, 517, 1736, 11153, 368, 1305, 2560, 277, 4158, 4065, 459, 4118, 44722, 11479, 4021, 50624], "temperature": 0.0, "avg_logprob": -0.15768722065708093, "compression_ratio": 1.873469387755102, "no_speech_prob": 0.04019126668572426}, {"id": 370, "seek": 208008, "start": 2085.2799999999997, "end": 2089.04, "text": " est\u00e1 ni siquiera gramatical pero est\u00e1 por lo menos manten\u00eda la negaci\u00f3n digamos manten\u00eda que", "tokens": [50624, 3192, 3867, 1511, 35134, 21353, 267, 804, 4768, 3192, 1515, 450, 8902, 38417, 2686, 635, 2485, 3482, 36430, 38417, 2686, 631, 50812], "temperature": 0.0, "avg_logprob": -0.15768722065708093, "compression_ratio": 1.873469387755102, "no_speech_prob": 0.04019126668572426}, {"id": 371, "seek": 208008, "start": 2089.04, "end": 2095.16, "text": " era una oraci\u00f3n negativa entonces hay cuidado con esto la traducci\u00f3n suena mucho mejor pero", "tokens": [50812, 4249, 2002, 420, 3482, 2485, 18740, 13003, 4842, 31891, 416, 7433, 635, 2479, 1311, 5687, 459, 4118, 9824, 11479, 4768, 51118], "temperature": 0.0, "avg_logprob": -0.15768722065708093, "compression_ratio": 1.873469387755102, "no_speech_prob": 0.04019126668572426}, {"id": 372, "seek": 208008, "start": 2095.16, "end": 2098.92, "text": " a veces podemos estar sacrificando fidelidad sacrificando adecuaci\u00f3n de la traducci\u00f3n", "tokens": [51118, 257, 17054, 12234, 8755, 14108, 1806, 283, 16189, 4580, 14108, 1806, 614, 3045, 84, 3482, 368, 635, 2479, 1311, 5687, 51306], "temperature": 0.0, "avg_logprob": -0.15768722065708093, "compression_ratio": 1.873469387755102, "no_speech_prob": 0.04019126668572426}, {"id": 373, "seek": 208008, "start": 2102.12, "end": 2106.64, "text": " bien esos son los modelos de lenguaje ahora pasemos a la otra los modelos de traducci\u00f3n", "tokens": [51466, 3610, 22411, 1872, 1750, 2316, 329, 368, 35044, 84, 11153, 9923, 1736, 4485, 257, 635, 13623, 1750, 2316, 329, 368, 2479, 1311, 5687, 51692], "temperature": 0.0, "avg_logprob": -0.15768722065708093, "compression_ratio": 1.873469387755102, "no_speech_prob": 0.04019126668572426}, {"id": 374, "seek": 210664, "start": 2107.2799999999997, "end": 2114.64, "text": " la componente pdf dado de la ecuaci\u00f3n mide lo que es la ecuaci\u00f3n o fidelidad de una traducci\u00f3n", "tokens": [50396, 635, 4026, 1576, 280, 45953, 29568, 368, 635, 11437, 84, 3482, 275, 482, 450, 631, 785, 635, 11437, 84, 3482, 277, 283, 16189, 4580, 368, 2002, 2479, 1311, 5687, 50764], "temperature": 0.0, "avg_logprob": -0.11735909020722803, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0019463737262412906}, {"id": 375, "seek": 210664, "start": 2114.64, "end": 2120.68, "text": " y la otra y para esto necesito corpus paralelos o corpus biling\u00fces que para poder entrenar", "tokens": [50764, 288, 635, 13623, 288, 1690, 7433, 11909, 3528, 1181, 31624, 26009, 338, 329, 277, 1181, 31624, 272, 4883, 774, 279, 631, 1690, 8152, 45069, 289, 51066], "temperature": 0.0, "avg_logprob": -0.11735909020722803, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0019463737262412906}, {"id": 376, "seek": 210664, "start": 2120.68, "end": 2124.12, "text": " estos modelos los corpus biling\u00fces son bastante m\u00e1s dif\u00edciles de construir que los corpus", "tokens": [51066, 12585, 2316, 329, 1750, 1181, 31624, 272, 4883, 774, 279, 1872, 14651, 3573, 17258, 279, 368, 38445, 631, 1750, 1181, 31624, 51238], "temperature": 0.0, "avg_logprob": -0.11735909020722803, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0019463737262412906}, {"id": 377, "seek": 210664, "start": 2124.12, "end": 2128.7999999999997, "text": " monoling\u00fces digamos no alcanza con hacer una pasada por la web y obtener texto de un idioma", "tokens": [51238, 1108, 401, 278, 774, 279, 36430, 572, 419, 7035, 2394, 416, 6720, 2002, 1736, 1538, 1515, 635, 3670, 288, 28326, 260, 35503, 368, 517, 18014, 6440, 51472], "temperature": 0.0, "avg_logprob": -0.11735909020722803, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0019463737262412906}, {"id": 378, "seek": 210664, "start": 2128.7999999999997, "end": 2136.04, "text": " y bueno los modelos que vamos a ver son los propuestos por brown brown y su equipo en 1993", "tokens": [51472, 288, 11974, 1750, 2316, 329, 631, 5295, 257, 1306, 1872, 1750, 2365, 42738, 1515, 6292, 6292, 288, 459, 30048, 465, 25137, 51834], "temperature": 0.0, "avg_logprob": -0.11735909020722803, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0019463737262412906}, {"id": 379, "seek": 213604, "start": 2136.04, "end": 2140.4, "text": " que trabajan en ibm ellos construyeron cinco modelos de c\u00f3mo construir cinco modelos digamos", "tokens": [50364, 631, 9618, 282, 465, 39073, 76, 16353, 12946, 7224, 266, 21350, 2316, 329, 368, 12826, 38445, 21350, 2316, 329, 36430, 50582], "temperature": 0.0, "avg_logprob": -0.17833776641310306, "compression_ratio": 1.876984126984127, "no_speech_prob": 0.005232037045061588}, {"id": 380, "seek": 213604, "start": 2140.4, "end": 2145.7599999999998, "text": " en creciente complejidad de c\u00f3mo construir un modelo de traducci\u00f3n para traducci\u00f3n estad\u00edstica", "tokens": [50582, 465, 1197, 537, 1576, 44424, 73, 4580, 368, 12826, 38445, 517, 27825, 368, 2479, 1311, 5687, 1690, 2479, 1311, 5687, 39160, 19512, 2262, 50850], "temperature": 0.0, "avg_logprob": -0.17833776641310306, "compression_ratio": 1.876984126984127, "no_speech_prob": 0.005232037045061588}, {"id": 381, "seek": 213604, "start": 2147.44, "end": 2151.92, "text": " y bueno los modelos la diferencia entre cada modelo se es en la historia de generaci\u00f3n de", "tokens": [50934, 288, 11974, 1750, 2316, 329, 635, 38844, 3962, 8411, 27825, 369, 785, 465, 635, 18385, 368, 1337, 3482, 368, 51158], "temperature": 0.0, "avg_logprob": -0.17833776641310306, "compression_ratio": 1.876984126984127, "no_speech_prob": 0.005232037045061588}, {"id": 382, "seek": 213604, "start": 2151.92, "end": 2156.08, "text": " las de las oraciones candidatas y bueno despu\u00e9s vamos a ver tambi\u00e9n otro modelo un poco m\u00e1s", "tokens": [51158, 2439, 368, 2439, 420, 9188, 6268, 37892, 288, 11974, 15283, 5295, 257, 1306, 6407, 11921, 27825, 517, 10639, 3573, 51366], "temperature": 0.0, "avg_logprob": -0.17833776641310306, "compression_ratio": 1.876984126984127, "no_speech_prob": 0.005232037045061588}, {"id": 383, "seek": 213604, "start": 2156.08, "end": 2162.04, "text": " moderno pero bueno vamos a empezar viendo m\u00e1s bien los modelos de brown a qu\u00e9 me refiero con", "tokens": [51366, 4363, 78, 4768, 11974, 5295, 257, 31168, 34506, 3573, 3610, 1750, 2316, 329, 368, 6292, 257, 8057, 385, 1895, 12030, 416, 51664], "temperature": 0.0, "avg_logprob": -0.17833776641310306, "compression_ratio": 1.876984126984127, "no_speech_prob": 0.005232037045061588}, {"id": 384, "seek": 216204, "start": 2162.12, "end": 2167.96, "text": " historia de generaci\u00f3n de las oraciones candidatas una historia de generaci\u00f3n esto lo digo ahora", "tokens": [50368, 18385, 368, 1337, 3482, 368, 2439, 420, 9188, 6268, 37892, 2002, 18385, 368, 1337, 3482, 7433, 450, 22990, 9923, 50660], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 385, "seek": 216204, "start": 2167.96, "end": 2171.12, "text": " pero en realidad lo vamos a profundizar despu\u00e9s una historia de generaci\u00f3n en realidad es como", "tokens": [50660, 4768, 465, 25635, 450, 5295, 257, 40958, 9736, 15283, 2002, 18385, 368, 1337, 3482, 465, 25635, 785, 2617, 50818], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 386, "seek": 216204, "start": 2171.12, "end": 2175.36, "text": " una especie de proceso mental que seguir\u00eda un traductor cuando quiere pasar de una oraci\u00f3n a la", "tokens": [50818, 2002, 49368, 368, 29314, 4973, 631, 18584, 2686, 517, 2479, 84, 1672, 7767, 23877, 25344, 368, 2002, 420, 3482, 257, 635, 51030], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 387, "seek": 216204, "start": 2175.36, "end": 2180.88, "text": " otra entonces estas historias se basan en decir bueno un traductor agarra una oraci\u00f3n en el idioma", "tokens": [51030, 13623, 13003, 13897, 4058, 4609, 369, 987, 282, 465, 10235, 11974, 517, 2479, 84, 1672, 623, 289, 424, 2002, 420, 3482, 465, 806, 18014, 6440, 51306], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 388, "seek": 216204, "start": 2180.88, "end": 2186.56, "text": " origen y despu\u00e9s elige la cantidad de palabras que voy a tener el idioma destino reordena palabras", "tokens": [51306, 2349, 268, 288, 15283, 806, 3969, 635, 33757, 368, 35240, 631, 7552, 257, 11640, 806, 18014, 6440, 2677, 2982, 319, 765, 4118, 35240, 51590], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 389, "seek": 216204, "start": 2186.56, "end": 2190.88, "text": " despu\u00e9s va traduciendo una a una seg\u00fan un diccionario despu\u00e9s agrega palabras nuevas que", "tokens": [51590, 15283, 2773, 2479, 1311, 7304, 2002, 257, 2002, 36570, 517, 14285, 10015, 4912, 15283, 623, 3375, 64, 35240, 42817, 631, 51806], "temperature": 0.0, "avg_logprob": -0.13649651663643972, "compression_ratio": 2.067137809187279, "no_speech_prob": 0.015426118858158588}, {"id": 390, "seek": 219088, "start": 2190.88, "end": 2195.88, "text": " no estaban en la oraci\u00f3n ese tipo de cosas digamos el tipo de pasos me lo voy a escribir en", "tokens": [50364, 572, 36713, 465, 635, 420, 3482, 10167, 9746, 368, 12218, 36430, 806, 9746, 368, 1736, 329, 385, 450, 7552, 257, 30598, 10119, 465, 50614], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 391, "seek": 219088, "start": 2195.88, "end": 2200.56, "text": " la historia de generaci\u00f3n y para qu\u00e9 sirve eso sirve para que a cada uno de esos pasos yo le", "tokens": [50614, 635, 18385, 368, 1337, 3482, 288, 1690, 8057, 4735, 303, 7287, 4735, 303, 1690, 631, 257, 8411, 8526, 368, 22411, 1736, 329, 5290, 476, 50848], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 392, "seek": 219088, "start": 2200.56, "end": 2205.0, "text": " puedo dar un valor num\u00e9rico un valor en cuanto a probabilidades y despu\u00e9s lo que voy a hacer", "tokens": [50848, 21612, 4072, 517, 15367, 1031, 526, 23776, 517, 15367, 465, 36685, 257, 31959, 10284, 288, 15283, 450, 631, 7552, 257, 6720, 51070], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 393, "seek": 219088, "start": 2205.0, "end": 2209.6, "text": " cuando entreno mi sistema es tunear esos valores num\u00e9ricos tunear todas esas probabilidades para", "tokens": [51070, 7767, 45069, 78, 2752, 13245, 785, 10864, 289, 22411, 38790, 1031, 27578, 329, 10864, 289, 10906, 23388, 31959, 10284, 1690, 51300], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 394, "seek": 219088, "start": 2209.6, "end": 2214.7200000000003, "text": " darme el c\u00e1lculo de probabilidad total vamos a profundizar m\u00e1s de en esto despu\u00e9s", "tokens": [51300, 4072, 1398, 806, 6476, 75, 25436, 368, 31959, 4580, 3217, 5295, 257, 40958, 9736, 3573, 368, 465, 7433, 15283, 51556], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 395, "seek": 219088, "start": 2216.44, "end": 2220.04, "text": " pero antes de pasar a lo que son los modelos de traducci\u00f3n vamos a hablar un poco de c\u00f3mo", "tokens": [51642, 4768, 11014, 368, 25344, 257, 450, 631, 1872, 1750, 2316, 329, 368, 2479, 1311, 5687, 5295, 257, 21014, 517, 10639, 368, 12826, 51822], "temperature": 0.0, "avg_logprob": -0.13844380678830448, "compression_ratio": 1.8945578231292517, "no_speech_prob": 0.0018230756977573037}, {"id": 396, "seek": 222004, "start": 2220.04, "end": 2225.44, "text": " se evaluan estos sistemas en general siempre es importante evaluar todo en el pln digamos porque", "tokens": [50364, 369, 6133, 282, 12585, 48720, 465, 2674, 12758, 785, 9416, 6133, 289, 5149, 465, 806, 499, 77, 36430, 4021, 50634], "temperature": 0.0, "avg_logprob": -0.14109504432008976, "compression_ratio": 1.8314176245210727, "no_speech_prob": 0.001450250274501741}, {"id": 397, "seek": 222004, "start": 2225.44, "end": 2231.0, "text": " no hay soluciones perfectas entonces voy a tener sistemas que andan mejor o peor que otros y bueno", "tokens": [50634, 572, 4842, 1404, 46649, 2176, 296, 13003, 7552, 257, 11640, 48720, 631, 293, 282, 11479, 277, 520, 284, 631, 16422, 288, 11974, 50912], "temperature": 0.0, "avg_logprob": -0.14109504432008976, "compression_ratio": 1.8314176245210727, "no_speech_prob": 0.001450250274501741}, {"id": 398, "seek": 222004, "start": 2231.0, "end": 2236.32, "text": " y la traducci\u00f3n autom\u00e1tica obviamente no es la excepci\u00f3n entonces me sirve poder evaluar los", "tokens": [50912, 288, 635, 2479, 1311, 5687, 3553, 23432, 36325, 572, 785, 635, 454, 27493, 5687, 13003, 385, 4735, 303, 8152, 6133, 289, 1750, 51178], "temperature": 0.0, "avg_logprob": -0.14109504432008976, "compression_ratio": 1.8314176245210727, "no_speech_prob": 0.001450250274501741}, {"id": 399, "seek": 222004, "start": 2236.32, "end": 2239.6, "text": " sistemas para poder saber qu\u00e9 sistema mejor que el otro y adem\u00e1s si yo hago cambios en mi", "tokens": [51178, 48720, 1690, 8152, 12489, 8057, 13245, 11479, 631, 806, 11921, 288, 21251, 1511, 5290, 38721, 18751, 2717, 465, 2752, 51342], "temperature": 0.0, "avg_logprob": -0.14109504432008976, "compression_ratio": 1.8314176245210727, "no_speech_prob": 0.001450250274501741}, {"id": 400, "seek": 222004, "start": 2239.6, "end": 2244.68, "text": " sistema poder evaluar de vuelta a ver si mejor\u00e9 o no entonces qu\u00e9 puedo considerar una buena", "tokens": [51342, 13245, 8152, 6133, 289, 368, 41542, 257, 1306, 1511, 11479, 526, 277, 572, 13003, 8057, 21612, 1949, 289, 2002, 25710, 51596], "temperature": 0.0, "avg_logprob": -0.14109504432008976, "compression_ratio": 1.8314176245210727, "no_speech_prob": 0.001450250274501741}, {"id": 401, "seek": 224468, "start": 2244.72, "end": 2248.2799999999997, "text": " traducci\u00f3n para empezar eso es una pregunta que es abierto en su", "tokens": [50366, 2479, 1311, 5687, 1690, 31168, 7287, 785, 2002, 24252, 631, 785, 410, 20747, 465, 459, 50544], "temperature": 0.0, "avg_logprob": -0.17674170421952962, "compression_ratio": 2.1055045871559632, "no_speech_prob": 0.12940052151679993}, {"id": 402, "seek": 224468, "start": 2251.44, "end": 2256.16, "text": " digamos es abierto en su respuesta no o sea yo ten\u00eda en un sistema de traducci\u00f3n ten\u00eda una", "tokens": [50702, 36430, 785, 410, 20747, 465, 459, 40585, 572, 277, 4158, 5290, 23718, 465, 517, 13245, 368, 2479, 1311, 5687, 23718, 2002, 50938], "temperature": 0.0, "avg_logprob": -0.17674170421952962, "compression_ratio": 2.1055045871559632, "no_speech_prob": 0.12940052151679993}, {"id": 403, "seek": 224468, "start": 2256.16, "end": 2260.6, "text": " referencia un candidato de referencia que era de katsat on the mat digamos esa era una traducci\u00f3n", "tokens": [50938, 2864, 10974, 517, 6268, 2513, 368, 2864, 10974, 631, 4249, 368, 350, 1720, 267, 322, 264, 3803, 36430, 11342, 4249, 2002, 2479, 1311, 5687, 51160], "temperature": 0.0, "avg_logprob": -0.17674170421952962, "compression_ratio": 2.1055045871559632, "no_speech_prob": 0.12940052151679993}, {"id": 404, "seek": 224468, "start": 2260.6, "end": 2267.3599999999997, "text": " de referencia y un sistema me dio seis posibles candidatos para esa traducci\u00f3n o sea originalmente", "tokens": [51160, 368, 2864, 10974, 288, 517, 13245, 385, 31965, 28233, 1366, 14428, 6268, 26818, 1690, 11342, 2479, 1311, 5687, 277, 4158, 3380, 4082, 51498], "temperature": 0.0, "avg_logprob": -0.17674170421952962, "compression_ratio": 2.1055045871559632, "no_speech_prob": 0.12940052151679993}, {"id": 405, "seek": 224468, "start": 2267.3599999999997, "end": 2273.48, "text": " hab\u00eda una frase por ejemplo en chino la traducci\u00f3n de referencia de katsat on the mat y mi sistema", "tokens": [51498, 16395, 2002, 38406, 1515, 13358, 465, 417, 2982, 635, 2479, 1311, 5687, 368, 2864, 10974, 368, 350, 1720, 267, 322, 264, 3803, 288, 2752, 13245, 51804], "temperature": 0.0, "avg_logprob": -0.17674170421952962, "compression_ratio": 2.1055045871559632, "no_speech_prob": 0.12940052151679993}, {"id": 406, "seek": 227348, "start": 2273.48, "end": 2279.2, "text": " a traducir el chino me dio estas opciones tengo de katsat on mat de on the mat de cat de cat on", "tokens": [50364, 257, 2479, 1311, 347, 806, 417, 2982, 385, 31965, 13897, 999, 23469, 13989, 368, 350, 1720, 267, 322, 3803, 368, 322, 264, 3803, 368, 3857, 368, 3857, 322, 50650], "temperature": 0.0, "avg_logprob": -0.1854272479853354, "compression_ratio": 2.0652173913043477, "no_speech_prob": 0.003290471388027072}, {"id": 407, "seek": 227348, "start": 2279.2, "end": 2284.92, "text": " the floor a katsat on the mat de katsat on the mat con min\u00fascula o de katsat on the straw mat", "tokens": [50650, 264, 4123, 257, 350, 1720, 267, 322, 264, 3803, 368, 350, 1720, 267, 322, 264, 3803, 416, 923, 10227, 2444, 64, 277, 368, 350, 1720, 267, 322, 264, 10099, 3803, 50936], "temperature": 0.0, "avg_logprob": -0.1854272479853354, "compression_ratio": 2.0652173913043477, "no_speech_prob": 0.003290471388027072}, {"id": 408, "seek": 227348, "start": 2286.92, "end": 2291.64, "text": " cu\u00e1les les parecen que son buenas traducciones de estos candidatos que me dio el sistema", "tokens": [51036, 2702, 842, 904, 1512, 7448, 13037, 631, 1872, 43852, 2479, 1311, 23469, 368, 12585, 6268, 26818, 631, 385, 31965, 806, 13245, 51272], "temperature": 0.0, "avg_logprob": -0.1854272479853354, "compression_ratio": 2.0652173913043477, "no_speech_prob": 0.003290471388027072}, {"id": 409, "seek": 227348, "start": 2291.64, "end": 2299.44, "text": " cu\u00e1les les gustan m\u00e1s la e que es de katsat on the mat pero con min\u00fascula en vez de comay\u00fascula", "tokens": [51272, 2702, 842, 904, 1512, 9679, 282, 3573, 635, 308, 631, 785, 368, 350, 1720, 267, 322, 264, 3803, 4768, 416, 923, 10227, 2444, 64, 465, 5715, 368, 395, 320, 10227, 2444, 64, 51662], "temperature": 0.0, "avg_logprob": -0.1854272479853354, "compression_ratio": 2.0652173913043477, "no_speech_prob": 0.003290471388027072}, {"id": 410, "seek": 229944, "start": 2299.44, "end": 2307.4, "text": " que otra la b on the mat de cat que otra la de les gusta tambi\u00e9n a katsat on the mat", "tokens": [50364, 631, 13623, 635, 272, 322, 264, 3803, 368, 3857, 631, 13623, 635, 368, 1512, 20576, 6407, 257, 350, 1720, 267, 322, 264, 3803, 50762], "temperature": 0.0, "avg_logprob": -0.23721800094995743, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.004719918128103018}, {"id": 411, "seek": 229944, "start": 2314.12, "end": 2318.76, "text": " capaz que no calienta tanto dependiendo del uso que le vas a dar esa frase en contexto capaz que no", "tokens": [51098, 35453, 631, 572, 2104, 1196, 64, 10331, 5672, 7304, 1103, 22728, 631, 476, 11481, 257, 4072, 11342, 38406, 465, 47685, 35453, 631, 572, 51330], "temperature": 0.0, "avg_logprob": -0.23721800094995743, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.004719918128103018}, {"id": 412, "seek": 229944, "start": 2318.76, "end": 2323.84, "text": " calienta tanto y bueno si la verdad no se ve nada cuando est\u00e1n las cosas marcadas en rojo pero bueno", "tokens": [51330, 2104, 1196, 64, 10331, 288, 11974, 1511, 635, 13692, 572, 369, 1241, 8096, 7767, 10368, 2439, 12218, 42365, 6872, 465, 744, 5134, 4768, 11974, 51584], "temperature": 0.0, "avg_logprob": -0.23721800094995743, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.004719918128103018}, {"id": 413, "seek": 232384, "start": 2323.84, "end": 2330.6400000000003, "text": " en fin cr\u00e9anme ac\u00e1 la cosa macaza en rojo son las que acaban de decir una buena traducci\u00f3n podemos", "tokens": [50364, 465, 962, 15609, 282, 1398, 23496, 635, 10163, 7912, 12257, 465, 744, 5134, 1872, 2439, 631, 13281, 282, 368, 10235, 2002, 25710, 2479, 1311, 5687, 12234, 50704], "temperature": 0.0, "avg_logprob": -0.16047611236572265, "compression_ratio": 1.94, "no_speech_prob": 0.012679334729909897}, {"id": 414, "seek": 232384, "start": 2330.6400000000003, "end": 2333.8, "text": " decir que es una traducci\u00f3n que le gusta a la gente que la gente dice si es una buena traducci\u00f3n", "tokens": [50704, 10235, 631, 785, 2002, 2479, 1311, 5687, 631, 476, 20576, 257, 635, 3788, 631, 635, 3788, 10313, 1511, 785, 2002, 25710, 2479, 1311, 5687, 50862], "temperature": 0.0, "avg_logprob": -0.16047611236572265, "compression_ratio": 1.94, "no_speech_prob": 0.012679334729909897}, {"id": 415, "seek": 232384, "start": 2333.8, "end": 2340.2000000000003, "text": " entonces ac\u00e1 se elige on the mat sat de cat a katsat on the mat y de katsat on the mat en", "tokens": [50862, 13003, 23496, 369, 806, 3969, 322, 264, 3803, 3227, 368, 3857, 257, 350, 1720, 267, 322, 264, 3803, 288, 368, 350, 1720, 267, 322, 264, 3803, 465, 51182], "temperature": 0.0, "avg_logprob": -0.16047611236572265, "compression_ratio": 1.94, "no_speech_prob": 0.012679334729909897}, {"id": 416, "seek": 232384, "start": 2340.2000000000003, "end": 2345.96, "text": " min\u00fascula y bueno como como decimos es le preguntamos a la gente a ver qu\u00e9 traducciones le gustan y", "tokens": [51182, 923, 10227, 2444, 64, 288, 11974, 2617, 2617, 979, 8372, 785, 476, 19860, 2151, 257, 635, 3788, 257, 1306, 8057, 2479, 1311, 23469, 476, 9679, 282, 288, 51470], "temperature": 0.0, "avg_logprob": -0.16047611236572265, "compression_ratio": 1.94, "no_speech_prob": 0.012679334729909897}, {"id": 417, "seek": 232384, "start": 2345.96, "end": 2351.1200000000003, "text": " bueno y ah\u00ed ponemos cu\u00e1les son las mejores traducciones o si no le damos a un conjunto de", "tokens": [51470, 11974, 288, 12571, 9224, 4485, 2702, 842, 904, 1872, 2439, 42284, 2479, 1311, 23469, 277, 1511, 572, 476, 274, 2151, 257, 517, 37776, 368, 51728], "temperature": 0.0, "avg_logprob": -0.16047611236572265, "compression_ratio": 1.94, "no_speech_prob": 0.012679334729909897}, {"id": 418, "seek": 235112, "start": 2351.12, "end": 2356.6, "text": " jurados las traducciones y le decimos que hagan un an\u00e1lisis un poco m\u00e1s preciso y nos digan bueno", "tokens": [50364, 12721, 4181, 2439, 2479, 1311, 23469, 288, 476, 979, 8372, 631, 324, 1275, 517, 44113, 28436, 517, 10639, 3573, 30109, 288, 3269, 2528, 282, 11974, 50638], "temperature": 0.0, "avg_logprob": -0.12963911744414783, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.03163425996899605}, {"id": 419, "seek": 235112, "start": 2356.6, "end": 2360.56, "text": " cu\u00e1nto le dan en uno al diez de adecuaci\u00f3n y cu\u00e1nto le dan en uno al diez de fluidez", "tokens": [50638, 44256, 78, 476, 3277, 465, 8526, 419, 48165, 368, 614, 3045, 84, 3482, 288, 44256, 78, 476, 3277, 465, 8526, 419, 48165, 368, 5029, 45170, 50836], "temperature": 0.0, "avg_logprob": -0.12963911744414783, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.03163425996899605}, {"id": 420, "seek": 235112, "start": 2363.56, "end": 2369.6, "text": " esa es otra forma de valor digamos y ah\u00ed ya nos est\u00e1n dando las dos medidas en general a los", "tokens": [50986, 11342, 785, 13623, 8366, 368, 15367, 36430, 288, 12571, 2478, 3269, 10368, 29854, 2439, 4491, 37295, 465, 2674, 257, 1750, 51288], "temperature": 0.0, "avg_logprob": -0.12963911744414783, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.03163425996899605}, {"id": 421, "seek": 235112, "start": 2369.6, "end": 2373.7599999999998, "text": " humanos nos cuesta realizar esta evaluaci\u00f3n en general tenemos una preferencia de la fluidez", "tokens": [51288, 34555, 3269, 2702, 7841, 36461, 5283, 6133, 3482, 465, 2674, 9914, 2002, 4382, 10974, 368, 635, 5029, 45170, 51496], "temperature": 0.0, "avg_logprob": -0.12963911744414783, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.03163425996899605}, {"id": 422, "seek": 235112, "start": 2373.7599999999998, "end": 2380.2, "text": " como pasaba hoy con el caso de traducci\u00f3n del chino al ingl\u00e9s por los pasajes de avi\u00f3n", "tokens": [51496, 2617, 1736, 5509, 13775, 416, 806, 9666, 368, 2479, 1311, 5687, 1103, 417, 2982, 419, 49766, 1515, 1750, 1736, 29362, 368, 1305, 2560, 51818], "temperature": 0.0, "avg_logprob": -0.12963911744414783, "compression_ratio": 1.7923076923076924, "no_speech_prob": 0.03163425996899605}, {"id": 423, "seek": 238112, "start": 2381.12, "end": 2385.88, "text": " adem\u00e1s la gente no se pone de acuerdo adem\u00e1s hay un problema que es que hacer este tipo de", "tokens": [50364, 21251, 635, 3788, 572, 369, 40192, 368, 28113, 21251, 4842, 517, 12395, 631, 785, 631, 6720, 4065, 9746, 368, 50602], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 424, "seek": 238112, "start": 2385.88, "end": 2390.04, "text": " evaluaciones con usuarios humanos lleva tiempo digamos hay que pagarles a los usuarios por", "tokens": [50602, 6133, 9188, 416, 32247, 9720, 34555, 37681, 11772, 36430, 4842, 631, 28024, 904, 257, 1750, 32247, 9720, 1515, 50810], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 425, "seek": 238112, "start": 2390.04, "end": 2395.7599999999998, "text": " hora para que est\u00e9n evaluando sistemas y despu\u00e9s yo les di un conjunto de traducciones ellos me", "tokens": [50810, 15098, 1690, 631, 871, 3516, 6133, 1806, 48720, 288, 15283, 5290, 1512, 1026, 517, 37776, 368, 2479, 1311, 23469, 16353, 385, 51096], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 426, "seek": 238112, "start": 2395.7599999999998, "end": 2400.44, "text": " las evaluaron y si hay un cambio en mi sistema para mejorarlo y de vueltas le tengo que darle", "tokens": [51096, 2439, 6133, 6372, 288, 1511, 4842, 517, 28731, 465, 2752, 13245, 1690, 11479, 19457, 288, 368, 9732, 2018, 296, 476, 13989, 631, 37666, 51330], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 427, "seek": 238112, "start": 2400.44, "end": 2404.24, "text": " conjunto de traducciones a los humanos y de vuelta lo tienen que evaluar y de vuelta tengo que pagar", "tokens": [51330, 37776, 368, 2479, 1311, 23469, 257, 1750, 34555, 288, 368, 41542, 450, 12536, 631, 6133, 289, 288, 368, 41542, 13989, 631, 28024, 51520], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 428, "seek": 238112, "start": 2405.48, "end": 2410.2, "text": " horas de usuarios humanos para que lo evaluen entonces es dif\u00edcil de reutilizar yo estar", "tokens": [51582, 19548, 368, 32247, 9720, 34555, 1690, 631, 450, 6133, 268, 13003, 785, 17258, 368, 319, 20835, 9736, 5290, 8755, 51818], "temperature": 0.0, "avg_logprob": -0.1633460802190444, "compression_ratio": 1.9859649122807017, "no_speech_prob": 0.002520730020478368}, {"id": 429, "seek": 241020, "start": 2410.2, "end": 2414.7599999999998, "text": " haciendo cambios constantemente en mi sistema y bueno y necesito tener una forma m\u00e1s r\u00e1pida de", "tokens": [50364, 20509, 18751, 2717, 5754, 16288, 465, 2752, 13245, 288, 11974, 288, 11909, 3528, 11640, 2002, 8366, 3573, 18213, 2887, 368, 50592], "temperature": 0.0, "avg_logprob": -0.10161531577676029, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0011399631621316075}, {"id": 430, "seek": 241020, "start": 2414.7599999999998, "end": 2419.56, "text": " evaluar a ver si estoy haciendo las cosas mejor entonces como este proceso de evaluaci\u00f3n es largo", "tokens": [50592, 6133, 289, 257, 1306, 1511, 15796, 20509, 2439, 12218, 11479, 13003, 2617, 4065, 29314, 368, 6133, 3482, 785, 31245, 50832], "temperature": 0.0, "avg_logprob": -0.10161531577676029, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0011399631621316075}, {"id": 431, "seek": 241020, "start": 2419.56, "end": 2424.08, "text": " es engorroso es caro lo que se ha vuelto m\u00e1s popular son los m\u00e9todos autom\u00e1ticos de evaluaci\u00f3n", "tokens": [50832, 785, 1741, 284, 2635, 78, 785, 1032, 78, 450, 631, 369, 324, 20126, 1353, 3573, 3743, 1872, 1750, 20275, 378, 329, 3553, 7656, 9940, 368, 6133, 3482, 51058], "temperature": 0.0, "avg_logprob": -0.10161531577676029, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0011399631621316075}, {"id": 432, "seek": 241020, "start": 2424.08, "end": 2430.9199999999996, "text": " y a continuaci\u00f3n vamos a ver uno que es muy utilizado en lo que es la traducci\u00f3n autom\u00e1tica", "tokens": [51058, 288, 257, 2993, 3482, 5295, 257, 1306, 8526, 631, 785, 5323, 19906, 1573, 465, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 51400], "temperature": 0.0, "avg_logprob": -0.10161531577676029, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0011399631621316075}, {"id": 433, "seek": 241020, "start": 2433.64, "end": 2439.56, "text": " bueno c\u00f3mo funciona un m\u00e9todo de evaluaci\u00f3n en realidad lo que hace alguien alguien que", "tokens": [51536, 11974, 12826, 26210, 517, 20275, 17423, 368, 6133, 3482, 465, 25635, 450, 631, 10032, 25814, 25814, 631, 51832], "temperature": 0.0, "avg_logprob": -0.10161531577676029, "compression_ratio": 1.839080459770115, "no_speech_prob": 0.0011399631621316075}, {"id": 434, "seek": 243956, "start": 2439.56, "end": 2447.0, "text": " est\u00e1 dise\u00f1ando un sistema es crearse un conjunto de oraciones con una traducci\u00f3n cada", "tokens": [50364, 3192, 3814, 2791, 1806, 517, 13245, 785, 1197, 11668, 517, 37776, 368, 420, 9188, 416, 2002, 2479, 1311, 5687, 8411, 50736], "temperature": 0.0, "avg_logprob": -0.11379960004021139, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.008021406829357147}, {"id": 435, "seek": 243956, "start": 2447.0, "end": 2450.64, "text": " uno con una traducci\u00f3n de referencia que est\u00e1 bien digamos una traducci\u00f3n hecha a mano entonces", "tokens": [50736, 8526, 416, 2002, 2479, 1311, 5687, 368, 2864, 10974, 631, 3192, 3610, 36430, 2002, 2479, 1311, 5687, 415, 4413, 257, 18384, 13003, 50918], "temperature": 0.0, "avg_logprob": -0.11379960004021139, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.008021406829357147}, {"id": 436, "seek": 243956, "start": 2450.64, "end": 2455.0, "text": " yo quiero evaluar un sistema que va del espa\u00f1ol al ingl\u00e9s lo que tengo es un conjunto de oraciones", "tokens": [50918, 5290, 16811, 6133, 289, 517, 13245, 631, 2773, 1103, 31177, 419, 49766, 450, 631, 13989, 785, 517, 37776, 368, 420, 9188, 51136], "temperature": 0.0, "avg_logprob": -0.11379960004021139, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.008021406829357147}, {"id": 437, "seek": 243956, "start": 2455.0, "end": 2460.36, "text": " en espa\u00f1ol y alguien alg\u00fan traductor humano me tradujo todas esas oraciones en espa\u00f1ol y", "tokens": [51136, 465, 31177, 288, 25814, 26300, 2479, 84, 1672, 30985, 385, 2479, 4579, 78, 10906, 23388, 420, 9188, 465, 31177, 288, 51404], "temperature": 0.0, "avg_logprob": -0.11379960004021139, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.008021406829357147}, {"id": 438, "seek": 243956, "start": 2460.36, "end": 2465.2, "text": " me dio un candidato o m\u00e1s candidato tal vez para cada una digamos a eso le voy a llamar referencias", "tokens": [51404, 385, 31965, 517, 6268, 2513, 277, 3573, 6268, 2513, 4023, 5715, 1690, 8411, 2002, 36430, 257, 7287, 476, 7552, 257, 16848, 289, 2864, 37246, 51646], "temperature": 0.0, "avg_logprob": -0.11379960004021139, "compression_ratio": 1.963265306122449, "no_speech_prob": 0.008021406829357147}, {"id": 439, "seek": 246520, "start": 2465.2, "end": 2469.7999999999997, "text": " traducciones de referencia lo siguiente que tengo que hacer es poder dise\u00f1ar una m\u00e9trica de", "tokens": [50364, 2479, 1311, 23469, 368, 2864, 10974, 450, 25666, 631, 13989, 631, 6720, 785, 8152, 3814, 2791, 289, 2002, 20275, 15192, 368, 50594], "temperature": 0.0, "avg_logprob": -0.11794302111766378, "compression_ratio": 1.9196787148594376, "no_speech_prob": 0.014240261167287827}, {"id": 440, "seek": 246520, "start": 2469.7999999999997, "end": 2475.04, "text": " similitud para que cuando mi sistema me da un candidato a traducci\u00f3n yo puedo establecer una", "tokens": [50594, 1034, 388, 21875, 1690, 631, 7767, 2752, 13245, 385, 1120, 517, 6268, 2513, 257, 2479, 1311, 5687, 5290, 21612, 37444, 1776, 2002, 50856], "temperature": 0.0, "avg_logprob": -0.11794302111766378, "compression_ratio": 1.9196787148594376, "no_speech_prob": 0.014240261167287827}, {"id": 441, "seek": 246520, "start": 2475.04, "end": 2479.16, "text": " similitud entre ese candidato y alguna de las referencias y bueno despu\u00e9s lo que voy a hacer", "tokens": [50856, 1034, 388, 21875, 3962, 10167, 6268, 2513, 288, 20651, 368, 2439, 2864, 37246, 288, 11974, 15283, 450, 631, 7552, 257, 6720, 51062], "temperature": 0.0, "avg_logprob": -0.11794302111766378, "compression_ratio": 1.9196787148594376, "no_speech_prob": 0.014240261167287827}, {"id": 442, "seek": 246520, "start": 2479.16, "end": 2485.7599999999998, "text": " es aplicar esa m\u00e9trica para los pares candidato y referencias y bueno y sacar como un promedio de", "tokens": [51062, 785, 18221, 289, 11342, 20275, 15192, 1690, 1750, 2502, 495, 6268, 2513, 288, 2864, 37246, 288, 11974, 288, 43823, 2617, 517, 2234, 292, 1004, 368, 51392], "temperature": 0.0, "avg_logprob": -0.11794302111766378, "compression_ratio": 1.9196787148594376, "no_speech_prob": 0.014240261167287827}, {"id": 443, "seek": 246520, "start": 2485.7599999999998, "end": 2492.04, "text": " todos los valores de similitud que tengo entonces se han inventado muchos m\u00e9todos de este estilo", "tokens": [51392, 6321, 1750, 38790, 368, 1034, 388, 21875, 631, 13989, 13003, 369, 7276, 7962, 1573, 17061, 20275, 378, 329, 368, 4065, 37470, 51706], "temperature": 0.0, "avg_logprob": -0.11794302111766378, "compression_ratio": 1.9196787148594376, "no_speech_prob": 0.014240261167287827}, {"id": 444, "seek": 249204, "start": 2492.04, "end": 2497.12, "text": " muchos m\u00e9todos autom\u00e1ticos que vamos a ver en particular se llama blue que es este una", "tokens": [50364, 17061, 20275, 378, 329, 3553, 7656, 9940, 631, 5295, 257, 1306, 465, 1729, 369, 23272, 3344, 631, 785, 4065, 2002, 50618], "temperature": 0.0, "avg_logprob": -0.13250710712215766, "compression_ratio": 1.9631147540983607, "no_speech_prob": 0.007902647368609905}, {"id": 445, "seek": 249204, "start": 2497.12, "end": 2503.04, "text": " m\u00e9trica muy difundida en lo que es la traducci\u00f3n autom\u00e1tica estad\u00edstica y bueno primero algunas", "tokens": [50618, 20275, 15192, 5323, 679, 997, 2887, 465, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 288, 11974, 21289, 27316, 50914], "temperature": 0.0, "avg_logprob": -0.13250710712215766, "compression_ratio": 1.9631147540983607, "no_speech_prob": 0.007902647368609905}, {"id": 446, "seek": 249204, "start": 2503.04, "end": 2508.24, "text": " definiciones le vamos a llamar referencia a una traducci\u00f3n que est\u00e1 traducida manualmente", "tokens": [50914, 1561, 29719, 476, 5295, 257, 16848, 289, 2864, 10974, 257, 2002, 2479, 1311, 5687, 631, 3192, 2479, 1311, 2887, 9688, 4082, 51174], "temperature": 0.0, "avg_logprob": -0.13250710712215766, "compression_ratio": 1.9631147540983607, "no_speech_prob": 0.007902647368609905}, {"id": 447, "seek": 249204, "start": 2508.24, "end": 2512.52, "text": " o sea consideramos que es una oraci\u00f3n correcta eso es una referencia y le vamos a llamar candidato", "tokens": [51174, 277, 4158, 1949, 2151, 631, 785, 2002, 420, 3482, 3006, 64, 7287, 785, 2002, 2864, 10974, 288, 476, 5295, 257, 16848, 289, 6268, 2513, 51388], "temperature": 0.0, "avg_logprob": -0.13250710712215766, "compression_ratio": 1.9631147540983607, "no_speech_prob": 0.007902647368609905}, {"id": 448, "seek": 249204, "start": 2512.52, "end": 2518.04, "text": " a una traducci\u00f3n que no tiene porque estar correcta porque le tradujo el sistema autom\u00e1tico y le", "tokens": [51388, 257, 2002, 2479, 1311, 5687, 631, 572, 7066, 4021, 8755, 3006, 64, 4021, 476, 2479, 4579, 78, 806, 13245, 3553, 28234, 288, 476, 51664], "temperature": 0.0, "avg_logprob": -0.13250710712215766, "compression_ratio": 1.9631147540983607, "no_speech_prob": 0.007902647368609905}, {"id": 449, "seek": 251804, "start": 2518.04, "end": 2523.16, "text": " vamos a llamar documento al conjunto de todas las oraciones candidatas al conjunto de todas las", "tokens": [50364, 5295, 257, 16848, 289, 4166, 78, 419, 37776, 368, 10906, 2439, 420, 9188, 6268, 37892, 419, 37776, 368, 10906, 2439, 50620], "temperature": 0.0, "avg_logprob": -0.10563607369699786, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.011122424155473709}, {"id": 450, "seek": 251804, "start": 2523.16, "end": 2528.0, "text": " oraciones traducidas por el sistema que es lo que vamos a estar evaluando as\u00ed que recuerden tenemos", "tokens": [50620, 420, 9188, 2479, 1311, 11382, 1515, 806, 13245, 631, 785, 450, 631, 5295, 257, 8755, 6133, 1806, 8582, 631, 39092, 1556, 9914, 50862], "temperature": 0.0, "avg_logprob": -0.10563607369699786, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.011122424155473709}, {"id": 451, "seek": 251804, "start": 2528.0, "end": 2534.7599999999998, "text": " referencia candidato y documento y bueno qu\u00e9 es lo primero que se nos puede ocurrir hacer cuando", "tokens": [50862, 2864, 10974, 6268, 2513, 288, 4166, 78, 288, 11974, 8057, 785, 450, 21289, 631, 369, 3269, 8919, 26430, 10949, 6720, 7767, 51200], "temperature": 0.0, "avg_logprob": -0.10563607369699786, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.011122424155473709}, {"id": 452, "seek": 251804, "start": 2534.7599999999998, "end": 2540.88, "text": " queremos saber si un candidato es bueno para la referencia o no lo primero que podemos hacer es", "tokens": [51200, 26813, 12489, 1511, 517, 6268, 2513, 785, 11974, 1690, 635, 2864, 10974, 277, 572, 450, 21289, 631, 12234, 6720, 785, 51506], "temperature": 0.0, "avg_logprob": -0.10563607369699786, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.011122424155473709}, {"id": 453, "seek": 254088, "start": 2540.88, "end": 2545.56, "text": " tratar de contar las palabras que ocurren en ambos entonces yo puedo tratar de contar", "tokens": [50364, 42549, 368, 27045, 2439, 35240, 631, 26430, 1095, 465, 41425, 13003, 5290, 21612, 42549, 368, 27045, 50598], "temperature": 0.0, "avg_logprob": -0.12635273311449133, "compression_ratio": 2.257142857142857, "no_speech_prob": 0.3846476674079895}, {"id": 454, "seek": 254088, "start": 2548.28, "end": 2553.12, "text": " palabras que ocurren en el candidato y palabras que ocurren en la referencia y ah\u00ed dir\u00eda que la", "tokens": [50734, 35240, 631, 26430, 1095, 465, 806, 6268, 2513, 288, 35240, 631, 26430, 1095, 465, 635, 2864, 10974, 288, 12571, 4746, 2686, 631, 635, 50976], "temperature": 0.0, "avg_logprob": -0.12635273311449133, "compression_ratio": 2.257142857142857, "no_speech_prob": 0.3846476674079895}, {"id": 455, "seek": 254088, "start": 2553.12, "end": 2556.92, "text": " elecci\u00f3n de las palabras del candidato si est\u00e1n las palabras del candidato si est\u00e1n tambi\u00e9n la", "tokens": [50976, 1118, 14735, 368, 2439, 35240, 1103, 6268, 2513, 1511, 10368, 2439, 35240, 1103, 6268, 2513, 1511, 10368, 6407, 635, 51166], "temperature": 0.0, "avg_logprob": -0.12635273311449133, "compression_ratio": 2.257142857142857, "no_speech_prob": 0.3846476674079895}, {"id": 456, "seek": 254088, "start": 2556.92, "end": 2561.1600000000003, "text": " referencia yo dir\u00eda que eso se acerca un poco la adecuaci\u00f3n se acerca que bueno por lo menos", "tokens": [51166, 2864, 10974, 5290, 4746, 2686, 631, 7287, 369, 46321, 517, 10639, 635, 614, 3045, 84, 3482, 369, 46321, 631, 11974, 1515, 450, 8902, 51378], "temperature": 0.0, "avg_logprob": -0.12635273311449133, "compression_ratio": 2.257142857142857, "no_speech_prob": 0.3846476674079895}, {"id": 457, "seek": 254088, "start": 2561.1600000000003, "end": 2566.84, "text": " us\u00f3 palabras que son fieles a la traducci\u00f3n de referencia pero si adem\u00e1s esas palabras est\u00e1n", "tokens": [51378, 505, 812, 35240, 631, 1872, 283, 1187, 279, 257, 635, 2479, 1311, 5687, 368, 2864, 10974, 4768, 1511, 21251, 23388, 35240, 10368, 51662], "temperature": 0.0, "avg_logprob": -0.12635273311449133, "compression_ratio": 2.257142857142857, "no_speech_prob": 0.3846476674079895}, {"id": 458, "seek": 256684, "start": 2566.84, "end": 2571.28, "text": " usadas en el mismo orden ah\u00ed se acerca un poco m\u00e1s a la fluidez o sea si est\u00e1n usadas en ese", "tokens": [50364, 505, 6872, 465, 806, 12461, 28615, 12571, 369, 46321, 517, 10639, 3573, 257, 635, 5029, 45170, 277, 4158, 1511, 10368, 505, 6872, 465, 10167, 50586], "temperature": 0.0, "avg_logprob": -0.19122492938960364, "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.002656002063304186}, {"id": 459, "seek": 256684, "start": 2571.28, "end": 2577.6000000000004, "text": " mismo orden puede sonar tan natural como la referencia y esto se puede hacer autom\u00e1ticamente haciendo", "tokens": [50586, 12461, 28615, 8919, 1872, 289, 7603, 3303, 2617, 635, 2864, 10974, 288, 7433, 369, 8919, 6720, 3553, 7656, 23653, 20509, 50902], "temperature": 0.0, "avg_logprob": -0.19122492938960364, "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.002656002063304186}, {"id": 460, "seek": 256684, "start": 2577.6000000000004, "end": 2586.1600000000003, "text": " conteos de n gramas ac\u00e1 yo tengo un una referencia que es de cazad mi sistema me ten\u00eda que haber", "tokens": [50902, 34444, 329, 368, 297, 677, 19473, 23496, 5290, 13989, 517, 2002, 2864, 10974, 631, 785, 368, 269, 921, 345, 2752, 13245, 385, 23718, 631, 15811, 51330], "temperature": 0.0, "avg_logprob": -0.19122492938960364, "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.002656002063304186}, {"id": 461, "seek": 256684, "start": 2586.1600000000003, "end": 2593.2400000000002, "text": " devuelto de cazad y ten\u00eda dos candidatos candidato a era de caz y el candidato b era cazad de entonces", "tokens": [51330, 1905, 3483, 1353, 368, 269, 921, 345, 288, 23718, 4491, 6268, 26818, 6268, 2513, 257, 4249, 368, 269, 921, 288, 806, 6268, 2513, 272, 4249, 269, 921, 345, 368, 13003, 51684], "temperature": 0.0, "avg_logprob": -0.19122492938960364, "compression_ratio": 1.8227272727272728, "no_speech_prob": 0.002656002063304186}, {"id": 462, "seek": 259324, "start": 2593.3999999999996, "end": 2596.62, "text": " en \u00e9ldogs \u0432\u0435\u043b extraordinary lo que puedo hacer es prevailer de n grams cu\u00e1les en gramas de los", "tokens": [50372, 465, 11810, 42008, 29328, 10581, 450, 631, 21612, 6720, 785, 46059, 260, 368, 297, 11899, 2702, 842, 904, 465, 677, 19473, 368, 1750, 50533], "temperature": 1.0, "avg_logprob": -1.4773741604989035, "compression_ratio": 1.9014778325123152, "no_speech_prob": 0.0085953613743186}, {"id": 463, "seek": 259324, "start": 2596.62, "end": 2603.3599999999997, "text": " candidatos pertenecen a la referencia entonces para el caso de deidad en la en grama de pertenece", "tokens": [50533, 6268, 26818, 680, 1147, 3045, 268, 257, 635, 2864, 10974, 13003, 1690, 806, 9666, 368, 368, 4580, 465, 635, 465, 677, 2404, 368, 680, 1147, 68, 384, 50870], "temperature": 1.0, "avg_logprob": -1.4773741604989035, "compression_ratio": 1.9014778325123152, "no_speech_prob": 0.0085953613743186}, {"id": 464, "seek": 259324, "start": 2603.3599999999997, "end": 2608.02, "text": " la referencia en el en grama cat pertenece a referencia al en grama de cad o sea el bigama de", "tokens": [50870, 635, 2864, 10974, 465, 806, 465, 677, 2404, 3857, 680, 1147, 68, 384, 257, 2864, 10974, 419, 465, 677, 2404, 368, 12209, 277, 4158, 806, 955, 2404, 368, 51103], "temperature": 1.0, "avg_logprob": -1.4773741604989035, "compression_ratio": 1.9014778325123152, "no_speech_prob": 0.0085953613743186}, {"id": 465, "seek": 259324, "start": 2608.02, "end": 2614.4599999999996, "text": " que tambi\u00e9n pertenece a la referencia para el caso del candidato de el Unic 1999 pertenece el", "tokens": [51103, 631, 6407, 680, 1147, 68, 384, 257, 635, 2864, 10974, 1690, 806, 9666, 1103, 6268, 2513, 368, 806, 1156, 299, 19952, 680, 1147, 68, 384, 806, 51425], "temperature": 1.0, "avg_logprob": -1.4773741604989035, "compression_ratio": 1.9014778325123152, "no_speech_prob": 0.0085953613743186}, {"id": 466, "seek": 261446, "start": 2614.46, "end": 2620.56, "text": " pertenece, el unigrama D pertenece, pero SatCat este bigrama no pertenece la referencia", "tokens": [50364, 680, 1147, 68, 384, 11, 806, 517, 328, 29762, 413, 680, 1147, 68, 384, 11, 4768, 5344, 34, 267, 4065, 955, 29762, 572, 680, 1147, 68, 384, 635, 2864, 10974, 50669], "temperature": 0.0, "avg_logprob": -0.1890522112949289, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.3429991900920868}, {"id": 467, "seek": 261446, "start": 2620.56, "end": 2625.6, "text": " y CatD tampoco pertenece a la referencia. Y adem\u00e1s el \u00fanico trigrama que hay, SatCatD", "tokens": [50669, 288, 9565, 35, 36838, 680, 1147, 68, 384, 257, 635, 2864, 10974, 13, 398, 21251, 806, 26113, 35386, 29762, 631, 4842, 11, 5344, 34, 267, 35, 50921], "temperature": 0.0, "avg_logprob": -0.1890522112949289, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.3429991900920868}, {"id": 468, "seek": 261446, "start": 2625.6, "end": 2629.88, "text": " tampoco est\u00e1 en la referencia. Entonces lo que aparece a la derecha son los engramas", "tokens": [50921, 36838, 3192, 465, 635, 2864, 10974, 13, 15097, 450, 631, 37863, 257, 635, 15969, 4413, 1872, 1750, 465, 1342, 296, 51135], "temperature": 0.0, "avg_logprob": -0.1890522112949289, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.3429991900920868}, {"id": 469, "seek": 261446, "start": 2629.88, "end": 2637.0, "text": " que s\u00ed pertenecen tanto al candidato como a la referencia. As\u00ed que bueno, resumiendo,", "tokens": [51135, 631, 8600, 680, 1147, 3045, 268, 10331, 419, 6268, 2513, 2617, 257, 635, 2864, 10974, 13, 17419, 631, 11974, 11, 725, 449, 7304, 11, 51491], "temperature": 0.0, "avg_logprob": -0.1890522112949289, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.3429991900920868}, {"id": 470, "seek": 261446, "start": 2637.0, "end": 2642.36, "text": " yo puedo contar la cantidad de hits de unigramas, de bigramas, de trigramas y para el candidato", "tokens": [51491, 5290, 21612, 27045, 635, 33757, 368, 8664, 368, 517, 328, 2356, 296, 11, 368, 955, 2356, 296, 11, 368, 35386, 2356, 296, 288, 1690, 806, 6268, 2513, 51759], "temperature": 0.0, "avg_logprob": -0.1890522112949289, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.3429991900920868}, {"id": 471, "seek": 264236, "start": 2642.36, "end": 2645.88, "text": " hace cumple que todos los unigramas que hay pertenece a la referencia, as\u00ed que voy a", "tokens": [50364, 10032, 12713, 781, 631, 6321, 1750, 517, 328, 2356, 296, 631, 4842, 680, 1147, 68, 384, 257, 635, 2864, 10974, 11, 8582, 631, 7552, 257, 50540], "temperature": 0.0, "avg_logprob": -0.17773763835430145, "compression_ratio": 1.908296943231441, "no_speech_prob": 0.03104173205792904}, {"id": 472, "seek": 264236, "start": 2645.88, "end": 2651.44, "text": " tener dos de dos hits, para los bigramas voy a tener uno de uno, pero para el candidato", "tokens": [50540, 11640, 4491, 368, 4491, 8664, 11, 1690, 1750, 955, 2356, 296, 7552, 257, 11640, 8526, 368, 8526, 11, 4768, 1690, 806, 6268, 2513, 50818], "temperature": 0.0, "avg_logprob": -0.17773763835430145, "compression_ratio": 1.908296943231441, "no_speech_prob": 0.03104173205792904}, {"id": 473, "seek": 264236, "start": 2651.44, "end": 2657.2400000000002, "text": " B los unigramas me dan tres de tres, digamos tres hits, los bigramas no, o sea tengo dos", "tokens": [50818, 363, 1750, 517, 328, 2356, 296, 385, 3277, 15890, 368, 15890, 11, 36430, 15890, 8664, 11, 1750, 955, 2356, 296, 572, 11, 277, 4158, 13989, 4491, 51108], "temperature": 0.0, "avg_logprob": -0.17773763835430145, "compression_ratio": 1.908296943231441, "no_speech_prob": 0.03104173205792904}, {"id": 474, "seek": 264236, "start": 2657.2400000000002, "end": 2660.6800000000003, "text": " bigramas posibles si ninguno estaba bien y los trigramas tampoco, tengo un trigrama", "tokens": [51108, 955, 2356, 296, 1366, 14428, 1511, 17210, 12638, 17544, 3610, 288, 1750, 35386, 2356, 296, 36838, 11, 13989, 517, 35386, 29762, 51280], "temperature": 0.0, "avg_logprob": -0.17773763835430145, "compression_ratio": 1.908296943231441, "no_speech_prob": 0.03104173205792904}, {"id": 475, "seek": 264236, "start": 2660.6800000000003, "end": 2666.44, "text": " posible y no estaba bien. Entonces por ahora parece que le va ganando de Cat, el candidato", "tokens": [51280, 26644, 288, 572, 17544, 3610, 13, 15097, 1515, 9923, 14120, 631, 476, 2773, 7574, 1806, 368, 9565, 11, 806, 6268, 2513, 51568], "temperature": 0.0, "avg_logprob": -0.17773763835430145, "compression_ratio": 1.908296943231441, "no_speech_prob": 0.03104173205792904}, {"id": 476, "seek": 266644, "start": 2666.44, "end": 2673.16, "text": " A de Cat le va ganando a SatCatD como traducci\u00f3n. Bien, \u00bfqu\u00e9 puedo hacer con los conteos de", "tokens": [50364, 316, 368, 9565, 476, 2773, 7574, 1806, 257, 5344, 34, 267, 35, 2617, 2479, 1311, 5687, 13, 16956, 11, 3841, 16412, 21612, 6720, 416, 1750, 34444, 329, 368, 50700], "temperature": 0.0, "avg_logprob": -0.14660881547366872, "compression_ratio": 1.8353909465020577, "no_speech_prob": 0.14710591733455658}, {"id": 477, "seek": 266644, "start": 2673.16, "end": 2679.48, "text": " engramas? Lo que hago habitualmente, o sea contar engramas, contar unigramas, bigramas", "tokens": [50700, 465, 1342, 296, 30, 6130, 631, 38721, 46883, 4082, 11, 277, 4158, 27045, 465, 1342, 296, 11, 27045, 517, 328, 2356, 296, 11, 955, 2356, 296, 51016], "temperature": 0.0, "avg_logprob": -0.14660881547366872, "compression_ratio": 1.8353909465020577, "no_speech_prob": 0.14710591733455658}, {"id": 478, "seek": 266644, "start": 2679.48, "end": 2684.7200000000003, "text": " y gramas, se acerca un poco a lo que es la noci\u00f3n de una precisi\u00f3n de algo. Entonces", "tokens": [51016, 288, 21353, 296, 11, 369, 46321, 517, 10639, 257, 450, 631, 785, 635, 572, 5687, 368, 2002, 7974, 2560, 368, 8655, 13, 15097, 51278], "temperature": 0.0, "avg_logprob": -0.14660881547366872, "compression_ratio": 1.8353909465020577, "no_speech_prob": 0.14710591733455658}, {"id": 479, "seek": 266644, "start": 2684.7200000000003, "end": 2688.6, "text": " lo que voy a hacer es contarlos por separado, voy a decir voy a contar todos los unigramas", "tokens": [51278, 450, 631, 7552, 257, 6720, 785, 660, 39734, 1515, 3128, 1573, 11, 7552, 257, 10235, 7552, 257, 27045, 6321, 1750, 517, 328, 2356, 296, 51472], "temperature": 0.0, "avg_logprob": -0.14660881547366872, "compression_ratio": 1.8353909465020577, "no_speech_prob": 0.14710591733455658}, {"id": 480, "seek": 266644, "start": 2688.6, "end": 2692.36, "text": " por un lado, todos los bigramas por otro, todos los trigramas por otro y para cada uno", "tokens": [51472, 1515, 517, 11631, 11, 6321, 1750, 955, 2356, 296, 1515, 11921, 11, 6321, 1750, 35386, 2356, 296, 1515, 11921, 288, 1690, 8411, 8526, 51660], "temperature": 0.0, "avg_logprob": -0.14660881547366872, "compression_ratio": 1.8353909465020577, "no_speech_prob": 0.14710591733455658}, {"id": 481, "seek": 269236, "start": 2692.36, "end": 2699.32, "text": " de esos me voy a armar una precisi\u00f3n. Voy a decir que tengo el candidato CSUB, digamos", "tokens": [50364, 368, 22411, 385, 7552, 257, 3726, 289, 2002, 7974, 2560, 13, 25563, 257, 10235, 631, 13989, 806, 6268, 2513, 383, 20214, 33, 11, 36430, 50712], "temperature": 0.0, "avg_logprob": -0.14758067200149316, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.117670439183712}, {"id": 482, "seek": 269236, "start": 2699.32, "end": 2705.28, "text": " un candidato que voy a considerar, voy a contar los hits de orden N de CSUB, digamos los hits", "tokens": [50712, 517, 6268, 2513, 631, 7552, 257, 1949, 289, 11, 7552, 257, 27045, 1750, 8664, 368, 28615, 426, 368, 383, 20214, 33, 11, 36430, 1750, 8664, 51010], "temperature": 0.0, "avg_logprob": -0.14758067200149316, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.117670439183712}, {"id": 483, "seek": 269236, "start": 2705.28, "end": 2710.76, "text": " de unigrama de CSUB, le voy a llamar H de CSUB y voy a contar la cantidad de unigramas", "tokens": [51010, 368, 517, 328, 29762, 368, 383, 20214, 33, 11, 476, 7552, 257, 16848, 289, 389, 368, 383, 20214, 33, 288, 7552, 257, 27045, 635, 33757, 368, 517, 328, 2356, 296, 51284], "temperature": 0.0, "avg_logprob": -0.14758067200149316, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.117670439183712}, {"id": 484, "seek": 269236, "start": 2710.76, "end": 2716.32, "text": " totales que hay, le voy a llamar T de CSUB. Pero adem\u00e1s voy a hacer esto en vez de hacerlo", "tokens": [51284, 3217, 279, 631, 4842, 11, 476, 7552, 257, 16848, 289, 314, 368, 383, 20214, 33, 13, 9377, 21251, 7552, 257, 6720, 7433, 465, 5715, 368, 32039, 51562], "temperature": 0.0, "avg_logprob": -0.14758067200149316, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.117670439183712}, {"id": 485, "seek": 269236, "start": 2716.32, "end": 2721.08, "text": " para una sola oraci\u00f3n, para un candidato y su referencia, le voy a hacer para todo", "tokens": [51562, 1690, 2002, 34162, 420, 3482, 11, 1690, 517, 6268, 2513, 288, 459, 2864, 10974, 11, 476, 7552, 257, 6720, 1690, 5149, 51800], "temperature": 0.0, "avg_logprob": -0.14758067200149316, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.117670439183712}, {"id": 486, "seek": 272108, "start": 2721.08, "end": 2726.48, "text": " el documento, voy a contar todos los unigramas que estaban en mis candidatos, voy a ver cu\u00e1nto", "tokens": [50364, 806, 4166, 78, 11, 7552, 257, 27045, 6321, 1750, 517, 328, 2356, 296, 631, 36713, 465, 3346, 6268, 26818, 11, 7552, 257, 1306, 44256, 78, 50634], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 487, "seek": 272108, "start": 2726.48, "end": 2731.24, "text": " de esos estaban bien y voy a hacer esta divisi\u00f3n, entonces me va a dar que cu\u00e1l es la precisi\u00f3n", "tokens": [50634, 368, 22411, 36713, 3610, 288, 7552, 257, 6720, 5283, 25974, 2560, 11, 13003, 385, 2773, 257, 4072, 631, 44318, 785, 635, 7974, 2560, 50872], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 488, "seek": 272108, "start": 2731.24, "end": 2738.04, "text": " en unigramas. Que va a ser, bueno, tanta cantidad de unigramas estaban bien dividido, toda la", "tokens": [50872, 465, 517, 328, 2356, 296, 13, 4493, 2773, 257, 816, 11, 11974, 11, 40864, 33757, 368, 517, 328, 2356, 296, 36713, 3610, 4996, 2925, 11, 11687, 635, 51212], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 489, "seek": 272108, "start": 2738.04, "end": 2742.88, "text": " cantidad de unigramas que genero en los candidatos. Despu\u00e9s voy a hacer eso para bigramas, voy", "tokens": [51212, 33757, 368, 517, 328, 2356, 296, 631, 1337, 78, 465, 1750, 6268, 26818, 13, 40995, 7552, 257, 6720, 7287, 1690, 955, 2356, 296, 11, 7552, 51454], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 490, "seek": 272108, "start": 2742.88, "end": 2746.16, "text": " a contar toda la cantidad de bigramas que estaban bien, porque estaban en el candidato", "tokens": [51454, 257, 27045, 11687, 635, 33757, 368, 955, 2356, 296, 631, 36713, 3610, 11, 4021, 36713, 465, 806, 6268, 2513, 51618], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 491, "seek": 272108, "start": 2746.16, "end": 2749.68, "text": " en la referencia, dividido toda la cantidad de bigramas que hay en el candidato. Voy", "tokens": [51618, 465, 635, 2864, 10974, 11, 4996, 2925, 11687, 635, 33757, 368, 955, 2356, 296, 631, 4842, 465, 806, 6268, 2513, 13, 25563, 51794], "temperature": 0.0, "avg_logprob": -0.13802321649366808, "compression_ratio": 2.2063492063492065, "no_speech_prob": 0.15428835153579712}, {"id": 492, "seek": 274968, "start": 2749.7599999999998, "end": 2753.52, "text": " a hacer lo mismo para trigramas y voy a hacer lo mismo para 4g, en general se suele llegar", "tokens": [50368, 257, 6720, 450, 12461, 1690, 35386, 2356, 296, 288, 7552, 257, 6720, 450, 12461, 1690, 1017, 70, 11, 465, 2674, 369, 459, 16884, 24892, 50556], "temperature": 0.0, "avg_logprob": -0.15403947234153748, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.031484778970479965}, {"id": 493, "seek": 274968, "start": 2753.52, "end": 2758.3999999999996, "text": " hasta 4, digamos en traducci\u00f3n autom\u00e1tica estad\u00edstica, la medida blue llega a calcular", "tokens": [50556, 10764, 1017, 11, 36430, 465, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 11, 635, 32984, 3344, 40423, 257, 2104, 17792, 50800], "temperature": 0.0, "avg_logprob": -0.15403947234153748, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.031484778970479965}, {"id": 494, "seek": 274968, "start": 2758.3999999999996, "end": 2763.8799999999997, "text": " hasta 4. Entonces bueno, lo que me defino ah\u00ed es lo que se llama probabilidad de orden", "tokens": [50800, 10764, 1017, 13, 15097, 11974, 11, 450, 631, 385, 1561, 78, 12571, 785, 450, 631, 369, 23272, 31959, 4580, 368, 28615, 51074], "temperature": 0.0, "avg_logprob": -0.15403947234153748, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.031484778970479965}, {"id": 495, "seek": 274968, "start": 2763.8799999999997, "end": 2768.8799999999997, "text": " n, la probabilidad, perd\u00f3n, precisi\u00f3n de orden n, la precisi\u00f3n para unigrama, la precisi\u00f3n", "tokens": [51074, 297, 11, 635, 31959, 4580, 11, 12611, 1801, 11, 7974, 2560, 368, 28615, 297, 11, 635, 7974, 2560, 1690, 517, 328, 29762, 11, 635, 7974, 2560, 51324], "temperature": 0.0, "avg_logprob": -0.15403947234153748, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.031484778970479965}, {"id": 496, "seek": 274968, "start": 2768.8799999999997, "end": 2776.08, "text": " para bigramas, la precisi\u00f3n para trigramas, etc\u00e9tera. Bien, esta m\u00e9trica que estamos", "tokens": [51324, 1690, 955, 2356, 296, 11, 635, 7974, 2560, 1690, 35386, 2356, 296, 11, 5183, 526, 23833, 13, 16956, 11, 5283, 20275, 15192, 631, 10382, 51684], "temperature": 0.0, "avg_logprob": -0.15403947234153748, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.031484778970479965}, {"id": 497, "seek": 277608, "start": 2776.08, "end": 2780.96, "text": " construyendo es bastante f\u00e1cil de enga\u00f1ar, en realidad yo me defin\u00ed una probabilidad,", "tokens": [50364, 12946, 88, 3999, 785, 14651, 17474, 368, 1741, 23217, 289, 11, 465, 25635, 5290, 385, 1561, 870, 2002, 31959, 4580, 11, 50608], "temperature": 0.0, "avg_logprob": -0.2157841197779921, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.157139852643013}, {"id": 498, "seek": 277608, "start": 2780.96, "end": 2784.6, "text": " por ejemplo la probabilidad de orden 1 y la puedo enga\u00f1ar muy f\u00e1cil, porque yo me", "tokens": [50608, 1515, 13358, 635, 31959, 4580, 368, 28615, 502, 288, 635, 21612, 1741, 23217, 289, 5323, 17474, 11, 4021, 5290, 385, 50790], "temperature": 0.0, "avg_logprob": -0.2157841197779921, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.157139852643013}, {"id": 499, "seek": 277608, "start": 2784.6, "end": 2789.7999999999997, "text": " puedo construir un candidato que tiene siempre la misma palabra. Puedo decir, bueno, un candidato", "tokens": [50790, 21612, 38445, 517, 6268, 2513, 631, 7066, 12758, 635, 24946, 31702, 13, 430, 5827, 78, 10235, 11, 11974, 11, 517, 6268, 2513, 51050], "temperature": 0.0, "avg_logprob": -0.2157841197779921, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.157139852643013}, {"id": 500, "seek": 277608, "start": 2789.7999999999997, "end": 2797.08, "text": " para la referencia de katsato nemat es el candidato DDDDD. Como yo justo le envoqu\u00e9", "tokens": [51050, 1690, 635, 2864, 10974, 368, 350, 1720, 2513, 408, 15677, 785, 806, 6268, 2513, 413, 20818, 20818, 13, 11913, 5290, 40534, 476, 465, 3080, 16412, 51414], "temperature": 0.0, "avg_logprob": -0.2157841197779921, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.157139852643013}, {"id": 501, "seek": 277608, "start": 2797.08, "end": 2800.48, "text": " a una palabra que est\u00e1 en la referencia, entonces cuento los unigramas y me da que", "tokens": [51414, 257, 2002, 31702, 631, 3192, 465, 635, 2864, 10974, 11, 13003, 2702, 15467, 1750, 517, 328, 2356, 296, 288, 385, 1120, 631, 51584], "temperature": 0.0, "avg_logprob": -0.2157841197779921, "compression_ratio": 1.7215686274509805, "no_speech_prob": 0.157139852643013}, {"id": 502, "seek": 280048, "start": 2800.48, "end": 2806.4, "text": " hay 6 hits de 6, a pesar de que la traducci\u00f3n es horrible. Entonces como hago para evitar", "tokens": [50364, 4842, 1386, 8664, 368, 1386, 11, 257, 41951, 368, 631, 635, 2479, 1311, 5687, 785, 9263, 13, 15097, 2617, 38721, 1690, 31326, 50660], "temperature": 0.0, "avg_logprob": -0.15475827556545452, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.44119447469711304}, {"id": 503, "seek": 280048, "start": 2806.4, "end": 2810.96, "text": " esto, lo que se suele hacer es clipping, lo que significa que cuento cu\u00e1nto es la cantidad", "tokens": [50660, 7433, 11, 450, 631, 369, 459, 16884, 6720, 785, 49320, 11, 450, 631, 19957, 631, 2702, 15467, 44256, 78, 785, 635, 33757, 50888], "temperature": 0.0, "avg_logprob": -0.15475827556545452, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.44119447469711304}, {"id": 504, "seek": 280048, "start": 2810.96, "end": 2814.84, "text": " m\u00e1xima de palabras en la referencia y no permito que haya m\u00e1s de eso, entonces yo ac\u00e1 tengo", "tokens": [50888, 31031, 64, 368, 35240, 465, 635, 2864, 10974, 288, 572, 13423, 78, 631, 24693, 3573, 368, 7287, 11, 13003, 5290, 23496, 13989, 51082], "temperature": 0.0, "avg_logprob": -0.15475827556545452, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.44119447469711304}, {"id": 505, "seek": 280048, "start": 2814.84, "end": 2821.32, "text": " hasta dos palabras D, entonces no puedo contar 6 de 6, tendr\u00eda que contar m\u00e1ximo 2 de 6.", "tokens": [51082, 10764, 4491, 35240, 413, 11, 13003, 572, 21612, 27045, 1386, 368, 1386, 11, 3928, 37183, 631, 27045, 38876, 568, 368, 1386, 13, 51406], "temperature": 0.0, "avg_logprob": -0.15475827556545452, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.44119447469711304}, {"id": 506, "seek": 280048, "start": 2821.32, "end": 2826.2, "text": " Entonces ah\u00ed evitamos ese problema de que bueno alguien se haga el vivo y genere simplemente", "tokens": [51406, 15097, 12571, 1073, 270, 2151, 10167, 12395, 368, 631, 11974, 25814, 369, 46726, 806, 30689, 288, 41553, 33190, 51650], "temperature": 0.0, "avg_logprob": -0.15475827556545452, "compression_ratio": 1.667870036101083, "no_speech_prob": 0.44119447469711304}, {"id": 507, "seek": 282620, "start": 2826.2, "end": 2833.3999999999996, "text": " una sola palabra. Bien, entonces hasta ahora vimos dos cosas, calculamos la precisi\u00f3n", "tokens": [50364, 2002, 34162, 31702, 13, 16956, 11, 13003, 10764, 9923, 49266, 4491, 12218, 11, 4322, 2151, 635, 7974, 2560, 50724], "temperature": 0.0, "avg_logprob": -0.1587671140829722, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.2740333378314972}, {"id": 508, "seek": 282620, "start": 2833.3999999999996, "end": 2838.96, "text": " de orden n, la precisi\u00f3n de cada uno de los unigramas o bigramas o trigramas, lo segundo", "tokens": [50724, 368, 28615, 297, 11, 635, 7974, 2560, 368, 8411, 8526, 368, 1750, 517, 328, 2356, 296, 277, 955, 2356, 296, 277, 35386, 2356, 296, 11, 450, 17954, 51002], "temperature": 0.0, "avg_logprob": -0.1587671140829722, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.2740333378314972}, {"id": 509, "seek": 282620, "start": 2838.96, "end": 2842.64, "text": " que vimos es que vamos a hacer clipping para evitar pasarnos de conteo en las palabras", "tokens": [51002, 631, 49266, 785, 631, 5295, 257, 6720, 49320, 1690, 31326, 1736, 24979, 368, 34444, 78, 465, 2439, 35240, 51186], "temperature": 0.0, "avg_logprob": -0.1587671140829722, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.2740333378314972}, {"id": 510, "seek": 282620, "start": 2842.64, "end": 2851.6, "text": " que aparecen m\u00e1s de una vez. Lo tercero que pasa es, ve\u00edamos en este ejemplo de ac\u00e1,", "tokens": [51186, 631, 15004, 13037, 3573, 368, 2002, 5715, 13, 6130, 38103, 78, 631, 20260, 785, 11, 1241, 16275, 465, 4065, 13358, 368, 23496, 11, 51634], "temperature": 0.0, "avg_logprob": -0.1587671140829722, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.2740333378314972}, {"id": 511, "seek": 285160, "start": 2851.6, "end": 2857.6, "text": " ac\u00e1 tenemos dos candidatos de CAT y SAT-CAT-D y lo que pasaba ac\u00e1 era que le estaba yendo", "tokens": [50364, 23496, 9914, 4491, 6268, 26818, 368, 41192, 288, 31536, 12, 34, 2218, 12, 35, 288, 450, 631, 1736, 5509, 23496, 4249, 631, 476, 17544, 288, 3999, 50664], "temperature": 0.0, "avg_logprob": -0.1794608409010519, "compression_ratio": 1.8641975308641976, "no_speech_prob": 0.4036843180656433}, {"id": 512, "seek": 285160, "start": 2857.6, "end": 2864.6, "text": " mejor a la traducci\u00f3n de de CAT porque ten\u00eda todos los unigramas que est\u00e1n en la traducci\u00f3n,", "tokens": [50664, 11479, 257, 635, 2479, 1311, 5687, 368, 368, 41192, 4021, 23718, 6321, 1750, 517, 328, 2356, 296, 631, 10368, 465, 635, 2479, 1311, 5687, 11, 51014], "temperature": 0.0, "avg_logprob": -0.1794608409010519, "compression_ratio": 1.8641975308641976, "no_speech_prob": 0.4036843180656433}, {"id": 513, "seek": 285160, "start": 2864.6, "end": 2867.96, "text": " est\u00e1n tambi\u00e9n en la referencia y todos los bigramas tambi\u00e9n, en cambio el candidato", "tokens": [51014, 10368, 6407, 465, 635, 2864, 10974, 288, 6321, 1750, 955, 2356, 296, 6407, 11, 465, 28731, 806, 6268, 2513, 51182], "temperature": 0.0, "avg_logprob": -0.1794608409010519, "compression_ratio": 1.8641975308641976, "no_speech_prob": 0.4036843180656433}, {"id": 514, "seek": 285160, "start": 2867.96, "end": 2872.08, "text": " B no, el candidato B tiene unigramas que est\u00e1n pero bigramas y trigramas que no est\u00e1n,", "tokens": [51182, 363, 572, 11, 806, 6268, 2513, 363, 7066, 517, 328, 2356, 296, 631, 10368, 4768, 955, 2356, 296, 288, 35386, 2356, 296, 631, 572, 10368, 11, 51388], "temperature": 0.0, "avg_logprob": -0.1794608409010519, "compression_ratio": 1.8641975308641976, "no_speech_prob": 0.4036843180656433}, {"id": 515, "seek": 285160, "start": 2872.08, "end": 2877.36, "text": " entonces en cuanto a precisi\u00f3n el candidato A va bastante mejor. \u00bfPor qu\u00e9 va bastante", "tokens": [51388, 13003, 465, 36685, 257, 7974, 2560, 806, 6268, 2513, 316, 2773, 14651, 11479, 13, 3841, 24907, 8057, 2773, 14651, 51652], "temperature": 0.0, "avg_logprob": -0.1794608409010519, "compression_ratio": 1.8641975308641976, "no_speech_prob": 0.4036843180656433}, {"id": 516, "seek": 287736, "start": 2877.36, "end": 2882.84, "text": " mejor el candidato A? Porque es un candidato que es m\u00e1s corto que la referencia, o sea", "tokens": [50364, 11479, 806, 6268, 2513, 316, 30, 11287, 785, 517, 6268, 2513, 631, 785, 3573, 11278, 78, 631, 635, 2864, 10974, 11, 277, 4158, 50638], "temperature": 0.0, "avg_logprob": -0.12315394661643288, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.2991374433040619}, {"id": 517, "seek": 287736, "start": 2882.84, "end": 2887.6, "text": " es un candidato que tiene menos palabras. Como venimos definiendo la m\u00e9trica, si yo", "tokens": [50638, 785, 517, 6268, 2513, 631, 7066, 8902, 35240, 13, 11913, 6138, 8372, 1561, 7304, 635, 20275, 15192, 11, 1511, 5290, 50876], "temperature": 0.0, "avg_logprob": -0.12315394661643288, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.2991374433040619}, {"id": 518, "seek": 287736, "start": 2887.6, "end": 2892.8, "text": " tengo una referencia y despu\u00e9s tengo un candidato que es justo un prefijo de la referencia,", "tokens": [50876, 13989, 2002, 2864, 10974, 288, 15283, 13989, 517, 6268, 2513, 631, 785, 40534, 517, 18417, 24510, 368, 635, 2864, 10974, 11, 51136], "temperature": 0.0, "avg_logprob": -0.12315394661643288, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.2991374433040619}, {"id": 519, "seek": 287736, "start": 2892.8, "end": 2896.1600000000003, "text": " entonces va a cumplir que ese prefijo anda bien en todas las medidas de precisi\u00f3n porque", "tokens": [51136, 13003, 2773, 257, 37483, 347, 631, 10167, 18417, 24510, 21851, 3610, 465, 10906, 2439, 37295, 368, 7974, 2560, 4021, 51304], "temperature": 0.0, "avg_logprob": -0.12315394661643288, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.2991374433040619}, {"id": 520, "seek": 287736, "start": 2896.1600000000003, "end": 2901.04, "text": " todos los enigramas que tiene van a pertenecer a la referencia. As\u00ed que lo que hace la medida", "tokens": [51304, 6321, 1750, 465, 328, 2356, 296, 631, 7066, 3161, 257, 680, 1147, 68, 1776, 257, 635, 2864, 10974, 13, 17419, 631, 450, 631, 10032, 635, 32984, 51548], "temperature": 0.0, "avg_logprob": -0.12315394661643288, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.2991374433040619}, {"id": 521, "seek": 290104, "start": 2901.04, "end": 2910.68, "text": " blue es penalizar ese tipo de comportamiento, penaliza los candidatos que son muy cortos", "tokens": [50364, 3344, 785, 13661, 9736, 10167, 9746, 368, 25883, 16971, 11, 13661, 13427, 1750, 6268, 26818, 631, 1872, 5323, 11278, 329, 50846], "temperature": 0.0, "avg_logprob": -0.1792338989876412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.6466037034988403}, {"id": 522, "seek": 290104, "start": 2910.68, "end": 2917.2, "text": " para que digamos le d\u00e9 menos puntaje. Entonces, \u00bfpor qu\u00e9 se penalizan los candidatos cortos", "tokens": [50846, 1690, 631, 36430, 476, 2795, 8902, 4468, 1328, 2884, 13, 15097, 11, 3841, 2816, 8057, 369, 13661, 590, 282, 1750, 6268, 26818, 11278, 329, 51172], "temperature": 0.0, "avg_logprob": -0.1792338989876412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.6466037034988403}, {"id": 523, "seek": 290104, "start": 2917.2, "end": 2924.2799999999997, "text": " y no los candidatos largos? \u00bfPor qu\u00e9 les parece? Candidatos que son demasiado cortos", "tokens": [51172, 288, 572, 1750, 6268, 26818, 11034, 329, 30, 3841, 24907, 8057, 1512, 14120, 30, 20466, 327, 26818, 631, 1872, 39820, 11278, 329, 51526], "temperature": 0.0, "avg_logprob": -0.1792338989876412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.6466037034988403}, {"id": 524, "seek": 292428, "start": 2924.28, "end": 2931.0, "text": " se penalizan pero los demasiado largos no. La respuesta est\u00e1 en la slide, pero bueno.", "tokens": [50364, 369, 13661, 590, 282, 4768, 1750, 39820, 11034, 329, 572, 13, 2369, 40585, 3192, 465, 635, 4137, 11, 4768, 11974, 13, 50700], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 525, "seek": 292428, "start": 2931.0, "end": 2935.1200000000003, "text": " Se penaliza los candidatos cortos porque los candidatos largos, si yo genero un candidato", "tokens": [50700, 1100, 13661, 13427, 1750, 6268, 26818, 11278, 329, 4021, 1750, 6268, 26818, 11034, 329, 11, 1511, 5290, 1337, 78, 517, 6268, 2513, 50906], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 526, "seek": 292428, "start": 2935.1200000000003, "end": 2938.88, "text": " que es mucho m\u00e1s largo que la referencia, lo que va a pasar es que ese candidato tiene", "tokens": [50906, 631, 785, 9824, 3573, 31245, 631, 635, 2864, 10974, 11, 450, 631, 2773, 257, 25344, 785, 631, 10167, 6268, 2513, 7066, 51094], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 527, "seek": 292428, "start": 2938.88, "end": 2943.4, "text": " enigramas, seguramente tiene enigramas que no pertenecen a la referencia. Entonces, en", "tokens": [51094, 465, 328, 2356, 296, 11, 22179, 3439, 7066, 465, 328, 2356, 296, 631, 572, 680, 1147, 3045, 268, 257, 635, 2864, 10974, 13, 15097, 11, 465, 51320], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 528, "seek": 292428, "start": 2943.4, "end": 2948.0400000000004, "text": " el conteo de precisi\u00f3n me va a dar un puntaje m\u00e1s bajo. Candidatos largos ya est\u00e1n penalizados", "tokens": [51320, 806, 34444, 78, 368, 7974, 2560, 385, 2773, 257, 4072, 517, 4468, 1328, 2884, 3573, 30139, 13, 20466, 327, 26818, 11034, 329, 2478, 10368, 13661, 590, 4181, 51552], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 529, "seek": 292428, "start": 2948.0400000000004, "end": 2953.1000000000004, "text": " por la precisi\u00f3n, candidatos cortos no est\u00e1n penalizados por la precisi\u00f3n. Entonces, necesito", "tokens": [51552, 1515, 635, 7974, 2560, 11, 6268, 26818, 11278, 329, 572, 10368, 13661, 590, 4181, 1515, 635, 7974, 2560, 13, 15097, 11, 11909, 3528, 51805], "temperature": 0.0, "avg_logprob": -0.10911299965598366, "compression_ratio": 2.0839694656488548, "no_speech_prob": 0.39115187525749207}, {"id": 530, "seek": 295310, "start": 2953.1, "end": 2959.38, "text": " otro tipo de penalizaci\u00f3n para evitar eso. Bien, entonces, lo que vamos a dar es una cosa", "tokens": [50364, 11921, 9746, 368, 13661, 27603, 1690, 31326, 7287, 13, 16956, 11, 13003, 11, 450, 631, 5295, 257, 4072, 785, 2002, 10163, 50678], "temperature": 0.0, "avg_logprob": -0.20314981156036632, "compression_ratio": 1.7892561983471074, "no_speech_prob": 0.016841238364577293}, {"id": 531, "seek": 295310, "start": 2959.38, "end": 2963.98, "text": " que se llama penalizaci\u00f3n por brevedad o brevity penalty, que es un puntaje que se", "tokens": [50678, 631, 369, 23272, 13661, 27603, 1515, 1403, 937, 345, 277, 1403, 23110, 16263, 11, 631, 785, 517, 4468, 1328, 2884, 631, 369, 50908], "temperature": 0.0, "avg_logprob": -0.20314981156036632, "compression_ratio": 1.7892561983471074, "no_speech_prob": 0.016841238364577293}, {"id": 532, "seek": 295310, "start": 2963.98, "end": 2969.9, "text": " le da en referencia a que tan corto es un candidato respecto a la referencia y bueno,", "tokens": [50908, 476, 1120, 465, 2864, 10974, 257, 631, 7603, 11278, 78, 785, 517, 6268, 2513, 35694, 257, 635, 2864, 10974, 288, 11974, 11, 51204], "temperature": 0.0, "avg_logprob": -0.20314981156036632, "compression_ratio": 1.7892561983471074, "no_speech_prob": 0.016841238364577293}, {"id": 533, "seek": 295310, "start": 2969.9, "end": 2973.02, "text": " se calcula teniendo en cuenta todo el largo del documento, todo el largo del documento", "tokens": [51204, 369, 4322, 64, 2064, 7304, 465, 17868, 5149, 806, 31245, 1103, 4166, 78, 11, 5149, 806, 31245, 1103, 4166, 78, 51360], "temperature": 0.0, "avg_logprob": -0.20314981156036632, "compression_ratio": 1.7892561983471074, "no_speech_prob": 0.016841238364577293}, {"id": 534, "seek": 295310, "start": 2973.02, "end": 2978.9, "text": " traducido. Entonces ac\u00e1 yo defino que R' es el largo total de todas las referencias,", "tokens": [51360, 2479, 1311, 2925, 13, 15097, 23496, 5290, 1561, 78, 631, 497, 6, 785, 806, 31245, 3217, 368, 10906, 2439, 2864, 37246, 11, 51654], "temperature": 0.0, "avg_logprob": -0.20314981156036632, "compression_ratio": 1.7892561983471074, "no_speech_prob": 0.016841238364577293}, {"id": 535, "seek": 297890, "start": 2978.9, "end": 2986.6600000000003, "text": " R' es el largo total de todos los candidatos y entonces si el largo de los candidatos es", "tokens": [50364, 497, 6, 785, 806, 31245, 3217, 368, 6321, 1750, 6268, 26818, 288, 13003, 1511, 806, 31245, 368, 1750, 6268, 26818, 785, 50752], "temperature": 0.0, "avg_logprob": -0.16318748474121095, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.13933977484703064}, {"id": 536, "seek": 297890, "start": 2986.6600000000003, "end": 2991.86, "text": " mayor a largo de las referencias, no hay penalizaci\u00f3n, le pongo un 1, si el largo total de los candidatos", "tokens": [50752, 10120, 257, 31245, 368, 2439, 2864, 37246, 11, 572, 4842, 13661, 27603, 11, 476, 280, 25729, 517, 502, 11, 1511, 806, 31245, 3217, 368, 1750, 6268, 26818, 51012], "temperature": 0.0, "avg_logprob": -0.16318748474121095, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.13933977484703064}, {"id": 537, "seek": 297890, "start": 2991.86, "end": 2998.62, "text": " es menor a largo de las referencias, entonces lo calculo como e a la 1 menos la divisi\u00f3n", "tokens": [51012, 785, 26343, 257, 31245, 368, 2439, 2864, 37246, 11, 13003, 450, 4322, 78, 2617, 308, 257, 635, 502, 8902, 635, 25974, 2560, 51350], "temperature": 0.0, "avg_logprob": -0.16318748474121095, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.13933977484703064}, {"id": 538, "seek": 297890, "start": 2998.62, "end": 3005.82, "text": " entre los largos. Esto es una definici\u00f3n de probabilidad exponencial, digamos, no es", "tokens": [51350, 3962, 1750, 11034, 329, 13, 20880, 785, 2002, 1561, 15534, 368, 31959, 4580, 12680, 26567, 11, 36430, 11, 572, 785, 51710], "temperature": 0.0, "avg_logprob": -0.16318748474121095, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.13933977484703064}, {"id": 539, "seek": 300582, "start": 3005.82, "end": 3010.7000000000003, "text": " m\u00e1s que eso y en realidad lo que trata de hacer es penalizar traducciones que son", "tokens": [50364, 3573, 631, 7287, 288, 465, 25635, 450, 631, 31920, 368, 6720, 785, 13661, 9736, 2479, 1311, 23469, 631, 1872, 50608], "temperature": 0.0, "avg_logprob": -0.1551278380096936, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.27191466093063354}, {"id": 540, "seek": 300582, "start": 3010.7000000000003, "end": 3016.02, "text": " muy cortas. Entonces, si yo ten\u00eda un candidato que ten\u00eda 5 palabras, mientras la referencia", "tokens": [50608, 5323, 11278, 296, 13, 15097, 11, 1511, 5290, 23718, 517, 6268, 2513, 631, 23718, 1025, 35240, 11, 26010, 635, 2864, 10974, 50874], "temperature": 0.0, "avg_logprob": -0.1551278380096936, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.27191466093063354}, {"id": 541, "seek": 300582, "start": 3016.02, "end": 3021.6600000000003, "text": " ten\u00eda 10, lo voy a penalizar fuertemente, le voy a dar un 0.37 de penalizaci\u00f3n. Si yo", "tokens": [50874, 23718, 1266, 11, 450, 7552, 257, 13661, 9736, 8536, 911, 16288, 11, 476, 7552, 257, 4072, 517, 1958, 13, 12851, 368, 13661, 27603, 13, 4909, 5290, 51156], "temperature": 0.0, "avg_logprob": -0.1551278380096936, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.27191466093063354}, {"id": 542, "seek": 300582, "start": 3021.6600000000003, "end": 3026.34, "text": " ten\u00eda un candidato que estaba que era menor pero era m\u00e1s cercano, entonces la penalizaci\u00f3n", "tokens": [51156, 23718, 517, 6268, 2513, 631, 17544, 631, 4249, 26343, 4768, 4249, 3573, 36099, 3730, 11, 13003, 635, 13661, 27603, 51390], "temperature": 0.0, "avg_logprob": -0.1551278380096936, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.27191466093063354}, {"id": 543, "seek": 300582, "start": 3026.34, "end": 3031.82, "text": " no es tanta de 0.78 y despu\u00e9s si los largos son iguales o si el candidato es m\u00e1s largo,", "tokens": [51390, 572, 785, 40864, 368, 1958, 13, 30693, 288, 15283, 1511, 1750, 11034, 329, 1872, 10953, 279, 277, 1511, 806, 6268, 2513, 785, 3573, 31245, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1551278380096936, "compression_ratio": 1.7364341085271318, "no_speech_prob": 0.27191466093063354}, {"id": 544, "seek": 303182, "start": 3031.82, "end": 3037.82, "text": " no penalizo nada, le doy un 1 de puntaje. Bueno, entonces la m\u00e9trica Blue, que es una", "tokens": [50364, 572, 13661, 19055, 8096, 11, 476, 360, 88, 517, 502, 368, 4468, 1328, 2884, 13, 16046, 11, 13003, 635, 20275, 15192, 8510, 11, 631, 785, 2002, 50664], "temperature": 0.0, "avg_logprob": -0.1996185045975905, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.2647816836833954}, {"id": 545, "seek": 303182, "start": 3037.82, "end": 3043.6600000000003, "text": " m\u00e9trica muy usada en traducci\u00f3n autom\u00e1tica, pone todos estos juntos, digamos, todos estos", "tokens": [50664, 20275, 15192, 5323, 505, 1538, 465, 2479, 1311, 5687, 3553, 23432, 11, 40192, 6321, 12585, 33868, 11, 36430, 11, 6321, 12585, 50956], "temperature": 0.0, "avg_logprob": -0.1996185045975905, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.2647816836833954}, {"id": 546, "seek": 303182, "start": 3043.6600000000003, "end": 3047.98, "text": " pedacitos que estuvimos viendo los pone juntos en un solo c\u00e1lculo. Blue se calcula como", "tokens": [50956, 5670, 326, 11343, 631, 49777, 8372, 34506, 1750, 40192, 33868, 465, 517, 6944, 6476, 75, 25436, 13, 8510, 369, 4322, 64, 2617, 51172], "temperature": 0.0, "avg_logprob": -0.1996185045975905, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.2647816836833954}, {"id": 547, "seek": 303182, "start": 3047.98, "end": 3056.54, "text": " la penalizaci\u00f3n por probabilidad, el brevite penalti, por e a la suma de las precisiones", "tokens": [51172, 635, 13661, 27603, 1515, 31959, 4580, 11, 806, 1403, 85, 642, 3435, 3198, 72, 11, 1515, 308, 257, 635, 2408, 64, 368, 2439, 18356, 279, 51600], "temperature": 0.0, "avg_logprob": -0.1996185045975905, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.2647816836833954}, {"id": 548, "seek": 305654, "start": 3056.54, "end": 3078.06, "text": " que se ordenen. \u00bfQu\u00e9 palabra es ruido? Por ejemplo, Stro. Bueno, esta palabra es un", "tokens": [50364, 631, 369, 28615, 268, 13, 3841, 15137, 31702, 785, 5420, 2925, 30, 5269, 13358, 11, 42196, 13, 16046, 11, 5283, 31702, 785, 517, 51440], "temperature": 0.0, "avg_logprob": -0.33318446232722354, "compression_ratio": 1.2269503546099292, "no_speech_prob": 0.3495509922504425}, {"id": 549, "seek": 305654, "start": 3078.06, "end": 3082.22, "text": " unigrama que le va a dar 0 de precisi\u00f3n, digamos, porque no est\u00e1. Adem\u00e1s, participan", "tokens": [51440, 517, 328, 29762, 631, 476, 2773, 257, 4072, 1958, 368, 7974, 2560, 11, 36430, 11, 4021, 572, 3192, 13, 34621, 11, 3421, 282, 51648], "temperature": 0.0, "avg_logprob": -0.33318446232722354, "compression_ratio": 1.2269503546099292, "no_speech_prob": 0.3495509922504425}, {"id": 550, "seek": 308222, "start": 3082.22, "end": 3085.3799999999997, "text": " un unigrama que tambi\u00e9n le va a dar mala precisi\u00f3n porque tampoco est\u00e1 el unigrama.", "tokens": [50364, 517, 517, 328, 29762, 631, 6407, 476, 2773, 257, 4072, 37508, 7974, 2560, 4021, 36838, 3192, 806, 517, 328, 29762, 13, 50522], "temperature": 0.0, "avg_logprob": -0.20880164206027985, "compression_ratio": 1.8204081632653062, "no_speech_prob": 0.6400473117828369}, {"id": 551, "seek": 308222, "start": 3085.3799999999997, "end": 3090.2999999999997, "text": " Entonces lo que resta en realidad porque no est\u00e1 sumando la precisi\u00f3n. Ac\u00e1 yo tengo", "tokens": [50522, 15097, 450, 631, 1472, 64, 465, 25635, 4021, 572, 3192, 2408, 1806, 635, 7974, 2560, 13, 5097, 842, 5290, 13989, 50768], "temperature": 0.0, "avg_logprob": -0.20880164206027985, "compression_ratio": 1.8204081632653062, "no_speech_prob": 0.6400473117828369}, {"id": 552, "seek": 308222, "start": 3090.2999999999997, "end": 3097.54, "text": " 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 est\u00e1n bien pero hay uno que no. En cambio,", "tokens": [50768, 502, 11, 568, 11, 805, 11, 1017, 11, 1025, 11, 1386, 11, 1614, 517, 328, 2356, 296, 368, 1750, 46932, 1386, 10368, 3610, 4768, 4842, 8526, 631, 572, 13, 2193, 28731, 11, 51130], "temperature": 0.0, "avg_logprob": -0.20880164206027985, "compression_ratio": 1.8204081632653062, "no_speech_prob": 0.6400473117828369}, {"id": 553, "seek": 308222, "start": 3097.54, "end": 3102.22, "text": " en este tengo 6 unigramas de los cuales los 6 est\u00e1n bien. Entonces ac\u00e1 el hecho de agregar", "tokens": [51130, 465, 4065, 13989, 1386, 517, 328, 2356, 296, 368, 1750, 46932, 1750, 1386, 10368, 3610, 13, 15097, 23496, 806, 13064, 368, 4554, 2976, 51364], "temperature": 0.0, "avg_logprob": -0.20880164206027985, "compression_ratio": 1.8204081632653062, "no_speech_prob": 0.6400473117828369}, {"id": 554, "seek": 308222, "start": 3102.22, "end": 3109.4599999999996, "text": " palabras que no est\u00e1n bien, que no est\u00e1n en la referencia ya te penaliza. La diferencia", "tokens": [51364, 35240, 631, 572, 10368, 3610, 11, 631, 572, 10368, 465, 635, 2864, 10974, 2478, 535, 13661, 13427, 13, 2369, 38844, 51726], "temperature": 0.0, "avg_logprob": -0.20880164206027985, "compression_ratio": 1.8204081632653062, "no_speech_prob": 0.6400473117828369}, {"id": 555, "seek": 310946, "start": 3109.46, "end": 3113.62, "text": " es cuando yo tengo una traducci\u00f3n que es m\u00e1s corta. Si yo dir\u00eda solo de cut-sat-on,", "tokens": [50364, 785, 7767, 5290, 13989, 2002, 2479, 1311, 5687, 631, 785, 3573, 11278, 64, 13, 4909, 5290, 4746, 2686, 6944, 368, 1723, 12, 82, 267, 12, 266, 11, 50572], "temperature": 0.0, "avg_logprob": -0.26089768897830035, "compression_ratio": 1.7578125, "no_speech_prob": 0.4032047986984253}, {"id": 556, "seek": 310946, "start": 3113.62, "end": 3117.06, "text": " entonces ah\u00ed es m\u00e1s corta y no tengo forma de penalizarlo solo con la precisi\u00f3n. Entonces", "tokens": [50572, 13003, 12571, 785, 3573, 11278, 64, 288, 572, 13989, 8366, 368, 13661, 9736, 752, 6944, 416, 635, 7974, 2560, 13, 15097, 50744], "temperature": 0.0, "avg_logprob": -0.26089768897830035, "compression_ratio": 1.7578125, "no_speech_prob": 0.4032047986984253}, {"id": 557, "seek": 310946, "start": 3117.06, "end": 3123.82, "text": " tengo el otro penalizador que es porque la traducci\u00f3n es muy corta. Bien, entonces,", "tokens": [50744, 13989, 806, 11921, 13661, 590, 5409, 631, 785, 4021, 635, 2479, 1311, 5687, 785, 5323, 11278, 64, 13, 16956, 11, 13003, 11, 51082], "temperature": 0.0, "avg_logprob": -0.26089768897830035, "compression_ratio": 1.7578125, "no_speech_prob": 0.4032047986984253}, {"id": 558, "seek": 310946, "start": 3123.82, "end": 3133.62, "text": " les estaba comentando. Ac\u00e1. La medida Blue se define como una media geom\u00e9trica, definici\u00f3n", "tokens": [51082, 1512, 17544, 14541, 1806, 13, 5097, 842, 13, 2369, 32984, 8510, 369, 6964, 2617, 2002, 3021, 1519, 298, 4051, 15192, 11, 1561, 15534, 51572], "temperature": 0.0, "avg_logprob": -0.26089768897830035, "compression_ratio": 1.7578125, "no_speech_prob": 0.4032047986984253}, {"id": 559, "seek": 310946, "start": 3133.62, "end": 3138.7400000000002, "text": " de media geom\u00e9trica, de las precisiones de orden N. Tambi\u00e9n tienes un peso por precisi\u00f3n", "tokens": [51572, 368, 3021, 1519, 298, 4051, 15192, 11, 368, 2439, 18356, 279, 368, 28615, 426, 13, 25682, 20716, 517, 28149, 1515, 7974, 2560, 51828], "temperature": 0.0, "avg_logprob": -0.26089768897830035, "compression_ratio": 1.7578125, "no_speech_prob": 0.4032047986984253}, {"id": 560, "seek": 313874, "start": 3138.74, "end": 3144.22, "text": " que se puede variar pero en general se utiliza el mismo peso para todos. Multiplicado por", "tokens": [50364, 631, 369, 8919, 3034, 289, 4768, 465, 2674, 369, 4976, 13427, 806, 12461, 28149, 1690, 6321, 13, 29238, 4770, 1573, 1515, 50638], "temperature": 0.0, "avg_logprob": -0.23820165487436148, "compression_ratio": 1.5146443514644352, "no_speech_prob": 0.009652913548052311}, {"id": 561, "seek": 313874, "start": 3144.22, "end": 3155.8999999999996, "text": " la penalizaci\u00f3n por brevedad. Bien, eso. O sea, esa es la definici\u00f3n de la m\u00e9trica", "tokens": [50638, 635, 13661, 27603, 1515, 1403, 937, 345, 13, 16956, 11, 7287, 13, 422, 4158, 11, 11342, 785, 635, 1561, 15534, 368, 635, 20275, 15192, 51222], "temperature": 0.0, "avg_logprob": -0.23820165487436148, "compression_ratio": 1.5146443514644352, "no_speech_prob": 0.009652913548052311}, {"id": 562, "seek": 313874, "start": 3155.8999999999996, "end": 3161.1, "text": " Blue que es una m\u00e9trica que se utiliza much\u00edsimo. Esos puntajes que vemos hoy de 25,2 y 31 con", "tokens": [51222, 8510, 631, 785, 2002, 20275, 15192, 631, 369, 4976, 13427, 44722, 13, 2313, 329, 4468, 1328, 16549, 631, 20909, 13775, 368, 3552, 11, 17, 288, 10353, 416, 51482], "temperature": 0.0, "avg_logprob": -0.23820165487436148, "compression_ratio": 1.5146443514644352, "no_speech_prob": 0.009652913548052311}, {"id": 563, "seek": 313874, "start": 3161.1, "end": 3168.66, "text": " algo eran ejemplos de m\u00e9trica Blue aplicados a un sistema. Y bueno, una cosa importante,", "tokens": [51482, 8655, 32762, 10012, 5895, 329, 368, 20275, 15192, 8510, 18221, 4181, 257, 517, 13245, 13, 398, 11974, 11, 2002, 10163, 9416, 11, 51860], "temperature": 0.0, "avg_logprob": -0.23820165487436148, "compression_ratio": 1.5146443514644352, "no_speech_prob": 0.009652913548052311}, {"id": 564, "seek": 316866, "start": 3168.66, "end": 3172.1, "text": " algunos comentarios importantes sobre la m\u00e9trica Blue es que en general cuando un", "tokens": [50364, 21078, 36842, 27963, 5473, 635, 20275, 15192, 8510, 785, 631, 465, 2674, 7767, 517, 50536], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 565, "seek": 316866, "start": 3172.1, "end": 3176.02, "text": " sistema le da mejor, digamos, un conjunto de traducciones le va mejor en m\u00e9trica Blue,", "tokens": [50536, 13245, 476, 1120, 11479, 11, 36430, 11, 517, 37776, 368, 2479, 1311, 23469, 476, 2773, 11479, 465, 20275, 15192, 8510, 11, 50732], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 566, "seek": 316866, "start": 3176.02, "end": 3179.94, "text": " tambi\u00e9n le va mejor con un conjunto de humanos que eval\u00faen el sistema. O sea, que tiene una", "tokens": [50732, 6407, 476, 2773, 11479, 416, 517, 37776, 368, 34555, 631, 1073, 304, 2481, 268, 806, 13245, 13, 422, 4158, 11, 631, 7066, 2002, 50928], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 567, "seek": 316866, "start": 3179.94, "end": 3185.22, "text": " correlaci\u00f3n bastante buena con lo que es la evaluaci\u00f3n subjetiva humana. Pero como", "tokens": [50928, 13983, 3482, 14651, 25710, 416, 450, 631, 785, 635, 6133, 3482, 1422, 7108, 5931, 1952, 64, 13, 9377, 2617, 51192], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 568, "seek": 316866, "start": 3185.22, "end": 3189.8999999999996, "text": " contra, es dif\u00edcil de interpretar estos puntajes. O sea, si yo tengo un puntaje de, como nos", "tokens": [51192, 10742, 11, 785, 17258, 368, 7302, 289, 12585, 4468, 1328, 16549, 13, 422, 4158, 11, 1511, 5290, 13989, 517, 4468, 1328, 2884, 368, 11, 2617, 3269, 51426], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 569, "seek": 316866, "start": 3189.8999999999996, "end": 3193.62, "text": " pasaba hoy, que ten\u00eda un puntaje de 31, en realidad un 31 es un n\u00famero que puede ser", "tokens": [51426, 1736, 5509, 13775, 11, 631, 23718, 517, 4468, 1328, 2884, 368, 10353, 11, 465, 25635, 517, 10353, 785, 517, 14959, 631, 8919, 816, 51612], "temperature": 0.0, "avg_logprob": -0.18213109970092772, "compression_ratio": 1.7549668874172186, "no_speech_prob": 0.045298993587493896}, {"id": 570, "seek": 319362, "start": 3193.62, "end": 3200.54, "text": " muy bueno, muy malo, dependiendo del idioma. Pero, o sea, si todo saliera bien y yo tradujer", "tokens": [50364, 5323, 11974, 11, 5323, 2806, 78, 11, 5672, 7304, 1103, 18014, 6440, 13, 9377, 11, 277, 4158, 11, 1511, 5149, 1845, 10609, 3610, 288, 5290, 2479, 4579, 260, 50710], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 571, "seek": 319362, "start": 3200.54, "end": 3204.7799999999997, "text": " exactamente lo mismo que est\u00e1n las referencias, por construcci\u00f3n la medida me dar\u00eda uno.", "tokens": [50710, 48686, 450, 12461, 631, 10368, 2439, 2864, 37246, 11, 1515, 12946, 14735, 635, 32984, 385, 4072, 2686, 8526, 13, 50922], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 572, "seek": 319362, "start": 3204.7799999999997, "end": 3208.22, "text": " Pero en realidad es muy dif\u00edcil traducir exactamente lo que est\u00e1n las referencias,", "tokens": [50922, 9377, 465, 25635, 785, 5323, 17258, 2479, 1311, 347, 48686, 450, 631, 10368, 2439, 2864, 37246, 11, 51094], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 573, "seek": 319362, "start": 3208.22, "end": 3215.02, "text": " porque no es cierto que exista una \u00fanica traducci\u00f3n posible en la traducci\u00f3n, digamos, humana.", "tokens": [51094, 4021, 572, 785, 28558, 631, 2514, 64, 2002, 30104, 2479, 1311, 5687, 26644, 465, 635, 2479, 1311, 5687, 11, 36430, 11, 1952, 64, 13, 51434], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 574, "seek": 319362, "start": 3215.02, "end": 3219.02, "text": " Oraciones se pueden traducir de manera distinta y estar igualmente bien. Entonces es muy dif\u00edcil", "tokens": [51434, 1610, 9188, 369, 14714, 2479, 1311, 347, 368, 13913, 1483, 16071, 288, 8755, 10953, 4082, 3610, 13, 15097, 785, 5323, 17258, 51634], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 575, "seek": 319362, "start": 3219.02, "end": 3222.58, "text": " tener un conjunto de referencias que contemple todas las posibilidades. As\u00ed que mi traductor,", "tokens": [51634, 11640, 517, 37776, 368, 2864, 37246, 631, 660, 443, 781, 10906, 2439, 1366, 11607, 10284, 13, 17419, 631, 2752, 2479, 84, 1672, 11, 51812], "temperature": 0.0, "avg_logprob": -0.13838532852799926, "compression_ratio": 1.8300653594771241, "no_speech_prob": 0.6482321619987488}, {"id": 576, "seek": 322258, "start": 3222.58, "end": 3228.06, "text": " no es el pap\u00e1s que anda b\u00e1rbaro, pero el puntaje a\u00fan no es uno, no es 100, digamos,", "tokens": [50364, 572, 785, 806, 5806, 2490, 631, 21851, 272, 20335, 5356, 78, 11, 4768, 806, 4468, 1328, 2884, 31676, 572, 785, 8526, 11, 572, 785, 2319, 11, 36430, 11, 50638], "temperature": 0.0, "avg_logprob": -0.2682031595482017, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.022078318521380424}, {"id": 577, "seek": 322258, "start": 3228.06, "end": 3232.58, "text": " porque est\u00e1 eligiendo palabras distintas o eligiendo formas de escribir las oraciones", "tokens": [50638, 4021, 3192, 31089, 7304, 35240, 31489, 296, 277, 31089, 7304, 33463, 368, 30598, 10119, 2439, 420, 9188, 50864], "temperature": 0.0, "avg_logprob": -0.2682031595482017, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.022078318521380424}, {"id": 578, "seek": 322258, "start": 3232.58, "end": 3240.34, "text": " distintas. Entonces bueno, por eso es dif\u00edcil interpretar. Yo tengo un puntaje blue de 30", "tokens": [50864, 31489, 296, 13, 15097, 11974, 11, 1515, 7287, 785, 17258, 7302, 289, 13, 7616, 13989, 517, 4468, 1328, 2884, 3344, 368, 2217, 51252], "temperature": 0.0, "avg_logprob": -0.2682031595482017, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.022078318521380424}, {"id": 579, "seek": 322258, "start": 3240.34, "end": 3249.58, "text": " o de 50, o sea, de 0.3 o de 0.5, y puede ser buen\u00edsimo para ese sistema. Pero para algo", "tokens": [51252, 277, 368, 2625, 11, 277, 4158, 11, 368, 1958, 13, 18, 277, 368, 1958, 13, 20, 11, 288, 8919, 816, 30037, 49889, 1690, 10167, 13245, 13, 9377, 1690, 8655, 51714], "temperature": 0.0, "avg_logprob": -0.2682031595482017, "compression_ratio": 1.5482456140350878, "no_speech_prob": 0.022078318521380424}, {"id": 580, "seek": 324958, "start": 3249.58, "end": 3254.02, "text": " que s\u00ed me sirve much\u00edsimo el porcentaje, digamos, el puntaje de blue es para decir,", "tokens": [50364, 631, 8600, 385, 4735, 303, 44722, 806, 1515, 2207, 11153, 11, 36430, 11, 806, 4468, 1328, 2884, 368, 3344, 785, 1690, 10235, 11, 50586], "temperature": 0.0, "avg_logprob": -0.2123389354971952, "compression_ratio": 1.5297029702970297, "no_speech_prob": 0.08111148327589035}, {"id": 581, "seek": 324958, "start": 3254.02, "end": 3259.58, "text": " yo tengo mi sistema, lo evaluo, despu\u00e9s hago algunos cambios, evaluo de vuelta, y si subi\u00f3", "tokens": [50586, 5290, 13989, 2752, 13245, 11, 450, 6133, 78, 11, 15283, 38721, 21078, 18751, 2717, 11, 6133, 78, 368, 41542, 11, 288, 1511, 1422, 7138, 50864], "temperature": 0.0, "avg_logprob": -0.2123389354971952, "compression_ratio": 1.5297029702970297, "no_speech_prob": 0.08111148327589035}, {"id": 582, "seek": 324958, "start": 3259.58, "end": 3262.98, "text": " la performance con el puntaje blue, entonces estoy seguro de que mejor\u00f3 porque hay una", "tokens": [50864, 635, 3389, 416, 806, 4468, 1328, 2884, 3344, 11, 13003, 15796, 31424, 368, 631, 11479, 812, 4021, 4842, 2002, 51034], "temperature": 0.0, "avg_logprob": -0.2123389354971952, "compression_ratio": 1.5297029702970297, "no_speech_prob": 0.08111148327589035}, {"id": 583, "seek": 324958, "start": 3262.98, "end": 3265.06, "text": " correlaci\u00f3n con la evaluaci\u00f3n subjetiva.", "tokens": [51034, 13983, 3482, 416, 635, 6133, 3482, 1422, 7108, 5931, 13, 51138], "temperature": 0.0, "avg_logprob": -0.2123389354971952, "compression_ratio": 1.5297029702970297, "no_speech_prob": 0.08111148327589035}, {"id": 584, "seek": 326506, "start": 3265.06, "end": 3281.46, "text": " Para pasar el espa\u00f1ol ingl\u00e9s, en realidad lo que pasa es que entren\u00e1s otro traductor.", "tokens": [50364, 11107, 25344, 806, 31177, 49766, 11, 465, 25635, 450, 631, 20260, 785, 631, 45069, 2490, 11921, 2479, 84, 1672, 13, 51184], "temperature": 0.0, "avg_logprob": -0.29862520429823136, "compression_ratio": 1.330827067669173, "no_speech_prob": 0.26303738355636597}, {"id": 585, "seek": 326506, "start": 3281.46, "end": 3287.9, "text": " No, ac\u00e1 estoy hablando uno solo. Ac\u00e1 estoy hablando solamente en un sentido. Yo ten\u00eda", "tokens": [51184, 883, 11, 23496, 15796, 29369, 8526, 6944, 13, 5097, 842, 15796, 29369, 27814, 465, 517, 19850, 13, 7616, 23718, 51506], "temperature": 0.0, "avg_logprob": -0.29862520429823136, "compression_ratio": 1.330827067669173, "no_speech_prob": 0.26303738355636597}, {"id": 586, "seek": 328790, "start": 3287.9, "end": 3297.34, "text": " un sistema en espa\u00f1ol, por ejemplo, digo, una oraci\u00f3n en espa\u00f1ol, el gato se sent\u00f3,", "tokens": [50364, 517, 13245, 465, 31177, 11, 1515, 13358, 11, 22990, 11, 2002, 420, 3482, 465, 31177, 11, 806, 290, 2513, 369, 2279, 812, 11, 50836], "temperature": 0.0, "avg_logprob": -0.19543708917748837, "compression_ratio": 1.876543209876543, "no_speech_prob": 0.6936250329017639}, {"id": 587, "seek": 328790, "start": 3297.34, "end": 3301.82, "text": " y alguien me dijo, bueno, la traducci\u00f3n de referencia de eso es de cat-sat, y mi sistema", "tokens": [50836, 288, 25814, 385, 27024, 11, 11974, 11, 635, 2479, 1311, 5687, 368, 2864, 10974, 368, 7287, 785, 368, 3857, 12, 82, 267, 11, 288, 2752, 13245, 51060], "temperature": 0.0, "avg_logprob": -0.19543708917748837, "compression_ratio": 1.876543209876543, "no_speech_prob": 0.6936250329017639}, {"id": 588, "seek": 328790, "start": 3301.82, "end": 3306.7400000000002, "text": " me dijo, bueno, pero mis traducciones posibles son de cat y sat-cat-de. Entonces yo ten\u00eda", "tokens": [51060, 385, 27024, 11, 11974, 11, 4768, 3346, 2479, 1311, 23469, 1366, 14428, 1872, 368, 3857, 288, 3227, 12, 18035, 12, 1479, 13, 15097, 5290, 23718, 51306], "temperature": 0.0, "avg_logprob": -0.19543708917748837, "compression_ratio": 1.876543209876543, "no_speech_prob": 0.6936250329017639}, {"id": 589, "seek": 328790, "start": 3306.7400000000002, "end": 3310.1800000000003, "text": " un sistema en espa\u00f1ol, pero que traduce al ingl\u00e9s, digamos, un sistema de traducci\u00f3n", "tokens": [51306, 517, 13245, 465, 31177, 11, 4768, 631, 2479, 4176, 419, 49766, 11, 36430, 11, 517, 13245, 368, 2479, 1311, 5687, 51478], "temperature": 0.0, "avg_logprob": -0.19543708917748837, "compression_ratio": 1.876543209876543, "no_speech_prob": 0.6936250329017639}, {"id": 590, "seek": 328790, "start": 3310.1800000000003, "end": 3316.2200000000003, "text": " de espa\u00f1ol al ingl\u00e9s, pero no estoy traduciendo en el otro sentido. No, no es como las canciones.", "tokens": [51478, 368, 31177, 419, 49766, 11, 4768, 572, 15796, 2479, 1311, 7304, 465, 806, 11921, 19850, 13, 883, 11, 572, 785, 2617, 2439, 393, 23469, 13, 51780], "temperature": 0.0, "avg_logprob": -0.19543708917748837, "compression_ratio": 1.876543209876543, "no_speech_prob": 0.6936250329017639}, {"id": 591, "seek": 331622, "start": 3316.22, "end": 3320.06, "text": " Ac\u00e1, part\u00ed del espa\u00f1ol y llegu\u00e9 al ingl\u00e9s, y estoy tratando de evaluar comparando las", "tokens": [50364, 5097, 842, 11, 644, 870, 1103, 31177, 288, 11234, 42423, 419, 49766, 11, 288, 15796, 21507, 1806, 368, 6133, 289, 6311, 1806, 2439, 50556], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 592, "seek": 331622, "start": 3320.06, "end": 3324.74, "text": " frases en ingl\u00e9s esperadas con las frases en ingl\u00e9s generadas. Claro. Probablemente\u2026", "tokens": [50556, 431, 1957, 465, 49766, 10045, 6872, 416, 2439, 431, 1957, 465, 49766, 1337, 6872, 13, 33380, 13, 8736, 712, 4082, 1260, 50790], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 593, "seek": 331622, "start": 3324.74, "end": 3329.4599999999996, "text": " Ac\u00e1 est\u00e1 el mismo idioma, se entend\u00ed. Claro, pero est\u00e1 en el mismo idioma, o sea, lo", "tokens": [50790, 5097, 842, 3192, 806, 12461, 18014, 6440, 11, 369, 16612, 870, 13, 33380, 11, 4768, 3192, 465, 806, 12461, 18014, 6440, 11, 277, 4158, 11, 450, 51026], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 594, "seek": 331622, "start": 3329.4599999999996, "end": 3333.7799999999997, "text": " que nos mostramos ac\u00e1 era cu\u00e1l era la oraci\u00f3n o origen, porque para evaluar no nos importa", "tokens": [51026, 631, 3269, 881, 30227, 23496, 4249, 44318, 4249, 635, 420, 3482, 277, 2349, 268, 11, 4021, 1690, 6133, 289, 572, 3269, 33218, 51242], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 595, "seek": 331622, "start": 3333.7799999999997, "end": 3337.8599999999997, "text": " en realidad, para evaluar nos importa que comparar solamente la oraci\u00f3n candidato con", "tokens": [51242, 465, 25635, 11, 1690, 6133, 289, 3269, 33218, 631, 6311, 289, 27814, 635, 420, 3482, 6268, 2513, 416, 51446], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 596, "seek": 331622, "start": 3337.8599999999997, "end": 3343.14, "text": " la referencia, y la origen nos olvidamos. Sabemos que los dos intentaron traducir de la misma", "tokens": [51446, 635, 2864, 10974, 11, 288, 635, 2349, 268, 3269, 43194, 2151, 13, 13915, 4485, 631, 1750, 4491, 8446, 6372, 2479, 1311, 347, 368, 635, 24946, 51710], "temperature": 0.0, "avg_logprob": -0.2584722890149827, "compression_ratio": 1.7980132450331126, "no_speech_prob": 0.553769052028656}, {"id": 597, "seek": 334314, "start": 3343.14, "end": 3351.22, "text": " oraci\u00f3n, y bueno, y alguno le fue mejor que a otro. Bien, esos son comentarios de", "tokens": [50364, 420, 3482, 11, 288, 11974, 11, 288, 9813, 78, 476, 9248, 11479, 631, 257, 11921, 13, 16956, 11, 22411, 1872, 36842, 368, 50768], "temperature": 0.0, "avg_logprob": -0.1690075474400674, "compression_ratio": 1.83402489626556, "no_speech_prob": 0.18750439584255219}, {"id": 598, "seek": 334314, "start": 3351.22, "end": 3356.7, "text": " Blue, esto era evaluaci\u00f3n de los sistemas. Lo siguiente que vamos a ver es el problema", "tokens": [50768, 8510, 11, 7433, 4249, 6133, 3482, 368, 1750, 48720, 13, 6130, 25666, 631, 5295, 257, 1306, 785, 806, 12395, 51042], "temperature": 0.0, "avg_logprob": -0.1690075474400674, "compression_ratio": 1.83402489626556, "no_speech_prob": 0.18750439584255219}, {"id": 599, "seek": 334314, "start": 3356.7, "end": 3360.66, "text": " de los corpus paralelos. Antes de pasar a lo que son modelos de traducci\u00f3n, vamos a", "tokens": [51042, 368, 1750, 1181, 31624, 26009, 338, 329, 13, 39325, 368, 25344, 257, 450, 631, 1872, 2316, 329, 368, 2479, 1311, 5687, 11, 5295, 257, 51240], "temperature": 0.0, "avg_logprob": -0.1690075474400674, "compression_ratio": 1.83402489626556, "no_speech_prob": 0.18750439584255219}, {"id": 600, "seek": 334314, "start": 3360.66, "end": 3365.14, "text": " hablar un poco de lo que son los corpus paralelos, que son necesarios para construir un modelo", "tokens": [51240, 21014, 517, 10639, 368, 450, 631, 1872, 1750, 1181, 31624, 26009, 338, 329, 11, 631, 1872, 11909, 9720, 1690, 38445, 517, 27825, 51464], "temperature": 0.0, "avg_logprob": -0.1690075474400674, "compression_ratio": 1.83402489626556, "no_speech_prob": 0.18750439584255219}, {"id": 601, "seek": 334314, "start": 3365.14, "end": 3371.02, "text": " de traducci\u00f3n. Un corpus paralelo consiste en pares de textos en dos idiomas, por ejemplo,", "tokens": [51464, 368, 2479, 1311, 5687, 13, 1156, 1181, 31624, 26009, 10590, 49066, 465, 2502, 495, 368, 2487, 329, 465, 4491, 18014, 7092, 11, 1515, 13358, 11, 51758], "temperature": 0.0, "avg_logprob": -0.1690075474400674, "compression_ratio": 1.83402489626556, "no_speech_prob": 0.18750439584255219}, {"id": 602, "seek": 337102, "start": 3371.1, "end": 3375.66, "text": " tener textos en espa\u00f1ol y en ingl\u00e9s, pero adem\u00e1s yo tengo que tener alg\u00fan nivel, tengo", "tokens": [50368, 11640, 2487, 329, 465, 31177, 288, 465, 49766, 11, 4768, 21251, 5290, 13989, 631, 11640, 26300, 24423, 11, 13989, 50596], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 603, "seek": 337102, "start": 3375.66, "end": 3380.06, "text": " que tener una correspondencia entre esos textos. De alguna forma, yo tengo que saber c\u00f3mo", "tokens": [50596, 631, 11640, 2002, 6805, 10974, 3962, 22411, 2487, 329, 13, 1346, 20651, 8366, 11, 5290, 13989, 631, 12489, 12826, 50816], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 604, "seek": 337102, "start": 3380.06, "end": 3386.74, "text": " se corresponde un texto con el otro. Entonces, bueno, tiene que estar con conjuntos, digamos,", "tokens": [50816, 369, 6805, 68, 517, 35503, 416, 806, 11921, 13, 15097, 11, 11974, 11, 7066, 631, 8755, 416, 20295, 2760, 329, 11, 36430, 11, 51150], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 605, "seek": 337102, "start": 3386.74, "end": 3391.38, "text": " ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen,", "tokens": [51150, 28615, 4181, 368, 2487, 329, 465, 806, 35044, 84, 11153, 2349, 268, 11, 465, 806, 35044, 84, 11153, 2677, 2982, 11, 288, 11974, 11, 2514, 268, 11, 51382], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 606, "seek": 337102, "start": 3391.38, "end": 3395.66, "text": " en el mundo existen corpus paralelos para algunos idiomas, o sea, hay muchos idiomas", "tokens": [51382, 465, 806, 7968, 2514, 268, 1181, 31624, 26009, 338, 329, 1690, 21078, 18014, 7092, 11, 277, 4158, 11, 4842, 17061, 18014, 7092, 51596], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 607, "seek": 337102, "start": 3395.66, "end": 3399.78, "text": " en el mundo, pero no todos los pares de idiomas tienen corpus paralelo construido, entonces", "tokens": [51596, 465, 806, 7968, 11, 4768, 572, 6321, 1750, 2502, 495, 368, 18014, 7092, 12536, 1181, 31624, 26009, 10590, 12946, 2925, 11, 13003, 51802], "temperature": 0.0, "avg_logprob": -0.1537338282964001, "compression_ratio": 1.9386281588447654, "no_speech_prob": 0.3080660402774811}, {"id": 608, "seek": 339978, "start": 3399.86, "end": 3404.6600000000003, "text": " existen paralela de ingl\u00e9s, el chino ingl\u00e9s para la mayor\u00eda de los lenguajes europeos,", "tokens": [50368, 2514, 268, 26009, 4053, 368, 49766, 11, 806, 417, 2982, 49766, 1690, 635, 35342, 368, 1750, 35044, 84, 29362, 27207, 329, 11, 50608], "temperature": 0.0, "avg_logprob": -0.16983465323770852, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0058731441386044025}, {"id": 609, "seek": 339978, "start": 3404.6600000000003, "end": 3410.38, "text": " debido a su uso en la Uni\u00f3n Europea, digamos, existen tambi\u00e9n corpus paralelos para ellos,", "tokens": [50608, 50003, 257, 459, 22728, 465, 635, 1156, 2560, 3315, 64, 11, 36430, 11, 2514, 268, 6407, 1181, 31624, 26009, 338, 329, 1690, 16353, 11, 50894], "temperature": 0.0, "avg_logprob": -0.16983465323770852, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0058731441386044025}, {"id": 610, "seek": 339978, "start": 3410.38, "end": 3416.3, "text": " pero para la gran mayor\u00eda de pares de lenguas no hay, digamos, no tengo un par que traduzca", "tokens": [50894, 4768, 1690, 635, 9370, 35342, 368, 2502, 495, 368, 35044, 84, 296, 572, 4842, 11, 36430, 11, 572, 13989, 517, 971, 631, 2479, 3334, 496, 51190], "temperature": 0.0, "avg_logprob": -0.16983465323770852, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0058731441386044025}, {"id": 611, "seek": 339978, "start": 3416.3, "end": 3421.02, "text": " entre el chino y el guaran\u00ed, por ejemplo, o sea, es poco probable que se construya", "tokens": [51190, 3962, 806, 417, 2982, 288, 806, 7498, 282, 870, 11, 1515, 13358, 11, 277, 4158, 11, 785, 10639, 21759, 631, 369, 12946, 3016, 51426], "temperature": 0.0, "avg_logprob": -0.16983465323770852, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0058731441386044025}, {"id": 612, "seek": 339978, "start": 3421.02, "end": 3427.5400000000004, "text": " un par de estilos. Bien, \u00bfqu\u00e9 es un corpus paralelo? Ya que no se ve nada, de vuelta.", "tokens": [51426, 517, 971, 368, 871, 6136, 13, 16956, 11, 3841, 16412, 785, 517, 1181, 31624, 26009, 10590, 30, 6080, 631, 572, 369, 1241, 8096, 11, 368, 41542, 13, 51752], "temperature": 0.0, "avg_logprob": -0.16983465323770852, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.0058731441386044025}, {"id": 613, "seek": 342754, "start": 3427.54, "end": 3434.1, "text": " Ac\u00e1 hay un ejemplo, que no s\u00e9 si lo conocen, es un ejemplo famoso de corpus paralelo.", "tokens": [50364, 5097, 842, 4842, 517, 13358, 11, 631, 572, 7910, 1511, 450, 15871, 268, 11, 785, 517, 13358, 49526, 368, 1181, 31624, 26009, 10590, 13, 50692], "temperature": 0.0, "avg_logprob": -0.215145509321611, "compression_ratio": 1.407035175879397, "no_speech_prob": 0.002276981482282281}, {"id": 614, "seek": 342754, "start": 3437.62, "end": 3444.2599999999998, "text": " Tiene idea de lo que es, lo han visto alguna vez, \u00bfs\u00ed? La piedra de Rosetta. La piedra de Rosetta", "tokens": [50868, 314, 10174, 1558, 368, 450, 631, 785, 11, 450, 7276, 17558, 20651, 5715, 11, 3841, 82, 870, 30, 2369, 24186, 424, 368, 11144, 16593, 13, 2369, 24186, 424, 368, 11144, 16593, 51200], "temperature": 0.0, "avg_logprob": -0.215145509321611, "compression_ratio": 1.407035175879397, "no_speech_prob": 0.002276981482282281}, {"id": 615, "seek": 342754, "start": 3445.7, "end": 3453.9, "text": " fue una piedra que la construyeron, o por lo menos la tallaron en el a\u00f1o 196 a.C. y hablaba", "tokens": [51272, 9248, 2002, 24186, 424, 631, 635, 12946, 7224, 266, 11, 277, 1515, 450, 8902, 635, 6764, 6372, 465, 806, 15984, 7998, 257, 13, 34, 13, 288, 26280, 5509, 51682], "temperature": 0.0, "avg_logprob": -0.215145509321611, "compression_ratio": 1.407035175879397, "no_speech_prob": 0.002276981482282281}, {"id": 616, "seek": 345390, "start": 3453.9, "end": 3462.54, "text": " sobre la coronaci\u00f3n de Tolomeo V y su adoraci\u00f3n como semi-dios, etc\u00e9tera, etc\u00e9tera. Y bueno,", "tokens": [50364, 5473, 635, 10451, 3482, 368, 21402, 423, 78, 691, 288, 459, 614, 284, 3482, 2617, 12909, 12, 67, 2717, 11, 5183, 526, 23833, 11, 5183, 526, 23833, 13, 398, 11974, 11, 50796], "temperature": 0.0, "avg_logprob": -0.21543956625050512, "compression_ratio": 1.549800796812749, "no_speech_prob": 0.027279676869511604}, {"id": 617, "seek": 345390, "start": 3462.54, "end": 3469.5, "text": " estuvo perdida un mont\u00f3n de a\u00f1os hasta que durante las campa\u00f1as napole\u00f3nicas 1799 la", "tokens": [50796, 871, 43744, 12611, 2887, 517, 45259, 368, 11424, 10764, 631, 14427, 2439, 2255, 23217, 296, 9296, 4812, 1801, 9150, 3282, 8494, 635, 51144], "temperature": 0.0, "avg_logprob": -0.21543956625050512, "compression_ratio": 1.549800796812749, "no_speech_prob": 0.027279676869511604}, {"id": 618, "seek": 345390, "start": 3469.5, "end": 3475.7000000000003, "text": " encontraron en Egipto, en lugar Rosetta, casualmente, y se la llevaron para Francia y ah\u00ed la empezaron", "tokens": [51144, 17525, 266, 465, 43515, 647, 1353, 11, 465, 11467, 11144, 16593, 11, 13052, 4082, 11, 288, 369, 635, 27124, 6372, 1690, 17288, 2755, 288, 12571, 635, 18730, 6372, 51454], "temperature": 0.0, "avg_logprob": -0.21543956625050512, "compression_ratio": 1.549800796812749, "no_speech_prob": 0.027279676869511604}, {"id": 619, "seek": 345390, "start": 3475.7000000000003, "end": 3480.26, "text": " a analizar ling\u00fcistas, empezaron a tratar de entender qu\u00e9 es lo que dec\u00eda. Y bueno, descubrieron", "tokens": [51454, 257, 2624, 9736, 22949, 774, 14858, 11, 18730, 6372, 257, 42549, 368, 20054, 8057, 785, 450, 631, 37599, 13, 398, 11974, 11, 32592, 7326, 266, 51682], "temperature": 0.0, "avg_logprob": -0.21543956625050512, "compression_ratio": 1.549800796812749, "no_speech_prob": 0.027279676869511604}, {"id": 620, "seek": 348026, "start": 3480.26, "end": 3487.1400000000003, "text": " que tiene tres textos, vieron que tiene como tres regiones, tres textos y despu\u00e9s de estudiarla un", "tokens": [50364, 631, 7066, 15890, 2487, 329, 11, 371, 14440, 631, 7066, 2617, 15890, 4458, 279, 11, 15890, 2487, 329, 288, 15283, 368, 13542, 9448, 875, 517, 50708], "temperature": 0.0, "avg_logprob": -0.13538356703154894, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.29319462180137634}, {"id": 621, "seek": 348026, "start": 3487.1400000000003, "end": 3492.42, "text": " rato se dieron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas distintos. Y los", "tokens": [50708, 367, 2513, 369, 274, 14440, 17868, 631, 465, 25635, 450, 631, 7066, 785, 806, 12461, 35503, 465, 15890, 18014, 7092, 49337, 13, 398, 1750, 50972], "temperature": 0.0, "avg_logprob": -0.13538356703154894, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.29319462180137634}, {"id": 622, "seek": 348026, "start": 3492.42, "end": 3496.86, "text": " idiomas eran, el de arriba eran jerogl\u00edficos egipcios, del estilo de lo que uno encuentra dentro de las", "tokens": [50972, 18014, 7092, 32762, 11, 806, 368, 28469, 32762, 20160, 664, 75, 18869, 329, 24263, 647, 23132, 11, 1103, 37470, 368, 450, 631, 8526, 43274, 10856, 368, 2439, 51194], "temperature": 0.0, "avg_logprob": -0.13538356703154894, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.29319462180137634}, {"id": 623, "seek": 348026, "start": 3496.86, "end": 3502.7400000000002, "text": " pir\u00e1mides, el del medio era egipcio dem\u00f3tico, que era el egipcio vulgar que se usaba digamos en el", "tokens": [51194, 13528, 19524, 1875, 11, 806, 1103, 22123, 4249, 24263, 647, 8529, 1371, 34712, 2789, 11, 631, 4249, 806, 24263, 647, 8529, 7452, 2976, 631, 369, 505, 5509, 36430, 465, 806, 51488], "temperature": 0.0, "avg_logprob": -0.13538356703154894, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.29319462180137634}, {"id": 624, "seek": 348026, "start": 3502.7400000000002, "end": 3508.78, "text": " d\u00eda a d\u00eda, y el de abajo el todo era griego antiguo. Entonces, si bien ninguno de los tres idiomas se", "tokens": [51488, 12271, 257, 12271, 11, 288, 806, 368, 30613, 806, 5149, 4249, 677, 12200, 2511, 16397, 78, 13, 15097, 11, 1511, 3610, 17210, 12638, 368, 1750, 15890, 18014, 7092, 369, 51790], "temperature": 0.0, "avg_logprob": -0.13538356703154894, "compression_ratio": 1.8056537102473498, "no_speech_prob": 0.29319462180137634}, {"id": 625, "seek": 350878, "start": 3508.82, "end": 3515.46, "text": " hablaban, el momento que se encontr\u00f3 la piedra, los tres idiomas antiguos, el griego antiguo por lo", "tokens": [50366, 26280, 18165, 11, 806, 9333, 631, 369, 10176, 11721, 635, 24186, 424, 11, 1750, 15890, 18014, 7092, 2511, 16397, 329, 11, 806, 677, 12200, 2511, 16397, 78, 1515, 450, 50698], "temperature": 0.0, "avg_logprob": -0.1379191684026788, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.011807921342551708}, {"id": 626, "seek": 350878, "start": 3515.46, "end": 3520.1400000000003, "text": " menos s\u00ed se sab\u00eda, digamos, se conoc\u00eda como idioma, se sab\u00eda qu\u00e9 significaba y digamos, hab\u00eda gente", "tokens": [50698, 8902, 8600, 369, 5560, 2686, 11, 36430, 11, 369, 15871, 2686, 2617, 18014, 6440, 11, 369, 5560, 2686, 8057, 3350, 5509, 288, 36430, 11, 16395, 3788, 50932], "temperature": 0.0, "avg_logprob": -0.1379191684026788, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.011807921342551708}, {"id": 627, "seek": 350878, "start": 3520.1400000000003, "end": 3524.2200000000003, "text": " que lo estudiaba, los otros dos no, los otros dos eran lenguas completamente perdidas que nadie sab\u00eda", "tokens": [50932, 631, 450, 13542, 72, 5509, 11, 1750, 16422, 4491, 572, 11, 1750, 16422, 4491, 32762, 35044, 84, 296, 28381, 12611, 11382, 631, 28060, 5560, 2686, 51136], "temperature": 0.0, "avg_logprob": -0.1379191684026788, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.011807921342551708}, {"id": 628, "seek": 350878, "start": 3524.2200000000003, "end": 3530.2200000000003, "text": " identificarlas. Pero gracias al hecho de que en realidad se descubri\u00f3 que los tres textos hablan de", "tokens": [51136, 49456, 6843, 296, 13, 9377, 16611, 419, 13064, 368, 631, 465, 25635, 369, 32592, 44802, 631, 1750, 15890, 2487, 329, 3025, 8658, 368, 51436], "temperature": 0.0, "avg_logprob": -0.1379191684026788, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.011807921342551708}, {"id": 629, "seek": 350878, "start": 3530.2200000000003, "end": 3535.3, "text": " lo mismo, son el mismo texto en tres idiomas, entonces ah\u00ed se empez\u00f3 a hacer un trabajo de", "tokens": [51436, 450, 12461, 11, 1872, 806, 12461, 35503, 465, 15890, 18014, 7092, 11, 13003, 12571, 369, 18730, 812, 257, 6720, 517, 18099, 368, 51690], "temperature": 0.0, "avg_logprob": -0.1379191684026788, "compression_ratio": 1.7773851590106007, "no_speech_prob": 0.011807921342551708}, {"id": 630, "seek": 353530, "start": 3535.34, "end": 3539.86, "text": " alineaci\u00f3n, digamos, los arque\u00f3logos empezaron a decir, bueno, esta porci\u00f3n de texto ac\u00e1 se", "tokens": [50366, 419, 533, 3482, 11, 36430, 11, 1750, 594, 1077, 812, 4987, 329, 18730, 6372, 257, 10235, 11, 11974, 11, 5283, 1515, 5687, 368, 35503, 23496, 369, 50592], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 631, "seek": 353530, "start": 3539.86, "end": 3543.54, "text": " corresponde con esta de ac\u00e1, se corresponde con esta de ac\u00e1, y etc\u00e9tera, y a tratar de encontrar", "tokens": [50592, 6805, 68, 416, 5283, 368, 23496, 11, 369, 6805, 68, 416, 5283, 368, 23496, 11, 288, 5183, 526, 23833, 11, 288, 257, 42549, 368, 17525, 50776], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 632, "seek": 353530, "start": 3543.54, "end": 3548.6600000000003, "text": " correspondencias en los idiomas, y como sab\u00edan qu\u00e9 quer\u00eda decir en griego antiguo, empezaron a poder", "tokens": [50776, 6805, 37246, 465, 1750, 18014, 7092, 11, 288, 2617, 5560, 11084, 8057, 37869, 10235, 465, 677, 12200, 2511, 16397, 78, 11, 18730, 6372, 257, 8152, 51032], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 633, "seek": 353530, "start": 3548.6600000000003, "end": 3553.3, "text": " descubrir qu\u00e9 quer\u00edan decir en los otros idiomas. Entonces, a ra\u00edz de eso, es que empez\u00f3, digamos,", "tokens": [51032, 32592, 10949, 8057, 7083, 11084, 10235, 465, 1750, 16422, 18014, 7092, 13, 15097, 11, 257, 3342, 44551, 368, 7287, 11, 785, 631, 18730, 812, 11, 36430, 11, 51264], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 634, "seek": 353530, "start": 3553.3, "end": 3558.7400000000002, "text": " la egiptolog\u00eda moderna, se pudo empezar a descifrar, que dicen, por ejemplo, los jerogl\u00edficos est\u00e1n en", "tokens": [51264, 635, 24263, 22439, 29987, 10494, 629, 11, 369, 280, 6207, 31168, 257, 7471, 351, 5352, 11, 631, 33816, 11, 1515, 13358, 11, 1750, 20160, 664, 75, 18869, 329, 10368, 465, 51536], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 635, "seek": 353530, "start": 3558.7400000000002, "end": 3563.9, "text": " las pir\u00e1mides y bueno, un mont\u00f3n de cultura egipcia antiguas se conoce gracias a que se pudo descifrar", "tokens": [51536, 2439, 13528, 19524, 1875, 288, 11974, 11, 517, 45259, 368, 30576, 24263, 647, 2755, 2511, 16397, 296, 369, 33029, 384, 16611, 257, 631, 369, 280, 6207, 7471, 351, 5352, 51794], "temperature": 0.0, "avg_logprob": -0.15839854153719815, "compression_ratio": 1.921630094043887, "no_speech_prob": 0.041413549333810806}, {"id": 636, "seek": 356390, "start": 3563.9, "end": 3568.02, "text": " lo que dec\u00eda esta piedra. Y en definitiva, esto es un ejemplo de corpus paralelos, o sea, tengo el mismo", "tokens": [50364, 450, 631, 37599, 5283, 24186, 424, 13, 398, 465, 28781, 5931, 11, 7433, 785, 517, 13358, 368, 1181, 31624, 26009, 338, 329, 11, 277, 4158, 11, 13989, 806, 12461, 50570], "temperature": 0.0, "avg_logprob": -0.15929351054446797, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.006023702211678028}, {"id": 637, "seek": 356390, "start": 3568.02, "end": 3575.58, "text": " texto en tres idiomas y con un poco de esfuerzo logro alinear cu\u00e1les son cada uno de los elementos", "tokens": [50570, 35503, 465, 15890, 18014, 7092, 288, 416, 517, 10639, 368, 49213, 4765, 3565, 340, 419, 533, 289, 2702, 842, 904, 1872, 8411, 8526, 368, 1750, 35797, 50948], "temperature": 0.0, "avg_logprob": -0.15929351054446797, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.006023702211678028}, {"id": 638, "seek": 356390, "start": 3575.58, "end": 3583.78, "text": " de mis lenguajes y logro saber la traducci\u00f3n de los tres. Bueno, entonces, eso no llega al concepto", "tokens": [50948, 368, 3346, 35044, 84, 29362, 288, 3565, 340, 12489, 635, 2479, 1311, 5687, 368, 1750, 15890, 13, 16046, 11, 13003, 11, 7287, 572, 40423, 419, 3410, 78, 51358], "temperature": 0.0, "avg_logprob": -0.15929351054446797, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.006023702211678028}, {"id": 639, "seek": 356390, "start": 3583.78, "end": 3589.6600000000003, "text": " de alineaci\u00f3n, los corpus paralelos tienen distintos niveles de alineaci\u00f3n, lo m\u00e1s f\u00e1cil de encontrar", "tokens": [51358, 368, 419, 533, 3482, 11, 1750, 1181, 31624, 26009, 338, 329, 12536, 49337, 11461, 904, 368, 419, 533, 3482, 11, 450, 3573, 17474, 368, 17525, 51652], "temperature": 0.0, "avg_logprob": -0.15929351054446797, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.006023702211678028}, {"id": 640, "seek": 356390, "start": 3589.6600000000003, "end": 3593.1800000000003, "text": " son corpus que est\u00e1n alineados a nivel de documentos, yo tengo una colecci\u00f3n de documentos en", "tokens": [51652, 1872, 1181, 31624, 631, 10368, 419, 533, 4181, 257, 24423, 368, 4166, 329, 11, 5290, 13989, 2002, 45139, 14735, 368, 4166, 329, 465, 51828], "temperature": 0.0, "avg_logprob": -0.15929351054446797, "compression_ratio": 1.7700348432055748, "no_speech_prob": 0.006023702211678028}, {"id": 641, "seek": 359318, "start": 3593.18, "end": 3597.1, "text": " espa\u00f1ol y una colecci\u00f3n de documentos en chino y yo s\u00e9 qu\u00e9 documento se corresponde con qu\u00e9", "tokens": [50364, 31177, 288, 2002, 45139, 14735, 368, 4166, 329, 465, 417, 2982, 288, 5290, 7910, 8057, 4166, 78, 369, 6805, 68, 416, 8057, 50560], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 642, "seek": 359318, "start": 3597.1, "end": 3603.02, "text": " otro, pero no s\u00e9 nada m\u00e1s. Ser\u00eda mejor incluso que estuvieran alineados a nivel de alineaci\u00f3n,", "tokens": [50560, 11921, 11, 4768, 572, 7910, 8096, 3573, 13, 4210, 2686, 11479, 24018, 631, 49777, 38516, 419, 533, 4181, 257, 24423, 368, 419, 533, 3482, 11, 50856], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 643, "seek": 359318, "start": 3603.02, "end": 3607.58, "text": " adem\u00e1s de conocer los documentos, yo s\u00e9 cu\u00e1l es la relaci\u00f3n en espa\u00f1ol o con cu\u00e1l es la", "tokens": [50856, 21251, 368, 35241, 1750, 4166, 329, 11, 5290, 7910, 44318, 785, 635, 37247, 465, 31177, 277, 416, 44318, 785, 635, 51084], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 644, "seek": 359318, "start": 3607.58, "end": 3612.4199999999996, "text": " relaci\u00f3n en chino, digamos, tengo una correspondencia entre esas dos, pero ser\u00eda a\u00fan mejor y esto es lo", "tokens": [51084, 37247, 465, 417, 2982, 11, 36430, 11, 13989, 2002, 6805, 10974, 3962, 23388, 4491, 11, 4768, 23679, 31676, 11479, 288, 7433, 785, 450, 51326], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 645, "seek": 359318, "start": 3612.4199999999996, "end": 3616.66, "text": " que m\u00e1s nos servir\u00eda si estuvieran alineados a nivel de palabra. Cada uno de los caracteres que", "tokens": [51326, 631, 3573, 3269, 29463, 2686, 1511, 49777, 38516, 419, 533, 4181, 257, 24423, 368, 31702, 13, 38603, 8526, 368, 1750, 28760, 279, 631, 51538], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 646, "seek": 359318, "start": 3616.66, "end": 3620.2599999999998, "text": " est\u00e1n en chino se corresponde con qu\u00e9 palabra en espa\u00f1ol o qu\u00e9 grupo de palabras y cada una de las", "tokens": [51538, 10368, 465, 417, 2982, 369, 6805, 68, 416, 8057, 31702, 465, 31177, 277, 8057, 20190, 368, 35240, 288, 8411, 2002, 368, 2439, 51718], "temperature": 0.0, "avg_logprob": -0.18942413074058173, "compression_ratio": 2.051546391752577, "no_speech_prob": 0.01663590408861637}, {"id": 647, "seek": 362026, "start": 3620.3, "end": 3625.5400000000004, "text": " palabras en espa\u00f1ol, con qu\u00e9 grupo de caracteres se corresponde en chino. Esto es el ideal, pero claro,", "tokens": [50366, 35240, 465, 31177, 11, 416, 8057, 20190, 368, 28760, 279, 369, 6805, 68, 465, 417, 2982, 13, 20880, 785, 806, 7157, 11, 4768, 16742, 11, 50628], "temperature": 0.0, "avg_logprob": -0.14285880869085138, "compression_ratio": 1.725085910652921, "no_speech_prob": 0.012601339258253574}, {"id": 648, "seek": 362026, "start": 3625.5400000000004, "end": 3630.2200000000003, "text": " o sea, si ya es dif\u00edcil conseguir cosas que est\u00e9n alineadas a nivel documento, se imaginan que", "tokens": [50628, 277, 4158, 11, 1511, 2478, 785, 17258, 21229, 12218, 631, 871, 3516, 419, 533, 6872, 257, 24423, 4166, 78, 11, 369, 23427, 282, 631, 50862], "temperature": 0.0, "avg_logprob": -0.14285880869085138, "compression_ratio": 1.725085910652921, "no_speech_prob": 0.012601339258253574}, {"id": 649, "seek": 362026, "start": 3630.2200000000003, "end": 3637.6600000000003, "text": " nadie va a ir a mano alinear a nivel de palabra cada uno de las palabras de los idiomas. Entonces,", "tokens": [50862, 28060, 2773, 257, 3418, 257, 18384, 419, 533, 289, 257, 24423, 368, 31702, 8411, 8526, 368, 2439, 35240, 368, 1750, 18014, 7092, 13, 15097, 11, 51234], "temperature": 0.0, "avg_logprob": -0.14285880869085138, "compression_ratio": 1.725085910652921, "no_speech_prob": 0.012601339258253574}, {"id": 650, "seek": 362026, "start": 3637.6600000000003, "end": 3642.82, "text": " en la pr\u00e1ctica nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que,", "tokens": [51234, 465, 635, 27300, 29041, 13768, 5295, 257, 17525, 517, 1181, 31624, 419, 533, 1573, 257, 24423, 368, 31702, 11, 4768, 5295, 257, 1306, 631, 11, 51492], "temperature": 0.0, "avg_logprob": -0.14285880869085138, "compression_ratio": 1.725085910652921, "no_speech_prob": 0.012601339258253574}, {"id": 651, "seek": 362026, "start": 3642.82, "end": 3647.9, "text": " como resultado de la construcci\u00f3n de los modelos de lenguaje, se produce tambi\u00e9n como un producto", "tokens": [51492, 2617, 28047, 368, 635, 12946, 14735, 368, 1750, 2316, 329, 368, 35044, 84, 11153, 11, 369, 5258, 6407, 2617, 517, 47583, 51746], "temperature": 0.0, "avg_logprob": -0.14285880869085138, "compression_ratio": 1.725085910652921, "no_speech_prob": 0.012601339258253574}, {"id": 652, "seek": 364790, "start": 3647.9, "end": 3653.1, "text": " secundario, se produce la alineaci\u00f3n de los corpus, entonces obten\u00e9s las dos cosas a la vez.", "tokens": [50364, 907, 997, 4912, 11, 369, 5258, 635, 419, 533, 3482, 368, 1750, 1181, 31624, 11, 13003, 28326, 2191, 2439, 4491, 12218, 257, 635, 5715, 13, 50624], "temperature": 0.0, "avg_logprob": -0.14962675912039622, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.004216558299958706}, {"id": 653, "seek": 364790, "start": 3655.6600000000003, "end": 3661.82, "text": " Bueno, y otra cosa es que a diferencia del texto monolingua que yo usaba para los modelos", "tokens": [50752, 16046, 11, 288, 13623, 10163, 785, 631, 257, 38844, 1103, 35503, 1108, 401, 278, 4398, 631, 5290, 505, 5509, 1690, 1750, 2316, 329, 51060], "temperature": 0.0, "avg_logprob": -0.14962675912039622, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.004216558299958706}, {"id": 654, "seek": 364790, "start": 3661.82, "end": 3667.42, "text": " de lenguaje, es muy raro que naturalmente se produzcan textos en dos idiomas a la vez, o sea,", "tokens": [51060, 368, 35044, 84, 11153, 11, 785, 5323, 367, 9708, 631, 3303, 4082, 369, 28093, 7035, 2487, 329, 465, 4491, 18014, 7092, 257, 635, 5715, 11, 277, 4158, 11, 51340], "temperature": 0.0, "avg_logprob": -0.14962675912039622, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.004216558299958706}, {"id": 655, "seek": 364790, "start": 3667.42, "end": 3675.26, "text": " hay que buscarlos bastante, digamos, bastante cuidadosamente. Existen algunos contextos en", "tokens": [51340, 4842, 631, 26170, 9389, 14651, 11, 36430, 11, 14651, 20770, 4181, 3439, 13, 2111, 4821, 21078, 4319, 329, 465, 51732], "temperature": 0.0, "avg_logprob": -0.14962675912039622, "compression_ratio": 1.6255506607929515, "no_speech_prob": 0.004216558299958706}, {"id": 656, "seek": 367526, "start": 3675.26, "end": 3679.3, "text": " donde eso se produce. Por ejemplo, en algunos portales de noticias puede pasar que tengan", "tokens": [50364, 10488, 7287, 369, 5258, 13, 5269, 13358, 11, 465, 21078, 2436, 4229, 368, 406, 48042, 8919, 25344, 631, 46874, 50566], "temperature": 0.0, "avg_logprob": -0.14373840824250253, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.028113486245274544}, {"id": 657, "seek": 367526, "start": 3679.3, "end": 3683.6600000000003, "text": " versiones en distintos idiomas y lo que hagan es traducir las noticias en distintos idiomas.", "tokens": [50566, 3037, 279, 465, 49337, 18014, 7092, 288, 450, 631, 324, 1275, 785, 2479, 1311, 347, 2439, 406, 48042, 465, 49337, 18014, 7092, 13, 50784], "temperature": 0.0, "avg_logprob": -0.14373840824250253, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.028113486245274544}, {"id": 658, "seek": 367526, "start": 3683.6600000000003, "end": 3687.5400000000004, "text": " Entonces, si yo puedo encontrar uno de esos, es una buena fuente para construirme un corpus", "tokens": [50784, 15097, 11, 1511, 5290, 21612, 17525, 8526, 368, 22411, 11, 785, 2002, 25710, 8536, 1576, 1690, 38445, 1398, 517, 1181, 31624, 50978], "temperature": 0.0, "avg_logprob": -0.14373840824250253, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.028113486245274544}, {"id": 659, "seek": 367526, "start": 3687.5400000000004, "end": 3692.26, "text": " paralelo alineado a nivel de documento. Yo s\u00e9, esta noticia se corresponde con esta otra en el otro", "tokens": [50978, 26009, 10590, 419, 533, 1573, 257, 24423, 368, 4166, 78, 13, 7616, 7910, 11, 5283, 406, 15341, 369, 6805, 68, 416, 5283, 13623, 465, 806, 11921, 51214], "temperature": 0.0, "avg_logprob": -0.14373840824250253, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.028113486245274544}, {"id": 660, "seek": 367526, "start": 3692.26, "end": 3698.6600000000003, "text": " idioma. Pero un lugar en donde se producen naturalmente este tipo de textos es en los pa\u00edses que", "tokens": [51214, 18014, 6440, 13, 9377, 517, 11467, 465, 10488, 369, 1082, 13037, 3303, 4082, 4065, 9746, 368, 2487, 329, 785, 465, 1750, 23070, 631, 51534], "temperature": 0.0, "avg_logprob": -0.14373840824250253, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.028113486245274544}, {"id": 661, "seek": 369866, "start": 3698.66, "end": 3704.3399999999997, "text": " son biling\u00fces o multiling\u00fces. Por ejemplo, en Canad\u00e1, que hablan ingl\u00e9s y franc\u00e9s,", "tokens": [50364, 1872, 272, 4883, 774, 279, 277, 2120, 4883, 774, 279, 13, 5269, 13358, 11, 465, 10380, 842, 11, 631, 3025, 8658, 49766, 288, 30514, 2191, 11, 50648], "temperature": 0.0, "avg_logprob": -0.15702064001738136, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.33590155839920044}, {"id": 662, "seek": 369866, "start": 3704.3399999999997, "end": 3709.74, "text": " las discusiones del Parlamento canadiense siempre por ley tienen que transcribirse en los dos", "tokens": [50648, 2439, 717, 1149, 5411, 1103, 29666, 8824, 393, 345, 1053, 405, 12758, 1515, 27786, 12536, 631, 1145, 1142, 10119, 405, 465, 1750, 4491, 50918], "temperature": 0.0, "avg_logprob": -0.15702064001738136, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.33590155839920044}, {"id": 663, "seek": 369866, "start": 3709.74, "end": 3713.54, "text": " idiomas, tienen que traducirse, si est\u00e1n en ingl\u00e9s se traducen en franc\u00e9s, si est\u00e1n en franc\u00e9s se", "tokens": [50918, 18014, 7092, 11, 12536, 631, 2479, 1311, 36097, 11, 1511, 10368, 465, 49766, 369, 2479, 1311, 268, 465, 30514, 2191, 11, 1511, 10368, 465, 30514, 2191, 369, 51108], "temperature": 0.0, "avg_logprob": -0.15702064001738136, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.33590155839920044}, {"id": 664, "seek": 369866, "start": 3713.54, "end": 3719.3799999999997, "text": " traducen en ingl\u00e9s, y guardan una correspondencia entre eso, guardan los documentos de todas las", "tokens": [51108, 2479, 1311, 268, 465, 49766, 11, 288, 6290, 282, 2002, 6805, 10974, 3962, 7287, 11, 6290, 282, 1750, 4166, 329, 368, 10906, 2439, 51400], "temperature": 0.0, "avg_logprob": -0.15702064001738136, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.33590155839920044}, {"id": 665, "seek": 369866, "start": 3719.3799999999997, "end": 3724.02, "text": " discusiones del Parlamento en los dos idiomas. Entonces, ah\u00ed, naturalmente se produce un corpus", "tokens": [51400, 717, 1149, 5411, 1103, 29666, 8824, 465, 1750, 4491, 18014, 7092, 13, 15097, 11, 12571, 11, 3303, 4082, 369, 5258, 517, 1181, 31624, 51632], "temperature": 0.0, "avg_logprob": -0.15702064001738136, "compression_ratio": 1.8784313725490196, "no_speech_prob": 0.33590155839920044}, {"id": 666, "seek": 372402, "start": 3724.02, "end": 3728.34, "text": " paralelo en el nivel de documentos para el ingl\u00e9s y el franc\u00e9s, ese se conoce como el corpus", "tokens": [50364, 26009, 10590, 465, 806, 24423, 368, 4166, 329, 1690, 806, 49766, 288, 806, 30514, 2191, 11, 10167, 369, 33029, 384, 2617, 806, 1181, 31624, 50580], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 667, "seek": 372402, "start": 3728.34, "end": 3734.5, "text": " Hansard. Eso tambi\u00e9n ocurre en Hong Kong, en Hong Kong se habla ingl\u00e9s y chino, son los idiomas", "tokens": [50580, 17926, 515, 13, 27795, 6407, 26430, 265, 465, 8868, 9832, 11, 465, 8868, 9832, 369, 42135, 49766, 288, 417, 2982, 11, 1872, 1750, 18014, 7092, 50888], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 668, "seek": 372402, "start": 3734.5, "end": 3738.78, "text": " oficiales. Entonces, el corpus m\u00e1s grande que se tiene para ingl\u00e9s y chino est\u00e1 hecho como una", "tokens": [50888, 37189, 279, 13, 15097, 11, 806, 1181, 31624, 3573, 8883, 631, 369, 7066, 1690, 49766, 288, 417, 2982, 3192, 13064, 2617, 2002, 51102], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 669, "seek": 372402, "start": 3738.78, "end": 3742.66, "text": " compilaci\u00f3n de lo que son las discusiones del Parlamento de Hong Kong. Y tambi\u00e9n pasa en la", "tokens": [51102, 715, 388, 3482, 368, 450, 631, 1872, 2439, 717, 1149, 5411, 1103, 29666, 8824, 368, 8868, 9832, 13, 398, 6407, 20260, 465, 635, 51296], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 670, "seek": 372402, "start": 3742.66, "end": 3748.78, "text": " Uni\u00f3n Europea, en el Parlamento Europeo tambi\u00e9n tienen la costumbre de traducir todas las discusiones", "tokens": [51296, 1156, 2560, 3315, 64, 11, 465, 806, 29666, 8824, 3315, 78, 6407, 12536, 635, 2063, 449, 2672, 368, 2479, 1311, 347, 10906, 2439, 717, 1149, 5411, 51602], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 671, "seek": 372402, "start": 3748.78, "end": 3752.78, "text": " a todos los idiomas o a muchos de los idiomas que se usan en la Uni\u00f3n Europea. Entonces,", "tokens": [51602, 257, 6321, 1750, 18014, 7092, 277, 257, 17061, 368, 1750, 18014, 7092, 631, 369, 505, 282, 465, 635, 1156, 2560, 3315, 64, 13, 15097, 11, 51802], "temperature": 0.0, "avg_logprob": -0.15949026143775796, "compression_ratio": 1.9266666666666667, "no_speech_prob": 0.5618047714233398}, {"id": 672, "seek": 375278, "start": 3752.94, "end": 3758.42, "text": " hay corpus paralelos para casi todos los idiomas de la Uni\u00f3n Europea. Pero claro, todos estos", "tokens": [50372, 4842, 1181, 31624, 26009, 338, 329, 1690, 22567, 6321, 1750, 18014, 7092, 368, 635, 1156, 2560, 3315, 64, 13, 9377, 16742, 11, 6321, 12585, 50646], "temperature": 0.0, "avg_logprob": -0.1547530038016183, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.004281958565115929}, {"id": 673, "seek": 375278, "start": 3758.42, "end": 3763.1000000000004, "text": " est\u00e1n alineados a nivel de documentos. Yo s\u00e9 qu\u00e9 documento se corresponde con cu\u00e1l es otro en el", "tokens": [50646, 10368, 419, 533, 4181, 257, 24423, 368, 4166, 329, 13, 7616, 7910, 8057, 4166, 78, 369, 6805, 68, 416, 44318, 785, 11921, 465, 806, 50880], "temperature": 0.0, "avg_logprob": -0.1547530038016183, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.004281958565115929}, {"id": 674, "seek": 375278, "start": 3763.1000000000004, "end": 3771.34, "text": " otro idioma, pero no a nivel de oraciones y mucho menos a nivel de palabras. Pero bueno, partiendo", "tokens": [50880, 11921, 18014, 6440, 11, 4768, 572, 257, 24423, 368, 420, 9188, 288, 9824, 8902, 257, 24423, 368, 35240, 13, 9377, 11974, 11, 644, 7304, 51292], "temperature": 0.0, "avg_logprob": -0.1547530038016183, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.004281958565115929}, {"id": 675, "seek": 375278, "start": 3771.34, "end": 3777.34, "text": " de un corpus alineado a nivel de documentos, yo puedo llegar a construirme por lo menos una", "tokens": [51292, 368, 517, 1181, 31624, 419, 533, 1573, 257, 24423, 368, 4166, 329, 11, 5290, 21612, 24892, 257, 38445, 1398, 1515, 450, 8902, 2002, 51592], "temperature": 0.0, "avg_logprob": -0.1547530038016183, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.004281958565115929}, {"id": 676, "seek": 377734, "start": 3777.34, "end": 3783.9, "text": " alineaci\u00f3n a nivel de oraciones. Si en un proceso relativamente sencillo, esto se conoce como el", "tokens": [50364, 419, 533, 3482, 257, 24423, 368, 420, 9188, 13, 4909, 465, 517, 29314, 21960, 3439, 46749, 78, 11, 7433, 369, 33029, 384, 2617, 806, 50692], "temperature": 0.0, "avg_logprob": -0.15995761804413378, "compression_ratio": 1.8018433179723503, "no_speech_prob": 0.062380384653806686}, {"id": 677, "seek": 377734, "start": 3783.9, "end": 3794.82, "text": " algoritmo de Gale y Church, que es un algoritmo relativamente f\u00e1cil para alinear corpus, o sea,", "tokens": [50692, 3501, 50017, 3280, 368, 460, 1220, 288, 7882, 11, 631, 785, 517, 3501, 50017, 3280, 21960, 3439, 17474, 1690, 419, 533, 289, 1181, 31624, 11, 277, 4158, 11, 51238], "temperature": 0.0, "avg_logprob": -0.15995761804413378, "compression_ratio": 1.8018433179723503, "no_speech_prob": 0.062380384653806686}, {"id": 678, "seek": 377734, "start": 3794.82, "end": 3798.06, "text": " para pasar corpus que est\u00e1n alineados a nivel de documentos, pasarlos a que est\u00e9n alineados a", "tokens": [51238, 1690, 25344, 1181, 31624, 631, 10368, 419, 533, 4181, 257, 24423, 368, 4166, 329, 11, 1736, 39734, 257, 631, 871, 3516, 419, 533, 4181, 257, 51400], "temperature": 0.0, "avg_logprob": -0.15995761804413378, "compression_ratio": 1.8018433179723503, "no_speech_prob": 0.062380384653806686}, {"id": 679, "seek": 377734, "start": 3798.06, "end": 3804.02, "text": " nivel de oraci\u00f3n. Y bueno, esto es un algoritmo que funciona, est\u00e1 un poco basado en lo que era el", "tokens": [51400, 24423, 368, 420, 3482, 13, 398, 11974, 11, 7433, 785, 517, 3501, 50017, 3280, 631, 26210, 11, 3192, 517, 10639, 987, 1573, 465, 450, 631, 4249, 806, 51698], "temperature": 0.0, "avg_logprob": -0.15995761804413378, "compression_ratio": 1.8018433179723503, "no_speech_prob": 0.062380384653806686}, {"id": 680, "seek": 380402, "start": 3804.02, "end": 3809.54, "text": " algoritmo de distancia de edici\u00f3n de Levenstein, que vimos hace bastante tiempo en el curso.", "tokens": [50364, 3501, 50017, 3280, 368, 1483, 22862, 368, 1257, 15534, 368, 1456, 553, 9089, 11, 631, 49266, 10032, 14651, 11772, 465, 806, 31085, 13, 50640], "temperature": 0.0, "avg_logprob": -0.19617893459560634, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0024400153197348118}, {"id": 681, "seek": 380402, "start": 3814.62, "end": 3819.86, "text": " Es como muy parecido, tambi\u00e9n es un algoritmo de programaci\u00f3n din\u00e1mica, similar a ese, funciona de", "tokens": [50894, 2313, 2617, 5323, 7448, 17994, 11, 6407, 785, 517, 3501, 50017, 3280, 368, 1461, 3482, 3791, 19524, 2262, 11, 2531, 257, 10167, 11, 26210, 368, 51156], "temperature": 0.0, "avg_logprob": -0.19617893459560634, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0024400153197348118}, {"id": 682, "seek": 380402, "start": 3819.86, "end": 3823.78, "text": " la siguiente manera. O sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de c\u00f3mo", "tokens": [51156, 635, 25666, 13913, 13, 422, 4158, 11, 572, 5295, 257, 4072, 450, 9824, 465, 1141, 11780, 11, 4768, 5295, 257, 4072, 2002, 1558, 368, 12826, 51352], "temperature": 0.0, "avg_logprob": -0.19617893459560634, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0024400153197348118}, {"id": 683, "seek": 380402, "start": 3823.78, "end": 3829.78, "text": " es que funciona. El algoritmo de Gale y Church dice, yo voy a tener un conjunto de oraciones en un idioma", "tokens": [51352, 785, 631, 26210, 13, 2699, 3501, 50017, 3280, 368, 460, 1220, 288, 7882, 10313, 11, 5290, 7552, 257, 11640, 517, 37776, 368, 420, 9188, 465, 517, 18014, 6440, 51652], "temperature": 0.0, "avg_logprob": -0.19617893459560634, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0024400153197348118}, {"id": 684, "seek": 382978, "start": 3829.78, "end": 3841.5, "text": " y otro conjunto de oraciones en el otro idioma. Entonces considero que un traductor para cada", "tokens": [50364, 288, 11921, 37776, 368, 420, 9188, 465, 806, 11921, 18014, 6440, 13, 15097, 1949, 78, 631, 517, 2479, 84, 1672, 1690, 8411, 50950], "temperature": 0.0, "avg_logprob": -0.15813688474280813, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.004509590566158295}, {"id": 685, "seek": 382978, "start": 3841.5, "end": 3846.7000000000003, "text": " oraci\u00f3n pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma. Un traductor,", "tokens": [50950, 420, 3482, 280, 6207, 15811, 33104, 15890, 999, 23469, 11, 36430, 11, 1690, 1736, 6843, 296, 419, 11921, 18014, 6440, 13, 1156, 2479, 84, 1672, 11, 51210], "temperature": 0.0, "avg_logprob": -0.15813688474280813, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.004509590566158295}, {"id": 686, "seek": 382978, "start": 3846.7000000000003, "end": 3852.1800000000003, "text": " supongan un traductor humano, agarr\u00f3 oraciones que estaban en espa\u00f1ol y oraciones que estaban en", "tokens": [51210, 9331, 556, 282, 517, 2479, 84, 1672, 30985, 11, 623, 2284, 812, 420, 9188, 631, 36713, 465, 31177, 288, 420, 9188, 631, 36713, 465, 51484], "temperature": 0.0, "avg_logprob": -0.15813688474280813, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.004509590566158295}, {"id": 687, "seek": 382978, "start": 3852.1800000000003, "end": 3858.6600000000003, "text": " franc\u00e9s. Vamos a no ponerles EIF porque lo que puede confundir con las otras cosas. As\u00ed que vamos", "tokens": [51484, 30514, 2191, 13, 10894, 257, 572, 19149, 904, 462, 12775, 4021, 450, 631, 8919, 1497, 997, 347, 416, 2439, 20244, 12218, 13, 17419, 631, 5295, 51808], "temperature": 0.0, "avg_logprob": -0.15813688474280813, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.004509590566158295}, {"id": 688, "seek": 385866, "start": 3858.66, "end": 3865.8599999999997, "text": " a decir, el lenguaje origen era F, franc\u00e9s y el lenguaje destino era espa\u00f1ol. Bien, entonces un", "tokens": [50364, 257, 10235, 11, 806, 35044, 84, 11153, 2349, 268, 4249, 479, 11, 30514, 2191, 288, 806, 35044, 84, 11153, 2677, 2982, 4249, 31177, 13, 16956, 11, 13003, 517, 50724], "temperature": 0.0, "avg_logprob": -0.13119002750941686, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0030725516844540834}, {"id": 689, "seek": 385866, "start": 3865.8599999999997, "end": 3870.74, "text": " traductor humano cada vez que se enfrentaba una oraci\u00f3n ten\u00eda tres posibilidades. O bien traduc\u00eda", "tokens": [50724, 2479, 84, 1672, 30985, 8411, 5715, 631, 369, 33771, 5509, 2002, 420, 3482, 23718, 15890, 1366, 11607, 10284, 13, 422, 3610, 2479, 1311, 2686, 50968], "temperature": 0.0, "avg_logprob": -0.13119002750941686, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0030725516844540834}, {"id": 690, "seek": 385866, "start": 3870.74, "end": 3877.14, "text": " una oraci\u00f3n por otra oraci\u00f3n, o bien parte esta oraci\u00f3n en dos y traduce una oraci\u00f3n por dos,", "tokens": [50968, 2002, 420, 3482, 1515, 13623, 420, 3482, 11, 277, 3610, 6975, 5283, 420, 3482, 465, 4491, 288, 2479, 4176, 2002, 420, 3482, 1515, 4491, 11, 51288], "temperature": 0.0, "avg_logprob": -0.13119002750941686, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0030725516844540834}, {"id": 691, "seek": 385866, "start": 3877.14, "end": 3882.7799999999997, "text": " o bien borra esta oraci\u00f3n. Decide que no es tan importante y agarra y borra la oraci\u00f3n. Entonces", "tokens": [51288, 277, 3610, 14828, 424, 5283, 420, 3482, 13, 12427, 482, 631, 572, 785, 7603, 9416, 288, 623, 289, 424, 288, 14828, 424, 635, 420, 3482, 13, 15097, 51570], "temperature": 0.0, "avg_logprob": -0.13119002750941686, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0030725516844540834}, {"id": 692, "seek": 385866, "start": 3882.7799999999997, "end": 3888.14, "text": " las tres operaciones que se hacen a nivel de oraci\u00f3n son la de transformarla en cero, una o dos", "tokens": [51570, 2439, 15890, 2208, 9188, 631, 369, 27434, 257, 24423, 368, 420, 3482, 1872, 635, 368, 4088, 34148, 465, 269, 2032, 11, 2002, 277, 4491, 51838], "temperature": 0.0, "avg_logprob": -0.13119002750941686, "compression_ratio": 1.8426966292134832, "no_speech_prob": 0.0030725516844540834}, {"id": 693, "seek": 388814, "start": 3888.14, "end": 3898.66, "text": " oraciones del otro lado. Eso es una cosa. Lo otro es el costo relativo de alinear estas dos oraciones", "tokens": [50364, 420, 9188, 1103, 11921, 11631, 13, 27795, 785, 2002, 10163, 13, 6130, 11921, 785, 806, 2063, 78, 1039, 18586, 368, 419, 533, 289, 13897, 4491, 420, 9188, 50890], "temperature": 0.0, "avg_logprob": -0.13436799579196507, "compression_ratio": 2.1038251366120218, "no_speech_prob": 0.006380010396242142}, {"id": 694, "seek": 388814, "start": 3898.66, "end": 3903.02, "text": " depende del largo relativo de las oraciones. Entonces, si yo tengo dos oraciones que tienen un", "tokens": [50890, 47091, 1103, 31245, 1039, 18586, 368, 2439, 420, 9188, 13, 15097, 11, 1511, 5290, 13989, 4491, 420, 9188, 631, 12536, 517, 51108], "temperature": 0.0, "avg_logprob": -0.13436799579196507, "compression_ratio": 2.1038251366120218, "no_speech_prob": 0.006380010396242142}, {"id": 695, "seek": 388814, "start": 3903.02, "end": 3910.7799999999997, "text": " largo muy parecido, le voy a dar un costo menor para alinearlos, era menor o mayor, si menor. Si", "tokens": [51108, 31245, 5323, 7448, 17994, 11, 476, 7552, 257, 4072, 517, 2063, 78, 26343, 1690, 419, 533, 39734, 11, 4249, 26343, 277, 10120, 11, 1511, 26343, 13, 4909, 51496], "temperature": 0.0, "avg_logprob": -0.13436799579196507, "compression_ratio": 2.1038251366120218, "no_speech_prob": 0.006380010396242142}, {"id": 696, "seek": 388814, "start": 3910.7799999999997, "end": 3915.3399999999997, "text": " tiene un largo muy parecido le voy a dar un valor menor para alinear, si tiene un largo muy", "tokens": [51496, 7066, 517, 31245, 5323, 7448, 17994, 476, 7552, 257, 4072, 517, 15367, 26343, 1690, 419, 533, 289, 11, 1511, 7066, 517, 31245, 5323, 51724], "temperature": 0.0, "avg_logprob": -0.13436799579196507, "compression_ratio": 2.1038251366120218, "no_speech_prob": 0.006380010396242142}, {"id": 697, "seek": 391534, "start": 3915.38, "end": 3920.5, "text": " distinto, una es muy corta y la otra es muy larga, entonces le doy un valor mayor para alinear. Entonces", "tokens": [50366, 1483, 17246, 11, 2002, 785, 5323, 11278, 64, 288, 635, 13623, 785, 5323, 1613, 3680, 11, 13003, 476, 360, 88, 517, 15367, 10120, 1690, 419, 533, 289, 13, 15097, 50622], "temperature": 0.0, "avg_logprob": -0.1488025665283203, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.015661532059311867}, {"id": 698, "seek": 391534, "start": 3920.5, "end": 3926.7400000000002, "text": " lo que ellos hacen es pensando en todo este tipo de operaciones que hay, todas las combinaciones", "tokens": [50622, 450, 631, 16353, 27434, 785, 34525, 465, 5149, 4065, 9746, 368, 2208, 9188, 631, 4842, 11, 10906, 2439, 38514, 9188, 50934], "temperature": 0.0, "avg_logprob": -0.1488025665283203, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.015661532059311867}, {"id": 699, "seek": 391534, "start": 3926.7400000000002, "end": 3935.26, "text": " de operaciones posibles, o sea, partir esta operaci\u00f3n en dos o no partirla o eliminarla o dejarla", "tokens": [50934, 368, 2208, 9188, 1366, 14428, 11, 277, 4158, 11, 13906, 5283, 2208, 3482, 465, 4491, 277, 572, 13906, 875, 277, 7892, 34148, 277, 24391, 875, 51360], "temperature": 0.0, "avg_logprob": -0.1488025665283203, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.015661532059311867}, {"id": 700, "seek": 391534, "start": 3935.26, "end": 3939.7000000000003, "text": " como est\u00e1. Entonces, con programaci\u00f3n din\u00e1mica ven todas las posibilidades, ven todas las posibilidades", "tokens": [51360, 2617, 3192, 13, 15097, 11, 416, 1461, 3482, 3791, 19524, 2262, 6138, 10906, 2439, 1366, 11607, 10284, 11, 6138, 10906, 2439, 1366, 11607, 10284, 51582], "temperature": 0.0, "avg_logprob": -0.1488025665283203, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.015661532059311867}, {"id": 701, "seek": 391534, "start": 3939.7000000000003, "end": 3944.98, "text": " de operar distinto para llegar al otro lado y calculan las que le da un costo menor. O sea,", "tokens": [51582, 368, 2208, 289, 1483, 17246, 1690, 24892, 419, 11921, 11631, 288, 4322, 282, 2439, 631, 476, 1120, 517, 2063, 78, 26343, 13, 422, 4158, 11, 51846], "temperature": 0.0, "avg_logprob": -0.1488025665283203, "compression_ratio": 1.8550185873605949, "no_speech_prob": 0.015661532059311867}, {"id": 702, "seek": 394498, "start": 3945.02, "end": 3949.78, "text": " para cada una de las posibilidades calcula cu\u00e1l es el costo de cada par de oraciones,", "tokens": [50366, 1690, 8411, 2002, 368, 2439, 1366, 11607, 10284, 4322, 64, 44318, 785, 806, 2063, 78, 368, 8411, 971, 368, 420, 9188, 11, 50604], "temperature": 0.0, "avg_logprob": -0.15700257619222005, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0038700709119439125}, {"id": 703, "seek": 394498, "start": 3949.78, "end": 3957.86, "text": " suman todos los costos del documento y se quedan con el caso que les d\u00e9 un costo menor en alineaci\u00f3n,", "tokens": [50604, 2408, 282, 6321, 1750, 2063, 329, 1103, 4166, 78, 288, 369, 13617, 282, 416, 806, 9666, 631, 1512, 2795, 517, 2063, 78, 26343, 465, 419, 533, 3482, 11, 51008], "temperature": 0.0, "avg_logprob": -0.15700257619222005, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0038700709119439125}, {"id": 704, "seek": 394498, "start": 3957.86, "end": 3962.3, "text": " eso se puede hacer eficientemente usando programaci\u00f3n din\u00e1mica, lo mismo que", "tokens": [51008, 7287, 369, 8919, 6720, 49510, 1196, 16288, 29798, 1461, 3482, 3791, 19524, 2262, 11, 450, 12461, 631, 51230], "temperature": 0.0, "avg_logprob": -0.15700257619222005, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0038700709119439125}, {"id": 705, "seek": 396230, "start": 3962.3, "end": 3976.3, "text": " hac\u00edamos con la distancia de edici\u00f3n de Levenstein. Bueno, y este algoritmo que es relativamente", "tokens": [50364, 46093, 16275, 416, 635, 1483, 22862, 368, 1257, 15534, 368, 1456, 553, 9089, 13, 16046, 11, 288, 4065, 3501, 50017, 3280, 631, 785, 21960, 3439, 51064], "temperature": 0.0, "avg_logprob": -0.2070967900125604, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.4598142206668854}, {"id": 706, "seek": 396230, "start": 3976.3, "end": 3982.5800000000004, "text": " sencillo, digamos, es una soluci\u00f3n bastante simple, logra una tasa de error muy buena,", "tokens": [51064, 46749, 78, 11, 36430, 11, 785, 2002, 24807, 5687, 14651, 2199, 11, 3565, 424, 2002, 8023, 64, 368, 6713, 5323, 25710, 11, 51378], "temperature": 0.0, "avg_logprob": -0.2070967900125604, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.4598142206668854}, {"id": 707, "seek": 396230, "start": 3982.5800000000004, "end": 3987.94, "text": " que es de un 4%, digamos, sobre todo para idiomas relacionados, para idiomas que se", "tokens": [51378, 631, 785, 368, 517, 1017, 8923, 36430, 11, 5473, 5149, 1690, 18014, 7092, 27189, 4181, 11, 1690, 18014, 7092, 631, 369, 51646], "temperature": 0.0, "avg_logprob": -0.2070967900125604, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.4598142206668854}, {"id": 708, "seek": 398794, "start": 3987.94, "end": 3992.58, "text": " parecen como el ingl\u00e9s y el espa\u00f1ol, etc\u00e9tera, logra una tasa bastante baja de error de un 4%,", "tokens": [50364, 7448, 13037, 2617, 806, 49766, 288, 806, 31177, 11, 5183, 526, 23833, 11, 3565, 424, 2002, 8023, 64, 14651, 49427, 368, 6713, 368, 517, 1017, 8923, 50596], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 709, "seek": 398794, "start": 3992.58, "end": 3996.46, "text": " hay algunas mejoras que se pueden hacer, pero en realidad un 4% es algo que est\u00e1 bastante bien.", "tokens": [50596, 4842, 27316, 11479, 296, 631, 369, 14714, 6720, 11, 4768, 465, 25635, 517, 1017, 4, 785, 8655, 631, 3192, 14651, 3610, 13, 50790], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 710, "seek": 398794, "start": 3997.46, "end": 4002.78, "text": " Hay un catch que es que para sistemas de traducci\u00f3n distintos o traducciones no literales,", "tokens": [50840, 8721, 517, 3745, 631, 785, 631, 1690, 48720, 368, 2479, 1311, 5687, 49337, 277, 2479, 1311, 23469, 572, 20411, 279, 11, 51106], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 711, "seek": 398794, "start": 4002.78, "end": 4006.7400000000002, "text": " esto se rompe un poco, por ejemplo, para traducir entre ingl\u00e9s y chino, que en chino", "tokens": [51106, 7433, 369, 7438, 494, 517, 10639, 11, 1515, 13358, 11, 1690, 2479, 1311, 347, 3962, 49766, 288, 417, 2982, 11, 631, 465, 417, 2982, 51304], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 712, "seek": 398794, "start": 4006.7400000000002, "end": 4010.42, "text": " ni siquiera est\u00e1 claro cu\u00e1les son los l\u00edmites de las palabras y eso es m\u00e1s dif\u00edcil de ver.", "tokens": [51304, 3867, 1511, 35134, 3192, 16742, 2702, 842, 904, 1872, 1750, 287, 14569, 3324, 368, 2439, 35240, 288, 7287, 785, 3573, 17258, 368, 1306, 13, 51488], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 713, "seek": 398794, "start": 4010.42, "end": 4014.78, "text": " Entonces, bueno, este tipo de algoritmos no funcionan tan bien. Y bueno,", "tokens": [51488, 15097, 11, 11974, 11, 4065, 9746, 368, 3501, 50017, 3415, 572, 14186, 282, 7603, 3610, 13, 398, 11974, 11, 51706], "temperature": 0.0, "avg_logprob": -0.17457228342692058, "compression_ratio": 1.6595092024539877, "no_speech_prob": 0.23916487395763397}, {"id": 714, "seek": 401478, "start": 4014.78, "end": 4017.98, "text": " hay variantes que funcionan un poco mejor. As\u00ed que bueno.", "tokens": [50364, 4842, 3034, 9327, 631, 14186, 282, 517, 10639, 11479, 13, 17419, 631, 11974, 13, 50524], "temperature": 0.0, "avg_logprob": -0.22201049022185496, "compression_ratio": 1.228813559322034, "no_speech_prob": 0.005910498555749655}, {"id": 715, "seek": 401478, "start": 4021.1800000000003, "end": 4025.3, "text": " Hoy vamos a dejar por ac\u00e1 y vamos a continuar la pr\u00f3xima con modelos de traducci\u00f3n.", "tokens": [50684, 28664, 5295, 257, 24391, 1515, 23496, 288, 5295, 257, 29980, 635, 24096, 416, 2316, 329, 368, 2479, 1311, 5687, 13, 50890], "temperature": 0.0, "avg_logprob": -0.22201049022185496, "compression_ratio": 1.228813559322034, "no_speech_prob": 0.005910498555749655}], "language": "es"}