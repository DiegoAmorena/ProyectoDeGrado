{"text": " Bueno, bienvenidos. En la clase de hoy vamos a ver el tema de redes neuronales que, bueno, es como digamos, el estado del arte, lo que son las cosas de procesamiento del lenguaje natural en general hoy en d\u00eda se rosuelen con redes neuronales. Entonces, es un poco para continuar con lo que ve\u00edamos la vez pasada. Hab\u00edamos visto m\u00e9todos de clasificaci\u00f3n, hab\u00edamos visto que hab\u00eda algunos para clasificar cosas en categor\u00edas, hab\u00eda algunos secuenciales, hab\u00eda algunos que llamamos modelos del lenguaje y de los m\u00e9todos de clasificaci\u00f3n, en realidad, vimos en profundidad, nadie valles, pero vimos que hab\u00eda otro, por ejemplo, algo de la decisi\u00f3n, regresi\u00f3n log\u00edstica, Supervector Machines y redes neuronales y para los m\u00e9todos secuenciales tambi\u00e9n aparecian las reneonales, para los modelos del lenguaje tambi\u00e9n aparecian las reneonales. Entonces, como que las reneonales son un m\u00e9todo muy importante que es muy vers\u00e1til y se usa para muchas cosas. Entonces, nos vamos a concentrar un poco, vamos a dar en esta clase una introducci\u00f3n a lo que son las redes y adem\u00e1s ver c\u00f3mo se usan particularmente para el lenguaje. O sea, vamos a hablar las t\u00e9cnicas de vectores de palabras y c\u00f3mo aplicar eso a precisamente el lenguaje natural. Entonces, \u00bfc\u00f3mo empieza esto? Esto empieza inspirado en esto de ac\u00e1, que es una neurona biol\u00f3gica, esto lo habr\u00e1n visto en el hiceo, en biolog\u00eda. Una neurona es un tipo de c\u00e9lula del sistema nervioso de los animales. \u00bfQu\u00e9 tiene distintas partes? \u00bfC\u00f3mo se puede ver ah\u00ed? S\u00ed, puedo apuntar, o puedo apuntar. \u00bfAboquela con esto? Hay, tiene distintas partes, tiene como unos pelitos que entran dentro del cuerpo de neuronas que se llaman dendritas y despu\u00e9s tiene como una especie de cola que sale de la neurona que se llama acci\u00f3n y, bueno, ac\u00e1 en el centro tenemos lo que ser\u00eda el cuerpo de la neurona, el soma. Entonces, en esas por esas dendritas vienen impulsos el\u00e9ctricos, las dendritas act\u00faan como inhibidores o activadores, pero vienen impulsos el\u00e9ctricos, eso se condensan adentro del soma que sea el cuerpo y si se supera cierto un bral de actividad el\u00e9ctrica, entonces la neurona dispara un solo punto por el acci\u00f3n, un solo impulso el\u00e9ctrico por el acci\u00f3n, lo manda hacia afuera y ese acci\u00f3n est\u00e1 conectado a otras dendritas que est\u00e1n en otras neuronas. Entonces, esto tiene un mont\u00f3n de entradas, se condensan en el cuerpo de la c\u00e9lula, de la neurona, dispara un solo pulso el\u00e9ctrico para afuera y ese pulso el\u00e9ctrico viaja a otras neuronas. Entonces, como esas neuronas est\u00e1n conectadas en una especie de red, cada acci\u00f3n de una neuronas est\u00e1 conectada a las dendritas de otras, entonces la salida de una es la entrada de otras. Esto conforma una red dentro del cerebro o el sistema nervioso de los animales y eso es lo que componen una renauronal, en este caso una renauronal natural, una renauronal biol\u00f3gica. Entonces, en los a\u00f1os 40 se propuso la primera versi\u00f3n matem\u00e1tica de c\u00f3mo funciona una neurona, entonces hubo unos cient\u00edficos que dijieron, bueno, vamos a tratar de simplificar esto m\u00e1s posible, a estar a verlo y generar una versi\u00f3n en una ecuaci\u00f3n que trata de representar esto. Entonces, ellos dise\u00f1aron esta ecuaci\u00f3n de ac\u00e1, en la cual yo dice, bueno, vamos a cambiar esta neurona biol\u00f3gica que ten\u00eda todas estas partes y vamos a crear una especie de neuronar artificial en la cual yo tengo un conjunto de entradas, un conjunto de pesos de entrada que est\u00e1n ac\u00e1, que vendr\u00edan a hacer el equivalente a las dendritas. Voy a tener impulso el\u00e9ctrico de entrada que son como X1, X2, X3 hasta Xn, que digamos que son los inputs que va a tener esa neurona. Despu\u00e9s, en el centro lo que hago es sumarlos y en realidad lo que estoy sumando es el producto entre cada impulso de entrada y el peso correspondiente. Tambi\u00e9n le voy a agregar un valor de sesgo y despu\u00e9s la salida le voy a pasar por una funci\u00f3n de activaci\u00f3n y eso me va a dar la salida de la neurona. Bien, o sea, esta parte les vamos a estar viendo en detalle. Pero en definitiva, es como que yo tuviera esta ecuaci\u00f3n de abajo, \u00bfno? Yo tengo la sumatoria de las entradas multiplicadas por pesos, a eso le subo un sesgo, que se llama B y todo eso se lo aplico una funci\u00f3n sigma que es un poco que son esas funciones sigma. Entonces ven que es una, digamos, es como una ecuaci\u00f3n lineal, \u00bfno? O sea, la sumatoria ni de XC por WB sub y m\u00e1s B, todo eso es una, digamos, una f\u00f3rmula lineal y a eso le agrego un sigma, digamos, se lo aplica un sigma que esta va a ser una funci\u00f3n lineal. Bien, entonces, m\u00e1s adelante para simplificar esta ecuaci\u00f3n y para que despu\u00e9s queden m\u00e1s f\u00e1ciles de calcular las cosas, lo que se hace es decir, bueno, este valor que ven\u00edamos ac\u00e1, esta B que est\u00e1 sumando, que digamos se usa para que, ah\u00ed, esta B que est\u00e1 ac\u00e1, que se usa para que, digamos, para poder completar toda la ecuaci\u00f3n lineal, lo que se hace agregarla como un peso m\u00e1s, entonces decimos, bueno, tenemos una entrada m\u00e1s que vale uno y su peso correspondiente es el sesgo. De eso, en realidad, digamos, despu\u00e9s nos olvidamos. Cuando vamos a trabajar con estas cosas como que no utilizamos mucho el sesgo y nos concentramos en decir, bueno, vamos a tener un vector que son entradas, que son los X1 hasta XN y un mont\u00f3n de pesos que son los W1s WBN y adentro la neurona, lo que pasa es que voy a hacer el producto interro entre esos entre el vector X y el vector W y se lo voy a pasar a la funci\u00f3n sigma. Bien, entonces, esas funciones de activaci\u00f3n sigma hay varias, o sea, al principio, digamos, cuando dise\u00f1aron primero esta neurona, lo que se les hab\u00eda ocurrido primero era decir, bueno, yo lo que hago es sumar todas estas, digamos, todos estos impulsos multiplicados por los pesos, lo sumo y si esa suma supera cierto umbral, que el umbral lo podr\u00edan calcular o mucho que se ha utilizado en uno o en una de esas cosas, bueno, si supera cierto umbral, entonces mando uno para fuera y si no mando ser. Eso era lo primero que se le hab\u00eda ocurrido, pero bueno, despu\u00e9s empezaron a encontrar otras funciones que eran mejores para poder entrenar mejores arredes y en definitiva, como que no hay mucho criterio de qu\u00e9 restricciones que tiene que tener esa funci\u00f3n, salvo que tiene que ser derivable, tiene que ser, tiene que ir como de menos a m\u00e1s, digamos, puede ser de 0 a 1 o de 0 m\u00e1s infinito o de menos infinito m\u00e1s infinito y tiene que ser no lineal, tiene que tener alg\u00fan punto de no linealidad. Entonces, estas son algunas muy usadas, por ejemplo, la funci\u00f3n sigma o id o funci\u00f3n log\u00edstica, que es la misma que se usa, lo que estamos hablando de un rato, digamos, el m\u00e9todo de regresi\u00f3n log\u00edstica utiliza tambi\u00e9n esta funci\u00f3n, la tangente par\u00f3lica es otra, la funci\u00f3n relu es muy usada y la relu se define como el m\u00e1ximo entre 0 y 0, relu de 0 es el m\u00e1ximo entre 0 y 0, entonces vale 0 para todos los valores, excepto para cuando todos los valores menores que 0, pero cuando vale el mayor que 0, vale directamente el valor. Estas son unas funciones un poco esta\u00f1a, pues yo les dije que ten\u00edan que hacer todas derivables y esta justo no es derivable en el punto 0, pero despu\u00e9s es derivable en todo el resto de los reales. Bueno, ya hay otras m\u00e1s, pero estas como son como de las m\u00e1s utilizadas. Bien, lo importante ac\u00e1 es que estas funciones de activaci\u00f3n provenan una no linealidad y vamos a ver, \u00bfpor qu\u00e9? Ok, bueno, entonces vimos lo que era una neurona, imag\u00ednense que en general las neuronas se ponen como en grupos, digamos, y se distribuyen en capas dentro de una red, \u00bfno? Entonces, este es un ejemplo de una de las redes neuronales m\u00e1s simples, m\u00e1s simples que en realidad son \u00fatiles para algo, que se conoce como Perceptron Multi-Capa o Redfield Forward Multi-Capa, que funcione de la siguiente manera, \u00bfno? Nosotros tenemos todas las entradas, esas que yo les dec\u00eda que la centrada es X1, X2, X3, etc\u00e9tera, este Xn, ser\u00eda como una primera capa de entrada y despu\u00e9s yo ubico un mont\u00f3n de neuronas en una segunda capa y las capas que vienen despu\u00e9s de la entrada le voy a llamar capas ocultas, o sea, tengo una primera capa de entrada, esa capa lleva a una capa oculta y todas las neuronas de la capa oculta est\u00e1n interconectadas con todas las neuronas de la capa de entrada, o sea, hay pesos que van de todas a todas, despu\u00e9s puedo tener otra segunda capa oculta, otra tercera capa oculta, etc\u00e9tera, hasta que llevo a una \u00faltima capa que tambi\u00e9n est\u00e1 interconectada con la anterior, que es la capa de salida, bien, pero no hay enlaces que vayan entre la capa inicial y la capa de salida, digamos, la capa de entrada y la capa de salida, sino que siempre los enlaces van entre una capa y la siguiente, entonces ac\u00e1 yo digo que tengo una arquitectura en capas donde tengo este, en seg\u00fan esta imagen K, capas ocultas, tengo la capa oculta 1, capa oculta 2, capa oculta K y despu\u00e9s una capa de salida, bien, entonces esta es como la arquitectura m\u00e1s sencilla, yo tengo un mont\u00f3n de capas, una atr\u00e1s de otra y cada capa est\u00e1 completamente interconectada con la anterior, pero nunca saltan entre capas, bien, entonces analicemos un poco que es lo que pasa dentro de esas capas y para eso vamos a tratar de mirar la capa, bien, yo tengo entonces en esa imagen es como estamos viendo la frontera entre una capa y la siguiente, yo tengo la frontera de la capa W1, la capa y y la capa y m\u00e1s 1, entonces voy a decir que los estados de las neuronas en la capa y que llegan a la capa y son X1 super\u00ed, X2 super\u00ed, X3 super\u00ed, X4 super\u00ed, bien, eso va a ser el estado de la capa y y quiero calcular cu\u00e1l va a ser el valor de la capa y m\u00e1s 1 dado que el valor de la capa y era eso, entonces la capa y yo ten\u00eda que val\u00eda esto, X1 super\u00ed, X2 super\u00ed, X3 super\u00ed y creo que llegamos a 4, esta, X4 super, esto es un vector, bien, entonces recuerden como calcul\u00e1bamos el valor de una neurona, dec\u00edamos que por ejemplo para calcular la neurona que est\u00e1 y arriba que es X1 y m\u00e1s 1 el valor de esta neurona se calculaba como y ten\u00eda que hacer las sumas digamos de los inputs que est\u00e1 donde la de izquierdo por los pesos que llegaban hasta ah\u00ed, entonces en este caso son todas las neuronas que est\u00e1n en la capa y, todos los valores de la neuronas multiplicados por todos los valores de las flechitas, entonces ser\u00eda X1 super\u00ed por W y la flechita que est\u00e1 yendo desde la neurona 1 de la capa y hasta la neurona 1 de la capa y m\u00e1s 1 se llama W1, entonces X1 por W1, m\u00e1s la segunda capa, perd\u00f3n la segunda neurona de la capa y por el segundo peso, este era el 2, 1, el peso 2, 1, esto tambi\u00e9n es de la capa y m\u00e1s X3 por W3, uno, todo esto es de la capa y, m\u00e1s X4 por W4, uno, bien, entonces la salida X sub 1 de la capa y m\u00e1s 1 es el producto de todas estas ac\u00e1, bien, es el producto de la neurona 1 de la capa anterior por el peso 1, la neurona 2 de la capa anterior por el peso 2, 1, la neurona 3 de la capa anterior por el peso 3, 1, lo mismo puedo hacer para la otra, puedo decir X2 y ser\u00eda igual solo que cambiando ac\u00e1 cambiando los lugares a 2, entonces yo es X1 y por W1, 2 y, m\u00e1s 2 estos, m\u00e1s X4 y por W4, 2 y, bien, s\u00ed, decimos, ah\u00ed est\u00e1, cuando estamos en una arquitectura en capas como \u00e9sta es as\u00ed, cada de todas las neuronas de la capa siguiente est\u00e1n conectadas con la anterior, pero nunca saltan de capas, nunca cruzan hacia otra, y nunca vuelen hacia atr\u00e1s, que es otra cosa que puede pasar en otras arquitecturas de redes, pero esta que es la m\u00e1s simple es cada capa con la siguiente, bueno, entonces X3 ser\u00eda lo mismo, X1 y ac\u00e1 el peso 1, 3, tanda tata, X4, el peso 4, 3, s\u00ed, la dimensi\u00f3n es de ah\u00ed, los X son vectores de la carrera o de vez con reales, s\u00ed, o sea, no, ac\u00e1 son todos reales, X, todos los X y todos los doles son todos valores reales, entonces eso quer\u00eda llegar, yo tengo, X1, X2, X3, X4 son 4 valores reales que componen un vector, y si yo agarro todos los doles 1, 1, 2, 1, doles 3, 1, doles 4, 1, doles 1, doles 2, etc\u00e9tera, esto compone una matriz, en realidad, yo puedo construirme la matriz de la capa Y, es igual esta matriz que tiene dole 1, 1, hasta dole 4, 3, bien, W, 1, 3, W, 4, 1, bien, esto es una matriz, entonces al tener eso, en realidad yo puedo expresar la salida de esta capa, puedo expresar los estados en los cuales digamos los valores en los que quedan las neuronas de la capa siguiente, los puedo expresar como un producto de matrices, yo digo, el vector en la capa Y era esto, entonces el vector en la capa Y m\u00e1s 1 va a ser el producto de XC por WI, digamos esto termina siendo un producto de matrices, si hace el producto de matrices me dar\u00eda X1 por W1, X2 por W1, X3 por W3, 1, X4 por W1, que es lo mismo que est\u00e9 ac\u00e1, y si vamos con la segunda columna, me da el mismo de ac\u00e1, y si vamos con la tercera columna, me da el mismo de ac\u00e1, pero es en definitiva la salida de esta capa, digamos si yo tengo esa neuron ah\u00ed, la salida de la capa, a ver d\u00f3nde les creo, les pido ac\u00e1 porque esto nos va a tener que quedar para despu\u00e9s para poder mirarlo, pero bueno, tengo X subra\u00ed, este es el vector de entrada, y voy a poner ac\u00e1 copiar la matriz esta, W1 1 hasta W4 1, W4 3, W1 3, la matriz, entonces, digo que el valor de X y m\u00e1s 1 va a ser el valor en Y por la matriz que representa los pesos de la capa Y, y a esto lo que me falta agregarle es el sigma, que es la funci\u00f3n de activaci\u00f3n y el sigma tambi\u00e9n puede pertenecer a la capa y digamos yo puedo tener distintas funciones de activaci\u00f3n por capa, bien, entonces, concentremos en esto, decimos que si yo tengo una arquitectura en capa, donde cada capa est\u00e1 conectada con la anterior, digamos todas las neuronas una capa est\u00e1n conectadas con todas las neuronas de la anterior, entonces, puedo calcular la activaci\u00f3n o los valores que va a tener la capa Y m\u00e1s 1 en funci\u00f3n de la capa Y con esta formula ac\u00e1, as\u00ed que supongamos que tengo, eso creo que es exactamente lo mismo que dice ac\u00e1, ah\u00ed est\u00e1, tengo esa entrada, la salida va a ser ese vector, digamos, de tres neuronas y tengo esos pesos, por lo tanto puedo calcularlo de esta manera, bien, entonces supongamos que tengo una arquitectura que tiene tres capas, o m\u00e1s, digamos, tiene dos capas ocultas, entonces eso significa que si tengo dos capas ocultas voy a tener una matriz de pesos, que le voy a llamar W1 y una matriz de peso que le voy a llamar W2, entonces me va a venir un vector X que va a ser un vector que tiene un mont\u00f3n de trabajo, X1 hasta Xn, esto es un vector, quiero ver cu\u00e1l va a ser la salida de la red suponiendo que tengo una capa de pesos W1 con una funci\u00f3n de activaci\u00f3n sigma 1 y una capa de pesos W2 con una funci\u00f3n de activaci\u00f3n sigma 2, c\u00f3mo me quedar\u00eda la salida de la red, digamos, de qu\u00e9, cu\u00e1l ser\u00eda la f\u00f3rmula para la salida de la red, vamos a llamarle Rn de X a la salida de esta red que es una red que tiene dos capas ocultas y tiene esa estructura, est\u00e1 estructura en capas, \u00bfqu\u00e9 les parece? S\u00ed, ah\u00ed est\u00e1, X por del V1 y esto le aplicamos sigma 1, y despu\u00e9s esto multiplicamos por W2, ah\u00ed est\u00e1, la hacemos W2 y le pasamos sigma 2, exacto, bien, entonces eso ser\u00eda, digamos, la ecuaci\u00f3n que te queda de una arquitectura con dos capas ocultas, y bueno, la salida se calcular\u00eda de esta manera, tenemos el vector X, el vector X que le multiplicamos por los pesos de la capa 1, despu\u00e9s le pasamos la funci\u00f3n de activaci\u00f3n, a esa resultado le multiplicamos por los pesos de la capa 2 y le aplicamos la funci\u00f3n de activaci\u00f3n y esa es la salida. Si tuvieramos m\u00e1s capas, si esto fuera un perceptro multicapa de 30 capas, entonces tendr\u00edamos como m\u00e1s a\u00f1adimiento en esto, pero m\u00e1s o menos el camino. Bien, entonces \u00bfqu\u00e9 pasar\u00eda si estas funciones de activaci\u00f3n fueran la funci\u00f3n identidad o fueran funciones lineales como multiplicar por 4 o algo del estilo, \u00bfqu\u00e9 pasar\u00eda en ese caso? Ah\u00ed est\u00e1, en ese caso, si esto fuera la identidad o si fuera multiplicado por una constante, pero supongamos que fuera la funci\u00f3n identidad, entonces ac\u00e1 esto me dar\u00eda lo mismo que hacer X por W1 por W2, que es lo mismo que hacer X por una cosa que es un producto entre dos matrices y un producto entre dos matrices vea otra matriz, entonces si estas funciones fueran una funci\u00f3n identidad o fueran una funci\u00f3n lineal o fueran una funci\u00f3n de esas, digamos, simples, entonces todo esto ser\u00eda una ecuaci\u00f3n lineal, o sea yo podr\u00eda reescribirlo siempre como el producto entre un vector y una matriz, que es un sistema lineal. Bien, esa es la raz\u00f3n por la cual se necesita que estas cosas acasean no lineales, que era lo que les dec\u00eda que bueno, casi que el \u00fanico requisito que tienen es tener estas funciones de activaci\u00f3n es que sean no lineales, porque si son lineales cuando yo empiezo a arquitecturar estas cosas en capas, me queda simplemente un producto de matrices, porque me interesa que sea no lineal y porque, o sea, me molesta que esto sea un sistema lineal, porque si yo tengo un sistema lineal, digamos, si yo tengo que el resultado de mi red lo puede expresar como X por una matriz, entonces bueno, hay cierta clase de problemas, que voy a poder resolver, pero todos los problemas que son no lineales, todos los problemas que no se pueden capturar por una estructura lineal, entonces no lo puedo resolver. Bien, s\u00ed. Incluso sin la activaci\u00f3n, o sea, es una reneural que no tiene que ir a ninguna, o sea, simplemente es multiplicar un vector por un conjunto de pesos. Bien, entonces, si yo tengo solamente una funci\u00f3n lineal, hay un conjunto de problemas que puedo modelar, es verdad, pero no son todos, y de hecho no lo vamos a ver, pero hay una demostraci\u00f3n que dice que teniendo funciones de activaci\u00f3n no lineales, alcanza incluso con tener una sola capa oculta y alguna cosita m\u00e1s para modelar cualquier tipo de funci\u00f3n que habiamos interese, digamos, con ciertas propiedades, por lo menos que se ha continuo en siento intervalo, etc\u00e9tera, pero asumiendo ciertas propiedades bastante normales, es posible incluso con una sola capa, con una cantidad ruitada de neuronas, modelar cualquier funci\u00f3n posible. Y eso es un poco el poder que tiene las reneurales, en realidad, son como suficientemente flexibles como para modelar cualquier cosa, cosa que cuando ve\u00edamos, bueno, no hay valles, era un ejemplo que modelaba ciertos tipos de problemas, si miran regresi\u00f3n log\u00edstica, podemos modelarse de dos tipos de problemas, pero algunos no, las reneurales en calidad son super flexibles y podemos modelar cualquier cosa. Entonces, sabemos que, para casi cualquier funci\u00f3n que a\u00fan no le interese modelar, existe una reneural que podr\u00eda llegar a cumplirla con suficienta nivel de precisi\u00f3n, que vamos ah\u00ed, teor\u00eda y m\u00e1s que les muestran, sin embargo, encontrarla en la pr\u00e1ctica no es tan f\u00e1cil, o sea, sabemos que existe una, la familia de la reneurales, hay alguna funci\u00f3n que me va a permitir hacer todo lo que quiera, pero bueno, de all\u00e1 encontrarla no es tan sencillo, pero bueno, por lo menos sabemos que existe. Igual, con estas cosas que tenemos, o sea, sabiendo lo m\u00e1s que es arquitecturando en capas y teniendo la funci\u00f3n de activaci\u00f3n no lineal en cada una, ya ten\u00e9s un mont\u00f3n de funciones interesantes que pueden servir para modelar muchas cosas. Bien, preguntas ac\u00e1. Bueno, estas otras funciones de activaci\u00f3n interesante que se conoce como la funci\u00f3n softmax, se utiliza para los problemas de clasificaci\u00f3n discretos, por ejemplo, hay que tener en el segundo obligatorio que, bueno, es el problema de clasificar un tweet y lo quiero clasificar en si es positivo, negativo, neutro o nada, no, tengo esas cuatro clases. Entonces, la funci\u00f3n de activaci\u00f3n softmax es como una generalizaci\u00f3n de la funci\u00f3n log\u00edstica de la sigmoide, que se calcula de esta manera, dice bueno, yo asumo que los pesos de salida, que son n\u00fameros reales, van a formar una probabilidad, digamos, lo quiero transformar en una probabilidad, entonces lo calcula de manera, digo que el valor para y su y su v es e a la y su v sobre la sumatoria de e a la el resto. Esto solamente para que lo tengan en cuenta, es muy probable que si van a usar rengebranales en la segunda tarea, tengan que utilizar al final una capa, que se llama capas softmax, que es una capa que tiene una funci\u00f3n de activaci\u00f3n especial que sirve para transformar las salidas en distribuci\u00f3n de probabilidad. S\u00ed, y la mayor, si tiene una distribuci\u00f3n de probabilidades, y bueno, la sociedad que tiene probabilidad mayor, ah\u00ed tienes que tener una, ser\u00eda como una log\u00edstica independiente por cada una. Entonces, si es mayor que cero, digo que es valido, si no, o sea, si voy a decir que puedo tener m\u00e1s de un label a la vez, ah\u00ed tendr\u00edas que hacer otra cosa. En softmax, va a intentar que sea una distribuci\u00f3n de probabilidades, entonces probablemente te queda una clase que gane y las dem\u00e1s sea mucho m\u00e1s bajitas. Bien, bueno, entonces, recuerden que estamos siempre utilizando n\u00fameros, por ahora no hemos visto nada del lenguaje, eso lo vamos a ver un poco m\u00e1s adelante, ahora son todos n\u00fameros. En la entrada me vienen n\u00fameros reales, en los pesos tengo n\u00fameros reales, hago multiplicaciones, le paso funciones de activaci\u00f3n, etc\u00e9tera, y me da otro vector de n\u00fameros reales, o sea, la salida de esto va a ser un vector de n\u00fameros reales, tener en cuenta que cada una de estas cosas van a tener sus dimensiones, yo voy a tener, ac\u00e1 ten\u00eda una entrada que ten\u00eda cuatro vectores, para cuatro valores, una matriz que ten\u00eda cuatro por tres, entonces al multiplicarlo me devuelve tres, si la siguiente capa es de tres por ocho, entonces me va a volver ocho y as\u00ed, o sea, los tama\u00f1os de las matrices, o sea, los tama\u00f1os de las capas tienen que coincidir. Pero en definitiva son todos vectores, \u00bfno? Por ahora, esto es un c\u00e1lculo utilizando c\u00e1lculo num\u00e9rico vectorial. Entonces, vamos a hablar un poco de c\u00f3mo se entrenan estas redes, y vamos a pensar de la siguiente manera, \u00bfc\u00f3mo esto es un m\u00e9todo de aprendizaje autom\u00e1tico? Yo voy a tener, como vimos en las clases anteriores, voy a tener un conjunto de entrenamiento, un conjunto de desarrollo, un conjunto de test, entonces supongamos que yo tengo un conjunto de entrenamiento que tiene en ejemplos, o sea, en ejemplos significa que voy a tener en estos vectores y en salidas distintas, que les voy a llamar y, entonces, los vectores de entrada son estos, los vectores de salidas son estos de ac\u00e1, y yo tengo que tratar de ver si la salida se parece al entrada. Entonces, supongamos que la salida es solamente un valor, \u00bfno? O sea, para simplificar, vamos a asumir que la entrada de la red es un vector de cualquier dimensi\u00f3n, y la salida solamente es un valor real, \u00bfno? Es posible, \u00bfno? O sea, lo que estoy haciendo es tener una red que tiene muchas capas, lo que sea, en el final, todo se reduce a una sola salida un valor real, obviamente esto despu\u00e9s se extiende a m\u00e1s valores reales, pero bueno, supongamos que tenemos una sola, \u00bfno? Entonces digo que tengo en instancias, o sea, en valores x v, este es mi conjunto de entrenamiento, supongamos, o el conjunto en el que estoy tratando de medir cosas x v y me dice que esto es x v, deber\u00edan corresponderse con diferentes valores de x v, \u00bfno? Este es el conjunto de valores esperados, yo digo que para x v 1 tengo un y v 1, para x v 2 tengo un y v 2, bien, por ahora son todos n\u00fameros reales, y adem\u00e1s tengo que yo tengo una red neuronal con ciertos pesos, que se la puedo aplicar a x v y con sus matrices de pesos, entonces mi red neuronal me va a dar cierto valor y le voy a llamar y sub\u00ed techo, \u00bfc\u00f3mo puedo saber si est\u00e1 bien lo que me da la red neuronal para x v o no? De qu\u00e9 manera yo puedo llegar a medir si est\u00e1 bien o no, este valor que me dio. Si, ah\u00ed est\u00e1, o sea, mi salida, en mi conjunto yo dec\u00eda, bueno, la salida ten\u00eda haber sido y sub\u00ed, y la salida de medio de la red es y sub\u00ed techo, \u00bfc\u00f3mo puedo saber si ese est\u00e1 bien o mal? O sea, \u00bfqu\u00e9 medida me dice si est\u00e1 bien o mal? Ah\u00ed est\u00e1, lo puedo restar y digo bueno, \u00bfqu\u00e9 tanto se parecen estos dos? Si esto est\u00e1 cerca de cero, es un valor muy chiquito, entonces yo puedo decir que estas dos cosas son iguales, por lo tanto la red me est\u00e1 dando un resultado parecido al que yo esperaba, y si estos dos son muy diferentes, entonces esto me va a dar un valor bastante alto, entonces yo tengo muchos de estos, no tengo n ejemplos de este estilo, as\u00ed que lo que voy a hacer es sumar todos estos, de igual 1 hasta n, sumo todos los valores, tengo un problema ac\u00e1 que es que a veces yo puedo le puedo ahorrar por mucho, a veces le puedo ahorrar por poco, pero a veces esto me va a dar negativo, esto me va a dar positivo, entonces si yo lo sumo todos capaz que me da cero por casualidad, entonces lo que hago es ponerlos acuadrado, para decir bueno, yo siempre voy a sumar valores positivos, entonces si mi salida es distinta, el valor esperado siempre esto me va a dar un resultado positivo, bien, entonces como estoy comparando n ejemplos, a esto lo voy a dividir entre n, esto de ac\u00e1 me da una m\u00e9trica condensada que me dice que tanto se equivoco mi red respecto a los valores, a todos los valores esperados, y de hecho esta es una de las m\u00e9tricas posibles para medir eso, esta es muy usada, se llama mce, minzcuerderor o error cuadratico medio y es una de las m\u00e9tricas m\u00e1s conocidas, entonces esto es una m\u00e9trica que me permite medir la discrepancia que hay entre los valores esperados de una red ac\u00e1 era isu y, entre los valores esperados de una red y los valores que la red dio con todos los pesos que tiene hasta el momento, recuerden que este isu y se calculaba como el resultado de la red para exu y los pesos de red, entonces este tipo de funciones que miden la diferencia entre los valores esperados y los valores que me dio la red de verdad se llaman funciones de perdida, bien, o sea el nombre de perdida no se movien de donde sale, pero se le fue, se le suele llamar funciones de perdida los functions y bueno es uno de los conceptos que no tiene que aprender cuando aprende de redes neuronales, porque para entrenarlas yo lo que tengo que hacer es elegir una los function apropiada para problemas, entonces estas de las m\u00e1s comunes, el error cuadratico medio sirve mucho para problemas donde los valores resultados son valores reales, no sirve tanto para cuando los valores esperados resultantes son por ejemplo una distribuci\u00f3n de probabilidades o una categor\u00eda en muchas como ese problema que tienen en el laboratorio, para eso utiliza notas, por ejemplo la entrop\u00eda cruzada o en particular una versi\u00f3n de entrop\u00eda cruzada que sirve para decir yo tengo un solo valor correcto de entre muchos que en el laboratorio les pasa eso digamos que tengo un tweet y es positivo o en negativo o en neutro no puede ser m\u00e1s de une, entonces para eso se usa la \u00faltima, es una versi\u00f3n de la entrop\u00eda cruzada para valores categoricos, bien y existen unas cuantas m\u00e1s digamos, o sea pero en definitiva siempre tengo que tener funciones de estilo como pasaba con la funci\u00f3n de activaci\u00f3n lo que se espera de una funci\u00f3n de perdias es que sea derivable y en el caso de las funciones de perdias lo que se espera es que cuando la salida de la red se parece much\u00edsimo a los valores esperados, tiene que estar cercana a cero o tiene que ser un valor m\u00ednimo y cuando la salida de la red es muy diferente tengo que ser un valor m\u00e1s grande, bien, ok entonces \u00bfpor qu\u00e9 es que yo quiero que todo esto sea derivable? \u00bfPor qu\u00e9 les parece? S\u00ed, es exacto para minimizar el hecho de que yo voy a hacer que esto sea derivable digamos que lo que est\u00e1 dentro o sea este es y su techo y sub\u00ed techo menos y sub\u00ed y esto lo calcul\u00e9 con esto que est\u00e1 ac\u00e1 entonces esto es una sobre n por la sumatoria de 1 esta n de una cosa que ten\u00eda la forma sigma de sigma de sigma de x por w a la 1 por w2, no s\u00e9 qu\u00e9 menos y sub\u00ed al cuadrado, bien entonces ac\u00e1 entonces yo ten\u00eda una cosa que era todo derivable y ac\u00e1 afuera tengo otra funci\u00f3n que tambi\u00e9n es derivable tanto de las funciones de activaci\u00f3n como todos los resultados de la red nominal como la funci\u00f3n de perdias como todas estas cosas son todos derivables para que quiero eso porque efectivamente voy a derivar digamos o sea la t\u00e9cnica se utiliza para entrenar estas cosas se basa mucho en encontrar derivadas y vamos a dotar de ver por qu\u00e9 bien entonces para entrenar una de estas redes recordemos que digamos para entrenar estas redes yo recordemos que tengo conjunto de entrenamiento, un conjunto de desarrollo, un conjunto de test y me interesa tratar de minimizar esto o sea yo tengo que la red se calcula como dependiendo de el valor de entrada y el conjunto de pesos que tengo yo voy a multiplicar ese valor de entrada por una matriz y por otra por la funcional activaci\u00f3n etc\u00e9tera hasta obtener un resultado pero entonces notar que este valor est\u00e1 en funci\u00f3n de la entrada que es que es que es subir y el conjunto de pesos o leve, no ac\u00e1 yo tengo una funci\u00f3n que es que est\u00e1n funci\u00f3n de dos cosas estas son las entradas de conjunto de entrenamiento o del conjunto que estoy mediendo y estos son los pesos que yo le puedo dar a cada una de las capas entonces una cosa interesante es que yo puedo mirar este problema desde el punto de vista de que estos valores los dej\u00f3 fijos digo mi conjunto de entrenamiento lo conozco entonces los valores est\u00e1n fijos y yo puedo ir cambiando los pesos hasta encontrar el conjunto de pesos ideales que permita que los valores de entrenamiento multiplicados por esos pesos me den la sal\u00eda que yo quiero entonces ah\u00ed eso se transforma en un problema como dec\u00edan por ah\u00ed un problema de demonizaci\u00f3n, un problema de optimizaci\u00f3n en el cual lo que voy a hacer es tomar esto como variable entonces yo lo que quiero encontrar es el argmin para la familia posible de pesos de las distintas matrices lo leve de esta funci\u00f3n ac\u00e1 que es uno sobre n por sumatoria nn y subitecho menos y sub\u00ed al cuadrado bien y voy a encontrar el argmin en w o sea lo que est\u00e1 ac\u00e1 dentro que es rn de xc w le voy variando estos w hasta que hasta encontrar el ideal bien entonces supongamos que tengo una funci\u00f3n as\u00ed no vamos a ver una funci\u00f3n bastante simple como para ver c\u00f3mo funciona esto el entrenamiento de una red se da utilizando una t\u00e9cnica de llama de senso por gradiente hay otras t\u00e9cnicas pero estas por lejos la m\u00e1s utilizada de todas y la t\u00e9cnica de senso por gradiente funcione la ciente manera si yo tuviera una funci\u00f3n que va solamente en una dimensi\u00f3n y quiero minimizarla y arranco con un punto por ac\u00e1 digo bueno mi peso inicial me dice que voy a terminar en este lado entonces yo puedo calcular la derivada en ese lado y decir bueno para aquel lado voy bajando mi funci\u00f3n de costo o sea suponiendo que esta es la funci\u00f3n de p\u00e9rdida o funci\u00f3n de costo puedo decir para aquel lado voy bajando mi funci\u00f3n de p\u00e9rdida y dice bueno lo voy bajando si bajo por esta dimensi\u00f3n si bajo por esta direcci\u00f3n entonces ah\u00ed le digo bueno baja un poquito por ah\u00ed y calculame otro valor que va a estar ac\u00e1 y ah\u00ed devuelta voy a calcular la derivada y digo bueno en qu\u00e9 sentido voy bajando y se voy bajando si voy para all\u00e1 entonces ah\u00ed me encuentro tu valor que este en esa direcci\u00f3n calculo de vuelta la derivada y as\u00ed o sea yo puedo ir iterando de esta manera hasta llegar a un m\u00ednimo bien eso me llama de senso por gradiente porque yo tengo quiero encontrar el m\u00ednimo de una funci\u00f3n supongamos que esta es mi funci\u00f3n de p\u00e9rdida y empec\u00e9 teniendo este valor calculo donde est\u00e1 la direcci\u00f3n en la cual puedo bajar m\u00e1s y voy movi\u00e9ndome por ah\u00ed hasta llegar al punto bajo esto es un caso ideal en el cual yo tengo una sola variable que estoy tratando de encontrar en el caso real yo estoy minimizando digamos minimizando esta funci\u00f3n respecto a W que es una cosa que son muchas matrices con muchos pesos con muchas cosas y pueden llegar a hacer miles de millones de pesos pero bueno en un caso ideal si yo estuviera solamente minimizando una sever\u00eda de esta manera cuando yo estoy minimizando millones de variables a la vez lo que pasa es que esta superficie digamos lo que tengo ac\u00e1 no va a ser una curva tan linda sino que va a ser una superficie rusa que tiene un mont\u00f3n de de de \u00f3ptimos locales que no me van a servir pero cuando yo hago este algoritmo lo que va a hacer es caerse en un \u00f3ptimo local imag\u00ednense que si esta curva tuviera esta forma entonces este algoritmo llegar\u00eda a un \u00f3ptimo local por ac\u00e1 pero se perder\u00eda el \u00f3ptimo global que estaba por ac\u00e1 bien eso es algo que puede pasar entonces bueno no se asusten que cuando uno entra en una rena uronal nunca va a estar seguro de que encontr\u00e9 el \u00f3ptimo posible de toda la red de todas las posibles sino que bueno tengo que conformarme con encontrar una bastante buena probando varias veces bueno entonces dec\u00edamos esto sobre entrenamiento el entrenamiento intenta encontrar los pesos que minimizan esta funci\u00f3n de perdiado o sea la combinaci\u00f3n de matricios olv que hace que esta funci\u00f3n sea lo menor posible la t\u00e9cnica se utiliza el senso por gradiente que es lo que est\u00e1 mencionando ac\u00e1 se usa una cosa de llamas de senso por dancias estoc\u00e1stico que se trata de agarrar cada punto yo agarr\u00f3 cada punto de entrada y trato de hacer el senso por gradiente consiguiendo solamente ese punto y despu\u00e9s agarr\u00f3 otro punto de entrada y luego varias veces el problema que tiene eso es que es superlento o sea es como que tiene buena propiedad de convergencia pero es superlento entonces lo que se hace es hacer de senso por gradiente en lote o en batches que significa bueno en vez de tomar todo el conjunto de entrenamiento que puede tener 100 mil millones de ejemplos tomo de a 120 o no s\u00e9 200 o elijo un batch que digo bueno tomo este conjunto de ejemplos y hago de senso por ah\u00ed despu\u00e9s tomo otro conjunto de senso por la gente por ah\u00ed y hasta llegar a un \u00f3ptimo bien los siguientes backpropagation entonces yo les dije hasta ahora que todas las cosas ten\u00edan que ser derivables y el hecho de que sean derivables implica que lo vamos a derivar en alg\u00fan momento no vamos a hacer ac\u00e1 ninguna derivada digamos porque en realidad los paquetes que se utilizan para trabajar con estas con estas cosas en realidad son paquetes que permiten hacer derivaci\u00f3n autom\u00e1tica o sea toda la gracia de construir redes neuronales utilizando ciertas librer\u00edas es que las librer\u00edas permiten definir todas estas cosas como vectores y despu\u00e9s ellos hacen las derivadas autom\u00e1ticamente calculan todo autom\u00e1ticamente pero en definitiva la t\u00e9cnica que se usa para calcular se llama propiedad que implica que cuando yo voy calculando los pesos de una red para los valores de una red yo digo el lo que tornen lo multiplico por del V despu\u00e9s le paso la funci\u00f3n de activaci\u00f3n lo multiplico por otra V le paso la funci\u00f3n de activaci\u00f3n a medida que voy calculando eso voy dejando como todos los valores intermedios esos valores se usan de atr\u00e1s para adelante por el llamado propiedad y son para calcular las derivadas porque en realidad todos los valores de sumas multiplicaciones etc\u00e9tera que yo fui dejando el medio se utilizan como que siempre calculan para despu\u00e9s calcular la derivada y el vaculopadillo es una t\u00e9cnica que me ayuda a hacer eso r\u00e1pidamente bien entonces esta es la pregunta que le dec\u00eda hoy yo puedo encontrar la mejor funci\u00f3n posible puedo contar la mejor reneuronal que explique mi problema 100% bien la verdad que no porque en general este proceso se cae en \u00f3ptimos locales y este tipo de funciones que tienen miles de millones de par\u00e1metros lo que pasa que tiene much\u00edsimos \u00faltimos locales y bueno el entrenamiento se va a caer siempre en un \u00f3ptimo local lo que no hace para evitar eso de alguna manera es por ejemplo entrenar varias veces una misma red diciendo bueno tengo una misma r\u00e9cola, los mismos par\u00e1metros le entren\u00f3 muchas veces y veo cual cual le fue mejor de todos los entrenamientos esa es una de las formas y el otro problema detiene es el sobre ajuste creo que no lo mencionamos en la clase anterior sobre ajuste significa que las reneuronales tienen un problema que lo tienen otro m\u00e9todo de clasificaci\u00f3n pero las reneuronales es en particular porque como que son muy vers\u00e1tiles y es que se pueden aprender muy f\u00e1cil todo el conjunto de entrenamiento yo puedo entrenar una red que se aprenda muy bien en conjunto de entrenamiento y me diga s\u00ed para este X le corresponde este I y anda b\u00e1rbaro y el la funci\u00f3n de los vea casi cero y sin embargo lo pruebo en conjunto de test y le va horrible y eso es muy f\u00e1cil porque como les dec\u00eda como las reneuronales pueden modelar cualquier tipo de funci\u00f3n entonces es muy f\u00e1cil que se aprendan todo el conjunto de entrenamiento y despu\u00e9s para el conjunto de tele vaya espantoso ese ese fen\u00f3meno se llama sobre ajuste entonces bueno hay como distintas t\u00e9cnicas para tratar de evitarlo y que la red no digamos no sea ajustes a los datos sino que se va a generalizar m\u00e1s etc\u00e9tera bien entonces s\u00ed es una pregunta interesante en realidad hay un conjunto de t\u00e9cnicas que sirven para decir yo puedo entrenar una red con un conjunto de datos m\u00e1s amplio que capaz que no est\u00e1 el todo correcto y despu\u00e9s una vez que tengo una red de entrenada la entreno de vuelta con un conjunto m\u00e1s chico pero que tiene mejor calidad y eso da mejor resultado que entrenarla directamente con el conjunto m\u00e1s chico o con otro tipo de datos entonces de ah\u00ed hay variante es cierto que una red una vez que ya consegu\u00ed los pesos de la red lo puedo seguir entrenando usando otros conjuntos y eso es valido o sea se usa es una t\u00e9cnica que se usa y est\u00e1 buena porque da buenos resultados bien igual en atare de ustedes no s\u00e9 no s\u00e9 si va a la pena hacerlo o sea probablemente si van a entrenar reneurales lo hacen lo van con los datos que tienen no no creo que sean necesarios a mucha cosa m\u00e1s pero s\u00ed tratar de ver un poco lo que vamos a ver ahora que hasta ahora vieron que estamos viendo n\u00fameros reales o sea entra a un vector de n\u00fameros reales sal\u00edan n\u00fameros reales vectores de n\u00fameros reales s\u00ed s\u00ed s\u00ed s\u00ed s\u00ed se usan a veces en la pr\u00e1ctica da mejor resultado probar varias veces y o hacer una prueba digamos tipo grid search en el cual digo tengo tantos par\u00e1metros y probar con todos o aleatoriamente probar asampliando distintos par\u00e1metros y entrenar es cierto que tambi\u00e9n se usan meteor\u00edsticas evolutivos y algunas otras para tratar de optimizar la red pero no s\u00e9 en la pr\u00e1ctica si es que dan tan buenos resultados o simplemente ir probando con distintas combinaciones andando mejor bueno o general encontrar buenos resultados igual s\u00ed s\u00ed s\u00ed s\u00ed bueno claro pero el problema es que la funci\u00f3n de p\u00e9rdida no va a tener un \u00f3ptimo global normalmente no va a tener porque la funci\u00f3n de p\u00e9rdida tiene esta cosa en el medio no estoy minimizando una cosa que es algo no lineal y que tiene millones de par\u00e1metros y yo puedo ir en la direcci\u00f3n de cualquiera de los millones de par\u00e1metros entonces por eso normalmente digamos eso te genera una superficie super rubosa que tiene un mont\u00f3n de de su d\u00eda as\u00ed bajada por todos lados y justo en boca la el \u00f3ptimo global es muy dif\u00edcil o sea nada te garantiza que puedas tener el \u00f3ptimo global claro s\u00ed s\u00ed pero ac\u00e1 queremos esplicitamente que la funci\u00f3n de activaci\u00f3n sea algo que me deje la funci\u00f3n complicada digamos si vos claro si claro si vos hace que la funci\u00f3n de activaci\u00f3n sea tan simple que esto queda como una funci\u00f3n convexa entonces pierde capacidad de generalizaci\u00f3n la red por eso se dice tambi\u00e9n que esto es un problema de optimizaci\u00f3n no convexa entonces en optimizaci\u00f3n convexa uno puede asegurar que siempre tenemos un \u00f3ptimo global y lo podr\u00edamos llegar a encontrar con alguna t\u00e9cnica pero esto es la minimizaci\u00f3n no convexa la forma de la gr\u00e1fica siempre va a tener subidas y bajadas en alg\u00fan lado bien m\u00e1s preguntas ac\u00e1 entonces pasemos a la parte del lenguaje bien dec\u00edamos hasta el momento ten\u00edamos una reneuronal que a la cual le entraban valores reales y sal\u00edan valores reales pero nosotros en realidad nos interesa trabajar con texto nos interesa trabajar con palabras oraciones documentos tweets en el caso del oriatorio y el problema de este que tenemos una red que le entra valores reales no es un problema raro digamos un problema que le pasa a la mayor\u00eda de los m\u00e9todos de prenses autom\u00e1ticos y estuvieron mirando algo de regresi\u00f3n log\u00edstica etc\u00e9tera siempre yo tengo que mandarle valores reales a las cosas salvo en la iglesia es que m\u00e1s o menos uno puede decir bueno trabajo con palabras o sea como en la extracci\u00f3n esto trabaja en nivel de palabras en el resto siempre est\u00e1 esperando que yo le mande valores num\u00e9ricos entonces yo necesito poder tener una buena representaci\u00f3n num\u00e9rica de los textos y de paso voy a pedir una propiedad m\u00e1s que es que esa representaci\u00f3n num\u00e9rica tenga algunas propiedades interesantes como por ejemplo una m\u00e9trica de distancia que haga que las palabras m\u00e1s cercan las palabras m\u00e1s similares y este m\u00e1s cerca y la m\u00e1s diferente de este m\u00e1s lejos por ejemplo puedo pedir eso en una en una representaci\u00f3n entonces vamos a ver una t\u00e9cnica de llamar warden bedings o vectores de palabras que se utiliza para representar las palabras y despu\u00e9s eso lo pudo utilizar como entrada una red y la t\u00e9cnica se basa en la hip\u00f3tesis distribucional que son hip\u00f3tesis que surgi\u00f3 en los 50 con este Firth que era un linguista l\u00f3gico etc\u00e9tera y dec\u00edan lo siguiente bueno las palabras que aparecen en contextos similares tienden a tener significados similares y ac\u00e1 tenemos un ejemplito que dice este ejemplito tiene como algunas palabras y algunas ideas de contexto no la milanesa con queso m\u00e1s rica la uruguayas si es rica la hamburguesa con queso la milanesa con queso musarelas le decimos una politana no s\u00e9 qu\u00e9 est\u00e1 eso como que est\u00e1 hablando de milanesas hamburguesas comida y despu\u00e9s el otro dice el auto\u00f1o es una de las citaciones del a\u00f1o el verano es mi situaci\u00f3n de favoritas el invierno en invierno hace pila de fr\u00edo en verano nunca hace fr\u00edo y est\u00e1 hablando como de otra cosa no claramente las palabras rojas se parecen m\u00e1s entre s\u00ed las palabras azules se parecen m\u00e1s entre s\u00ed entonces idealmente yo quer\u00eda tener una representaci\u00f3n que a las rojas las deje m\u00e1s o menos cerca y a las azules violetas las deje m\u00e1s o menos en otro lado bueno una primera idea que surg\u00eda es lo que se conoce como matriz t\u00e9rmino t\u00e9rmino que se se realiza contando palabras contando cuando una palabra parece cu\u00e1nta vez aparece una palabra en el contexto de otra entonces por ejemplo en este caso yo digo yo tomo alrededor de una palabra en palabras de contexto alrededor y cuento cu\u00e1nta vez se aparece otra en ese contexto entonces como ejemplo tenemos bueno estos son los ejemplos anteriores no la milanesa con queso m\u00e1s rica la hamburguesa no s\u00e9 qu\u00e9 el auto\u00f1o tal cosa y pregunta c\u00f3mo quedar\u00eda la matriz utilizando un contexto de cuatro palabras y ac\u00e1 no s\u00e9 si lo llevan a ver todos pero me aparece que por ejemplo la palabra milanesa tiene las palabras rica y queso en su contexto de la palabra hamburguesa tambi\u00e9n pero la palabra to\u00f1o no la palabra to\u00f1o tiene en su contexto bueno ac\u00e1 justo como estoy tomando en igual cuatro no pasa pero las palabras verano y invierno tienen en su contexto la palabra fr\u00edo y no tienen ni rica ni queso entonces eso es con en igual cuatro no contando cuatro palabras alrededor si yo considerara en igual cinco entonces ah\u00ed si aparecer\u00eda o to\u00f1o tiene la palabra estaciones en su en su contexto y verano tambi\u00e9n tiene estaciones en su contexto entonces es como que me van quedando zonas de la matriz que est\u00e1n como m\u00e1s acopladas entre s\u00ed no como que tienen mayor nivel de proximidad y otras zonas que no entonces ah\u00ed ya tendr\u00eda como una especie de primera aproximaci\u00f3n a lo que ser\u00eda en vectores de palabras que es decir bueno yo puedo representar cada palabra con una fila de esta matriz y esa fila de la matriz va a tener ciertas propiedades cosas de que palabras que est\u00e1n cerca van a sem\u00e1nticamente similares van a estar cerca en esas en esas filas un problema que tiene esta representaci\u00f3n que dice ah\u00ed abajo es que son vectores muy grandes yo tengo vectores de tama\u00f1o b\u00e1sicamente el tama\u00f1o del vocabulario si yo tengo considero 10 mil para ver vocabulario o tener vectores de tama\u00f1o de 10 mil donde la mayor\u00eda de los de los n\u00fameros van a ser cero y algunos van a ser valores distintos de cero entonces me va a pasar que los vectores son dispersos o spars bien entonces ah\u00ed como refinaciones esta t\u00e9cnica que se utiliza bastante o sea esta esta t\u00e9cnica de de construir matriz y determinos t\u00e9rminos se puede usar como base para calcular ciertos tipos de vectores de palabras el algoritmo glob se basa en comentar comenzar en esta matriz los algoritmos de pca de principal componente an\u00e1lisis se pueden usar para reducir la dimensionelidad de esta matriz en realidad este tipo de matrices tiene sus usos pero la que vamos a ver es una t\u00e9cnica un poco posterior a las matrices tambi\u00e9n o t\u00e9rmino que digamos que est\u00e1 como en el inicio de lo que fue las revoluciones que se han dado en pelea en los \u00faltimos a\u00f1os no este este es un trabajo de 2013 un trabajo de bueno un investigador que ya no es mi collode que propuso en 2013 una t\u00e9cnica que en realidad son dos acorimos distintos que se llama Word to back o sea ir acorribo para ir de palabras a vectores y que su idea era construir vectores de ensos o sea vectores que tuviera una dimensi\u00f3n mucho m\u00e1s chica de vocabulario en vez de tener un vectore tama\u00f1o de 10 mil yo voy a tener un vectore tama\u00f1o 100 o 250 o 300 y por el hecho de comprimir todo el vocabulario en esos vectores m\u00e1s densos entonces gan\u00f3 esas propiedades de que palabras m\u00e1s cercanas son sim\u00e1nticamente similares entonces bueno obviamente no lo van s\u00f3lo por comprimir sino por c\u00f3mo se entrena esto entonces la idea de los algoritmos de Word to back es decir bueno en vez de contar como la matriz determin\u00f3 t\u00e9rmino de las palabras dentro de un contexto yo lo voy a ver con un problema de clasificaci\u00f3n un problema de probabil\u00edstico en el cual voy a predecir qu\u00e9 tan probable es que la palabra C aparezca en el contexto de la palabra W bien entonces voy a tener una predicci\u00f3n la producci\u00f3n de que es cierto que aparece la palabra W en el contexto de la palabra C en el contexto de la palabra W eso ser\u00eda P de m\u00e1s WS pero a su vez tengo que tener una predicci\u00f3n negativa o sea yo tengo que saber cu\u00e1les son los ejemplos positivos y cu\u00e1les son los ejemplos negativos entonces lo que se hace para esto es decir bueno yo tengo un gran corpus una gran colecci\u00f3n de palabras y yo puedo medir puedo llegar a medir cu\u00e1les son los contextos donde aparece la palabra C en el contexto de la palabra W pero adem\u00e1s puedo llegar a medir los casos en los cuales no pasa o sea yo puedo soltear palabra solatoria si decir bueno una palabra aleatoria no siempre est\u00e1n en contexto de una palabra W entonces con eso me invento ejemplos negativos tengo ejemplos positivos que son bueno la palabra queso aparece en el contexto de la palabra burbesa ejemplos negativos son sortes de una palabra cualquiera y sali\u00f3 yo que se \u00e1rbol bueno la palabra \u00e1rbol no aparece en el contexto de la palabra burbesa bien entonces el algoritmo skip gran que es uno de los algoritmos de portubec m\u00e1s m\u00e1s utilizados utiliza este ese principio y lo ve como una red neuronal intenta modelar esto como una renebronal en la cual yo tengo una capa de entrada y la capa de entrada va a ser una representaci\u00f3n one hot esto lo mencionamos la de pasada la representaci\u00f3n one hot es as\u00ed no en la representaci\u00f3n one hot yo voy a tener un vector para la palabra queso y un vector para la palabra hamburguesa donde voy a tener una columna para cada una de las palabras posibles entonces voy a tener ac\u00e1 perro ac\u00e1 voy a tener comer ac\u00e1 voy a tener \u00e1rbol tan tata y ac\u00e1 va a estar queso en angulado y ac\u00e1 va a estar hamburguesa en otro lado y ac\u00e1 va a dar m\u00e1s cosas y entonces la representaci\u00f3n de la palabra queso es cero en todos lados y un uno ac\u00e1 y cero en todo el resto la palabra burbesa es cero en todos lados cero ac\u00e1 y un uno en la burbesa y cero en todo el resto esto es la representaci\u00f3n one hot entonces esta red neuronal en realidad digamos es una renebronal que intenta predecir este problema probabil\u00edstico toma como entrada ese vector de cero y uno es el vector one hot donde la entrada es todo el vocabulario posible tiene una capa oculta en el medio es una red que tiene una sola capa oculta y como salida tiene una distribuci\u00f3n de probabilidades de todas las palabras en contexto entonces la entrada es supongamos que esto tiene tama\u00f1o 10 mil no tengo 10 mil palabras posibles 10 mil palabras en el vocabulario entonces la entrada de la red va a ser una cosa de tama\u00f1o 10 mil entrada tiene tama\u00f1o 10 mil y la salida va a tener c por 10 mil c es cu\u00e1ntas palabras de contexto estoy contando o sea si yo estoy contando no s\u00e9 10 palabras alrededor de la que estoy mirando entonces va a ser una salida c por 10 mil esto c por 10 mil representan cu\u00e1l es la probabilidad de que una palabra cualquiera por ejemplo hamburguesa est\u00e9 en un contexto de tres palabras para atr\u00e1s de la palabra queso cu\u00e1l es la probabilidad que la palabra perro est\u00e9 en un contexto de dos palabras para adelante la palabra queso y as\u00ed eso es las c por 10 mil salidas y en el medio tiene una capa que ah\u00ed dice en edim la capa oculta que tiene tama\u00f1o 10 mil por dim y dim es la dimensi\u00f3n de los vectores que eso que les dec\u00eda que pod\u00eda hacer dimensi\u00f3n 100 o dimensi\u00f3n 300 o dimensi\u00f3n 150 es un n\u00famero mucho m\u00e1s chico que vocabulario entonces pensem\u00f3lo como esto la tano mientras es un vector o un hot que tiene un uno y un mont\u00f3n de ceros y despu\u00e9s lo paso por una matriz de pesos que tiene este tama\u00f1o 10 mil por por ejemplo 300 10 mil por 300 entonces al multiplicar eso por mi vector ac\u00e1 esto me devuelve una sola fila de esa matriz que tiene dimensi\u00f3n 300 y eso se lo voy a pasar a la funci\u00f3n de activaci\u00f3n a su vez eso tiene como una especie de segunda capa en la cual aparece m\u00e1s peso para poder calcular estas salidas pero en realidad al m\u00e9todo despu\u00e9s de que se entrena con un mont\u00f3n de valores positivos un mont\u00f3n de valores negativos dice bueno que eso parece en el contexto de muruesas pero perro no aparece en el contexto de la muruesa etc\u00e9tera tengo un mont\u00f3n de valores de este estilo cuando termina de entrenar y se bueno llegu\u00e9 al mejor c\u00e1lculo de probabilidades en realidad yo tiro todo el resto de las capas y me quedo solamente con esta de ac\u00e1 con la capa oculta la capa oculta es una tabla que me dice para cada una de las palabras hay 300 valores reales que le representan bien entonces me dice bueno para la palabra que eso esto 300 valores van a ser menos uno tres con cuatro ocho con seis no s\u00e9 qu\u00e9 est\u00e1 todo as\u00ed 300 valores y para las palabras muruesa menos dos tres con uno etc\u00e9tera etc\u00e9tera o sea voy a tener un mont\u00f3n de valores reales que le representan que representan esos n\u00fameros no lo s\u00e9 y nadie lo sabe pero sabemos que ah\u00ed est\u00e1 codificada la informaci\u00f3n importante para poder despu\u00e9s trabajar con esos n\u00fameros con esos con esas palabras bien hay eso se le llama Word in badings esta capa oculta que est\u00e1 ac\u00e1 en esta en esta t\u00e9cnica de Wordback se le llama capa de badings a la capa oculta que queda entrenada despu\u00e9s de esto bien preguntas ustedes que palabra que esto s\u00ed es para ir a la capa oculta y por el producto porque la matriz doble vez una matriz de 10 mil por dimensi\u00f3n y mi vector one hot es un vector que tiene tama\u00f1o de 10 mil pero hay un solo uno no son todos heros y uno entonces al hacer el producto me queda exclusivamente la fila que representa la matriz la palabra que eso bien entonces con esto se logra con esta t\u00e9cnica Wordback y otras t\u00e9cnicas de construcci\u00f3n de Word in badings s\u00ed no el resultado de la capa oculta se lo pasas en esta t\u00e9cnica por lo menos le pasas el resultado de la capa oculta a otros pesos que van a ir a la salida y esos pesos son los que calculan la probabilidad de salida pero en realidad despu\u00e9s todos esos pesos que aparecen despu\u00e9s no me importa o sea despu\u00e9s de que yo termino de entrenar todo la \u00fanica capa con la que me voy a quedar es con la del medio que es la que me he interesado entrenar el resto es como una especie de excusa que se usa para esta tarea para poder encontrar la capa del medio la salida tiene c por 10 mil que significa yo estoy prediciendo cu\u00e1l es la probabilidad en todas las seis palabras de contexto de caparesca alguna palabra bien entonces les hicimos logramos nuestro objetivo que era decir que hago que puedo asociar a una palabra a un string un vector de valores reales entonces tengo la palabra perro y me va a dar un vector de valores reales la palabra comer y me va a dar otro vector de valores reales adem\u00e1s se cumple que los vectores cuanto m\u00e1s cercanos est\u00e1n en ese espacio de dimensi\u00f3n 300 entonces significa las palabras son m\u00e1s similares en alg\u00fan sentido o si est\u00e1n m\u00e1s lejanos entonces son m\u00e1s dis\u00edmiles puedo utilizar por ejemplo la similiaridad coseno para eso si yo calculo el coseno del \u00e1ngulo del otro lado vectores eso es una buena medida para saber qu\u00e9 est\u00e1n parecidos son o incluso para usar la distancia o cl\u00eddea tambi\u00e9n para calcular eso pero la similiaridad coseno es la que m\u00e1s se usa y adem\u00e1s de que tiene esa propiedad de que las palabras m\u00e1s cercanas son m\u00e1s parecidas de alguna manera estas t\u00e9cnicas descubren cosas interesantes que uno no las entren\u00f3 para que las descubran digamos sino que aparecen como de yapa y aparecen cosas como que por ejemplo yo puedo hacer operaciones entre los vectores entonces si yo tengo el vector de rey y le resto el vector de hombre y le sumo el vector de mujer me queda el vector de rey y eso es una propiedad que aparece despu\u00e9s de que yo entren estos vectores suele suceder en alendenar estas colecciones de vectores que agarro el vector de mujer le resto de hombre y le sumo rey y me queda rey o agarro el vector de Uruguay le resto donde veo le sumo Francia me da Par\u00eds no entonces ah\u00ed en un caso estoy haciendo una transformaci\u00f3n un poco morfol\u00f3gica decir bueno este hombre es la mujer como rey esa rey y el otro estoy haciendo una transformaci\u00f3n m\u00e1s sem\u00e1ntica como diciendo la capital de Uruguay y la capital de Francia es Par\u00eds y de alguna forma yo nunca le dije al sistema que tiene que aprender eso pero por la forma que hayan creado los vectores suelen tener propiedad de este estilo bien eso fue como lo lo primero sorprendente que encontraron acerca de estos m\u00e9todos que es que se pueden como que derrebo de aprender esas cosas pero no est\u00e1n excesos del problema como por ejemplo si yo tengo una palabra la palabra vela voy a tener un solo vector que representa la palabra vela y vela es una palabra que es amigo o sea es polis\u00e9mica yo puedo tener una vela para aprender una vela vamos para poner una vela de cumplea\u00f1os o sea una pag\u00f3n o puedo tener un barco a vela y bueno en los dos casos tengo la misma representaci\u00f3n o el gato hidr\u00e1ulico y el gato animal tambi\u00e9n tengo la misma representaci\u00f3n el banco de sentarse y el banco de financiero tambi\u00e9n tengo la misma representaci\u00f3n etc\u00e9tera entonces eso es un problema que tienen estos estas t\u00e9cnicas y es que yo no tengo digamos no estoy usando por ejemplo wordnet que vieron guarnas en una acci\u00f3n es clase no no tengo un repositorio significado de wordnet que me ayude a decir cu\u00e1l es cu\u00e1l sino que ac\u00e1 solamente tengo un representante para cada palabra bien y bueno esta esta t\u00e9cnica tiene ese problema despu\u00e9s hay otras tecnicas me permiten crear vectores contextuales que d\u00eda bueno es la palabra gato en esta oraci\u00f3n donde probablemente sea un gato animal y no un gato hidr\u00e1ulico bien entonces una vez que construimos esta colecci\u00f3n de vectores como los evaluamos c\u00f3mo sabemos est\u00e1n bien bueno hay como dos formas de evaluarlos bastante comunes se habla de test intr\u00ednsecos y test en extr\u00ednsecos que significan cosas distintas intr\u00ednsecos significa yo mido propiedades del conjunto de vectores que constru\u00ed entonces una de las que se miden es exactamente lo que dec\u00eda no reci\u00e9n me diamos que aparece una propiedad que es que yo puedo hacer dibujar como en especie para el logramos en el cual digo que hombre es a mujer como rey esa y espero que es mi colecci\u00f3n de vectores haya quedado reina digamos como resultado de su operaci\u00f3n o Uruguay esa montevideo como francia esa y espero que haya quedado par\u00eds en ese lugar entonces bueno una forma de valor estos estos sistemas es construirme una colecci\u00f3n grande de estos test se llaman test de analog\u00edas entonces me puedo hacer una colecci\u00f3n grande estos test y ver a cu\u00e1ntos le moca mi colecci\u00f3n entonces con yo tengo varias colecciones en vez de distintas veo que este le invoco m\u00e1s veces y el invoco menos veces otro son los test de similitud o similaridad que esto se hacen con intervenci\u00f3n humana un poco m\u00e1s fuerte que es preguntar un mont\u00f3n de personas por ejemplo que es m\u00e1s parecido a un durasno una silla una mesa o una manzana a un avestrus o cosas de estilo entonces tal le dicen a la gente trata de arranquear estas cuatro cinco palabras de cu\u00e1l es m\u00e1s parecida menos parecida entonces le preguntar un mont\u00f3n de personas las personas hacen sus listas y despu\u00e9s mir\u00e1s dentro de tu colecci\u00f3n de vectores si las distancias relativas entre esas palabras son similares o no a la que esperaban los humanos entonces cuanto m\u00e1s similar sea haciendo el el test de Spirman para eso el descorrelaci\u00f3n de Spirman se puede sacar una medida de qu\u00e9 tanto se parece a la intuici\u00f3n humana lo que el sistema dice eso es llamante es intr\u00ednseco porque yo estoy abarrando la colecci\u00f3n de vectores que constru\u00ed y las estoy testeando sola los test extr\u00ednsecos se refieren a agarro mi colecci\u00f3n de vectores y la meto en una tarea de p l n un poco m\u00e1s grande y veo qu\u00e9 tal le va entonces ac\u00e1 significa bueno yo supongamos que tengo un sistema de p l n que hace traducci\u00f3n autom\u00e1tica o an\u00e1lisis de sentimiento o recuperaci\u00f3n de informaci\u00f3n o un chatbot o lo que sea si yo tengo un sistema que ya funciona y le cambio su capa de su colecci\u00f3n de vectores por la m\u00eda que yo entren\u00e9 y el sistema mejora en su performance entonces digo que puedo decir que mi colecci\u00f3n de vectores mejora la performance entonces puedo decir que la colecci\u00f3n de vectores es buena eso de llamas test extr\u00ednseco o sea no estoy probando directamente las propiedades de los en vectores sino que estoy probando c\u00f3mo se comportan en un sistema m\u00e1s grande bien entonces otra forma de evaluar esto m\u00e1s bien no creo que lleguen a ver nada porque est\u00e1 muy chiquito pero bueno vamos a mencionarlo es visualizarlos en bedings recuerden que esto ten\u00eda dimensi\u00f3n 100 350 que era una dimensi\u00f3n mucho m\u00e1s chica que el vocabulario pero igual es una dimensi\u00f3n muy grande o sea lo sumano podemos visualizar dos tres dimensiones de lo sumo y m\u00e1s de eso ya nos mareamos y estos son vectores de 300 dimensiones pero una forma de visualizarlos es usar las t\u00e9cnicas de reducci\u00f3n de dimensionalidad por ejemplo p c a y t s n s son de las m\u00e1s comunes son t\u00e9cnicas que me permiten agarrar 300 dimensiones y bajarlas a dos para poder dibujarlo en un plano entonces ac\u00e1 no llegan a ver estos son dos trabajos que hicimos en el grupo para distintos colecciones en bedings en distintos idiomas voy a agarrar esto ahora s\u00ed s\u00ed queda bien entonces en este tenemos un trabajo hecho para el espa\u00f1ol son vectores de palabras en espa\u00f1ol y est\u00e1n no van a llegar a verlo lo que est\u00e1n ac\u00e1 porque se ve muy chiquito pero por ejemplo ac\u00e1 aparece un cl\u00e1ster de a\u00f1os que est\u00e1n todos juntos ac\u00e1 aparecen nombres de personas que est\u00e1n todos juntos abajo aparecen lugares per\u00fa, Uruguay, Bolivia que aparecen como cl\u00e1sterizados todos juntos entonces uno espera que una colecci\u00f3n de vectores que haya quedado bien entrenada aparezcan como cl\u00e1sters con cosas que son sem\u00e1nticamente similares y el trabajo de la derecha es un trabajo similar pero que est\u00e1 hecho para el Guarani y bueno ac\u00e1 se ve tambi\u00e9n m\u00e1s claro que aparecen cosas como relacionadas con fechas est\u00e1n en h\u00e9roes las relacionadas con colores est\u00e1n en en cian las relacionadas con no se bien que dice ah\u00ed animales est\u00e1n en verde etc\u00e9tera pa\u00edses est\u00e1n en azul etc\u00e9tera como que no puede estar en esas regiones obviamente esto no es perfecto van a quedar alguna cosa por fuera etc\u00e9tera pero si uno logra ver que m\u00e1s o menos cl\u00e1steriza entonces tiene como cierta cierta entuici\u00f3n de que andan mejor esos vectores bien preguntas entonces los guerden beings fueron en definitiva una de las primeras revoluciones que ocurrieron los \u00faltimos a\u00f1os en lo cual es pln y posible que despu\u00e9s se empezaron a utilizar arquitecturas de redes m\u00e1s complejas o sea gracias a que tenemos en bedings y decimos puedo representar una palabra como un vector de 30 dimensiones ese vector de 30 dimensiones que son n\u00fameros reales se lo pueden chufar como entrada a una red neuronal y puedo obtener cosas m\u00e1s complicadas a m\u00ed me interesaba de hace un rato dijimos tener representaciones de palabras pero adem\u00e1s de oraciones o de tweets o de documentos enteros y bueno por lo menos yo tengo representaci\u00f3n de palabras usando guerden bedings como que eso est\u00e1 bastante bien resuelto y gracias a que ahora tengo guerden bedings para usar arquitecturas m\u00e1s complejas como las redes convolucionales las redes lstm las redes tipo transformers los transformers son lo que m\u00e1s se utiliza bien d\u00eda pero adem\u00e1s puedo hacer otra cosa con los en bedings algo un poco m\u00e1s simple pero que a su vez me sirve para resolver otras problemas y es usar la t\u00e9cnica de centr\u00f3ide que es as\u00ed esta les va a servir en la tarea salvo que quieran entrenar una red m\u00e1s compleja que tambi\u00e9n son bienvenidos si quieren entrenar una lstm un transformer pero el centr\u00f3ide es una t\u00e9cnica es muy sencilla supongamos que yo tengo mi mi capa en bedings que tiene bueno dice quesos representas y hamburguesas representas y perro es as\u00ed gato es as\u00ed etc\u00e9tera tengo vectores para cada palabra y tengo ahora un tweet que le quiero representar utilizando la colecci\u00f3n en bedings yo simplemente puedo agarrar todas las palabras del tweet buscar todos los vectores correspondientes y hacer el promedio a eso se llama hacer un centr\u00f3ide de todos los en bedings del tweet y uno dice est\u00e1 apreciado el promedio de perro gato no o sea el tweet dice este no me gust\u00f3 la pel\u00edcula se hago el promedio no me gust\u00f3 la pel\u00edcula y a\u00fan promedio todos en bedin mediar papa frita pero sin embargo funciona bastante bien es como un poco antintuitivo pero hacer el promedio de todas esas 300 dimensiones de las distintas palabras despu\u00e9s yo utilizo eso como entrada para otro otro sistema de clasificaci\u00f3n no s\u00f3lo una rena urnal sino que ah\u00ed ya puede utilizar otro tipo de cosas como su proyecto en machines o regresi\u00f3n log\u00edstica y anda bastante bien o sea es como extra\u00f1o pero sobre todo para el problema de an\u00e1lisis de sentimiento anda bastante bien bueno esa es la t\u00e9cnica del centr\u00f3ide es una t\u00e9cnica f\u00e1cil de decir si yo tengo una colecci\u00f3n en bedings puedo hacerme en bedings de oraciones o en bedings de textos un poco m\u00e1s grandes simplemente promediendo los en bedings que tengo bien entonces ahora lo que vamos a ver en el resto de la clase en unos minutos son ejemplos de c\u00f3mo funcionan estas arquitecturas m\u00e1s complejas que puede utilizar gracias a que tengo en bedings no las vamos a ver en profundidad sino que simplemente vamos a pasar por arriba pero es una idea para ver qu\u00e9 clase de cosas se pueden hacer y empecemos por las convolutivas las redes tipo CNN se llaman redes convolutivas o convolucionales y originalmente se utilizaban como para procesar im\u00e1genes o sea tambi\u00e9n se utilizan todav\u00eda en d\u00eda para procesar im\u00e1genes y lo que hacen es ir recorriendo como que se aumenta una imagen en cuadraditos y lo van recorriendo digamos y despu\u00e9s obtienen como informaci\u00f3n de cada uno de los cuadraditos bueno pero tambi\u00e9n se han aplicado al lenguaje y la forma que se aplica el lenguaje es como decir va tomando de enegramos y va viendo yo que se por ejemplo tres palabras a la vez y va obteniendo datos de cada una de las tres palabras a la vez y despu\u00e9s con eso despu\u00e9s saca un total entonces lo interesante es que digamos puedo pasar a tener cosas de orden m\u00e1s grande que una palabra o sea ahora en bedes para usar una sola palabra estoy produciendo toda una variaci\u00f3n entonces tenias una pregunta bien entonces un ejemplo como funciona esto supongamos que estoy tratando de clasificar tweets y digo la pel\u00edcula fue muy aburrida yo me puedo construir una red neuronal de tipo convolutiva que lo que va a ser es decir bueno a los embeddings de la de a tres palabras los voy tomando de a tres palabras considero los embeddings de la pel\u00edcula fue y a esos tres embeddings se los paso a una red a esa unidad convolutiva que lo que va a ser es mirar estas tres palabras y tratar de sacar informaci\u00f3n de las tres y devolverme una cosa que tenga cierto tama\u00f1o fijo y despu\u00e9s se va a mover la ventana y en vez de la pel\u00edcula fue va a considerar las palabras pel\u00edculas fue muy y de vuelta lo va a pasar por esa subred y va tratar de sacar salidas y despu\u00e9s fue muy aburrida lo va a pasar por la misma subred tratar de sacar salidas despu\u00e9s voy a tener una capa que dice bueno de todas estas salidas intermedias que tuve obtengo los m\u00e1ximos y esos m\u00e1ximos los uso para calcular mi salida que mi salida final ser\u00eda positivo o negativo en el otro o no no estas redes esta capa convolutiva que ah\u00ed en el medio parece como capa convolutiva es entonces a sus redes que estoy viendo ah\u00ed en realidad son los mismos pesos no es como la misma que se va moviendo y me va dando resultados distintos bien entonces lo bueno que tiene es que yo agarr\u00f3 todo una entrada que son muchas palabras y me va a dar una salida \u00fanica digamos condensa todas las palabras se queda como con las digamos las dimensiones m\u00e1ximas de cada una que le quede m\u00e1s le interesen y con eso calcula una salida bien esa es la red tipo convolutiva las redes el STM pertenecen a un grupo m\u00e1s grande de redes que se llama las redes recurrentes que significa son redes con memoria que van mirando una cada palabra a la vez y van recordando lo que viene hasta el momento entonces esto me sirve para obtener una salida final o tambi\u00e9n para obtener salidas por palabras entonces vamos a ver c\u00f3mo funciona de estas esto como una especie de diagrama de c\u00f3mo ser\u00eda una una red recurrente similar a la que ve\u00edamos hace un rato digamos en capas pero ahora yo voy a tener una capa que tiene un enlace ese asimismo digamos todas las neuronas de esa capa van a tener un enlace de vuelto de vuelta a ese asimismo se llama capa recurrente y bueno despu\u00e9s voy a tener una capa de salida entonces cuando yo voy a ver c\u00f3mo funciona eso con un tweet que quiero clasificar como la pel\u00edcula fue muy aburrida funcionar\u00eda esta manera yo digo bueno primero agarr\u00f3 la palabra a la el embedding de la palabra a la se lo paso a la red y despu\u00e9s voy a agarrar el embedding de la palabra pel\u00edcula y se lo paso de vuelta a la red pero esta vez adem\u00e1s de poner el embedding de la palabra pel\u00edcula voy a poner tambi\u00e9n la salida del paso anterior entonces esto va consumiendo una palabra a la vez y siempre consumiendo la salida de la etapa anterior entonces va consumiendo la pel\u00edcula fue muy aburrida cuando lleg\u00f3 aburrida ya consumi\u00f3 la salida de todas las capas anteriores y la palabra nueva y ah\u00ed es como que la salida de ese \u00faltimo paso ya medio tiene como una especie de versi\u00f3n condensada de todo lo que era la elaboraci\u00f3n y ah\u00ed con esos \u00faltimos pesos calculo la salida positivo, negativo, neutro o no adem\u00e1s si yo quisiera podr\u00eda ir sacando para ir sacando los pesos de cada una de las salidas entonces ah\u00ed tendr\u00eda como una salida por palabra entonces esto podr\u00eda servir por ejemplo para los problemas de clasificaci\u00f3n de secuencia que ve\u00edamos la despasada bueno con una red de estetilo se puede hacer clasificaci\u00f3n de secuencia sacando una salida por palabra s\u00ed ten\u00eda una pregunta el embedding exacto s\u00ed s\u00ed la entrada en esto caso yo digo bueno asumo que tengo bordemente yo ya puedo utilizar estas redes m\u00e1s complejas bien y la que es la arquitectura del estado del arte hoy en d\u00eda es la arquitectura de tipo transformer que tambi\u00e9n es una arquitectura que utiliza secuencias de entrada pero es una arquitectura bastante m\u00e1s compleja ac\u00e1 vamos a ver solamente una idea muy muy b\u00e1sica como funciona pero es una arquitectura que tiene con muchos muchos pedazos y hace muchas cosas distintas y bueno se basa en una cosa que se llama capas autotensionales ahora no vamos a ver qu\u00e9 es el modelo attentional pero lo vamos a ver la clase que viene normalmente como bueno un ejemplo de c\u00f3mo funciona el sistema de traducci\u00f3n autom\u00e1tica que utiliza modelos autotensionales bueno una variante de eso es el modelo autotensional que lo que hace es construir una matriz entre las palabras de una oraci\u00f3n y s\u00ed misma yo tengo una oraci\u00f3n que tiene en palabras y va a tratar de cruzar las n palabras con las propias n palabras y tratar de establecer conexiones entre cada uno de los pares entonces termina calculando una matriz y lo bueno que tiene es que me permite construir en beding contextuales por palabra o sea en bedings de una palabra vista en contexto y adem\u00e1s un embeding total de la oraci\u00f3n entonces funciona m\u00e1s o menos as\u00ed esto como una especie de representaci\u00f3n muy vaga de lo que es un transformer no o sea de forma de realidad tiene como muchas partes m\u00e1s complejas pero imag\u00ednense que funciona esta manera no yo digo tengo una oraci\u00f3n en la pel\u00edcula fue muy aburrida entonces la voy a pasar por una capa autotensional que significa yo cruzo todas las palabras con todas y calculo la relevancia de cada palabra contra las dem\u00e1s eso me va a dar una serie de salidas y eso lo que hace es construirme como una colecci\u00f3n de en bedings de nivel 1 o sea yo empec\u00e9 con los borde en bedings de la pel\u00edcula fue una fue muy aburrida y ahora voy a tener una colecci\u00f3n de en beding de nivel 1 que ya mirando algo de contexto eso eso es en beding de nivel 1 a su vez de los pasos de vuelta a otra capa autotensional que devuelta los cruzos a todos con todos y me devuelta a dar una salida que son los en beding de nivel 2 y eso lo sigo pasando por varias capas autotensionales que los cruzan todos con todos hasta que al final me terminan dando o sea lo voy a pasar en el capas y me terminan dando una salida de nivel 5 digamos entonces al inicio ten\u00eda borde en bedings que miraban solamente una palabra a la vez y lo que tengo al final ya son como en bedings contextuales en los cuales ya considero varias veces cruzar todas las palabras con todas entonces como que eso va ganando informaci\u00f3n en cada paso a su vez a bien despu\u00e9s de que yo tengo estos en beding contextuales en general se utiliza otra red m\u00e1s de tipo de coder puede ser un transforme puede ser una lstm algo m\u00e1s pero necesito otra cosa que es la que me diga por ejemplo si es positivo negativa o neutro etc\u00e9tera pero es otro tipo de red que despu\u00e9s decodifica esa informaci\u00f3n pero bueno por lo menos atacayo ya constru\u00ed en bedings de cosas pero bien lo que tengo ac\u00e1 son ten\u00eda la pel\u00edcula fue muy aburrida y eso lo transform\u00e9 en ten\u00eda cinco palabras y lo transform\u00e9 en cinco en bedings digamos que de distintos niveles pero siempre son cinco en bedings entonces yo dir\u00eda que el primero se corresponde con la el segundo con pel\u00edcula tercero con fue es una una versi\u00f3n contextual del en beding porque significa la palabra pel\u00edcula en el contexto de la pel\u00edcula fue muy aburrida no es la palabra pel\u00edcula en general entonces si yo tuviera una braci\u00f3n que tiene gato ser\u00eda gato en el contexto de el gato como pescado que no ser\u00eda lo mismo que cuando estoy hablando un gato y un gato y un gato y un gato probablemente o sea los en bedings que de distintos bien pero adem\u00e1s me interesa tener una representaci\u00f3n de la oraci\u00f3n entera y para eso lo que se hace es agregar un toque en extra un toque en llamado celse se pone al principio de la oraci\u00f3n y se lo hace jugar con todos los las capas atenci\u00f3nales del medio entonces yo tengo una palabra extra que como no es una palabra de la oraci\u00f3n no tiene un en beding contextual sino lo que hace es capturar la informaci\u00f3n de toda la oraci\u00f3n a la vez entonces es en beding que me queda afuera el en beding que corresponde al toque en celse ese que despu\u00e9s yo puedo utilizar para predecir cosas yo lo utilizo como un en beding que tiene cierto tama\u00f1o y se lo paso una capa de softmax para que me prediga as\u00ed esa es positiva negativo a neutra o no bien bueno y para terminar terminar comentarles lo el tipo de herramientas que pueden utilizar para trabajar con redes neuronales obviamente para el segundo laboratorio van a poder utilizar redes neuronales si quieren de todo tipo si quieren colecciones en bedings nosotros tambi\u00e9n les podemos dar o pueden bajar algunas que est\u00e9n disponibles en la web pero bueno herramientas habituales para trabajar con esto son por ejemplo tensorflow y pator que son dos ilotecas el tensorflow de google y pator es de meta o de facebook y bueno queras en general trabaja contar sonflog y hanginfaces es un repositorio que tiene un mont\u00f3n de modelos ya aprendrenados para muchos idiomas y para muchas cosas que ya se pueden utilizar autos de box y funciona muy bien y bueno estas son estas herramientas y otras m\u00e1s las van a poder utilizar en laboratorio bueno por hoy eso la pr\u00f3xima vez vamos a ver producci\u00f3n autom\u00e1tica", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.6000000000000005, "text": " Bueno, bienvenidos. En la clase de hoy vamos a ver el tema de redes neuronales que, bueno,", "tokens": [50364, 16046, 11, 3610, 40668, 13, 2193, 635, 44578, 368, 13775, 5295, 257, 1306, 806, 15854, 368, 16762, 34090, 4229, 631, 11, 11974, 11, 50744], "temperature": 0.0, "avg_logprob": -0.30655228796084066, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.28614333271980286}, {"id": 1, "seek": 0, "start": 7.6000000000000005, "end": 12.120000000000001, "text": " es como digamos, el estado del arte, lo que son las cosas de procesamiento del lenguaje natural", "tokens": [50744, 785, 2617, 36430, 11, 806, 18372, 1103, 29159, 11, 450, 631, 1872, 2439, 12218, 368, 17565, 16971, 1103, 35044, 84, 11153, 3303, 50970], "temperature": 0.0, "avg_logprob": -0.30655228796084066, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.28614333271980286}, {"id": 2, "seek": 0, "start": 12.120000000000001, "end": 18.56, "text": " en general hoy en d\u00eda se rosuelen con redes neuronales. Entonces, es un poco para continuar", "tokens": [50970, 465, 2674, 13775, 465, 12271, 369, 18953, 3483, 268, 416, 16762, 34090, 4229, 13, 15097, 11, 785, 517, 10639, 1690, 29980, 51292], "temperature": 0.0, "avg_logprob": -0.30655228796084066, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.28614333271980286}, {"id": 3, "seek": 0, "start": 18.56, "end": 22.16, "text": " con lo que ve\u00edamos la vez pasada. Hab\u00edamos visto m\u00e9todos de clasificaci\u00f3n, hab\u00edamos", "tokens": [51292, 416, 450, 631, 1241, 16275, 635, 5715, 1736, 1538, 13, 14225, 16275, 17558, 20275, 378, 329, 368, 596, 296, 40802, 11, 3025, 16275, 51472], "temperature": 0.0, "avg_logprob": -0.30655228796084066, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.28614333271980286}, {"id": 4, "seek": 0, "start": 22.16, "end": 26.64, "text": " visto que hab\u00eda algunos para clasificar cosas en categor\u00edas, hab\u00eda algunos secuenciales,", "tokens": [51472, 17558, 631, 16395, 21078, 1690, 596, 296, 25625, 12218, 465, 19250, 10025, 11, 16395, 21078, 907, 7801, 1013, 279, 11, 51696], "temperature": 0.0, "avg_logprob": -0.30655228796084066, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.28614333271980286}, {"id": 5, "seek": 2664, "start": 26.64, "end": 31.76, "text": " hab\u00eda algunos que llamamos modelos del lenguaje y de los m\u00e9todos de clasificaci\u00f3n, en realidad,", "tokens": [50364, 16395, 21078, 631, 16848, 2151, 2316, 329, 1103, 35044, 84, 11153, 288, 368, 1750, 20275, 378, 329, 368, 596, 296, 40802, 11, 465, 25635, 11, 50620], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 6, "seek": 2664, "start": 31.76, "end": 36.24, "text": " vimos en profundidad, nadie valles, pero vimos que hab\u00eda otro, por ejemplo, algo de la decisi\u00f3n,", "tokens": [50620, 49266, 465, 40958, 4580, 11, 28060, 371, 37927, 11, 4768, 49266, 631, 16395, 11921, 11, 1515, 13358, 11, 8655, 368, 635, 18206, 2560, 11, 50844], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 7, "seek": 2664, "start": 36.24, "end": 43.88, "text": " regresi\u00f3n log\u00edstica, Supervector Machines y redes neuronales y para los m\u00e9todos secuenciales", "tokens": [50844, 47108, 2560, 3565, 19512, 2262, 11, 4548, 303, 1672, 12089, 1652, 288, 16762, 34090, 4229, 288, 1690, 1750, 20275, 378, 329, 907, 7801, 1013, 279, 51226], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 8, "seek": 2664, "start": 43.88, "end": 47.400000000000006, "text": " tambi\u00e9n aparecian las reneonales, para los modelos del lenguaje tambi\u00e9n aparecian las reneonales.", "tokens": [51226, 6407, 15004, 537, 282, 2439, 319, 716, 266, 4229, 11, 1690, 1750, 2316, 329, 1103, 35044, 84, 11153, 6407, 15004, 537, 282, 2439, 319, 716, 266, 4229, 13, 51402], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 9, "seek": 2664, "start": 47.400000000000006, "end": 50.92, "text": " Entonces, como que las reneonales son un m\u00e9todo muy importante que es muy vers\u00e1til y se", "tokens": [51402, 15097, 11, 2617, 631, 2439, 319, 716, 266, 4229, 1872, 517, 20275, 17423, 5323, 9416, 631, 785, 5323, 1774, 7656, 388, 288, 369, 51578], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 10, "seek": 2664, "start": 50.92, "end": 54.480000000000004, "text": " usa para muchas cosas. Entonces, nos vamos a concentrar un poco, vamos a dar en esta clase una", "tokens": [51578, 29909, 1690, 16072, 12218, 13, 15097, 11, 3269, 5295, 257, 5512, 5352, 517, 10639, 11, 5295, 257, 4072, 465, 5283, 44578, 2002, 51756], "temperature": 0.0, "avg_logprob": -0.2642572770207565, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.0009006624459289014}, {"id": 11, "seek": 5448, "start": 54.48, "end": 59.4, "text": " introducci\u00f3n a lo que son las redes y adem\u00e1s ver c\u00f3mo se usan particularmente para el lenguaje.", "tokens": [50364, 2814, 14735, 257, 450, 631, 1872, 2439, 16762, 288, 21251, 1306, 12826, 369, 505, 282, 1729, 4082, 1690, 806, 35044, 84, 11153, 13, 50610], "temperature": 0.0, "avg_logprob": -0.27160780006479995, "compression_ratio": 1.5617529880478087, "no_speech_prob": 0.005324148572981358}, {"id": 12, "seek": 5448, "start": 59.4, "end": 64.84, "text": " O sea, vamos a hablar las t\u00e9cnicas de vectores de palabras y c\u00f3mo aplicar eso a precisamente", "tokens": [50610, 422, 4158, 11, 5295, 257, 21014, 2439, 25564, 40672, 368, 1241, 349, 2706, 368, 35240, 288, 12826, 18221, 289, 7287, 257, 44901, 50882], "temperature": 0.0, "avg_logprob": -0.27160780006479995, "compression_ratio": 1.5617529880478087, "no_speech_prob": 0.005324148572981358}, {"id": 13, "seek": 5448, "start": 64.84, "end": 70.24, "text": " el lenguaje natural. Entonces, \u00bfc\u00f3mo empieza esto? Esto empieza inspirado en esto de ac\u00e1, que es", "tokens": [50882, 806, 35044, 84, 11153, 3303, 13, 15097, 11, 3841, 46614, 44577, 7433, 30, 20880, 44577, 17432, 1573, 465, 7433, 368, 23496, 11, 631, 785, 51152], "temperature": 0.0, "avg_logprob": -0.27160780006479995, "compression_ratio": 1.5617529880478087, "no_speech_prob": 0.005324148572981358}, {"id": 14, "seek": 5448, "start": 70.24, "end": 77.52, "text": " una neurona biol\u00f3gica, esto lo habr\u00e1n visto en el hiceo, en biolog\u00eda. Una neurona es un tipo de", "tokens": [51152, 2002, 34090, 64, 3228, 27629, 2262, 11, 7433, 450, 32794, 7200, 17558, 465, 806, 50026, 78, 11, 465, 3228, 29987, 13, 15491, 34090, 64, 785, 517, 9746, 368, 51516], "temperature": 0.0, "avg_logprob": -0.27160780006479995, "compression_ratio": 1.5617529880478087, "no_speech_prob": 0.005324148572981358}, {"id": 15, "seek": 7752, "start": 77.52, "end": 84.56, "text": " c\u00e9lula del sistema nervioso de los animales. \u00bfQu\u00e9 tiene distintas partes? \u00bfC\u00f3mo se puede ver ah\u00ed?", "tokens": [50364, 29064, 3780, 1103, 13245, 5724, 23540, 368, 1750, 45102, 13, 3841, 15137, 7066, 31489, 296, 31210, 30, 3841, 28342, 369, 8919, 1306, 12571, 30, 50716], "temperature": 0.0, "avg_logprob": -0.37360846642220374, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.019478369504213333}, {"id": 16, "seek": 7752, "start": 84.56, "end": 90.44, "text": " S\u00ed, puedo apuntar, o puedo apuntar. \u00bfAboquela con esto?", "tokens": [50716, 12375, 11, 21612, 1882, 2760, 289, 11, 277, 21612, 1882, 2760, 289, 13, 3841, 32, 1763, 358, 4053, 416, 7433, 30, 51010], "temperature": 0.0, "avg_logprob": -0.37360846642220374, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.019478369504213333}, {"id": 17, "seek": 7752, "start": 90.44, "end": 97.03999999999999, "text": " Hay, tiene distintas partes, tiene como unos pelitos que entran dentro del cuerpo de neuronas que se", "tokens": [51010, 8721, 11, 7066, 31489, 296, 31210, 11, 7066, 2617, 17780, 6178, 11343, 631, 948, 4257, 10856, 1103, 20264, 368, 34090, 296, 631, 369, 51340], "temperature": 0.0, "avg_logprob": -0.37360846642220374, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.019478369504213333}, {"id": 18, "seek": 7752, "start": 97.03999999999999, "end": 102.0, "text": " llaman dendritas y despu\u00e9s tiene como una especie de cola que sale de la neurona que se llama", "tokens": [51340, 4849, 6147, 274, 521, 3210, 296, 288, 15283, 7066, 2617, 2002, 49368, 368, 40495, 631, 8680, 368, 635, 34090, 64, 631, 369, 23272, 51588], "temperature": 0.0, "avg_logprob": -0.37360846642220374, "compression_ratio": 1.6682242990654206, "no_speech_prob": 0.019478369504213333}, {"id": 19, "seek": 10200, "start": 102.0, "end": 110.0, "text": " acci\u00f3n y, bueno, ac\u00e1 en el centro tenemos lo que ser\u00eda el cuerpo de la neurona, el soma. Entonces,", "tokens": [50364, 696, 5687, 288, 11, 11974, 11, 23496, 465, 806, 24607, 9914, 450, 631, 23679, 806, 20264, 368, 635, 34090, 64, 11, 806, 3307, 64, 13, 15097, 11, 50764], "temperature": 0.0, "avg_logprob": -0.2115420544241357, "compression_ratio": 1.774891774891775, "no_speech_prob": 0.0076195127330720425}, {"id": 20, "seek": 10200, "start": 110.0, "end": 117.28, "text": " en esas por esas dendritas vienen impulsos el\u00e9ctricos, las dendritas act\u00faan como inhibidores o activadores,", "tokens": [50764, 465, 23388, 1515, 23388, 274, 521, 3210, 296, 49298, 704, 9468, 329, 806, 526, 349, 1341, 329, 11, 2439, 274, 521, 3210, 296, 605, 2481, 282, 2617, 20406, 38835, 277, 2430, 11856, 11, 51128], "temperature": 0.0, "avg_logprob": -0.2115420544241357, "compression_ratio": 1.774891774891775, "no_speech_prob": 0.0076195127330720425}, {"id": 21, "seek": 10200, "start": 117.28, "end": 123.32, "text": " pero vienen impulsos el\u00e9ctricos, eso se condensan adentro del soma que sea el cuerpo y si se supera", "tokens": [51128, 4768, 49298, 704, 9468, 329, 806, 526, 349, 1341, 329, 11, 7287, 369, 2224, 694, 282, 614, 317, 340, 1103, 3307, 64, 631, 4158, 806, 20264, 288, 1511, 369, 1687, 64, 51430], "temperature": 0.0, "avg_logprob": -0.2115420544241357, "compression_ratio": 1.774891774891775, "no_speech_prob": 0.0076195127330720425}, {"id": 22, "seek": 10200, "start": 123.32, "end": 127.12, "text": " cierto un bral de actividad el\u00e9ctrica, entonces la neurona dispara un solo punto por el acci\u00f3n,", "tokens": [51430, 28558, 517, 738, 304, 368, 605, 33490, 806, 526, 349, 15192, 11, 13003, 635, 34090, 64, 14548, 64, 517, 6944, 14326, 1515, 806, 696, 5687, 11, 51620], "temperature": 0.0, "avg_logprob": -0.2115420544241357, "compression_ratio": 1.774891774891775, "no_speech_prob": 0.0076195127330720425}, {"id": 23, "seek": 12712, "start": 127.52000000000001, "end": 133.96, "text": " un solo impulso el\u00e9ctrico por el acci\u00f3n, lo manda hacia afuera y ese acci\u00f3n est\u00e1 conectado a otras", "tokens": [50384, 517, 6944, 704, 425, 539, 806, 526, 349, 23776, 1515, 806, 696, 5687, 11, 450, 7411, 64, 21365, 3238, 84, 1663, 288, 10167, 696, 5687, 3192, 30458, 1573, 257, 20244, 50706], "temperature": 0.0, "avg_logprob": -0.17668590929684222, "compression_ratio": 2.057377049180328, "no_speech_prob": 0.01598985679447651}, {"id": 24, "seek": 12712, "start": 133.96, "end": 141.0, "text": " dendritas que est\u00e1n en otras neuronas. Entonces, esto tiene un mont\u00f3n de entradas, se condensan en el", "tokens": [50706, 274, 521, 3210, 296, 631, 10368, 465, 20244, 34090, 296, 13, 15097, 11, 7433, 7066, 517, 45259, 368, 948, 48906, 11, 369, 2224, 694, 282, 465, 806, 51058], "temperature": 0.0, "avg_logprob": -0.17668590929684222, "compression_ratio": 2.057377049180328, "no_speech_prob": 0.01598985679447651}, {"id": 25, "seek": 12712, "start": 141.0, "end": 146.6, "text": " cuerpo de la c\u00e9lula, de la neurona, dispara un solo pulso el\u00e9ctrico para afuera y ese pulso el\u00e9ctrico", "tokens": [51058, 20264, 368, 635, 29064, 3780, 11, 368, 635, 34090, 64, 11, 14548, 64, 517, 6944, 8331, 539, 806, 526, 349, 23776, 1690, 3238, 84, 1663, 288, 10167, 8331, 539, 806, 526, 349, 23776, 51338], "temperature": 0.0, "avg_logprob": -0.17668590929684222, "compression_ratio": 2.057377049180328, "no_speech_prob": 0.01598985679447651}, {"id": 26, "seek": 12712, "start": 146.6, "end": 150.12, "text": " viaja a otras neuronas. Entonces, como esas neuronas est\u00e1n conectadas en una especie de red,", "tokens": [51338, 5766, 2938, 257, 20244, 34090, 296, 13, 15097, 11, 2617, 23388, 34090, 296, 10368, 30458, 6872, 465, 2002, 49368, 368, 2182, 11, 51514], "temperature": 0.0, "avg_logprob": -0.17668590929684222, "compression_ratio": 2.057377049180328, "no_speech_prob": 0.01598985679447651}, {"id": 27, "seek": 12712, "start": 150.12, "end": 155.56, "text": " cada acci\u00f3n de una neuronas est\u00e1 conectada a las dendritas de otras, entonces la salida de una", "tokens": [51514, 8411, 696, 5687, 368, 2002, 34090, 296, 3192, 30458, 1538, 257, 2439, 274, 521, 3210, 296, 368, 20244, 11, 13003, 635, 1845, 2887, 368, 2002, 51786], "temperature": 0.0, "avg_logprob": -0.17668590929684222, "compression_ratio": 2.057377049180328, "no_speech_prob": 0.01598985679447651}, {"id": 28, "seek": 15556, "start": 155.56, "end": 160.4, "text": " es la entrada de otras. Esto conforma una red dentro del cerebro o el sistema nervioso de los animales", "tokens": [50364, 785, 635, 37119, 368, 20244, 13, 20880, 18975, 64, 2002, 2182, 10856, 1103, 11643, 9120, 277, 806, 13245, 5724, 23540, 368, 1750, 45102, 50606], "temperature": 0.0, "avg_logprob": -0.2584073598148259, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0007990641752257943}, {"id": 29, "seek": 15556, "start": 160.4, "end": 165.36, "text": " y eso es lo que componen una renauronal, en este caso una renauronal natural, una renauronal", "tokens": [50606, 288, 7287, 785, 450, 631, 4026, 268, 2002, 319, 629, 374, 21523, 11, 465, 4065, 9666, 2002, 319, 629, 374, 21523, 3303, 11, 2002, 319, 629, 374, 21523, 50854], "temperature": 0.0, "avg_logprob": -0.2584073598148259, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0007990641752257943}, {"id": 30, "seek": 15556, "start": 165.36, "end": 173.4, "text": " biol\u00f3gica. Entonces, en los a\u00f1os 40 se propuso la primera versi\u00f3n matem\u00e1tica de c\u00f3mo", "tokens": [50854, 3228, 27629, 2262, 13, 15097, 11, 465, 1750, 11424, 3356, 369, 2365, 24431, 635, 17382, 47248, 3803, 443, 23432, 368, 12826, 51256], "temperature": 0.0, "avg_logprob": -0.2584073598148259, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0007990641752257943}, {"id": 31, "seek": 15556, "start": 173.4, "end": 178.24, "text": " funciona una neurona, entonces hubo unos cient\u00edficos que dijieron, bueno, vamos a tratar de simplificar", "tokens": [51256, 26210, 2002, 34090, 64, 11, 13003, 11838, 78, 17780, 37053, 329, 631, 47709, 14440, 11, 11974, 11, 5295, 257, 42549, 368, 6883, 25625, 51498], "temperature": 0.0, "avg_logprob": -0.2584073598148259, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0007990641752257943}, {"id": 32, "seek": 15556, "start": 178.24, "end": 183.04, "text": " esto m\u00e1s posible, a estar a verlo y generar una versi\u00f3n en una ecuaci\u00f3n que trata de representar", "tokens": [51498, 7433, 3573, 26644, 11, 257, 8755, 257, 1306, 752, 288, 1337, 289, 2002, 47248, 465, 2002, 11437, 84, 3482, 631, 31920, 368, 2906, 289, 51738], "temperature": 0.0, "avg_logprob": -0.2584073598148259, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0007990641752257943}, {"id": 33, "seek": 18304, "start": 183.04, "end": 188.51999999999998, "text": " esto. Entonces, ellos dise\u00f1aron esta ecuaci\u00f3n de ac\u00e1, en la cual yo dice, bueno, vamos a cambiar", "tokens": [50364, 7433, 13, 15097, 11, 16353, 3814, 2791, 6372, 5283, 11437, 84, 3482, 368, 23496, 11, 465, 635, 10911, 5290, 10313, 11, 11974, 11, 5295, 257, 37738, 50638], "temperature": 0.0, "avg_logprob": -0.19666704737154164, "compression_ratio": 1.7256317689530687, "no_speech_prob": 0.0012828995240852237}, {"id": 34, "seek": 18304, "start": 188.51999999999998, "end": 193.76, "text": " esta neurona biol\u00f3gica que ten\u00eda todas estas partes y vamos a crear una especie de neuronar", "tokens": [50638, 5283, 34090, 64, 3228, 27629, 2262, 631, 23718, 10906, 13897, 31210, 288, 5295, 257, 31984, 2002, 49368, 368, 34090, 289, 50900], "temperature": 0.0, "avg_logprob": -0.19666704737154164, "compression_ratio": 1.7256317689530687, "no_speech_prob": 0.0012828995240852237}, {"id": 35, "seek": 18304, "start": 193.76, "end": 199.51999999999998, "text": " artificial en la cual yo tengo un conjunto de entradas, un conjunto de pesos de entrada que est\u00e1n", "tokens": [50900, 11677, 465, 635, 10911, 5290, 13989, 517, 37776, 368, 948, 48906, 11, 517, 37776, 368, 33204, 368, 37119, 631, 10368, 51188], "temperature": 0.0, "avg_logprob": -0.19666704737154164, "compression_ratio": 1.7256317689530687, "no_speech_prob": 0.0012828995240852237}, {"id": 36, "seek": 18304, "start": 199.51999999999998, "end": 204.68, "text": " ac\u00e1, que vendr\u00edan a hacer el equivalente a las dendritas. Voy a tener impulso el\u00e9ctrico de", "tokens": [51188, 23496, 11, 631, 10169, 81, 11084, 257, 6720, 806, 9052, 1576, 257, 2439, 274, 521, 3210, 296, 13, 25563, 257, 11640, 41767, 539, 806, 526, 349, 23776, 368, 51446], "temperature": 0.0, "avg_logprob": -0.19666704737154164, "compression_ratio": 1.7256317689530687, "no_speech_prob": 0.0012828995240852237}, {"id": 37, "seek": 18304, "start": 204.68, "end": 210.39999999999998, "text": " entrada que son como X1, X2, X3 hasta Xn, que digamos que son los inputs que va a tener esa", "tokens": [51446, 37119, 631, 1872, 2617, 1783, 16, 11, 1783, 17, 11, 1783, 18, 10764, 1783, 77, 11, 631, 36430, 631, 1872, 1750, 15743, 631, 2773, 257, 11640, 11342, 51732], "temperature": 0.0, "avg_logprob": -0.19666704737154164, "compression_ratio": 1.7256317689530687, "no_speech_prob": 0.0012828995240852237}, {"id": 38, "seek": 21040, "start": 210.4, "end": 216.12, "text": " neurona. Despu\u00e9s, en el centro lo que hago es sumarlos y en realidad lo que estoy sumando es el", "tokens": [50364, 34090, 64, 13, 40995, 11, 465, 806, 24607, 450, 631, 38721, 785, 2408, 39734, 288, 465, 25635, 450, 631, 15796, 2408, 1806, 785, 806, 50650], "temperature": 0.0, "avg_logprob": -0.18300715489174002, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004316050559282303}, {"id": 39, "seek": 21040, "start": 216.12, "end": 223.28, "text": " producto entre cada impulso de entrada y el peso correspondiente. Tambi\u00e9n le voy a agregar un valor", "tokens": [50650, 47583, 3962, 8411, 41767, 539, 368, 37119, 288, 806, 28149, 6805, 8413, 13, 25682, 476, 7552, 257, 4554, 2976, 517, 15367, 51008], "temperature": 0.0, "avg_logprob": -0.18300715489174002, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004316050559282303}, {"id": 40, "seek": 21040, "start": 223.28, "end": 228.56, "text": " de sesgo y despu\u00e9s la salida le voy a pasar por una funci\u00f3n de activaci\u00f3n y eso me va a dar", "tokens": [51008, 368, 5385, 1571, 288, 15283, 635, 1845, 2887, 476, 7552, 257, 25344, 1515, 2002, 43735, 368, 2430, 3482, 288, 7287, 385, 2773, 257, 4072, 51272], "temperature": 0.0, "avg_logprob": -0.18300715489174002, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004316050559282303}, {"id": 41, "seek": 21040, "start": 228.56, "end": 233.68, "text": " la salida de la neurona. Bien, o sea, esta parte les vamos a estar viendo en detalle. Pero en", "tokens": [51272, 635, 1845, 2887, 368, 635, 34090, 64, 13, 16956, 11, 277, 4158, 11, 5283, 6975, 1512, 5295, 257, 8755, 34506, 465, 1141, 11780, 13, 9377, 465, 51528], "temperature": 0.0, "avg_logprob": -0.18300715489174002, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004316050559282303}, {"id": 42, "seek": 21040, "start": 233.68, "end": 238.28, "text": " definitiva, es como que yo tuviera esta ecuaci\u00f3n de abajo, \u00bfno? Yo tengo la sumatoria de las", "tokens": [51528, 28781, 5931, 11, 785, 2617, 631, 5290, 38177, 10609, 5283, 11437, 84, 3482, 368, 30613, 11, 3841, 1771, 30, 7616, 13989, 635, 2408, 1639, 654, 368, 2439, 51758], "temperature": 0.0, "avg_logprob": -0.18300715489174002, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004316050559282303}, {"id": 43, "seek": 23828, "start": 238.28, "end": 246.28, "text": " entradas multiplicadas por pesos, a eso le subo un sesgo, que se llama B y todo eso se lo aplico", "tokens": [50364, 948, 48906, 17596, 6872, 1515, 33204, 11, 257, 7287, 476, 1422, 78, 517, 5385, 1571, 11, 631, 369, 23272, 363, 288, 5149, 7287, 369, 450, 25522, 2789, 50764], "temperature": 0.0, "avg_logprob": -0.30459660932052235, "compression_ratio": 1.6995515695067265, "no_speech_prob": 0.004060985054820776}, {"id": 44, "seek": 23828, "start": 246.28, "end": 253.56, "text": " una funci\u00f3n sigma que es un poco que son esas funciones sigma. Entonces ven que es una, digamos,", "tokens": [50764, 2002, 43735, 12771, 631, 785, 517, 10639, 631, 1872, 23388, 1019, 23469, 12771, 13, 15097, 6138, 631, 785, 2002, 11, 36430, 11, 51128], "temperature": 0.0, "avg_logprob": -0.30459660932052235, "compression_ratio": 1.6995515695067265, "no_speech_prob": 0.004060985054820776}, {"id": 45, "seek": 23828, "start": 253.56, "end": 259.76, "text": " es como una ecuaci\u00f3n lineal, \u00bfno? O sea, la sumatoria ni de XC por WB sub y m\u00e1s B,", "tokens": [51128, 785, 2617, 2002, 11437, 84, 3482, 1622, 304, 11, 3841, 1771, 30, 422, 4158, 11, 635, 2408, 1639, 654, 3867, 368, 1783, 34, 1515, 343, 33, 1422, 288, 3573, 363, 11, 51438], "temperature": 0.0, "avg_logprob": -0.30459660932052235, "compression_ratio": 1.6995515695067265, "no_speech_prob": 0.004060985054820776}, {"id": 46, "seek": 23828, "start": 259.76, "end": 265.24, "text": " todo eso es una, digamos, una f\u00f3rmula lineal y a eso le agrego un sigma, digamos, se lo aplica un", "tokens": [51438, 5149, 7287, 785, 2002, 11, 36430, 11, 2002, 283, 15614, 76, 3780, 1622, 304, 288, 257, 7287, 476, 623, 3375, 78, 517, 12771, 11, 36430, 11, 369, 450, 25522, 2262, 517, 51712], "temperature": 0.0, "avg_logprob": -0.30459660932052235, "compression_ratio": 1.6995515695067265, "no_speech_prob": 0.004060985054820776}, {"id": 47, "seek": 26524, "start": 265.24, "end": 272.28000000000003, "text": " sigma que esta va a ser una funci\u00f3n lineal. Bien, entonces, m\u00e1s adelante para simplificar esta ecuaci\u00f3n y", "tokens": [50364, 12771, 631, 5283, 2773, 257, 816, 2002, 43735, 1622, 304, 13, 16956, 11, 13003, 11, 3573, 40214, 1690, 6883, 25625, 5283, 11437, 84, 3482, 288, 50716], "temperature": 0.0, "avg_logprob": -0.23497205167203336, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.00039742724038660526}, {"id": 48, "seek": 26524, "start": 272.28000000000003, "end": 276.76, "text": " para que despu\u00e9s queden m\u00e1s f\u00e1ciles de calcular las cosas, lo que se hace es decir, bueno, este valor", "tokens": [50716, 1690, 631, 15283, 421, 6876, 3573, 17474, 279, 368, 2104, 17792, 2439, 12218, 11, 450, 631, 369, 10032, 785, 10235, 11, 11974, 11, 4065, 15367, 50940], "temperature": 0.0, "avg_logprob": -0.23497205167203336, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.00039742724038660526}, {"id": 49, "seek": 26524, "start": 276.76, "end": 285.32, "text": " que ven\u00edamos ac\u00e1, esta B que est\u00e1 sumando, que digamos se usa para que, ah\u00ed, esta B que est\u00e1 ac\u00e1,", "tokens": [50940, 631, 6138, 16275, 23496, 11, 5283, 363, 631, 3192, 2408, 1806, 11, 631, 36430, 369, 29909, 1690, 631, 11, 12571, 11, 5283, 363, 631, 3192, 23496, 11, 51368], "temperature": 0.0, "avg_logprob": -0.23497205167203336, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.00039742724038660526}, {"id": 50, "seek": 26524, "start": 285.32, "end": 291.64, "text": " que se usa para que, digamos, para poder completar toda la ecuaci\u00f3n lineal, lo que se hace", "tokens": [51368, 631, 369, 29909, 1690, 631, 11, 36430, 11, 1690, 8152, 1557, 289, 11687, 635, 11437, 84, 3482, 1622, 304, 11, 450, 631, 369, 10032, 51684], "temperature": 0.0, "avg_logprob": -0.23497205167203336, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.00039742724038660526}, {"id": 51, "seek": 29164, "start": 291.64, "end": 296.12, "text": " agregarla como un peso m\u00e1s, entonces decimos, bueno, tenemos una entrada m\u00e1s que vale uno y su peso", "tokens": [50364, 623, 3375, 34148, 2617, 517, 28149, 3573, 11, 13003, 979, 8372, 11, 11974, 11, 9914, 2002, 37119, 3573, 631, 15474, 8526, 288, 459, 28149, 50588], "temperature": 0.0, "avg_logprob": -0.2159226594147859, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.033892057836055756}, {"id": 52, "seek": 29164, "start": 296.12, "end": 301.32, "text": " correspondiente es el sesgo. De eso, en realidad, digamos, despu\u00e9s nos olvidamos. Cuando vamos a", "tokens": [50588, 6805, 8413, 785, 806, 5385, 1571, 13, 1346, 7287, 11, 465, 25635, 11, 36430, 11, 15283, 3269, 43194, 2151, 13, 21907, 5295, 257, 50848], "temperature": 0.0, "avg_logprob": -0.2159226594147859, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.033892057836055756}, {"id": 53, "seek": 29164, "start": 301.32, "end": 305.32, "text": " trabajar con estas cosas como que no utilizamos mucho el sesgo y nos concentramos en decir, bueno,", "tokens": [50848, 30793, 416, 13897, 12218, 2617, 631, 572, 19906, 2151, 9824, 806, 5385, 1571, 288, 3269, 5512, 30227, 465, 10235, 11, 11974, 11, 51048], "temperature": 0.0, "avg_logprob": -0.2159226594147859, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.033892057836055756}, {"id": 54, "seek": 29164, "start": 305.32, "end": 310.91999999999996, "text": " vamos a tener un vector que son entradas, que son los X1 hasta XN y un mont\u00f3n de pesos que son", "tokens": [51048, 5295, 257, 11640, 517, 8062, 631, 1872, 948, 48906, 11, 631, 1872, 1750, 1783, 16, 10764, 1783, 45, 288, 517, 45259, 368, 33204, 631, 1872, 51328], "temperature": 0.0, "avg_logprob": -0.2159226594147859, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.033892057836055756}, {"id": 55, "seek": 29164, "start": 310.91999999999996, "end": 315.64, "text": " los W1s WBN y adentro la neurona, lo que pasa es que voy a hacer el producto interro entre esos", "tokens": [51328, 1750, 343, 16, 82, 343, 33, 45, 288, 614, 317, 340, 635, 12087, 4037, 11, 450, 631, 20260, 785, 631, 7552, 257, 6720, 806, 47583, 728, 340, 3962, 22411, 51564], "temperature": 0.0, "avg_logprob": -0.2159226594147859, "compression_ratio": 1.7013888888888888, "no_speech_prob": 0.033892057836055756}, {"id": 56, "seek": 31564, "start": 315.64, "end": 324.28, "text": " entre el vector X y el vector W y se lo voy a pasar a la funci\u00f3n sigma. Bien, entonces,", "tokens": [50364, 3962, 806, 8062, 1783, 288, 806, 8062, 343, 288, 369, 450, 7552, 257, 25344, 257, 635, 43735, 12771, 13, 16956, 11, 13003, 11, 50796], "temperature": 0.0, "avg_logprob": -0.22003767423540632, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001852179877460003}, {"id": 57, "seek": 31564, "start": 324.28, "end": 330.68, "text": " esas funciones de activaci\u00f3n sigma hay varias, o sea, al principio, digamos, cuando dise\u00f1aron", "tokens": [50796, 23388, 1019, 23469, 368, 2430, 3482, 12771, 4842, 37496, 11, 277, 4158, 11, 419, 34308, 11, 36430, 11, 7767, 3814, 2791, 6372, 51116], "temperature": 0.0, "avg_logprob": -0.22003767423540632, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001852179877460003}, {"id": 58, "seek": 31564, "start": 330.68, "end": 336.03999999999996, "text": " primero esta neurona, lo que se les hab\u00eda ocurrido primero era decir, bueno, yo lo que hago es sumar", "tokens": [51116, 21289, 5283, 12087, 4037, 11, 450, 631, 369, 1512, 16395, 26430, 81, 2925, 21289, 4249, 10235, 11, 11974, 11, 5290, 450, 631, 38721, 785, 2408, 289, 51384], "temperature": 0.0, "avg_logprob": -0.22003767423540632, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001852179877460003}, {"id": 59, "seek": 31564, "start": 336.03999999999996, "end": 344.28, "text": " todas estas, digamos, todos estos impulsos multiplicados por los pesos, lo sumo y si esa suma supera", "tokens": [51384, 10906, 13897, 11, 36430, 11, 6321, 12585, 704, 9468, 329, 17596, 4181, 1515, 1750, 33204, 11, 450, 2408, 78, 288, 1511, 11342, 2408, 64, 1687, 64, 51796], "temperature": 0.0, "avg_logprob": -0.22003767423540632, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001852179877460003}, {"id": 60, "seek": 34428, "start": 344.28, "end": 348.52, "text": " cierto umbral, que el umbral lo podr\u00edan calcular o mucho que se ha utilizado en uno o en una de esas", "tokens": [50364, 28558, 1105, 32728, 11, 631, 806, 1105, 32728, 450, 15305, 11084, 2104, 17792, 277, 9824, 631, 369, 324, 19906, 1573, 465, 8526, 277, 465, 2002, 368, 23388, 50576], "temperature": 0.0, "avg_logprob": -0.28958917700726056, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.0016042054630815983}, {"id": 61, "seek": 34428, "start": 348.52, "end": 354.03999999999996, "text": " cosas, bueno, si supera cierto umbral, entonces mando uno para fuera y si no mando ser. Eso era lo primero", "tokens": [50576, 12218, 11, 11974, 11, 1511, 1687, 64, 28558, 1105, 32728, 11, 13003, 7411, 78, 8526, 1690, 24818, 288, 1511, 572, 7411, 78, 816, 13, 27795, 4249, 450, 21289, 50852], "temperature": 0.0, "avg_logprob": -0.28958917700726056, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.0016042054630815983}, {"id": 62, "seek": 34428, "start": 354.03999999999996, "end": 359.64, "text": " que se le hab\u00eda ocurrido, pero bueno, despu\u00e9s empezaron a encontrar otras funciones que eran mejores", "tokens": [50852, 631, 369, 476, 16395, 26430, 81, 2925, 11, 4768, 11974, 11, 15283, 18730, 6372, 257, 17525, 20244, 1019, 23469, 631, 32762, 42284, 51132], "temperature": 0.0, "avg_logprob": -0.28958917700726056, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.0016042054630815983}, {"id": 63, "seek": 34428, "start": 359.64, "end": 365.47999999999996, "text": " para poder entrenar mejores arredes y en definitiva, como que no hay mucho criterio de qu\u00e9 restricciones", "tokens": [51132, 1690, 8152, 45069, 289, 42284, 594, 986, 279, 288, 465, 28781, 5931, 11, 2617, 631, 572, 4842, 9824, 9912, 1004, 368, 8057, 1472, 1341, 23469, 51424], "temperature": 0.0, "avg_logprob": -0.28958917700726056, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.0016042054630815983}, {"id": 64, "seek": 34428, "start": 365.47999999999996, "end": 371.0, "text": " que tiene que tener esa funci\u00f3n, salvo que tiene que ser derivable, tiene que ser, tiene que ir como", "tokens": [51424, 631, 7066, 631, 11640, 11342, 43735, 11, 1845, 3080, 631, 7066, 631, 816, 10151, 712, 11, 7066, 631, 816, 11, 7066, 631, 3418, 2617, 51700], "temperature": 0.0, "avg_logprob": -0.28958917700726056, "compression_ratio": 1.8339222614840989, "no_speech_prob": 0.0016042054630815983}, {"id": 65, "seek": 37100, "start": 371.08, "end": 376.24, "text": " de menos a m\u00e1s, digamos, puede ser de 0 a 1 o de 0 m\u00e1s infinito o de menos infinito m\u00e1s infinito y", "tokens": [50368, 368, 8902, 257, 3573, 11, 36430, 11, 8919, 816, 368, 1958, 257, 502, 277, 368, 1958, 3573, 7193, 3528, 277, 368, 8902, 7193, 3528, 3573, 7193, 3528, 288, 50626], "temperature": 0.0, "avg_logprob": -0.21738688605172293, "compression_ratio": 1.8523985239852399, "no_speech_prob": 0.0006859115092083812}, {"id": 66, "seek": 37100, "start": 376.24, "end": 380.72, "text": " tiene que ser no lineal, tiene que tener alg\u00fan punto de no linealidad. Entonces, estas son algunas muy", "tokens": [50626, 7066, 631, 816, 572, 1622, 304, 11, 7066, 631, 11640, 26300, 14326, 368, 572, 1622, 304, 4580, 13, 15097, 11, 13897, 1872, 27316, 5323, 50850], "temperature": 0.0, "avg_logprob": -0.21738688605172293, "compression_ratio": 1.8523985239852399, "no_speech_prob": 0.0006859115092083812}, {"id": 67, "seek": 37100, "start": 380.72, "end": 385.16, "text": " usadas, por ejemplo, la funci\u00f3n sigma o id o funci\u00f3n log\u00edstica, que es la misma que se usa,", "tokens": [50850, 505, 6872, 11, 1515, 13358, 11, 635, 43735, 12771, 277, 4496, 277, 43735, 3565, 19512, 2262, 11, 631, 785, 635, 24946, 631, 369, 29909, 11, 51072], "temperature": 0.0, "avg_logprob": -0.21738688605172293, "compression_ratio": 1.8523985239852399, "no_speech_prob": 0.0006859115092083812}, {"id": 68, "seek": 37100, "start": 385.16, "end": 391.2, "text": " lo que estamos hablando de un rato, digamos, el m\u00e9todo de regresi\u00f3n log\u00edstica utiliza tambi\u00e9n esta", "tokens": [51072, 450, 631, 10382, 29369, 368, 517, 367, 2513, 11, 36430, 11, 806, 20275, 17423, 368, 47108, 2560, 3565, 19512, 2262, 4976, 13427, 6407, 5283, 51374], "temperature": 0.0, "avg_logprob": -0.21738688605172293, "compression_ratio": 1.8523985239852399, "no_speech_prob": 0.0006859115092083812}, {"id": 69, "seek": 37100, "start": 391.2, "end": 398.48, "text": " funci\u00f3n, la tangente par\u00f3lica es otra, la funci\u00f3n relu es muy usada y la relu se define como el", "tokens": [51374, 43735, 11, 635, 10266, 1576, 971, 812, 44266, 785, 13623, 11, 635, 43735, 1039, 84, 785, 5323, 505, 1538, 288, 635, 1039, 84, 369, 6964, 2617, 806, 51738], "temperature": 0.0, "avg_logprob": -0.21738688605172293, "compression_ratio": 1.8523985239852399, "no_speech_prob": 0.0006859115092083812}, {"id": 70, "seek": 39848, "start": 398.48, "end": 403.08000000000004, "text": " m\u00e1ximo entre 0 y 0, relu de 0 es el m\u00e1ximo entre 0 y 0, entonces vale 0 para todos los valores,", "tokens": [50364, 38876, 3962, 1958, 288, 1958, 11, 1039, 84, 368, 1958, 785, 806, 38876, 3962, 1958, 288, 1958, 11, 13003, 15474, 1958, 1690, 6321, 1750, 38790, 11, 50594], "temperature": 0.0, "avg_logprob": -0.2716894223708515, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0013550299918279052}, {"id": 71, "seek": 39848, "start": 403.08000000000004, "end": 409.08000000000004, "text": " excepto para cuando todos los valores menores que 0, pero cuando vale el mayor que 0, vale directamente", "tokens": [50594, 3993, 78, 1690, 7767, 6321, 1750, 38790, 1706, 2706, 631, 1958, 11, 4768, 7767, 15474, 806, 10120, 631, 1958, 11, 15474, 46230, 50894], "temperature": 0.0, "avg_logprob": -0.2716894223708515, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0013550299918279052}, {"id": 72, "seek": 39848, "start": 409.08000000000004, "end": 412.88, "text": " el valor. Estas son unas funciones un poco esta\u00f1a, pues yo les dije que ten\u00edan que hacer todas", "tokens": [50894, 806, 15367, 13, 4410, 296, 1872, 25405, 1019, 23469, 517, 10639, 5283, 12150, 11, 11059, 5290, 1512, 39414, 631, 47596, 631, 6720, 10906, 51084], "temperature": 0.0, "avg_logprob": -0.2716894223708515, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0013550299918279052}, {"id": 73, "seek": 39848, "start": 412.88, "end": 417.64000000000004, "text": " derivables y esta justo no es derivable en el punto 0, pero despu\u00e9s es derivable en todo el", "tokens": [51084, 10151, 2965, 288, 5283, 40534, 572, 785, 10151, 712, 465, 806, 14326, 1958, 11, 4768, 15283, 785, 10151, 712, 465, 5149, 806, 51322], "temperature": 0.0, "avg_logprob": -0.2716894223708515, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0013550299918279052}, {"id": 74, "seek": 39848, "start": 417.64000000000004, "end": 423.08000000000004, "text": " resto de los reales. Bueno, ya hay otras m\u00e1s, pero estas como son como de las m\u00e1s utilizadas.", "tokens": [51322, 28247, 368, 1750, 957, 279, 13, 16046, 11, 2478, 4842, 20244, 3573, 11, 4768, 13897, 2617, 1872, 2617, 368, 2439, 3573, 19906, 6872, 13, 51594], "temperature": 0.0, "avg_logprob": -0.2716894223708515, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0013550299918279052}, {"id": 75, "seek": 42308, "start": 423.08, "end": 431.24, "text": " Bien, lo importante ac\u00e1 es que estas funciones de activaci\u00f3n provenan una no linealidad y vamos a", "tokens": [50364, 16956, 11, 450, 9416, 23496, 785, 631, 13897, 1019, 23469, 368, 2430, 3482, 12785, 282, 2002, 572, 1622, 304, 4580, 288, 5295, 257, 50772], "temperature": 0.0, "avg_logprob": -0.2701027961004348, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0005985356401652098}, {"id": 76, "seek": 42308, "start": 431.24, "end": 438.44, "text": " ver, \u00bfpor qu\u00e9? Ok, bueno, entonces vimos lo que era una neurona, imag\u00ednense que en general las", "tokens": [50772, 1306, 11, 3841, 2816, 8057, 30, 3477, 11, 11974, 11, 13003, 49266, 450, 631, 4249, 2002, 12087, 4037, 11, 2576, 10973, 1288, 631, 465, 2674, 2439, 51132], "temperature": 0.0, "avg_logprob": -0.2701027961004348, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0005985356401652098}, {"id": 77, "seek": 42308, "start": 438.44, "end": 448.12, "text": " neuronas se ponen como en grupos, digamos, y se distribuyen en capas dentro de una red, \u00bfno?", "tokens": [51132, 12087, 38027, 369, 9224, 268, 2617, 465, 33758, 11, 36430, 11, 288, 369, 4400, 84, 16580, 465, 1410, 296, 10856, 368, 2002, 2182, 11, 3841, 1771, 30, 51616], "temperature": 0.0, "avg_logprob": -0.2701027961004348, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0005985356401652098}, {"id": 78, "seek": 44812, "start": 448.12, "end": 453.0, "text": " Entonces, este es un ejemplo de una de las redes neuronales m\u00e1s simples, m\u00e1s simples que en", "tokens": [50364, 15097, 11, 4065, 785, 517, 13358, 368, 2002, 368, 2439, 16762, 34090, 4229, 3573, 21730, 11, 3573, 21730, 631, 465, 50608], "temperature": 0.0, "avg_logprob": -0.2951846861503494, "compression_ratio": 1.6822742474916388, "no_speech_prob": 0.1383339762687683}, {"id": 79, "seek": 44812, "start": 453.0, "end": 459.04, "text": " realidad son \u00fatiles para algo, que se conoce como Perceptron Multi-Capa o Redfield Forward Multi-Capa,", "tokens": [50608, 25635, 1872, 6991, 83, 4680, 1690, 8655, 11, 631, 369, 33029, 384, 2617, 3026, 1336, 2044, 29238, 12, 34, 7961, 277, 4477, 7610, 35524, 29238, 12, 34, 7961, 11, 50910], "temperature": 0.0, "avg_logprob": -0.2951846861503494, "compression_ratio": 1.6822742474916388, "no_speech_prob": 0.1383339762687683}, {"id": 80, "seek": 44812, "start": 459.04, "end": 464.52, "text": " que funcione de la siguiente manera, \u00bfno? Nosotros tenemos todas las entradas, esas que yo les dec\u00eda", "tokens": [50910, 631, 1019, 66, 5328, 368, 635, 25666, 13913, 11, 3841, 1771, 30, 18749, 11792, 9914, 10906, 2439, 948, 48906, 11, 23388, 631, 5290, 1512, 37599, 51184], "temperature": 0.0, "avg_logprob": -0.2951846861503494, "compression_ratio": 1.6822742474916388, "no_speech_prob": 0.1383339762687683}, {"id": 81, "seek": 44812, "start": 464.52, "end": 470.92, "text": " que la centrada es X1, X2, X3, etc\u00e9tera, este Xn, ser\u00eda como una primera capa de entrada y despu\u00e9s", "tokens": [51184, 631, 635, 1489, 19120, 785, 1783, 16, 11, 1783, 17, 11, 1783, 18, 11, 5183, 526, 23833, 11, 4065, 1783, 77, 11, 23679, 2617, 2002, 17382, 1410, 64, 368, 37119, 288, 15283, 51504], "temperature": 0.0, "avg_logprob": -0.2951846861503494, "compression_ratio": 1.6822742474916388, "no_speech_prob": 0.1383339762687683}, {"id": 82, "seek": 44812, "start": 470.92, "end": 476.68, "text": " yo ubico un mont\u00f3n de neuronas en una segunda capa y las capas que vienen despu\u00e9s de la entrada le", "tokens": [51504, 5290, 26709, 2789, 517, 45259, 368, 34090, 296, 465, 2002, 21978, 1410, 64, 288, 2439, 1410, 296, 631, 49298, 15283, 368, 635, 37119, 476, 51792], "temperature": 0.0, "avg_logprob": -0.2951846861503494, "compression_ratio": 1.6822742474916388, "no_speech_prob": 0.1383339762687683}, {"id": 83, "seek": 47668, "start": 476.68, "end": 482.8, "text": " voy a llamar capas ocultas, o sea, tengo una primera capa de entrada, esa capa lleva a una capa oculta y", "tokens": [50364, 7552, 257, 16848, 289, 1410, 296, 10409, 723, 296, 11, 277, 4158, 11, 13989, 2002, 17382, 1410, 64, 368, 37119, 11, 11342, 1410, 64, 37681, 257, 2002, 1410, 64, 10409, 723, 64, 288, 50670], "temperature": 0.0, "avg_logprob": -0.15550889038458104, "compression_ratio": 2.070588235294118, "no_speech_prob": 0.0005557566182687879}, {"id": 84, "seek": 47668, "start": 482.8, "end": 486.48, "text": " todas las neuronas de la capa oculta est\u00e1n interconectadas con todas las neuronas de la capa de entrada,", "tokens": [50670, 10906, 2439, 34090, 296, 368, 635, 1410, 64, 10409, 723, 64, 10368, 728, 66, 546, 349, 6872, 416, 10906, 2439, 34090, 296, 368, 635, 1410, 64, 368, 37119, 11, 50854], "temperature": 0.0, "avg_logprob": -0.15550889038458104, "compression_ratio": 2.070588235294118, "no_speech_prob": 0.0005557566182687879}, {"id": 85, "seek": 47668, "start": 486.48, "end": 494.56, "text": " o sea, hay pesos que van de todas a todas, despu\u00e9s puedo tener otra segunda capa oculta, otra tercera capa", "tokens": [50854, 277, 4158, 11, 4842, 33204, 631, 3161, 368, 10906, 257, 10906, 11, 15283, 21612, 11640, 13623, 21978, 1410, 64, 10409, 723, 64, 11, 13623, 1796, 41034, 1410, 64, 51258], "temperature": 0.0, "avg_logprob": -0.15550889038458104, "compression_ratio": 2.070588235294118, "no_speech_prob": 0.0005557566182687879}, {"id": 86, "seek": 47668, "start": 494.56, "end": 499.0, "text": " oculta, etc\u00e9tera, hasta que llevo a una \u00faltima capa que tambi\u00e9n est\u00e1 interconectada con la anterior,", "tokens": [51258, 10409, 723, 64, 11, 5183, 526, 23833, 11, 10764, 631, 12038, 3080, 257, 2002, 28118, 1410, 64, 631, 6407, 3192, 728, 66, 546, 349, 1538, 416, 635, 22272, 11, 51480], "temperature": 0.0, "avg_logprob": -0.15550889038458104, "compression_ratio": 2.070588235294118, "no_speech_prob": 0.0005557566182687879}, {"id": 87, "seek": 47668, "start": 499.0, "end": 506.64, "text": " que es la capa de salida, bien, pero no hay enlaces que vayan entre la capa inicial y la capa de salida,", "tokens": [51480, 631, 785, 635, 1410, 64, 368, 1845, 2887, 11, 3610, 11, 4768, 572, 4842, 465, 75, 2116, 631, 371, 20506, 3962, 635, 1410, 64, 44076, 288, 635, 1410, 64, 368, 1845, 2887, 11, 51862], "temperature": 0.0, "avg_logprob": -0.15550889038458104, "compression_ratio": 2.070588235294118, "no_speech_prob": 0.0005557566182687879}, {"id": 88, "seek": 50664, "start": 506.64, "end": 511.28, "text": " digamos, la capa de entrada y la capa de salida, sino que siempre los enlaces van entre una capa y la siguiente,", "tokens": [50364, 36430, 11, 635, 1410, 64, 368, 37119, 288, 635, 1410, 64, 368, 1845, 2887, 11, 18108, 631, 12758, 1750, 465, 75, 2116, 3161, 3962, 2002, 1410, 64, 288, 635, 25666, 11, 50596], "temperature": 0.0, "avg_logprob": -0.20904027402790543, "compression_ratio": 1.9288389513108615, "no_speech_prob": 0.0002886694564949721}, {"id": 89, "seek": 50664, "start": 511.28, "end": 518.6, "text": " entonces ac\u00e1 yo digo que tengo una arquitectura en capas donde tengo este, en seg\u00fan esta imagen K,", "tokens": [50596, 13003, 23496, 5290, 22990, 631, 13989, 2002, 40258, 5739, 2991, 465, 1410, 296, 10488, 13989, 4065, 11, 465, 36570, 5283, 40652, 591, 11, 50962], "temperature": 0.0, "avg_logprob": -0.20904027402790543, "compression_ratio": 1.9288389513108615, "no_speech_prob": 0.0002886694564949721}, {"id": 90, "seek": 50664, "start": 518.6, "end": 523.64, "text": " capas ocultas, tengo la capa oculta 1, capa oculta 2, capa oculta K y despu\u00e9s una capa de salida,", "tokens": [50962, 1410, 296, 10409, 723, 296, 11, 13989, 635, 1410, 64, 10409, 723, 64, 502, 11, 1410, 64, 10409, 723, 64, 568, 11, 1410, 64, 10409, 723, 64, 591, 288, 15283, 2002, 1410, 64, 368, 1845, 2887, 11, 51214], "temperature": 0.0, "avg_logprob": -0.20904027402790543, "compression_ratio": 1.9288389513108615, "no_speech_prob": 0.0002886694564949721}, {"id": 91, "seek": 50664, "start": 523.64, "end": 529.36, "text": " bien, entonces esta es como la arquitectura m\u00e1s sencilla, yo tengo un mont\u00f3n de capas, una atr\u00e1s de", "tokens": [51214, 3610, 11, 13003, 5283, 785, 2617, 635, 40258, 5739, 2991, 3573, 3151, 66, 5291, 11, 5290, 13989, 517, 45259, 368, 1410, 296, 11, 2002, 22906, 368, 51500], "temperature": 0.0, "avg_logprob": -0.20904027402790543, "compression_ratio": 1.9288389513108615, "no_speech_prob": 0.0002886694564949721}, {"id": 92, "seek": 50664, "start": 529.36, "end": 534.08, "text": " otra y cada capa est\u00e1 completamente interconectada con la anterior, pero nunca saltan entre capas,", "tokens": [51500, 13623, 288, 8411, 1410, 64, 3192, 28381, 728, 66, 546, 349, 1538, 416, 635, 22272, 11, 4768, 13768, 5139, 282, 3962, 1410, 296, 11, 51736], "temperature": 0.0, "avg_logprob": -0.20904027402790543, "compression_ratio": 1.9288389513108615, "no_speech_prob": 0.0002886694564949721}, {"id": 93, "seek": 53408, "start": 534.08, "end": 543.12, "text": " bien, entonces analicemos un poco que es lo que pasa dentro de esas capas y para eso vamos a", "tokens": [50364, 3610, 11, 13003, 2624, 299, 4485, 517, 10639, 631, 785, 450, 631, 20260, 10856, 368, 23388, 1410, 296, 288, 1690, 7287, 5295, 257, 50816], "temperature": 0.0, "avg_logprob": -0.2386547868902033, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0003126927185803652}, {"id": 94, "seek": 53408, "start": 543.12, "end": 550.6800000000001, "text": " tratar de mirar la capa, bien, yo tengo entonces en esa imagen es como estamos viendo la frontera", "tokens": [50816, 42549, 368, 3149, 289, 635, 1410, 64, 11, 3610, 11, 5290, 13989, 13003, 465, 11342, 40652, 785, 2617, 10382, 34506, 635, 431, 266, 23833, 51194], "temperature": 0.0, "avg_logprob": -0.2386547868902033, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0003126927185803652}, {"id": 95, "seek": 53408, "start": 550.6800000000001, "end": 558.9200000000001, "text": " entre una capa y la siguiente, yo tengo la frontera de la capa W1, la capa y y la capa y m\u00e1s 1,", "tokens": [51194, 3962, 2002, 1410, 64, 288, 635, 25666, 11, 5290, 13989, 635, 431, 266, 23833, 368, 635, 1410, 64, 343, 16, 11, 635, 1410, 64, 288, 288, 635, 1410, 64, 288, 3573, 502, 11, 51606], "temperature": 0.0, "avg_logprob": -0.2386547868902033, "compression_ratio": 1.7393939393939395, "no_speech_prob": 0.0003126927185803652}, {"id": 96, "seek": 55892, "start": 559.4, "end": 566.28, "text": " entonces voy a decir que los estados de las neuronas en la capa y que llegan a la capa y son", "tokens": [50388, 13003, 7552, 257, 10235, 631, 1750, 871, 4181, 368, 2439, 34090, 296, 465, 635, 1410, 64, 288, 631, 11234, 282, 257, 635, 1410, 64, 288, 1872, 50732], "temperature": 0.0, "avg_logprob": -0.19036879142125449, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003991210367530584}, {"id": 97, "seek": 55892, "start": 566.28, "end": 575.12, "text": " X1 super\u00ed, X2 super\u00ed, X3 super\u00ed, X4 super\u00ed, bien, eso va a ser el estado de la capa y y", "tokens": [50732, 1783, 16, 1687, 870, 11, 1783, 17, 1687, 870, 11, 1783, 18, 1687, 870, 11, 1783, 19, 1687, 870, 11, 3610, 11, 7287, 2773, 257, 816, 806, 18372, 368, 635, 1410, 64, 288, 288, 51174], "temperature": 0.0, "avg_logprob": -0.19036879142125449, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003991210367530584}, {"id": 98, "seek": 55892, "start": 575.12, "end": 582.0, "text": " quiero calcular cu\u00e1l va a ser el valor de la capa y m\u00e1s 1 dado que el valor de la capa y era eso,", "tokens": [51174, 16811, 2104, 17792, 44318, 2773, 257, 816, 806, 15367, 368, 635, 1410, 64, 288, 3573, 502, 29568, 631, 806, 15367, 368, 635, 1410, 64, 288, 4249, 7287, 11, 51518], "temperature": 0.0, "avg_logprob": -0.19036879142125449, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003991210367530584}, {"id": 99, "seek": 58200, "start": 582.0, "end": 593.44, "text": " entonces la capa y yo ten\u00eda que val\u00eda esto, X1 super\u00ed, X2 super\u00ed, X3 super\u00ed y creo que", "tokens": [50364, 13003, 635, 1410, 64, 288, 5290, 23718, 631, 1323, 2686, 7433, 11, 1783, 16, 1687, 870, 11, 1783, 17, 1687, 870, 11, 1783, 18, 1687, 870, 288, 14336, 631, 50936], "temperature": 0.0, "avg_logprob": -0.24979456265767416, "compression_ratio": 1.3834586466165413, "no_speech_prob": 0.0011602053418755531}, {"id": 100, "seek": 58200, "start": 593.44, "end": 605.76, "text": " llegamos a 4, esta, X4 super, esto es un vector, bien, entonces recuerden como calcul\u00e1bamos", "tokens": [50936, 11234, 2151, 257, 1017, 11, 5283, 11, 1783, 19, 1687, 11, 7433, 785, 517, 8062, 11, 3610, 11, 13003, 39092, 1556, 2617, 4322, 27879, 2151, 51552], "temperature": 0.0, "avg_logprob": -0.24979456265767416, "compression_ratio": 1.3834586466165413, "no_speech_prob": 0.0011602053418755531}, {"id": 101, "seek": 60576, "start": 606.52, "end": 611.8, "text": " el valor de una neurona, dec\u00edamos que por ejemplo para calcular la neurona que est\u00e1", "tokens": [50402, 806, 15367, 368, 2002, 34090, 64, 11, 979, 16275, 631, 1515, 13358, 1690, 2104, 17792, 635, 34090, 64, 631, 3192, 50666], "temperature": 0.0, "avg_logprob": -0.25260298592703684, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.007808609399944544}, {"id": 102, "seek": 60576, "start": 611.8, "end": 623.12, "text": " y arriba que es X1 y m\u00e1s 1 el valor de esta neurona se calculaba como y ten\u00eda que hacer las", "tokens": [50666, 288, 28469, 631, 785, 1783, 16, 288, 3573, 502, 806, 15367, 368, 5283, 34090, 64, 369, 4322, 5509, 2617, 288, 23718, 631, 6720, 2439, 51232], "temperature": 0.0, "avg_logprob": -0.25260298592703684, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.007808609399944544}, {"id": 103, "seek": 60576, "start": 623.12, "end": 629.64, "text": " sumas digamos de los inputs que est\u00e1 donde la de izquierdo por los pesos que llegaban hasta ah\u00ed,", "tokens": [51232, 2408, 296, 36430, 368, 1750, 15743, 631, 3192, 10488, 635, 368, 46428, 2595, 1515, 1750, 33204, 631, 11234, 18165, 10764, 12571, 11, 51558], "temperature": 0.0, "avg_logprob": -0.25260298592703684, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.007808609399944544}, {"id": 104, "seek": 60576, "start": 629.64, "end": 635.3199999999999, "text": " entonces en este caso son todas las neuronas que est\u00e1n en la capa y, todos los valores de la", "tokens": [51558, 13003, 465, 4065, 9666, 1872, 10906, 2439, 34090, 296, 631, 10368, 465, 635, 1410, 64, 288, 11, 6321, 1750, 38790, 368, 635, 51842], "temperature": 0.0, "avg_logprob": -0.25260298592703684, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.007808609399944544}, {"id": 105, "seek": 63532, "start": 635.32, "end": 644.32, "text": " neuronas multiplicados por todos los valores de las flechitas, entonces ser\u00eda X1 super\u00ed por", "tokens": [50364, 34090, 296, 17596, 4181, 1515, 6321, 1750, 38790, 368, 2439, 7025, 339, 14182, 11, 13003, 23679, 1783, 16, 1687, 870, 1515, 50814], "temperature": 0.0, "avg_logprob": -0.2355097189716909, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.00020773103460669518}, {"id": 106, "seek": 63532, "start": 644.32, "end": 651.9200000000001, "text": " W y la flechita que est\u00e1 yendo desde la neurona 1 de la capa y hasta la neurona 1 de la capa y", "tokens": [50814, 343, 288, 635, 7025, 339, 2786, 631, 3192, 288, 3999, 10188, 635, 34090, 64, 502, 368, 635, 1410, 64, 288, 10764, 635, 34090, 64, 502, 368, 635, 1410, 64, 288, 51194], "temperature": 0.0, "avg_logprob": -0.2355097189716909, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.00020773103460669518}, {"id": 107, "seek": 63532, "start": 651.9200000000001, "end": 662.12, "text": " m\u00e1s 1 se llama W1, entonces X1 por W1, m\u00e1s la segunda capa, perd\u00f3n la segunda neurona de la", "tokens": [51194, 3573, 502, 369, 23272, 343, 16, 11, 13003, 1783, 16, 1515, 343, 16, 11, 3573, 635, 21978, 1410, 64, 11, 12611, 1801, 635, 21978, 34090, 64, 368, 635, 51704], "temperature": 0.0, "avg_logprob": -0.2355097189716909, "compression_ratio": 1.6904761904761905, "no_speech_prob": 0.00020773103460669518}, {"id": 108, "seek": 66212, "start": 662.12, "end": 673.12, "text": " capa y por el segundo peso, este era el 2, 1, el peso 2, 1, esto tambi\u00e9n es de la capa y", "tokens": [50364, 1410, 64, 288, 1515, 806, 17954, 28149, 11, 4065, 4249, 806, 568, 11, 502, 11, 806, 28149, 568, 11, 502, 11, 7433, 6407, 785, 368, 635, 1410, 64, 288, 50914], "temperature": 0.0, "avg_logprob": -0.2597393776053813, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0006894454127177596}, {"id": 109, "seek": 66212, "start": 675.12, "end": 691.4, "text": " m\u00e1s X3 por W3, uno, todo esto es de la capa y, m\u00e1s X4 por W4, uno, bien, entonces la salida", "tokens": [51014, 3573, 1783, 18, 1515, 343, 18, 11, 8526, 11, 5149, 7433, 785, 368, 635, 1410, 64, 288, 11, 3573, 1783, 19, 1515, 343, 19, 11, 8526, 11, 3610, 11, 13003, 635, 1845, 2887, 51828], "temperature": 0.0, "avg_logprob": -0.2597393776053813, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0006894454127177596}, {"id": 110, "seek": 69212, "start": 692.4, "end": 703.0, "text": " X sub 1 de la capa y m\u00e1s 1 es el producto de todas estas ac\u00e1, bien, es el producto de la neurona 1 de la", "tokens": [50378, 1783, 1422, 502, 368, 635, 1410, 64, 288, 3573, 502, 785, 806, 47583, 368, 10906, 13897, 23496, 11, 3610, 11, 785, 806, 47583, 368, 635, 34090, 64, 502, 368, 635, 50908], "temperature": 0.0, "avg_logprob": -0.20547144900086106, "compression_ratio": 1.973856209150327, "no_speech_prob": 0.0015076537383720279}, {"id": 111, "seek": 69212, "start": 703.0, "end": 707.16, "text": " capa anterior por el peso 1, la neurona 2 de la capa anterior por el peso 2, 1, la neurona 3 de la", "tokens": [50908, 1410, 64, 22272, 1515, 806, 28149, 502, 11, 635, 34090, 64, 568, 368, 635, 1410, 64, 22272, 1515, 806, 28149, 568, 11, 502, 11, 635, 34090, 64, 805, 368, 635, 51116], "temperature": 0.0, "avg_logprob": -0.20547144900086106, "compression_ratio": 1.973856209150327, "no_speech_prob": 0.0015076537383720279}, {"id": 112, "seek": 69212, "start": 707.16, "end": 713.4, "text": " capa anterior por el peso 3, 1, lo mismo puedo hacer para la otra, puedo decir X2 y ser\u00eda igual", "tokens": [51116, 1410, 64, 22272, 1515, 806, 28149, 805, 11, 502, 11, 450, 12461, 21612, 6720, 1690, 635, 13623, 11, 21612, 10235, 1783, 17, 288, 23679, 10953, 51428], "temperature": 0.0, "avg_logprob": -0.20547144900086106, "compression_ratio": 1.973856209150327, "no_speech_prob": 0.0015076537383720279}, {"id": 113, "seek": 71340, "start": 713.4, "end": 723.3199999999999, "text": " solo que cambiando ac\u00e1 cambiando los lugares a 2, entonces yo es X1 y por W1, 2 y, m\u00e1s 2", "tokens": [50364, 6944, 631, 19569, 1806, 23496, 19569, 1806, 1750, 33105, 257, 568, 11, 13003, 5290, 785, 1783, 16, 288, 1515, 343, 16, 11, 568, 288, 11, 3573, 568, 50860], "temperature": 0.0, "avg_logprob": -0.31923906990651335, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.03221496567130089}, {"id": 114, "seek": 71340, "start": 723.3199999999999, "end": 737.68, "text": " estos, m\u00e1s X4 y por W4, 2 y, bien, s\u00ed, decimos, ah\u00ed est\u00e1, cuando estamos en una arquitectura en", "tokens": [50860, 12585, 11, 3573, 1783, 19, 288, 1515, 343, 19, 11, 568, 288, 11, 3610, 11, 8600, 11, 979, 8372, 11, 12571, 3192, 11, 7767, 10382, 465, 2002, 40258, 5739, 2991, 465, 51578], "temperature": 0.0, "avg_logprob": -0.31923906990651335, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.03221496567130089}, {"id": 115, "seek": 71340, "start": 737.68, "end": 741.72, "text": " capas como \u00e9sta es as\u00ed, cada de todas las neuronas de la capa siguiente est\u00e1n conectadas con", "tokens": [51578, 1410, 296, 2617, 1136, 9140, 785, 8582, 11, 8411, 368, 10906, 2439, 34090, 296, 368, 635, 1410, 64, 25666, 10368, 30458, 6872, 416, 51780], "temperature": 0.0, "avg_logprob": -0.31923906990651335, "compression_ratio": 1.5052631578947369, "no_speech_prob": 0.03221496567130089}, {"id": 116, "seek": 74172, "start": 741.84, "end": 747.5600000000001, "text": " la anterior, pero nunca saltan de capas, nunca cruzan hacia otra, y nunca vuelen hacia atr\u00e1s,", "tokens": [50370, 635, 22272, 11, 4768, 13768, 5139, 282, 368, 1410, 296, 11, 13768, 5140, 21238, 21365, 13623, 11, 288, 13768, 20126, 268, 21365, 22906, 11, 50656], "temperature": 0.0, "avg_logprob": -0.2566092926778911, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0044277384877204895}, {"id": 117, "seek": 74172, "start": 747.5600000000001, "end": 750.72, "text": " que es otra cosa que puede pasar en otras arquitecturas de redes, pero esta que es la m\u00e1s", "tokens": [50656, 631, 785, 13623, 10163, 631, 8919, 25344, 465, 20244, 40258, 5739, 12907, 368, 16762, 11, 4768, 5283, 631, 785, 635, 3573, 50814], "temperature": 0.0, "avg_logprob": -0.2566092926778911, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0044277384877204895}, {"id": 118, "seek": 74172, "start": 750.72, "end": 757.2, "text": " simple es cada capa con la siguiente, bueno, entonces X3 ser\u00eda lo mismo, X1 y ac\u00e1 el peso 1, 3,", "tokens": [50814, 2199, 785, 8411, 1410, 64, 416, 635, 25666, 11, 11974, 11, 13003, 1783, 18, 23679, 450, 12461, 11, 1783, 16, 288, 23496, 806, 28149, 502, 11, 805, 11, 51138], "temperature": 0.0, "avg_logprob": -0.2566092926778911, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.0044277384877204895}, {"id": 119, "seek": 75720, "start": 757.2, "end": 770.9200000000001, "text": " tanda tata, X4, el peso 4, 3, s\u00ed, la dimensi\u00f3n es de ah\u00ed, los X son vectores de la carrera o de", "tokens": [50364, 256, 5575, 256, 3274, 11, 1783, 19, 11, 806, 28149, 1017, 11, 805, 11, 8600, 11, 635, 5013, 694, 2560, 785, 368, 12571, 11, 1750, 1783, 1872, 1241, 349, 2706, 368, 635, 15910, 1663, 277, 368, 51050], "temperature": 0.0, "avg_logprob": -0.4594445322074142, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01505484338849783}, {"id": 120, "seek": 75720, "start": 770.9200000000001, "end": 778.2, "text": " vez con reales, s\u00ed, o sea, no, ac\u00e1 son todos reales, X, todos los X y todos los doles son", "tokens": [51050, 5715, 416, 957, 279, 11, 8600, 11, 277, 4158, 11, 572, 11, 23496, 1872, 6321, 957, 279, 11, 1783, 11, 6321, 1750, 1783, 288, 6321, 1750, 360, 904, 1872, 51414], "temperature": 0.0, "avg_logprob": -0.4594445322074142, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01505484338849783}, {"id": 121, "seek": 75720, "start": 778.2, "end": 785.7, "text": " todos valores reales, entonces eso quer\u00eda llegar, yo tengo, X1, X2, X3, X4 son 4 valores reales", "tokens": [51414, 6321, 38790, 957, 279, 11, 13003, 7287, 37869, 24892, 11, 5290, 13989, 11, 1783, 16, 11, 1783, 17, 11, 1783, 18, 11, 1783, 19, 1872, 1017, 38790, 957, 279, 51789], "temperature": 0.0, "avg_logprob": -0.4594445322074142, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.01505484338849783}, {"id": 122, "seek": 78570, "start": 785.7, "end": 791.58, "text": " que componen un vector, y si yo agarro todos los doles 1, 1, 2, 1, doles 3, 1, doles 4, 1,", "tokens": [50364, 631, 715, 32923, 517, 8062, 11, 288, 1511, 5290, 623, 2284, 78, 6321, 1750, 360, 904, 502, 11, 502, 11, 568, 11, 502, 11, 360, 904, 805, 11, 502, 11, 360, 904, 1017, 11, 502, 11, 50658], "temperature": 0.0, "avg_logprob": -0.29361186641277653, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.0029419518541544676}, {"id": 123, "seek": 78570, "start": 791.58, "end": 796.46, "text": " doles 1, doles 2, etc\u00e9tera, esto compone una matriz, en realidad, yo puedo construirme la", "tokens": [50658, 360, 904, 502, 11, 360, 904, 568, 11, 5183, 526, 23833, 11, 7433, 715, 546, 2002, 3803, 24959, 11, 465, 25635, 11, 5290, 21612, 38445, 1398, 635, 50902], "temperature": 0.0, "avg_logprob": -0.29361186641277653, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.0029419518541544676}, {"id": 124, "seek": 78570, "start": 796.46, "end": 806.6, "text": " matriz de la capa Y, es igual esta matriz que tiene dole 1, 1, hasta dole 4, 3, bien,", "tokens": [50902, 3803, 24959, 368, 635, 1410, 64, 398, 11, 785, 10953, 5283, 3803, 24959, 631, 7066, 360, 306, 502, 11, 502, 11, 10764, 360, 306, 1017, 11, 805, 11, 3610, 11, 51409], "temperature": 0.0, "avg_logprob": -0.29361186641277653, "compression_ratio": 1.638036809815951, "no_speech_prob": 0.0029419518541544676}, {"id": 125, "seek": 80660, "start": 806.72, "end": 818.08, "text": " W, 1, 3, W, 4, 1, bien, esto es una matriz, entonces al tener eso, en realidad yo puedo expresar la", "tokens": [50370, 343, 11, 502, 11, 805, 11, 343, 11, 1017, 11, 502, 11, 3610, 11, 7433, 785, 2002, 3803, 24959, 11, 13003, 419, 11640, 7287, 11, 465, 25635, 5290, 21612, 33397, 289, 635, 50938], "temperature": 0.0, "avg_logprob": -0.21528812906016473, "compression_ratio": 1.838862559241706, "no_speech_prob": 0.02460360713303089}, {"id": 126, "seek": 80660, "start": 818.08, "end": 823.32, "text": " salida de esta capa, puedo expresar los estados en los cuales digamos los valores en los que quedan", "tokens": [50938, 1845, 2887, 368, 5283, 1410, 64, 11, 21612, 33397, 289, 1750, 871, 4181, 465, 1750, 46932, 36430, 1750, 38790, 465, 1750, 631, 13617, 282, 51200], "temperature": 0.0, "avg_logprob": -0.21528812906016473, "compression_ratio": 1.838862559241706, "no_speech_prob": 0.02460360713303089}, {"id": 127, "seek": 80660, "start": 823.32, "end": 827.52, "text": " las neuronas de la capa siguiente, los puedo expresar como un producto de matrices, yo digo,", "tokens": [51200, 2439, 34090, 296, 368, 635, 1410, 64, 25666, 11, 1750, 21612, 33397, 289, 2617, 517, 47583, 368, 3803, 24373, 11, 5290, 22990, 11, 51410], "temperature": 0.0, "avg_logprob": -0.21528812906016473, "compression_ratio": 1.838862559241706, "no_speech_prob": 0.02460360713303089}, {"id": 128, "seek": 80660, "start": 827.52, "end": 835.08, "text": " el vector en la capa Y era esto, entonces el vector en la capa Y m\u00e1s 1 va a ser el producto de", "tokens": [51410, 806, 8062, 465, 635, 1410, 64, 398, 4249, 7433, 11, 13003, 806, 8062, 465, 635, 1410, 64, 398, 3573, 502, 2773, 257, 816, 806, 47583, 368, 51788], "temperature": 0.0, "avg_logprob": -0.21528812906016473, "compression_ratio": 1.838862559241706, "no_speech_prob": 0.02460360713303089}, {"id": 129, "seek": 83508, "start": 835.08, "end": 840.64, "text": " XC por WI, digamos esto termina siendo un producto de matrices, si hace el producto de matrices", "tokens": [50364, 1783, 34, 1515, 343, 40, 11, 36430, 7433, 1433, 1426, 31423, 517, 47583, 368, 3803, 24373, 11, 1511, 10032, 806, 47583, 368, 3803, 24373, 50642], "temperature": 0.0, "avg_logprob": -0.28000408199662014, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0007891064742580056}, {"id": 130, "seek": 83508, "start": 840.64, "end": 847.8000000000001, "text": " me dar\u00eda X1 por W1, X2 por W1, X3 por W3, 1, X4 por W1, que es lo mismo que est\u00e9", "tokens": [50642, 385, 4072, 2686, 1783, 16, 1515, 343, 16, 11, 1783, 17, 1515, 343, 16, 11, 1783, 18, 1515, 343, 18, 11, 502, 11, 1783, 19, 1515, 343, 16, 11, 631, 785, 450, 12461, 631, 34584, 51000], "temperature": 0.0, "avg_logprob": -0.28000408199662014, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0007891064742580056}, {"id": 131, "seek": 83508, "start": 847.8000000000001, "end": 851.34, "text": " ac\u00e1, y si vamos con la segunda columna, me da el mismo de ac\u00e1, y si vamos con la", "tokens": [51000, 23496, 11, 288, 1511, 5295, 416, 635, 21978, 5970, 629, 11, 385, 1120, 806, 12461, 368, 23496, 11, 288, 1511, 5295, 416, 635, 51177], "temperature": 0.0, "avg_logprob": -0.28000408199662014, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0007891064742580056}, {"id": 132, "seek": 83508, "start": 851.34, "end": 855.5600000000001, "text": " tercera columna, me da el mismo de ac\u00e1, pero es en definitiva la salida de esta capa,", "tokens": [51177, 1796, 41034, 5970, 629, 11, 385, 1120, 806, 12461, 368, 23496, 11, 4768, 785, 465, 28781, 5931, 635, 1845, 2887, 368, 5283, 1410, 64, 11, 51388], "temperature": 0.0, "avg_logprob": -0.28000408199662014, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0007891064742580056}, {"id": 133, "seek": 83508, "start": 856.76, "end": 862.8000000000001, "text": " digamos si yo tengo esa neuron ah\u00ed, la salida de la capa, a ver d\u00f3nde les creo,", "tokens": [51448, 36430, 1511, 5290, 13989, 11342, 34090, 12571, 11, 635, 1845, 2887, 368, 635, 1410, 64, 11, 257, 1306, 34264, 1512, 14336, 11, 51750], "temperature": 0.0, "avg_logprob": -0.28000408199662014, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0007891064742580056}, {"id": 134, "seek": 86280, "start": 863.52, "end": 867.24, "text": " les pido ac\u00e1 porque esto nos va a tener que quedar para despu\u00e9s para poder mirarlo,", "tokens": [50400, 1512, 280, 2925, 23496, 4021, 7433, 3269, 2773, 257, 11640, 631, 39244, 1690, 15283, 1690, 8152, 3149, 19457, 11, 50586], "temperature": 0.0, "avg_logprob": -0.35650821760589, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.004837940447032452}, {"id": 135, "seek": 86280, "start": 867.24, "end": 876.5999999999999, "text": " pero bueno, tengo X subra\u00ed, este es el vector de entrada, y voy a poner ac\u00e1 copiar la matriz", "tokens": [50586, 4768, 11974, 11, 13989, 1783, 1422, 424, 870, 11, 4065, 785, 806, 8062, 368, 37119, 11, 288, 7552, 257, 19149, 23496, 2971, 9448, 635, 3803, 24959, 51054], "temperature": 0.0, "avg_logprob": -0.35650821760589, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.004837940447032452}, {"id": 136, "seek": 87660, "start": 876.6, "end": 892.08, "text": " esta, W1 1 hasta W4 1, W4 3, W1 3, la matriz, entonces, digo que el valor de X", "tokens": [50364, 5283, 11, 343, 16, 502, 10764, 343, 19, 502, 11, 343, 19, 805, 11, 343, 16, 805, 11, 635, 3803, 24959, 11, 13003, 11, 22990, 631, 806, 15367, 368, 1783, 51138], "temperature": 0.0, "avg_logprob": -0.29695173899332683, "compression_ratio": 1.3360655737704918, "no_speech_prob": 0.05550942197442055}, {"id": 137, "seek": 87660, "start": 892.08, "end": 902.48, "text": " y m\u00e1s 1 va a ser el valor en Y por la matriz que representa los pesos de la capa Y,", "tokens": [51138, 288, 3573, 502, 2773, 257, 816, 806, 15367, 465, 398, 1515, 635, 3803, 24959, 631, 49823, 1750, 33204, 368, 635, 1410, 64, 398, 11, 51658], "temperature": 0.0, "avg_logprob": -0.29695173899332683, "compression_ratio": 1.3360655737704918, "no_speech_prob": 0.05550942197442055}, {"id": 138, "seek": 90248, "start": 903.36, "end": 909.64, "text": " y a esto lo que me falta agregarle es el sigma, que es la funci\u00f3n de activaci\u00f3n y el", "tokens": [50408, 288, 257, 7433, 450, 631, 385, 22111, 4554, 2976, 306, 785, 806, 12771, 11, 631, 785, 635, 43735, 368, 2430, 3482, 288, 806, 50722], "temperature": 0.0, "avg_logprob": -0.2539583297002883, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.0021143131889402866}, {"id": 139, "seek": 90248, "start": 909.64, "end": 913.4, "text": " sigma tambi\u00e9n puede pertenecer a la capa y digamos yo puedo tener distintas funciones de activaci\u00f3n", "tokens": [50722, 12771, 6407, 8919, 680, 1147, 68, 1776, 257, 635, 1410, 64, 288, 36430, 5290, 21612, 11640, 31489, 296, 1019, 23469, 368, 2430, 3482, 50910], "temperature": 0.0, "avg_logprob": -0.2539583297002883, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.0021143131889402866}, {"id": 140, "seek": 90248, "start": 913.4, "end": 922.12, "text": " por capa, bien, entonces, concentremos en esto, decimos que si yo tengo una arquitectura en capa,", "tokens": [50910, 1515, 1410, 64, 11, 3610, 11, 13003, 11, 5512, 28343, 465, 7433, 11, 979, 8372, 631, 1511, 5290, 13989, 2002, 40258, 5739, 2991, 465, 1410, 64, 11, 51346], "temperature": 0.0, "avg_logprob": -0.2539583297002883, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.0021143131889402866}, {"id": 141, "seek": 90248, "start": 922.12, "end": 926.44, "text": " donde cada capa est\u00e1 conectada con la anterior, digamos todas las neuronas una capa est\u00e1n conectadas", "tokens": [51346, 10488, 8411, 1410, 64, 3192, 30458, 1538, 416, 635, 22272, 11, 36430, 10906, 2439, 34090, 296, 2002, 1410, 64, 10368, 30458, 6872, 51562], "temperature": 0.0, "avg_logprob": -0.2539583297002883, "compression_ratio": 1.7522522522522523, "no_speech_prob": 0.0021143131889402866}, {"id": 142, "seek": 92644, "start": 926.44, "end": 933.84, "text": " con todas las neuronas de la anterior, entonces, puedo calcular la activaci\u00f3n o los valores que", "tokens": [50364, 416, 10906, 2439, 34090, 296, 368, 635, 22272, 11, 13003, 11, 21612, 2104, 17792, 635, 2430, 3482, 277, 1750, 38790, 631, 50734], "temperature": 0.0, "avg_logprob": -0.20666689621774773, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00021945963089819998}, {"id": 143, "seek": 92644, "start": 933.84, "end": 942.72, "text": " va a tener la capa Y m\u00e1s 1 en funci\u00f3n de la capa Y con esta formula ac\u00e1, as\u00ed que supongamos que", "tokens": [50734, 2773, 257, 11640, 635, 1410, 64, 398, 3573, 502, 465, 43735, 368, 635, 1410, 64, 398, 416, 5283, 8513, 23496, 11, 8582, 631, 9331, 556, 2151, 631, 51178], "temperature": 0.0, "avg_logprob": -0.20666689621774773, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00021945963089819998}, {"id": 144, "seek": 92644, "start": 942.72, "end": 950.44, "text": " tengo, eso creo que es exactamente lo mismo que dice ac\u00e1, ah\u00ed est\u00e1, tengo esa entrada,", "tokens": [51178, 13989, 11, 7287, 14336, 631, 785, 48686, 450, 12461, 631, 10313, 23496, 11, 12571, 3192, 11, 13989, 11342, 37119, 11, 51564], "temperature": 0.0, "avg_logprob": -0.20666689621774773, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00021945963089819998}, {"id": 145, "seek": 95044, "start": 951.24, "end": 956.6, "text": " la salida va a ser ese vector, digamos, de tres neuronas y tengo esos pesos,", "tokens": [50404, 635, 1845, 2887, 2773, 257, 816, 10167, 8062, 11, 36430, 11, 368, 15890, 34090, 296, 288, 13989, 22411, 33204, 11, 50672], "temperature": 0.0, "avg_logprob": -0.19348575999435869, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.002052289666607976}, {"id": 146, "seek": 95044, "start": 956.6, "end": 964.6400000000001, "text": " por lo tanto puedo calcularlo de esta manera, bien, entonces supongamos que tengo una arquitectura", "tokens": [50672, 1515, 450, 10331, 21612, 2104, 17792, 752, 368, 5283, 13913, 11, 3610, 11, 13003, 9331, 556, 2151, 631, 13989, 2002, 40258, 5739, 2991, 51074], "temperature": 0.0, "avg_logprob": -0.19348575999435869, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.002052289666607976}, {"id": 147, "seek": 95044, "start": 964.6400000000001, "end": 974.0400000000001, "text": " que tiene tres capas, o m\u00e1s, digamos, tiene dos capas ocultas, entonces eso significa que si", "tokens": [51074, 631, 7066, 15890, 1410, 296, 11, 277, 3573, 11, 36430, 11, 7066, 4491, 1410, 296, 10409, 723, 296, 11, 13003, 7287, 19957, 631, 1511, 51544], "temperature": 0.0, "avg_logprob": -0.19348575999435869, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.002052289666607976}, {"id": 148, "seek": 95044, "start": 974.0400000000001, "end": 979.2, "text": " tengo dos capas ocultas voy a tener una matriz de pesos, que le voy a llamar W1 y una", "tokens": [51544, 13989, 4491, 1410, 296, 10409, 723, 296, 7552, 257, 11640, 2002, 3803, 24959, 368, 33204, 11, 631, 476, 7552, 257, 16848, 289, 343, 16, 288, 2002, 51802], "temperature": 0.0, "avg_logprob": -0.19348575999435869, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.002052289666607976}, {"id": 149, "seek": 97920, "start": 979.2, "end": 986.6400000000001, "text": " matriz de peso que le voy a llamar W2, entonces me va a venir un vector X que va a ser un vector que", "tokens": [50364, 3803, 24959, 368, 28149, 631, 476, 7552, 257, 16848, 289, 343, 17, 11, 13003, 385, 2773, 257, 20817, 517, 8062, 1783, 631, 2773, 257, 816, 517, 8062, 631, 50736], "temperature": 0.0, "avg_logprob": -0.17185750118521756, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0006983542116358876}, {"id": 150, "seek": 97920, "start": 986.6400000000001, "end": 995.5600000000001, "text": " tiene un mont\u00f3n de trabajo, X1 hasta Xn, esto es un vector, quiero ver cu\u00e1l va a ser la salida", "tokens": [50736, 7066, 517, 45259, 368, 18099, 11, 1783, 16, 10764, 1783, 77, 11, 7433, 785, 517, 8062, 11, 16811, 1306, 44318, 2773, 257, 816, 635, 1845, 2887, 51182], "temperature": 0.0, "avg_logprob": -0.17185750118521756, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0006983542116358876}, {"id": 151, "seek": 97920, "start": 995.5600000000001, "end": 1003.08, "text": " de la red suponiendo que tengo una capa de pesos W1 con una funci\u00f3n de activaci\u00f3n sigma 1 y", "tokens": [51182, 368, 635, 2182, 9331, 266, 7304, 631, 13989, 2002, 1410, 64, 368, 33204, 343, 16, 416, 2002, 43735, 368, 2430, 3482, 12771, 502, 288, 51558], "temperature": 0.0, "avg_logprob": -0.17185750118521756, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.0006983542116358876}, {"id": 152, "seek": 100308, "start": 1003.08, "end": 1008.6, "text": " una capa de pesos W2 con una funci\u00f3n de activaci\u00f3n sigma 2, c\u00f3mo me quedar\u00eda la salida de la red,", "tokens": [50364, 2002, 1410, 64, 368, 33204, 343, 17, 416, 2002, 43735, 368, 2430, 3482, 12771, 568, 11, 12826, 385, 13617, 21178, 635, 1845, 2887, 368, 635, 2182, 11, 50640], "temperature": 0.0, "avg_logprob": -0.27751646846173755, "compression_ratio": 1.5808383233532934, "no_speech_prob": 0.00097791594453156}, {"id": 153, "seek": 100308, "start": 1008.6, "end": 1011.84, "text": " digamos, de qu\u00e9, cu\u00e1l ser\u00eda la f\u00f3rmula para la salida de la red,", "tokens": [50640, 36430, 11, 368, 8057, 11, 44318, 23679, 635, 283, 15614, 76, 3780, 1690, 635, 1845, 2887, 368, 635, 2182, 11, 50802], "temperature": 0.0, "avg_logprob": -0.27751646846173755, "compression_ratio": 1.5808383233532934, "no_speech_prob": 0.00097791594453156}, {"id": 154, "seek": 100308, "start": 1016.4000000000001, "end": 1025.24, "text": " vamos a llamarle Rn de X a la salida de esta red que es una red que tiene dos capas ocultas y", "tokens": [51030, 5295, 257, 16848, 36153, 497, 77, 368, 1783, 257, 635, 1845, 2887, 368, 5283, 2182, 631, 785, 2002, 2182, 631, 7066, 4491, 1410, 296, 10409, 723, 296, 288, 51472], "temperature": 0.0, "avg_logprob": -0.27751646846173755, "compression_ratio": 1.5808383233532934, "no_speech_prob": 0.00097791594453156}, {"id": 155, "seek": 102524, "start": 1025.24, "end": 1036.1200000000001, "text": " tiene esa estructura, est\u00e1 estructura en capas, \u00bfqu\u00e9 les parece? S\u00ed,", "tokens": [50364, 7066, 11342, 43935, 2991, 11, 3192, 43935, 2991, 465, 1410, 296, 11, 3841, 16412, 1512, 14120, 30, 12375, 11, 50908], "temperature": 0.0, "avg_logprob": -0.5399497892798447, "compression_ratio": 1.125, "no_speech_prob": 0.00472615472972393}, {"id": 156, "seek": 102524, "start": 1042.1200000000001, "end": 1045.76, "text": " ah\u00ed est\u00e1, X por del V1 y esto le aplicamos sigma 1,", "tokens": [51208, 12571, 3192, 11, 1783, 1515, 1103, 691, 16, 288, 7433, 476, 18221, 2151, 12771, 502, 11, 51390], "temperature": 0.0, "avg_logprob": -0.5399497892798447, "compression_ratio": 1.125, "no_speech_prob": 0.00472615472972393}, {"id": 157, "seek": 104576, "start": 1045.76, "end": 1052.16, "text": " y despu\u00e9s esto multiplicamos por W2, ah\u00ed est\u00e1, la hacemos W2 y le pasamos sigma 2,", "tokens": [50364, 288, 15283, 7433, 17596, 2151, 1515, 343, 17, 11, 12571, 3192, 11, 635, 33839, 343, 17, 288, 476, 1736, 2151, 12771, 568, 11, 50684], "temperature": 0.0, "avg_logprob": -0.2798196059006911, "compression_ratio": 1.875, "no_speech_prob": 0.008655504323542118}, {"id": 158, "seek": 104576, "start": 1052.16, "end": 1060.76, "text": " exacto, bien, entonces eso ser\u00eda, digamos, la ecuaci\u00f3n que te queda de una arquitectura con", "tokens": [50684, 1900, 78, 11, 3610, 11, 13003, 7287, 23679, 11, 36430, 11, 635, 11437, 84, 3482, 631, 535, 23314, 368, 2002, 40258, 5739, 2991, 416, 51114], "temperature": 0.0, "avg_logprob": -0.2798196059006911, "compression_ratio": 1.875, "no_speech_prob": 0.008655504323542118}, {"id": 159, "seek": 104576, "start": 1060.76, "end": 1066.84, "text": " dos capas ocultas, y bueno, la salida se calcular\u00eda de esta manera, tenemos el vector X,", "tokens": [51114, 4491, 1410, 296, 10409, 723, 296, 11, 288, 11974, 11, 635, 1845, 2887, 369, 4322, 21178, 368, 5283, 13913, 11, 9914, 806, 8062, 1783, 11, 51418], "temperature": 0.0, "avg_logprob": -0.2798196059006911, "compression_ratio": 1.875, "no_speech_prob": 0.008655504323542118}, {"id": 160, "seek": 104576, "start": 1066.84, "end": 1070.96, "text": " el vector X que le multiplicamos por los pesos de la capa 1, despu\u00e9s le pasamos la funci\u00f3n", "tokens": [51418, 806, 8062, 1783, 631, 476, 17596, 2151, 1515, 1750, 33204, 368, 635, 1410, 64, 502, 11, 15283, 476, 1736, 2151, 635, 43735, 51624], "temperature": 0.0, "avg_logprob": -0.2798196059006911, "compression_ratio": 1.875, "no_speech_prob": 0.008655504323542118}, {"id": 161, "seek": 104576, "start": 1070.96, "end": 1075.16, "text": " de activaci\u00f3n, a esa resultado le multiplicamos por los pesos de la capa 2 y le aplicamos la funci\u00f3n", "tokens": [51624, 368, 2430, 3482, 11, 257, 11342, 28047, 476, 17596, 2151, 1515, 1750, 33204, 368, 635, 1410, 64, 568, 288, 476, 18221, 2151, 635, 43735, 51834], "temperature": 0.0, "avg_logprob": -0.2798196059006911, "compression_ratio": 1.875, "no_speech_prob": 0.008655504323542118}, {"id": 162, "seek": 107516, "start": 1075.16, "end": 1079.8000000000002, "text": " de activaci\u00f3n y esa es la salida. Si tuvieramos m\u00e1s capas, si esto fuera un perceptro", "tokens": [50364, 368, 2430, 3482, 288, 11342, 785, 635, 1845, 2887, 13, 4909, 38177, 811, 2151, 3573, 1410, 296, 11, 1511, 7433, 24818, 517, 43276, 340, 50596], "temperature": 0.0, "avg_logprob": -0.2640116335165621, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.00046559367910958827}, {"id": 163, "seek": 107516, "start": 1079.8000000000002, "end": 1084.4, "text": " multicapa de 30 capas, entonces tendr\u00edamos como m\u00e1s a\u00f1adimiento en esto, pero m\u00e1s o menos", "tokens": [50596, 30608, 569, 64, 368, 2217, 1410, 296, 11, 13003, 3928, 81, 16275, 2617, 3573, 44980, 14007, 465, 7433, 11, 4768, 3573, 277, 8902, 50826], "temperature": 0.0, "avg_logprob": -0.2640116335165621, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.00046559367910958827}, {"id": 164, "seek": 107516, "start": 1084.4, "end": 1093.16, "text": " el camino. Bien, entonces \u00bfqu\u00e9 pasar\u00eda si estas funciones de activaci\u00f3n fueran la funci\u00f3n", "tokens": [50826, 806, 34124, 13, 16956, 11, 13003, 3841, 16412, 1736, 21178, 1511, 13897, 1019, 23469, 368, 2430, 3482, 17669, 282, 635, 43735, 51264], "temperature": 0.0, "avg_logprob": -0.2640116335165621, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.00046559367910958827}, {"id": 165, "seek": 107516, "start": 1093.16, "end": 1102.7, "text": " identidad o fueran funciones lineales como multiplicar por 4 o algo del estilo, \u00bfqu\u00e9", "tokens": [51264, 2473, 4580, 277, 17669, 282, 1019, 23469, 1622, 4229, 2617, 17596, 289, 1515, 1017, 277, 8655, 1103, 37470, 11, 3841, 16412, 51741], "temperature": 0.0, "avg_logprob": -0.2640116335165621, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.00046559367910958827}, {"id": 166, "seek": 110270, "start": 1102.7, "end": 1112.94, "text": " pasar\u00eda en ese caso? Ah\u00ed est\u00e1, en ese caso, si esto fuera la identidad o si fuera multiplicado", "tokens": [50364, 1736, 21178, 465, 10167, 9666, 30, 49924, 3192, 11, 465, 10167, 9666, 11, 1511, 7433, 24818, 635, 2473, 4580, 277, 1511, 24818, 17596, 1573, 50876], "temperature": 0.0, "avg_logprob": -0.22949696570327602, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.023565150797367096}, {"id": 167, "seek": 110270, "start": 1112.94, "end": 1116.94, "text": " por una constante, pero supongamos que fuera la funci\u00f3n identidad, entonces ac\u00e1 esto", "tokens": [50876, 1515, 2002, 47343, 11, 4768, 9331, 556, 2151, 631, 24818, 635, 43735, 2473, 4580, 11, 13003, 23496, 7433, 51076], "temperature": 0.0, "avg_logprob": -0.22949696570327602, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.023565150797367096}, {"id": 168, "seek": 110270, "start": 1116.94, "end": 1124.14, "text": " me dar\u00eda lo mismo que hacer X por W1 por W2, que es lo mismo que hacer X por una cosa que", "tokens": [51076, 385, 4072, 2686, 450, 12461, 631, 6720, 1783, 1515, 343, 16, 1515, 343, 17, 11, 631, 785, 450, 12461, 631, 6720, 1783, 1515, 2002, 10163, 631, 51436], "temperature": 0.0, "avg_logprob": -0.22949696570327602, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.023565150797367096}, {"id": 169, "seek": 110270, "start": 1124.14, "end": 1131.02, "text": " es un producto entre dos matrices y un producto entre dos matrices vea otra matriz, entonces", "tokens": [51436, 785, 517, 47583, 3962, 4491, 32284, 288, 517, 47583, 3962, 4491, 32284, 1241, 64, 13623, 3803, 24959, 11, 13003, 51780], "temperature": 0.0, "avg_logprob": -0.22949696570327602, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.023565150797367096}, {"id": 170, "seek": 113102, "start": 1131.02, "end": 1135.28, "text": " si estas funciones fueran una funci\u00f3n identidad o fueran una funci\u00f3n lineal o fueran una funci\u00f3n", "tokens": [50364, 1511, 13897, 1019, 23469, 17669, 282, 2002, 43735, 2473, 4580, 277, 17669, 282, 2002, 43735, 1622, 304, 277, 17669, 282, 2002, 43735, 50577], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 171, "seek": 113102, "start": 1135.28, "end": 1141.66, "text": " de esas, digamos, simples, entonces todo esto ser\u00eda una ecuaci\u00f3n lineal, o sea yo podr\u00eda", "tokens": [50577, 368, 23388, 11, 36430, 11, 21730, 11, 13003, 5149, 7433, 23679, 2002, 11437, 84, 3482, 1622, 304, 11, 277, 4158, 5290, 27246, 50896], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 172, "seek": 113102, "start": 1141.66, "end": 1145.62, "text": " reescribirlo siempre como el producto entre un vector y una matriz, que es un sistema", "tokens": [50896, 319, 279, 1142, 10119, 752, 12758, 2617, 806, 47583, 3962, 517, 8062, 288, 2002, 3803, 24959, 11, 631, 785, 517, 13245, 51094], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 173, "seek": 113102, "start": 1145.62, "end": 1151.52, "text": " lineal. Bien, esa es la raz\u00f3n por la cual se necesita que estas cosas acasean no", "tokens": [51094, 1622, 304, 13, 16956, 11, 11342, 785, 635, 38310, 1515, 635, 10911, 369, 45485, 631, 13897, 12218, 696, 651, 282, 572, 51389], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 174, "seek": 113102, "start": 1151.52, "end": 1154.74, "text": " lineales, que era lo que les dec\u00eda que bueno, casi que el \u00fanico requisito que tienen", "tokens": [51389, 1622, 4229, 11, 631, 4249, 450, 631, 1512, 37599, 631, 11974, 11, 22567, 631, 806, 26113, 49878, 3528, 631, 12536, 51550], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 175, "seek": 113102, "start": 1154.74, "end": 1158.58, "text": " es tener estas funciones de activaci\u00f3n es que sean no lineales, porque si son lineales", "tokens": [51550, 785, 11640, 13897, 1019, 23469, 368, 2430, 3482, 785, 631, 37670, 572, 1622, 4229, 11, 4021, 1511, 1872, 1622, 4229, 51742], "temperature": 0.0, "avg_logprob": -0.17533982140677315, "compression_ratio": 1.963235294117647, "no_speech_prob": 0.0024194533471018076}, {"id": 176, "seek": 115858, "start": 1158.58, "end": 1162.54, "text": " cuando yo empiezo a arquitecturar estas cosas en capas, me queda simplemente un producto", "tokens": [50364, 7767, 5290, 4012, 414, 4765, 257, 40258, 5739, 28586, 13897, 12218, 465, 1410, 296, 11, 385, 23314, 33190, 517, 47583, 50562], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 177, "seek": 115858, "start": 1162.54, "end": 1167.02, "text": " de matrices, porque me interesa que sea no lineal y porque, o sea, me molesta que esto sea", "tokens": [50562, 368, 32284, 11, 4021, 385, 728, 13708, 631, 4158, 572, 1622, 304, 288, 4021, 11, 277, 4158, 11, 385, 8015, 7841, 631, 7433, 4158, 50786], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 178, "seek": 115858, "start": 1167.02, "end": 1171.54, "text": " un sistema lineal, porque si yo tengo un sistema lineal, digamos, si yo tengo que el", "tokens": [50786, 517, 13245, 1622, 304, 11, 4021, 1511, 5290, 13989, 517, 13245, 1622, 304, 11, 36430, 11, 1511, 5290, 13989, 631, 806, 51012], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 179, "seek": 115858, "start": 1171.54, "end": 1175.82, "text": " resultado de mi red lo puede expresar como X por una matriz, entonces bueno, hay cierta", "tokens": [51012, 28047, 368, 2752, 2182, 450, 8919, 33397, 289, 2617, 1783, 1515, 2002, 3803, 24959, 11, 13003, 11974, 11, 4842, 39769, 1328, 51226], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 180, "seek": 115858, "start": 1175.82, "end": 1179.5, "text": " clase de problemas, que voy a poder resolver, pero todos los problemas que son no lineales,", "tokens": [51226, 44578, 368, 20720, 11, 631, 7552, 257, 8152, 34480, 11, 4768, 6321, 1750, 20720, 631, 1872, 572, 1622, 4229, 11, 51410], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 181, "seek": 115858, "start": 1179.5, "end": 1182.6799999999998, "text": " todos los problemas que no se pueden capturar por una estructura lineal, entonces no lo", "tokens": [51410, 6321, 1750, 20720, 631, 572, 369, 14714, 3770, 28586, 1515, 2002, 43935, 2991, 1622, 304, 11, 13003, 572, 450, 51569], "temperature": 0.0, "avg_logprob": -0.17889597776124802, "compression_ratio": 1.9703703703703703, "no_speech_prob": 0.009158757515251637}, {"id": 182, "seek": 118268, "start": 1182.68, "end": 1193.96, "text": " puedo resolver. Bien, s\u00ed. Incluso sin la activaci\u00f3n, o sea, es una reneural que no tiene", "tokens": [50364, 21612, 34480, 13, 16956, 11, 8600, 13, 7779, 3063, 78, 3343, 635, 2430, 3482, 11, 277, 4158, 11, 785, 2002, 319, 716, 1807, 631, 572, 7066, 50928], "temperature": 0.0, "avg_logprob": -0.320181586525657, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.17075465619564056}, {"id": 183, "seek": 118268, "start": 1193.96, "end": 1199.24, "text": " que ir a ninguna, o sea, simplemente es multiplicar un vector por un conjunto de pesos.", "tokens": [50928, 631, 3418, 257, 36073, 11, 277, 4158, 11, 33190, 785, 17596, 289, 517, 8062, 1515, 517, 37776, 368, 33204, 13, 51192], "temperature": 0.0, "avg_logprob": -0.320181586525657, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.17075465619564056}, {"id": 184, "seek": 118268, "start": 1199.24, "end": 1205.4, "text": " Bien, entonces, si yo tengo solamente una funci\u00f3n lineal, hay un conjunto de problemas que", "tokens": [51192, 16956, 11, 13003, 11, 1511, 5290, 13989, 27814, 2002, 43735, 1622, 304, 11, 4842, 517, 37776, 368, 20720, 631, 51500], "temperature": 0.0, "avg_logprob": -0.320181586525657, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.17075465619564056}, {"id": 185, "seek": 118268, "start": 1205.4, "end": 1210.46, "text": " puedo modelar, es verdad, pero no son todos, y de hecho no lo vamos a ver, pero hay una", "tokens": [51500, 21612, 2316, 289, 11, 785, 13692, 11, 4768, 572, 1872, 6321, 11, 288, 368, 13064, 572, 450, 5295, 257, 1306, 11, 4768, 4842, 2002, 51753], "temperature": 0.0, "avg_logprob": -0.320181586525657, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.17075465619564056}, {"id": 186, "seek": 121046, "start": 1210.46, "end": 1216.02, "text": " demostraci\u00f3n que dice que teniendo funciones de activaci\u00f3n no lineales, alcanza incluso", "tokens": [50364, 41556, 46205, 631, 10313, 631, 2064, 7304, 1019, 23469, 368, 2430, 3482, 572, 1622, 4229, 11, 419, 7035, 2394, 24018, 50642], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 187, "seek": 121046, "start": 1216.02, "end": 1220.78, "text": " con tener una sola capa oculta y alguna cosita m\u00e1s para modelar cualquier tipo de funci\u00f3n", "tokens": [50642, 416, 11640, 2002, 34162, 1410, 64, 10409, 723, 64, 288, 20651, 3792, 2786, 3573, 1690, 2316, 289, 21004, 9746, 368, 43735, 50880], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 188, "seek": 121046, "start": 1220.78, "end": 1224.26, "text": " que habiamos interese, digamos, con ciertas propiedades, por lo menos que se ha continuo", "tokens": [50880, 631, 3025, 72, 2151, 728, 1130, 11, 36430, 11, 416, 49252, 296, 2365, 1091, 2977, 11, 1515, 450, 8902, 631, 369, 324, 2993, 78, 51054], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 189, "seek": 121046, "start": 1224.26, "end": 1229.8600000000001, "text": " en siento intervalo, etc\u00e9tera, pero asumiendo ciertas propiedades bastante normales, es", "tokens": [51054, 465, 40340, 15035, 78, 11, 5183, 526, 23833, 11, 4768, 382, 449, 7304, 49252, 296, 2365, 1091, 2977, 14651, 2710, 279, 11, 785, 51334], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 190, "seek": 121046, "start": 1229.8600000000001, "end": 1233.5, "text": " posible incluso con una sola capa, con una cantidad ruitada de neuronas, modelar cualquier", "tokens": [51334, 26644, 24018, 416, 2002, 34162, 1410, 64, 11, 416, 2002, 33757, 5420, 270, 1538, 368, 34090, 296, 11, 2316, 289, 21004, 51516], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 191, "seek": 121046, "start": 1233.5, "end": 1239.38, "text": " funci\u00f3n posible. Y eso es un poco el poder que tiene las reneurales, en realidad, son", "tokens": [51516, 43735, 26644, 13, 398, 7287, 785, 517, 10639, 806, 8152, 631, 7066, 2439, 319, 716, 1807, 279, 11, 465, 25635, 11, 1872, 51810], "temperature": 0.0, "avg_logprob": -0.2605785238331762, "compression_ratio": 1.8581314878892734, "no_speech_prob": 0.020771510899066925}, {"id": 192, "seek": 123938, "start": 1239.38, "end": 1244.8200000000002, "text": " como suficientemente flexibles como para modelar cualquier cosa, cosa que cuando ve\u00edamos,", "tokens": [50364, 2617, 459, 1786, 1196, 16288, 5896, 14428, 2617, 1690, 2316, 289, 21004, 10163, 11, 10163, 631, 7767, 1241, 16275, 11, 50636], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 193, "seek": 123938, "start": 1244.8200000000002, "end": 1249.1000000000001, "text": " bueno, no hay valles, era un ejemplo que modelaba ciertos tipos de problemas, si miran", "tokens": [50636, 11974, 11, 572, 4842, 371, 37927, 11, 4249, 517, 13358, 631, 2316, 5509, 49252, 329, 37105, 368, 20720, 11, 1511, 3149, 282, 50850], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 194, "seek": 123938, "start": 1249.1000000000001, "end": 1252.94, "text": " regresi\u00f3n log\u00edstica, podemos modelarse de dos tipos de problemas, pero algunos no,", "tokens": [50850, 47108, 2560, 3565, 19512, 2262, 11, 12234, 2316, 11668, 368, 4491, 37105, 368, 20720, 11, 4768, 21078, 572, 11, 51042], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 195, "seek": 123938, "start": 1252.94, "end": 1258.66, "text": " las reneurales en calidad son super flexibles y podemos modelar cualquier cosa.", "tokens": [51042, 2439, 319, 716, 1807, 279, 465, 42955, 1872, 1687, 5896, 14428, 288, 12234, 2316, 289, 21004, 10163, 13, 51328], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 196, "seek": 123938, "start": 1258.66, "end": 1264.2600000000002, "text": " Entonces, sabemos que, para casi cualquier funci\u00f3n que a\u00fan no le interese modelar, existe", "tokens": [51328, 15097, 11, 27200, 631, 11, 1690, 22567, 21004, 43735, 631, 31676, 572, 476, 728, 1130, 2316, 289, 11, 16304, 51608], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 197, "seek": 123938, "start": 1264.2600000000002, "end": 1268.2600000000002, "text": " una reneural que podr\u00eda llegar a cumplirla con suficienta nivel de precisi\u00f3n, que vamos", "tokens": [51608, 2002, 319, 716, 1807, 631, 27246, 24892, 257, 37483, 347, 875, 416, 459, 1786, 1196, 64, 24423, 368, 7974, 2560, 11, 631, 5295, 51808], "temperature": 0.0, "avg_logprob": -0.3369689658836082, "compression_ratio": 1.8131487889273357, "no_speech_prob": 0.0019705560989677906}, {"id": 198, "seek": 126826, "start": 1268.26, "end": 1272.7, "text": " ah\u00ed, teor\u00eda y m\u00e1s que les muestran, sin embargo, encontrarla en la pr\u00e1ctica no es tan f\u00e1cil,", "tokens": [50364, 12571, 11, 40238, 2686, 288, 3573, 631, 1512, 2992, 377, 4257, 11, 3343, 23955, 11, 17525, 875, 465, 635, 27300, 29041, 572, 785, 7603, 17474, 11, 50586], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 199, "seek": 126826, "start": 1272.7, "end": 1277.7, "text": " o sea, sabemos que existe una, la familia de la reneurales, hay alguna funci\u00f3n que me", "tokens": [50586, 277, 4158, 11, 27200, 631, 16304, 2002, 11, 635, 24050, 368, 635, 319, 716, 1807, 279, 11, 4842, 20651, 43735, 631, 385, 50836], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 200, "seek": 126826, "start": 1277.7, "end": 1282.5, "text": " va a permitir hacer todo lo que quiera, pero bueno, de all\u00e1 encontrarla no es tan sencillo,", "tokens": [50836, 2773, 257, 46865, 6720, 5149, 450, 631, 421, 10609, 11, 4768, 11974, 11, 368, 30642, 17525, 875, 572, 785, 7603, 46749, 78, 11, 51076], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 201, "seek": 126826, "start": 1282.5, "end": 1286.78, "text": " pero bueno, por lo menos sabemos que existe. Igual, con estas cosas que tenemos, o sea,", "tokens": [51076, 4768, 11974, 11, 1515, 450, 8902, 27200, 631, 16304, 13, 19271, 901, 11, 416, 13897, 12218, 631, 9914, 11, 277, 4158, 11, 51290], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 202, "seek": 126826, "start": 1286.78, "end": 1290.82, "text": " sabiendo lo m\u00e1s que es arquitecturando en capas y teniendo la funci\u00f3n de activaci\u00f3n", "tokens": [51290, 5560, 7304, 450, 3573, 631, 785, 40258, 5739, 374, 1806, 465, 1410, 296, 288, 2064, 7304, 635, 43735, 368, 2430, 3482, 51492], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 203, "seek": 126826, "start": 1290.82, "end": 1295.62, "text": " no lineal en cada una, ya ten\u00e9s un mont\u00f3n de funciones interesantes que pueden servir", "tokens": [51492, 572, 1622, 304, 465, 8411, 2002, 11, 2478, 2064, 2191, 517, 45259, 368, 1019, 23469, 20157, 9327, 631, 14714, 29463, 51732], "temperature": 0.0, "avg_logprob": -0.22557196746001373, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0254476647824049}, {"id": 204, "seek": 129562, "start": 1295.62, "end": 1311.1, "text": " para modelar muchas cosas. Bien, preguntas ac\u00e1. Bueno, estas otras funciones de activaci\u00f3n", "tokens": [50364, 1690, 2316, 289, 16072, 12218, 13, 16956, 11, 39722, 23496, 13, 16046, 11, 13897, 20244, 1019, 23469, 368, 2430, 3482, 51138], "temperature": 0.0, "avg_logprob": -0.2780907574821921, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.0017771507846191525}, {"id": 205, "seek": 129562, "start": 1311.1, "end": 1316.82, "text": " interesante que se conoce como la funci\u00f3n softmax, se utiliza para los problemas de", "tokens": [51138, 36396, 631, 369, 33029, 384, 2617, 635, 43735, 2787, 41167, 11, 369, 4976, 13427, 1690, 1750, 20720, 368, 51424], "temperature": 0.0, "avg_logprob": -0.2780907574821921, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.0017771507846191525}, {"id": 206, "seek": 129562, "start": 1316.82, "end": 1323.5, "text": " clasificaci\u00f3n discretos, por ejemplo, hay que tener en el segundo obligatorio que, bueno,", "tokens": [51424, 596, 296, 40802, 2983, 1505, 329, 11, 1515, 13358, 11, 4842, 631, 11640, 465, 806, 17954, 9270, 48028, 631, 11, 11974, 11, 51758], "temperature": 0.0, "avg_logprob": -0.2780907574821921, "compression_ratio": 1.4565217391304348, "no_speech_prob": 0.0017771507846191525}, {"id": 207, "seek": 132350, "start": 1323.5, "end": 1328.14, "text": " es el problema de clasificar un tweet y lo quiero clasificar en si es positivo, negativo,", "tokens": [50364, 785, 806, 12395, 368, 596, 296, 25625, 517, 15258, 288, 450, 16811, 596, 296, 25625, 465, 1511, 785, 44710, 11, 2485, 18586, 11, 50596], "temperature": 0.0, "avg_logprob": -0.22456581115722657, "compression_ratio": 1.7921568627450981, "no_speech_prob": 0.10659059137105942}, {"id": 208, "seek": 132350, "start": 1328.14, "end": 1333.5, "text": " neutro o nada, no, tengo esas cuatro clases. Entonces, la funci\u00f3n de activaci\u00f3n softmax es", "tokens": [50596, 7989, 340, 277, 8096, 11, 572, 11, 13989, 23388, 28795, 596, 1957, 13, 15097, 11, 635, 43735, 368, 2430, 3482, 2787, 41167, 785, 50864], "temperature": 0.0, "avg_logprob": -0.22456581115722657, "compression_ratio": 1.7921568627450981, "no_speech_prob": 0.10659059137105942}, {"id": 209, "seek": 132350, "start": 1333.5, "end": 1340.98, "text": " como una generalizaci\u00f3n de la funci\u00f3n log\u00edstica de la sigmoide, que se calcula de esta", "tokens": [50864, 2617, 2002, 2674, 27603, 368, 635, 43735, 3565, 19512, 2262, 368, 635, 4556, 3280, 482, 11, 631, 369, 4322, 64, 368, 5283, 51238], "temperature": 0.0, "avg_logprob": -0.22456581115722657, "compression_ratio": 1.7921568627450981, "no_speech_prob": 0.10659059137105942}, {"id": 210, "seek": 132350, "start": 1340.98, "end": 1347.74, "text": " manera, dice bueno, yo asumo que los pesos de salida, que son n\u00fameros reales, van a formar", "tokens": [51238, 13913, 11, 10313, 11974, 11, 5290, 382, 40904, 631, 1750, 33204, 368, 1845, 2887, 11, 631, 1872, 36545, 957, 279, 11, 3161, 257, 1254, 289, 51576], "temperature": 0.0, "avg_logprob": -0.22456581115722657, "compression_ratio": 1.7921568627450981, "no_speech_prob": 0.10659059137105942}, {"id": 211, "seek": 132350, "start": 1347.74, "end": 1351.22, "text": " una probabilidad, digamos, lo quiero transformar en una probabilidad, entonces lo calcula de", "tokens": [51576, 2002, 31959, 4580, 11, 36430, 11, 450, 16811, 4088, 289, 465, 2002, 31959, 4580, 11, 13003, 450, 4322, 64, 368, 51750], "temperature": 0.0, "avg_logprob": -0.22456581115722657, "compression_ratio": 1.7921568627450981, "no_speech_prob": 0.10659059137105942}, {"id": 212, "seek": 135122, "start": 1351.22, "end": 1358.78, "text": " manera, digo que el valor para y su y su v es e a la y su v sobre la sumatoria de e a la", "tokens": [50364, 13913, 11, 22990, 631, 806, 15367, 1690, 288, 459, 288, 459, 371, 785, 308, 257, 635, 288, 459, 371, 5473, 635, 2408, 1639, 654, 368, 308, 257, 635, 50742], "temperature": 0.0, "avg_logprob": -0.2672983153253539, "compression_ratio": 1.7584745762711864, "no_speech_prob": 0.026387961581349373}, {"id": 213, "seek": 135122, "start": 1358.78, "end": 1365.18, "text": " el resto. Esto solamente para que lo tengan en cuenta, es muy probable que si van a usar", "tokens": [50742, 806, 28247, 13, 20880, 27814, 1690, 631, 450, 46874, 465, 17868, 11, 785, 5323, 21759, 631, 1511, 3161, 257, 14745, 51062], "temperature": 0.0, "avg_logprob": -0.2672983153253539, "compression_ratio": 1.7584745762711864, "no_speech_prob": 0.026387961581349373}, {"id": 214, "seek": 135122, "start": 1365.18, "end": 1369.42, "text": " rengebranales en la segunda tarea, tengan que utilizar al final una capa, que se llama", "tokens": [51062, 8124, 432, 1443, 282, 4229, 465, 635, 21978, 256, 35425, 11, 46874, 631, 24060, 419, 2572, 2002, 1410, 64, 11, 631, 369, 23272, 51274], "temperature": 0.0, "avg_logprob": -0.2672983153253539, "compression_ratio": 1.7584745762711864, "no_speech_prob": 0.026387961581349373}, {"id": 215, "seek": 135122, "start": 1369.42, "end": 1373.06, "text": " capas softmax, que es una capa que tiene una funci\u00f3n de activaci\u00f3n especial que sirve", "tokens": [51274, 1410, 296, 2787, 41167, 11, 631, 785, 2002, 1410, 64, 631, 7066, 2002, 43735, 368, 2430, 3482, 15342, 631, 4735, 303, 51456], "temperature": 0.0, "avg_logprob": -0.2672983153253539, "compression_ratio": 1.7584745762711864, "no_speech_prob": 0.026387961581349373}, {"id": 216, "seek": 135122, "start": 1373.06, "end": 1376.26, "text": " para transformar las salidas en distribuci\u00f3n de probabilidad.", "tokens": [51456, 1690, 4088, 289, 2439, 1845, 11382, 465, 4400, 30813, 368, 31959, 4580, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2672983153253539, "compression_ratio": 1.7584745762711864, "no_speech_prob": 0.026387961581349373}, {"id": 217, "seek": 137626, "start": 1376.26, "end": 1390.98, "text": " S\u00ed, y la mayor, si tiene una distribuci\u00f3n de probabilidades, y bueno, la sociedad que", "tokens": [50364, 12375, 11, 288, 635, 10120, 11, 1511, 7066, 2002, 4400, 30813, 368, 31959, 10284, 11, 288, 11974, 11, 635, 42306, 631, 51100], "temperature": 0.0, "avg_logprob": -0.40062282396399457, "compression_ratio": 1.4140625, "no_speech_prob": 0.06766205281019211}, {"id": 218, "seek": 137626, "start": 1390.98, "end": 1402.06, "text": " tiene probabilidad mayor, ah\u00ed tienes que tener una, ser\u00eda como una log\u00edstica independiente", "tokens": [51100, 7066, 31959, 4580, 10120, 11, 12571, 20716, 631, 11640, 2002, 11, 23679, 2617, 2002, 3565, 19512, 2262, 4819, 8413, 51654], "temperature": 0.0, "avg_logprob": -0.40062282396399457, "compression_ratio": 1.4140625, "no_speech_prob": 0.06766205281019211}, {"id": 219, "seek": 140206, "start": 1402.06, "end": 1408.26, "text": " por cada una. Entonces, si es mayor que cero, digo que es valido, si no, o sea, si", "tokens": [50364, 1515, 8411, 2002, 13, 15097, 11, 1511, 785, 10120, 631, 269, 2032, 11, 22990, 631, 785, 1323, 2925, 11, 1511, 572, 11, 277, 4158, 11, 1511, 50674], "temperature": 0.0, "avg_logprob": -0.2908897399902344, "compression_ratio": 1.6098484848484849, "no_speech_prob": 0.11040018498897552}, {"id": 220, "seek": 140206, "start": 1408.26, "end": 1412.4199999999998, "text": " voy a decir que puedo tener m\u00e1s de un label a la vez, ah\u00ed tendr\u00edas que hacer otra", "tokens": [50674, 7552, 257, 10235, 631, 21612, 11640, 3573, 368, 517, 7645, 257, 635, 5715, 11, 12571, 3928, 81, 10025, 631, 6720, 13623, 50882], "temperature": 0.0, "avg_logprob": -0.2908897399902344, "compression_ratio": 1.6098484848484849, "no_speech_prob": 0.11040018498897552}, {"id": 221, "seek": 140206, "start": 1412.4199999999998, "end": 1416.06, "text": " cosa. En softmax, va a intentar que sea una distribuci\u00f3n de probabilidades, entonces", "tokens": [50882, 10163, 13, 2193, 2787, 41167, 11, 2773, 257, 46596, 631, 4158, 2002, 4400, 30813, 368, 31959, 10284, 11, 13003, 51064], "temperature": 0.0, "avg_logprob": -0.2908897399902344, "compression_ratio": 1.6098484848484849, "no_speech_prob": 0.11040018498897552}, {"id": 222, "seek": 140206, "start": 1416.06, "end": 1424.06, "text": " probablemente te queda una clase que gane y las dem\u00e1s sea mucho m\u00e1s bajitas.", "tokens": [51064, 21759, 4082, 535, 23314, 2002, 44578, 631, 290, 1929, 288, 2439, 34682, 4158, 9824, 3573, 23589, 14182, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2908897399902344, "compression_ratio": 1.6098484848484849, "no_speech_prob": 0.11040018498897552}, {"id": 223, "seek": 140206, "start": 1424.06, "end": 1430.86, "text": " Bien, bueno, entonces, recuerden que estamos siempre utilizando n\u00fameros, por ahora no hemos", "tokens": [51464, 16956, 11, 11974, 11, 13003, 11, 39092, 1556, 631, 10382, 12758, 19906, 1806, 36545, 11, 1515, 9923, 572, 15396, 51804], "temperature": 0.0, "avg_logprob": -0.2908897399902344, "compression_ratio": 1.6098484848484849, "no_speech_prob": 0.11040018498897552}, {"id": 224, "seek": 143086, "start": 1430.86, "end": 1434.26, "text": " visto nada del lenguaje, eso lo vamos a ver un poco m\u00e1s adelante, ahora son todos", "tokens": [50364, 17558, 8096, 1103, 35044, 84, 11153, 11, 7287, 450, 5295, 257, 1306, 517, 10639, 3573, 40214, 11, 9923, 1872, 6321, 50534], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 225, "seek": 143086, "start": 1434.26, "end": 1440.3, "text": " n\u00fameros. En la entrada me vienen n\u00fameros reales, en los pesos tengo n\u00fameros reales,", "tokens": [50534, 36545, 13, 2193, 635, 37119, 385, 49298, 36545, 957, 279, 11, 465, 1750, 33204, 13989, 36545, 957, 279, 11, 50836], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 226, "seek": 143086, "start": 1440.3, "end": 1443.6999999999998, "text": " hago multiplicaciones, le paso funciones de activaci\u00f3n, etc\u00e9tera, y me da otro vector", "tokens": [50836, 38721, 17596, 9188, 11, 476, 29212, 1019, 23469, 368, 2430, 3482, 11, 5183, 526, 23833, 11, 288, 385, 1120, 11921, 8062, 51006], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 227, "seek": 143086, "start": 1443.6999999999998, "end": 1447.86, "text": " de n\u00fameros reales, o sea, la salida de esto va a ser un vector de n\u00fameros reales, tener", "tokens": [51006, 368, 36545, 957, 279, 11, 277, 4158, 11, 635, 1845, 2887, 368, 7433, 2773, 257, 816, 517, 8062, 368, 36545, 957, 279, 11, 11640, 51214], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 228, "seek": 143086, "start": 1447.86, "end": 1451.34, "text": " en cuenta que cada una de estas cosas van a tener sus dimensiones, yo voy a tener, ac\u00e1", "tokens": [51214, 465, 17868, 631, 8411, 2002, 368, 13897, 12218, 3161, 257, 11640, 3291, 10139, 279, 11, 5290, 7552, 257, 11640, 11, 23496, 51388], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 229, "seek": 143086, "start": 1451.34, "end": 1457.82, "text": " ten\u00eda una entrada que ten\u00eda cuatro vectores, para cuatro valores, una matriz que ten\u00eda", "tokens": [51388, 23718, 2002, 37119, 631, 23718, 28795, 8062, 279, 11, 1690, 28795, 38790, 11, 2002, 3803, 24959, 631, 23718, 51712], "temperature": 0.0, "avg_logprob": -0.21532711669476362, "compression_ratio": 1.916058394160584, "no_speech_prob": 0.0628502368927002}, {"id": 230, "seek": 145782, "start": 1457.82, "end": 1461.8999999999999, "text": " cuatro por tres, entonces al multiplicarlo me devuelve tres, si la siguiente capa es", "tokens": [50364, 28795, 1515, 15890, 11, 13003, 419, 17596, 19457, 385, 1905, 3483, 303, 15890, 11, 1511, 635, 25666, 1410, 64, 785, 50568], "temperature": 0.0, "avg_logprob": -0.26360532972547746, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.003253100672736764}, {"id": 231, "seek": 145782, "start": 1461.8999999999999, "end": 1468.06, "text": " de tres por ocho, entonces me va a volver ocho y as\u00ed, o sea, los tama\u00f1os de las matrices,", "tokens": [50568, 368, 15890, 1515, 3795, 78, 11, 13003, 385, 2773, 257, 33998, 3795, 78, 288, 8582, 11, 277, 4158, 11, 1750, 45342, 8242, 368, 2439, 3803, 24373, 11, 50876], "temperature": 0.0, "avg_logprob": -0.26360532972547746, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.003253100672736764}, {"id": 232, "seek": 145782, "start": 1468.06, "end": 1473.22, "text": " o sea, los tama\u00f1os de las capas tienen que coincidir. Pero en definitiva son todos", "tokens": [50876, 277, 4158, 11, 1750, 45342, 8242, 368, 2439, 1410, 296, 12536, 631, 13001, 33031, 13, 9377, 465, 28781, 5931, 1872, 6321, 51134], "temperature": 0.0, "avg_logprob": -0.26360532972547746, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.003253100672736764}, {"id": 233, "seek": 145782, "start": 1473.22, "end": 1482.06, "text": " vectores, \u00bfno? Por ahora, esto es un c\u00e1lculo utilizando c\u00e1lculo num\u00e9rico vectorial.", "tokens": [51134, 1241, 349, 2706, 11, 3841, 1771, 30, 5269, 9923, 11, 7433, 785, 517, 6476, 75, 25436, 19906, 1806, 6476, 75, 25436, 1031, 526, 23776, 8062, 831, 13, 51576], "temperature": 0.0, "avg_logprob": -0.26360532972547746, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.003253100672736764}, {"id": 234, "seek": 145782, "start": 1482.06, "end": 1486.26, "text": " Entonces, vamos a hablar un poco de c\u00f3mo se entrenan estas redes, y vamos a pensar", "tokens": [51576, 15097, 11, 5295, 257, 21014, 517, 10639, 368, 12826, 369, 45069, 282, 13897, 16762, 11, 288, 5295, 257, 18321, 51786], "temperature": 0.0, "avg_logprob": -0.26360532972547746, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.003253100672736764}, {"id": 235, "seek": 148626, "start": 1486.26, "end": 1491.62, "text": " de la siguiente manera, \u00bfc\u00f3mo esto es un m\u00e9todo de aprendizaje autom\u00e1tico? Yo voy", "tokens": [50364, 368, 635, 25666, 13913, 11, 3841, 46614, 7433, 785, 517, 20275, 17423, 368, 21003, 590, 11153, 3553, 28234, 30, 7616, 7552, 50632], "temperature": 0.0, "avg_logprob": -0.19153424560046586, "compression_ratio": 1.8644067796610169, "no_speech_prob": 0.030127834528684616}, {"id": 236, "seek": 148626, "start": 1491.62, "end": 1495.74, "text": " a tener, como vimos en las clases anteriores, voy a tener un conjunto de entrenamiento,", "tokens": [50632, 257, 11640, 11, 2617, 49266, 465, 2439, 596, 1957, 364, 34345, 2706, 11, 7552, 257, 11640, 517, 37776, 368, 45069, 16971, 11, 50838], "temperature": 0.0, "avg_logprob": -0.19153424560046586, "compression_ratio": 1.8644067796610169, "no_speech_prob": 0.030127834528684616}, {"id": 237, "seek": 148626, "start": 1495.74, "end": 1500.42, "text": " un conjunto de desarrollo, un conjunto de test, entonces supongamos que yo tengo un", "tokens": [50838, 517, 37776, 368, 38295, 11, 517, 37776, 368, 1500, 11, 13003, 9331, 556, 2151, 631, 5290, 13989, 517, 51072], "temperature": 0.0, "avg_logprob": -0.19153424560046586, "compression_ratio": 1.8644067796610169, "no_speech_prob": 0.030127834528684616}, {"id": 238, "seek": 148626, "start": 1500.42, "end": 1504.78, "text": " conjunto de entrenamiento que tiene en ejemplos, o sea, en ejemplos significa que voy", "tokens": [51072, 37776, 368, 45069, 16971, 631, 7066, 465, 10012, 5895, 329, 11, 277, 4158, 11, 465, 10012, 5895, 329, 19957, 631, 7552, 51290], "temperature": 0.0, "avg_logprob": -0.19153424560046586, "compression_ratio": 1.8644067796610169, "no_speech_prob": 0.030127834528684616}, {"id": 239, "seek": 148626, "start": 1504.78, "end": 1513.42, "text": " a tener en estos vectores y en salidas distintas, que les voy a llamar y, entonces, los vectores", "tokens": [51290, 257, 11640, 465, 12585, 1241, 349, 2706, 288, 465, 1845, 11382, 31489, 296, 11, 631, 1512, 7552, 257, 16848, 289, 288, 11, 13003, 11, 1750, 1241, 349, 2706, 51722], "temperature": 0.0, "avg_logprob": -0.19153424560046586, "compression_ratio": 1.8644067796610169, "no_speech_prob": 0.030127834528684616}, {"id": 240, "seek": 151342, "start": 1513.42, "end": 1518.26, "text": " de entrada son estos, los vectores de salidas son estos de ac\u00e1, y yo tengo que tratar", "tokens": [50364, 368, 37119, 1872, 12585, 11, 1750, 1241, 349, 2706, 368, 1845, 11382, 1872, 12585, 368, 23496, 11, 288, 5290, 13989, 631, 42549, 50606], "temperature": 0.0, "avg_logprob": -0.18245639357455942, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.0031289488542824984}, {"id": 241, "seek": 151342, "start": 1518.26, "end": 1527.54, "text": " de ver si la salida se parece al entrada. Entonces, supongamos que la salida es solamente", "tokens": [50606, 368, 1306, 1511, 635, 1845, 2887, 369, 14120, 419, 37119, 13, 15097, 11, 9331, 556, 2151, 631, 635, 1845, 2887, 785, 27814, 51070], "temperature": 0.0, "avg_logprob": -0.18245639357455942, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.0031289488542824984}, {"id": 242, "seek": 151342, "start": 1527.54, "end": 1533.22, "text": " un valor, \u00bfno? O sea, para simplificar, vamos a asumir que la entrada de la red es", "tokens": [51070, 517, 15367, 11, 3841, 1771, 30, 422, 4158, 11, 1690, 6883, 25625, 11, 5295, 257, 382, 449, 347, 631, 635, 37119, 368, 635, 2182, 785, 51354], "temperature": 0.0, "avg_logprob": -0.18245639357455942, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.0031289488542824984}, {"id": 243, "seek": 151342, "start": 1533.22, "end": 1538.94, "text": " un vector de cualquier dimensi\u00f3n, y la salida solamente es un valor real, \u00bfno? Es posible,", "tokens": [51354, 517, 8062, 368, 21004, 5013, 694, 2560, 11, 288, 635, 1845, 2887, 27814, 785, 517, 15367, 957, 11, 3841, 1771, 30, 2313, 26644, 11, 51640], "temperature": 0.0, "avg_logprob": -0.18245639357455942, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.0031289488542824984}, {"id": 244, "seek": 151342, "start": 1538.94, "end": 1542.7, "text": " \u00bfno? O sea, lo que estoy haciendo es tener una red que tiene muchas capas, lo que sea,", "tokens": [51640, 3841, 1771, 30, 422, 4158, 11, 450, 631, 15796, 20509, 785, 11640, 2002, 2182, 631, 7066, 16072, 1410, 296, 11, 450, 631, 4158, 11, 51828], "temperature": 0.0, "avg_logprob": -0.18245639357455942, "compression_ratio": 1.785425101214575, "no_speech_prob": 0.0031289488542824984}, {"id": 245, "seek": 154270, "start": 1542.7, "end": 1547.4, "text": " en el final, todo se reduce a una sola salida un valor real, obviamente esto despu\u00e9s", "tokens": [50364, 465, 806, 2572, 11, 5149, 369, 5407, 257, 2002, 34162, 1845, 2887, 517, 15367, 957, 11, 36325, 7433, 15283, 50599], "temperature": 0.0, "avg_logprob": -0.24781925162089238, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0010164498817175627}, {"id": 246, "seek": 154270, "start": 1547.4, "end": 1551.38, "text": " se extiende a m\u00e1s valores reales, pero bueno, supongamos que tenemos una sola, \u00bfno?", "tokens": [50599, 369, 1279, 45816, 257, 3573, 38790, 957, 279, 11, 4768, 11974, 11, 9331, 556, 2151, 631, 9914, 2002, 34162, 11, 3841, 1771, 30, 50798], "temperature": 0.0, "avg_logprob": -0.24781925162089238, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0010164498817175627}, {"id": 247, "seek": 154270, "start": 1551.38, "end": 1560.5, "text": " Entonces digo que tengo en instancias, o sea, en valores x v, este es mi conjunto de", "tokens": [50798, 15097, 22990, 631, 13989, 465, 1058, 282, 12046, 11, 277, 4158, 11, 465, 38790, 2031, 371, 11, 4065, 785, 2752, 37776, 368, 51254], "temperature": 0.0, "avg_logprob": -0.24781925162089238, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0010164498817175627}, {"id": 248, "seek": 154270, "start": 1560.5, "end": 1567.26, "text": " entrenamiento, supongamos, o el conjunto en el que estoy tratando de medir cosas x v y", "tokens": [51254, 45069, 16971, 11, 9331, 556, 2151, 11, 277, 806, 37776, 465, 806, 631, 15796, 21507, 1806, 368, 1205, 347, 12218, 2031, 371, 288, 51592], "temperature": 0.0, "avg_logprob": -0.24781925162089238, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0010164498817175627}, {"id": 249, "seek": 156726, "start": 1567.26, "end": 1573.66, "text": " me dice que esto es x v, deber\u00edan corresponderse con diferentes valores de x v, \u00bfno?", "tokens": [50364, 385, 10313, 631, 7433, 785, 2031, 371, 11, 29671, 11084, 6805, 260, 405, 416, 17686, 38790, 368, 2031, 371, 11, 3841, 1771, 30, 50684], "temperature": 0.0, "avg_logprob": -0.2112804511924843, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.020231598988175392}, {"id": 250, "seek": 156726, "start": 1573.66, "end": 1580.66, "text": " Este es el conjunto de valores esperados, yo digo que para x v 1 tengo un y v 1, para", "tokens": [50684, 16105, 785, 806, 37776, 368, 38790, 10045, 4181, 11, 5290, 22990, 631, 1690, 2031, 371, 502, 13989, 517, 288, 371, 502, 11, 1690, 51034], "temperature": 0.0, "avg_logprob": -0.2112804511924843, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.020231598988175392}, {"id": 251, "seek": 156726, "start": 1580.66, "end": 1589.08, "text": " x v 2 tengo un y v 2, bien, por ahora son todos n\u00fameros reales, y adem\u00e1s tengo que", "tokens": [51034, 2031, 371, 568, 13989, 517, 288, 371, 568, 11, 3610, 11, 1515, 9923, 1872, 6321, 36545, 957, 279, 11, 288, 21251, 13989, 631, 51455], "temperature": 0.0, "avg_logprob": -0.2112804511924843, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.020231598988175392}, {"id": 252, "seek": 158908, "start": 1589.08, "end": 1597.28, "text": " yo tengo una red neuronal con ciertos pesos, que se la puedo aplicar a x v y con sus", "tokens": [50364, 5290, 13989, 2002, 2182, 12087, 21523, 416, 49252, 329, 33204, 11, 631, 369, 635, 21612, 18221, 289, 257, 2031, 371, 288, 416, 3291, 50774], "temperature": 0.0, "avg_logprob": -0.23798555486342488, "compression_ratio": 1.671497584541063, "no_speech_prob": 0.046097565442323685}, {"id": 253, "seek": 158908, "start": 1597.28, "end": 1603.1599999999999, "text": " matrices de pesos, entonces mi red neuronal me va a dar cierto valor y le voy a llamar", "tokens": [50774, 32284, 368, 33204, 11, 13003, 2752, 2182, 12087, 21523, 385, 2773, 257, 4072, 28558, 15367, 288, 476, 7552, 257, 16848, 289, 51068], "temperature": 0.0, "avg_logprob": -0.23798555486342488, "compression_ratio": 1.671497584541063, "no_speech_prob": 0.046097565442323685}, {"id": 254, "seek": 158908, "start": 1603.1599999999999, "end": 1610.8, "text": " y sub\u00ed techo, \u00bfc\u00f3mo puedo saber si est\u00e1 bien lo que me da la red neuronal para x v o", "tokens": [51068, 288, 1422, 870, 535, 5738, 11, 3841, 46614, 21612, 12489, 1511, 3192, 3610, 450, 631, 385, 1120, 635, 2182, 12087, 21523, 1690, 2031, 371, 277, 51450], "temperature": 0.0, "avg_logprob": -0.23798555486342488, "compression_ratio": 1.671497584541063, "no_speech_prob": 0.046097565442323685}, {"id": 255, "seek": 158908, "start": 1610.8, "end": 1618.08, "text": " no? De qu\u00e9 manera yo puedo llegar a medir si est\u00e1 bien o no, este valor que me dio.", "tokens": [51450, 572, 30, 1346, 8057, 13913, 5290, 21612, 24892, 257, 1205, 347, 1511, 3192, 3610, 277, 572, 11, 4065, 15367, 631, 385, 31965, 13, 51814], "temperature": 0.0, "avg_logprob": -0.23798555486342488, "compression_ratio": 1.671497584541063, "no_speech_prob": 0.046097565442323685}, {"id": 256, "seek": 161808, "start": 1619.08, "end": 1628.3999999999999, "text": " Si, ah\u00ed est\u00e1, o sea, mi salida, en mi conjunto yo dec\u00eda, bueno, la salida ten\u00eda", "tokens": [50414, 4909, 11, 12571, 3192, 11, 277, 4158, 11, 2752, 1845, 2887, 11, 465, 2752, 37776, 5290, 37599, 11, 11974, 11, 635, 1845, 2887, 23718, 50880], "temperature": 0.0, "avg_logprob": -0.39414326148697093, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.024105530232191086}, {"id": 257, "seek": 161808, "start": 1628.3999999999999, "end": 1635.12, "text": " haber sido y sub\u00ed, y la salida de medio de la red es y sub\u00ed techo, \u00bfc\u00f3mo puedo saber", "tokens": [50880, 15811, 14444, 288, 1422, 870, 11, 288, 635, 1845, 2887, 368, 22123, 368, 635, 2182, 785, 288, 1422, 870, 535, 5738, 11, 3841, 46614, 21612, 12489, 51216], "temperature": 0.0, "avg_logprob": -0.39414326148697093, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.024105530232191086}, {"id": 258, "seek": 161808, "start": 1635.12, "end": 1638.96, "text": " si ese est\u00e1 bien o mal? O sea, \u00bfqu\u00e9 medida me dice si est\u00e1 bien o mal?", "tokens": [51216, 1511, 10167, 3192, 3610, 277, 2806, 30, 422, 4158, 11, 3841, 16412, 32984, 385, 10313, 1511, 3192, 3610, 277, 2806, 30, 51408], "temperature": 0.0, "avg_logprob": -0.39414326148697093, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.024105530232191086}, {"id": 259, "seek": 163896, "start": 1638.96, "end": 1649.68, "text": " Ah\u00ed est\u00e1, lo puedo restar y digo bueno, \u00bfqu\u00e9 tanto se parecen estos dos? Si esto est\u00e1", "tokens": [50364, 49924, 3192, 11, 450, 21612, 1472, 289, 288, 22990, 11974, 11, 3841, 16412, 10331, 369, 7448, 13037, 12585, 4491, 30, 4909, 7433, 3192, 50900], "temperature": 0.0, "avg_logprob": -0.21482082366943359, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.027140947058796883}, {"id": 260, "seek": 163896, "start": 1649.68, "end": 1653.48, "text": " cerca de cero, es un valor muy chiquito, entonces yo puedo decir que estas dos cosas son iguales,", "tokens": [50900, 26770, 368, 269, 2032, 11, 785, 517, 15367, 5323, 417, 3221, 3528, 11, 13003, 5290, 21612, 10235, 631, 13897, 4491, 12218, 1872, 10953, 279, 11, 51090], "temperature": 0.0, "avg_logprob": -0.21482082366943359, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.027140947058796883}, {"id": 261, "seek": 163896, "start": 1653.48, "end": 1660.72, "text": " por lo tanto la red me est\u00e1 dando un resultado parecido al que yo esperaba, y si estos dos son", "tokens": [51090, 1515, 450, 10331, 635, 2182, 385, 3192, 29854, 517, 28047, 7448, 17994, 419, 631, 5290, 10045, 5509, 11, 288, 1511, 12585, 4491, 1872, 51452], "temperature": 0.0, "avg_logprob": -0.21482082366943359, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.027140947058796883}, {"id": 262, "seek": 163896, "start": 1660.72, "end": 1665.8, "text": " muy diferentes, entonces esto me va a dar un valor bastante alto, entonces yo tengo muchos de", "tokens": [51452, 5323, 17686, 11, 13003, 7433, 385, 2773, 257, 4072, 517, 15367, 14651, 21275, 11, 13003, 5290, 13989, 17061, 368, 51706], "temperature": 0.0, "avg_logprob": -0.21482082366943359, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.027140947058796883}, {"id": 263, "seek": 166580, "start": 1665.9199999999998, "end": 1671.44, "text": " estos, no tengo n ejemplos de este estilo, as\u00ed que lo que voy a hacer es sumar todos estos,", "tokens": [50370, 12585, 11, 572, 13989, 297, 10012, 5895, 329, 368, 4065, 37470, 11, 8582, 631, 450, 631, 7552, 257, 6720, 785, 2408, 289, 6321, 12585, 11, 50646], "temperature": 0.0, "avg_logprob": -0.24511177860089203, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0029078135266900063}, {"id": 264, "seek": 166580, "start": 1671.44, "end": 1679.44, "text": " de igual 1 hasta n, sumo todos los valores, tengo un problema ac\u00e1 que es que a veces yo puedo", "tokens": [50646, 368, 10953, 502, 10764, 297, 11, 2408, 78, 6321, 1750, 38790, 11, 13989, 517, 12395, 23496, 631, 785, 631, 257, 17054, 5290, 21612, 51046], "temperature": 0.0, "avg_logprob": -0.24511177860089203, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0029078135266900063}, {"id": 265, "seek": 166580, "start": 1679.44, "end": 1682.68, "text": " le puedo ahorrar por mucho, a veces le puedo ahorrar por poco, pero a veces esto me va a dar", "tokens": [51046, 476, 21612, 44249, 5352, 1515, 9824, 11, 257, 17054, 476, 21612, 44249, 5352, 1515, 10639, 11, 4768, 257, 17054, 7433, 385, 2773, 257, 4072, 51208], "temperature": 0.0, "avg_logprob": -0.24511177860089203, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0029078135266900063}, {"id": 266, "seek": 166580, "start": 1682.68, "end": 1686.96, "text": " negativo, esto me va a dar positivo, entonces si yo lo sumo todos capaz que me da cero por casualidad,", "tokens": [51208, 2485, 18586, 11, 7433, 385, 2773, 257, 4072, 44710, 11, 13003, 1511, 5290, 450, 2408, 78, 6321, 35453, 631, 385, 1120, 269, 2032, 1515, 13052, 4580, 11, 51422], "temperature": 0.0, "avg_logprob": -0.24511177860089203, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0029078135266900063}, {"id": 267, "seek": 166580, "start": 1686.96, "end": 1691.8799999999999, "text": " entonces lo que hago es ponerlos acuadrado, para decir bueno, yo siempre voy a sumar valores", "tokens": [51422, 13003, 450, 631, 38721, 785, 19149, 9389, 696, 84, 345, 14974, 11, 1690, 10235, 11974, 11, 5290, 12758, 7552, 257, 2408, 289, 38790, 51668], "temperature": 0.0, "avg_logprob": -0.24511177860089203, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0029078135266900063}, {"id": 268, "seek": 169188, "start": 1691.88, "end": 1696.68, "text": " positivos, entonces si mi salida es distinta, el valor esperado siempre esto me va a dar un resultado", "tokens": [50364, 11218, 16501, 11, 13003, 1511, 2752, 1845, 2887, 785, 1483, 16071, 11, 806, 15367, 10045, 1573, 12758, 7433, 385, 2773, 257, 4072, 517, 28047, 50604], "temperature": 0.0, "avg_logprob": -0.20066263108026414, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.03577874228358269}, {"id": 269, "seek": 169188, "start": 1696.68, "end": 1701.8000000000002, "text": " positivo, bien, entonces como estoy comparando n ejemplos, a esto lo voy a dividir entre n,", "tokens": [50604, 44710, 11, 3610, 11, 13003, 2617, 15796, 6311, 1806, 297, 10012, 5895, 329, 11, 257, 7433, 450, 7552, 257, 4996, 347, 3962, 297, 11, 50860], "temperature": 0.0, "avg_logprob": -0.20066263108026414, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.03577874228358269}, {"id": 270, "seek": 169188, "start": 1703.64, "end": 1710.72, "text": " esto de ac\u00e1 me da una m\u00e9trica condensada que me dice que tanto se equivoco mi red respecto a los", "tokens": [50952, 7433, 368, 23496, 385, 1120, 2002, 20275, 15192, 2224, 694, 1538, 631, 385, 10313, 631, 10331, 369, 48726, 11198, 2752, 2182, 35694, 257, 1750, 51306], "temperature": 0.0, "avg_logprob": -0.20066263108026414, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.03577874228358269}, {"id": 271, "seek": 169188, "start": 1710.72, "end": 1714.2, "text": " valores, a todos los valores esperados, y de hecho esta es una de las m\u00e9tricas posibles para", "tokens": [51306, 38790, 11, 257, 6321, 1750, 38790, 10045, 4181, 11, 288, 368, 13064, 5283, 785, 2002, 368, 2439, 20275, 1341, 296, 1366, 14428, 1690, 51480], "temperature": 0.0, "avg_logprob": -0.20066263108026414, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.03577874228358269}, {"id": 272, "seek": 171420, "start": 1714.32, "end": 1722.4, "text": " medir eso, esta es muy usada, se llama mce, minzcuerderor o error cuadratico medio y es una de las", "tokens": [50370, 1205, 347, 7287, 11, 5283, 785, 5323, 505, 1538, 11, 369, 23272, 275, 384, 11, 923, 89, 66, 5486, 1068, 284, 277, 6713, 34434, 4481, 2789, 22123, 288, 785, 2002, 368, 2439, 50774], "temperature": 0.0, "avg_logprob": -0.24755776145241476, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.005225513596087694}, {"id": 273, "seek": 171420, "start": 1722.4, "end": 1731.28, "text": " m\u00e9tricas m\u00e1s conocidas, entonces esto es una m\u00e9trica que me permite medir la discrepancia que", "tokens": [50774, 20275, 1341, 296, 3573, 15871, 11382, 11, 13003, 7433, 785, 2002, 20275, 15192, 631, 385, 31105, 1205, 347, 635, 2983, 265, 6040, 2755, 631, 51218], "temperature": 0.0, "avg_logprob": -0.24755776145241476, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.005225513596087694}, {"id": 274, "seek": 171420, "start": 1731.28, "end": 1737.52, "text": " hay entre los valores esperados de una red ac\u00e1 era isu y, entre los valores esperados de una red y", "tokens": [51218, 4842, 3962, 1750, 38790, 10045, 4181, 368, 2002, 2182, 23496, 4249, 307, 84, 288, 11, 3962, 1750, 38790, 10045, 4181, 368, 2002, 2182, 288, 51530], "temperature": 0.0, "avg_logprob": -0.24755776145241476, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.005225513596087694}, {"id": 275, "seek": 171420, "start": 1737.52, "end": 1742.72, "text": " los valores que la red dio con todos los pesos que tiene hasta el momento, recuerden que este", "tokens": [51530, 1750, 38790, 631, 635, 2182, 31965, 416, 6321, 1750, 33204, 631, 7066, 10764, 806, 9333, 11, 39092, 1556, 631, 4065, 51790], "temperature": 0.0, "avg_logprob": -0.24755776145241476, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.005225513596087694}, {"id": 276, "seek": 174272, "start": 1742.72, "end": 1752.52, "text": " isu y se calculaba como el resultado de la red para exu y los pesos de red, entonces este tipo", "tokens": [50364, 307, 84, 288, 369, 4322, 5509, 2617, 806, 28047, 368, 635, 2182, 1690, 454, 84, 288, 1750, 33204, 368, 2182, 11, 13003, 4065, 9746, 50854], "temperature": 0.0, "avg_logprob": -0.3043334105304468, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.0016477458411827683}, {"id": 277, "seek": 174272, "start": 1752.52, "end": 1757.6000000000001, "text": " de funciones que miden la diferencia entre los valores esperados y los valores que me dio la", "tokens": [50854, 368, 1019, 23469, 631, 2062, 268, 635, 38844, 3962, 1750, 38790, 10045, 4181, 288, 1750, 38790, 631, 385, 31965, 635, 51108], "temperature": 0.0, "avg_logprob": -0.3043334105304468, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.0016477458411827683}, {"id": 278, "seek": 174272, "start": 1757.6000000000001, "end": 1763.8, "text": " red de verdad se llaman funciones de perdida, bien, o sea el nombre de perdida no se movien de donde", "tokens": [51108, 2182, 368, 13692, 369, 4849, 6147, 1019, 23469, 368, 12611, 2887, 11, 3610, 11, 277, 4158, 806, 13000, 368, 12611, 2887, 572, 369, 2402, 1053, 368, 10488, 51418], "temperature": 0.0, "avg_logprob": -0.3043334105304468, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.0016477458411827683}, {"id": 279, "seek": 174272, "start": 1763.8, "end": 1768.64, "text": " sale, pero se le fue, se le suele llamar funciones de perdida los functions y bueno es uno de los", "tokens": [51418, 8680, 11, 4768, 369, 476, 9248, 11, 369, 476, 459, 16884, 16848, 289, 1019, 23469, 368, 12611, 2887, 1750, 6828, 288, 11974, 785, 8526, 368, 1750, 51660], "temperature": 0.0, "avg_logprob": -0.3043334105304468, "compression_ratio": 1.8829268292682926, "no_speech_prob": 0.0016477458411827683}, {"id": 280, "seek": 176864, "start": 1768.64, "end": 1773.2800000000002, "text": " conceptos que no tiene que aprender cuando aprende de redes neuronales, porque para entrenarlas yo", "tokens": [50364, 3410, 329, 631, 572, 7066, 631, 24916, 7767, 21003, 68, 368, 16762, 34090, 4229, 11, 4021, 1690, 45069, 6843, 296, 5290, 50596], "temperature": 0.0, "avg_logprob": -0.20251499373337317, "compression_ratio": 1.8248175182481752, "no_speech_prob": 0.00398067245259881}, {"id": 281, "seek": 176864, "start": 1773.2800000000002, "end": 1777.96, "text": " lo que tengo que hacer es elegir una los function apropiada para problemas, entonces estas de las", "tokens": [50596, 450, 631, 13989, 631, 6720, 785, 14459, 347, 2002, 1750, 2445, 1882, 1513, 39018, 1690, 20720, 11, 13003, 13897, 368, 2439, 50830], "temperature": 0.0, "avg_logprob": -0.20251499373337317, "compression_ratio": 1.8248175182481752, "no_speech_prob": 0.00398067245259881}, {"id": 282, "seek": 176864, "start": 1777.96, "end": 1783.2800000000002, "text": " m\u00e1s comunes, el error cuadratico medio sirve mucho para problemas donde los valores resultados son", "tokens": [50830, 3573, 11040, 279, 11, 806, 6713, 34434, 4481, 2789, 22123, 4735, 303, 9824, 1690, 20720, 10488, 1750, 38790, 1874, 4181, 1872, 51096], "temperature": 0.0, "avg_logprob": -0.20251499373337317, "compression_ratio": 1.8248175182481752, "no_speech_prob": 0.00398067245259881}, {"id": 283, "seek": 176864, "start": 1783.2800000000002, "end": 1789.44, "text": " valores reales, no sirve tanto para cuando los valores esperados resultantes son por ejemplo una", "tokens": [51096, 38790, 957, 279, 11, 572, 4735, 303, 10331, 1690, 7767, 1750, 38790, 10045, 4181, 1874, 9327, 1872, 1515, 13358, 2002, 51404], "temperature": 0.0, "avg_logprob": -0.20251499373337317, "compression_ratio": 1.8248175182481752, "no_speech_prob": 0.00398067245259881}, {"id": 284, "seek": 176864, "start": 1789.44, "end": 1795.16, "text": " distribuci\u00f3n de probabilidades o una categor\u00eda en muchas como ese problema que tienen en el laboratorio,", "tokens": [51404, 4400, 30813, 368, 31959, 10284, 277, 2002, 19250, 2686, 465, 16072, 2617, 10167, 12395, 631, 12536, 465, 806, 5938, 48028, 11, 51690], "temperature": 0.0, "avg_logprob": -0.20251499373337317, "compression_ratio": 1.8248175182481752, "no_speech_prob": 0.00398067245259881}, {"id": 285, "seek": 179516, "start": 1795.64, "end": 1802.5400000000002, "text": " para eso utiliza notas, por ejemplo la entrop\u00eda cruzada o en particular una versi\u00f3n de entrop\u00eda", "tokens": [50388, 1690, 7287, 4976, 13427, 406, 296, 11, 1515, 13358, 635, 948, 1513, 2686, 5140, 89, 1538, 277, 465, 1729, 2002, 47248, 368, 948, 1513, 2686, 50733], "temperature": 0.0, "avg_logprob": -0.21832144601004463, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.001263715559616685}, {"id": 286, "seek": 179516, "start": 1802.5400000000002, "end": 1807.8400000000001, "text": " cruzada que sirve para decir yo tengo un solo valor correcto de entre muchos que en el laboratorio", "tokens": [50733, 5140, 89, 1538, 631, 4735, 303, 1690, 10235, 5290, 13989, 517, 6944, 15367, 3006, 78, 368, 3962, 17061, 631, 465, 806, 5938, 48028, 50998], "temperature": 0.0, "avg_logprob": -0.21832144601004463, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.001263715559616685}, {"id": 287, "seek": 179516, "start": 1807.8400000000001, "end": 1813.24, "text": " les pasa eso digamos que tengo un tweet y es positivo o en negativo o en neutro no puede ser m\u00e1s", "tokens": [50998, 1512, 20260, 7287, 36430, 631, 13989, 517, 15258, 288, 785, 44710, 277, 465, 2485, 18586, 277, 465, 7989, 340, 572, 8919, 816, 3573, 51268], "temperature": 0.0, "avg_logprob": -0.21832144601004463, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.001263715559616685}, {"id": 288, "seek": 179516, "start": 1813.24, "end": 1817.48, "text": " de une, entonces para eso se usa la \u00faltima, es una versi\u00f3n de la entrop\u00eda cruzada para valores", "tokens": [51268, 368, 2251, 11, 13003, 1690, 7287, 369, 29909, 635, 28118, 11, 785, 2002, 47248, 368, 635, 948, 1513, 2686, 5140, 89, 1538, 1690, 38790, 51480], "temperature": 0.0, "avg_logprob": -0.21832144601004463, "compression_ratio": 1.7863636363636364, "no_speech_prob": 0.001263715559616685}, {"id": 289, "seek": 181748, "start": 1817.6, "end": 1826.4, "text": " categoricos, bien y existen unas cuantas m\u00e1s digamos, o sea pero en definitiva siempre tengo que", "tokens": [50370, 19250, 9940, 11, 3610, 288, 2514, 268, 25405, 2702, 49153, 3573, 36430, 11, 277, 4158, 4768, 465, 28781, 5931, 12758, 13989, 631, 50810], "temperature": 0.0, "avg_logprob": -0.19643001869076587, "compression_ratio": 1.8979591836734695, "no_speech_prob": 0.0030637402087450027}, {"id": 290, "seek": 181748, "start": 1826.4, "end": 1830.2, "text": " tener funciones de estilo como pasaba con la funci\u00f3n de activaci\u00f3n lo que se espera de una", "tokens": [50810, 11640, 1019, 23469, 368, 37470, 2617, 1736, 5509, 416, 635, 43735, 368, 2430, 3482, 450, 631, 369, 37862, 368, 2002, 51000], "temperature": 0.0, "avg_logprob": -0.19643001869076587, "compression_ratio": 1.8979591836734695, "no_speech_prob": 0.0030637402087450027}, {"id": 291, "seek": 181748, "start": 1830.2, "end": 1836.24, "text": " funci\u00f3n de perdias es que sea derivable y en el caso de las funciones de perdias lo que se", "tokens": [51000, 43735, 368, 680, 4504, 296, 785, 631, 4158, 10151, 712, 288, 465, 806, 9666, 368, 2439, 1019, 23469, 368, 680, 4504, 296, 450, 631, 369, 51302], "temperature": 0.0, "avg_logprob": -0.19643001869076587, "compression_ratio": 1.8979591836734695, "no_speech_prob": 0.0030637402087450027}, {"id": 292, "seek": 181748, "start": 1836.24, "end": 1841.7, "text": " espera es que cuando la salida de la red se parece much\u00edsimo a los valores esperados,", "tokens": [51302, 37862, 785, 631, 7767, 635, 1845, 2887, 368, 635, 2182, 369, 14120, 44722, 257, 1750, 38790, 10045, 4181, 11, 51575], "temperature": 0.0, "avg_logprob": -0.19643001869076587, "compression_ratio": 1.8979591836734695, "no_speech_prob": 0.0030637402087450027}, {"id": 293, "seek": 181748, "start": 1841.7, "end": 1845.84, "text": " tiene que estar cercana a cero o tiene que ser un valor m\u00ednimo y cuando la salida de la red es", "tokens": [51575, 7066, 631, 8755, 36099, 2095, 257, 269, 2032, 277, 7066, 631, 816, 517, 15367, 47393, 288, 7767, 635, 1845, 2887, 368, 635, 2182, 785, 51782], "temperature": 0.0, "avg_logprob": -0.19643001869076587, "compression_ratio": 1.8979591836734695, "no_speech_prob": 0.0030637402087450027}, {"id": 294, "seek": 184584, "start": 1845.84, "end": 1857.1599999999999, "text": " muy diferente tengo que ser un valor m\u00e1s grande, bien, ok entonces \u00bfpor qu\u00e9 es que yo quiero", "tokens": [50364, 5323, 20973, 13989, 631, 816, 517, 15367, 3573, 8883, 11, 3610, 11, 3133, 13003, 3841, 2816, 8057, 785, 631, 5290, 16811, 50930], "temperature": 0.0, "avg_logprob": -0.33827344109030333, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.0003310964966658503}, {"id": 295, "seek": 184584, "start": 1857.1599999999999, "end": 1868.0, "text": " que todo esto sea derivable? \u00bfPor qu\u00e9 les parece? S\u00ed, es exacto para minimizar el hecho de", "tokens": [50930, 631, 5149, 7433, 4158, 10151, 712, 30, 3841, 24907, 8057, 1512, 14120, 30, 12375, 11, 785, 1900, 78, 1690, 4464, 9736, 806, 13064, 368, 51472], "temperature": 0.0, "avg_logprob": -0.33827344109030333, "compression_ratio": 1.2857142857142858, "no_speech_prob": 0.0003310964966658503}, {"id": 296, "seek": 186800, "start": 1868.0, "end": 1877.16, "text": " que yo voy a hacer que esto sea derivable digamos que lo que est\u00e1 dentro o sea este es y su", "tokens": [50364, 631, 5290, 7552, 257, 6720, 631, 7433, 4158, 10151, 712, 36430, 631, 450, 631, 3192, 10856, 277, 4158, 4065, 785, 288, 459, 50822], "temperature": 0.0, "avg_logprob": -0.24868864171645222, "compression_ratio": 1.525, "no_speech_prob": 0.0036545039620250463}, {"id": 297, "seek": 186800, "start": 1877.16, "end": 1884.8, "text": " techo y sub\u00ed techo menos y sub\u00ed y esto lo calcul\u00e9 con esto que est\u00e1 ac\u00e1 entonces esto", "tokens": [50822, 535, 5738, 288, 1422, 870, 535, 5738, 8902, 288, 1422, 870, 288, 7433, 450, 4322, 526, 416, 7433, 631, 3192, 23496, 13003, 7433, 51204], "temperature": 0.0, "avg_logprob": -0.24868864171645222, "compression_ratio": 1.525, "no_speech_prob": 0.0036545039620250463}, {"id": 298, "seek": 188480, "start": 1884.8, "end": 1895.04, "text": " es una sobre n por la sumatoria de 1 esta n de una cosa que ten\u00eda la forma sigma de", "tokens": [50364, 785, 2002, 5473, 297, 1515, 635, 2408, 1639, 654, 368, 502, 5283, 297, 368, 2002, 10163, 631, 23718, 635, 8366, 12771, 368, 50876], "temperature": 0.0, "avg_logprob": -0.3080176625932966, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.14976026117801666}, {"id": 299, "seek": 188480, "start": 1900.1599999999999, "end": 1912.52, "text": " sigma de sigma de x por w a la 1 por w2, no s\u00e9 qu\u00e9 menos y sub\u00ed al cuadrado, bien entonces ac\u00e1", "tokens": [51132, 12771, 368, 12771, 368, 2031, 1515, 261, 257, 635, 502, 1515, 261, 17, 11, 572, 7910, 8057, 8902, 288, 1422, 870, 419, 34434, 14974, 11, 3610, 13003, 23496, 51750], "temperature": 0.0, "avg_logprob": -0.3080176625932966, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.14976026117801666}, {"id": 300, "seek": 191252, "start": 1912.52, "end": 1917.68, "text": " entonces yo ten\u00eda una cosa que era todo derivable y ac\u00e1 afuera tengo otra funci\u00f3n que tambi\u00e9n es", "tokens": [50364, 13003, 5290, 23718, 2002, 10163, 631, 4249, 5149, 10151, 712, 288, 23496, 3238, 84, 1663, 13989, 13623, 43735, 631, 6407, 785, 50622], "temperature": 0.0, "avg_logprob": -0.27258408069610596, "compression_ratio": 1.87109375, "no_speech_prob": 0.009853391908109188}, {"id": 301, "seek": 191252, "start": 1917.68, "end": 1922.76, "text": " derivable tanto de las funciones de activaci\u00f3n como todos los resultados de la red nominal como", "tokens": [50622, 10151, 712, 10331, 368, 2439, 1019, 23469, 368, 2430, 3482, 2617, 6321, 1750, 36796, 368, 635, 2182, 41641, 2617, 50876], "temperature": 0.0, "avg_logprob": -0.27258408069610596, "compression_ratio": 1.87109375, "no_speech_prob": 0.009853391908109188}, {"id": 302, "seek": 191252, "start": 1922.76, "end": 1927.12, "text": " la funci\u00f3n de perdias como todas estas cosas son todos derivables para que quiero eso porque", "tokens": [50876, 635, 43735, 368, 680, 4504, 296, 2617, 10906, 13897, 12218, 1872, 6321, 10151, 2965, 1690, 631, 16811, 7287, 4021, 51094], "temperature": 0.0, "avg_logprob": -0.27258408069610596, "compression_ratio": 1.87109375, "no_speech_prob": 0.009853391908109188}, {"id": 303, "seek": 191252, "start": 1927.12, "end": 1933.04, "text": " efectivamente voy a derivar digamos o sea la t\u00e9cnica se utiliza para entrenar estas cosas se", "tokens": [51094, 22565, 23957, 7552, 257, 10151, 289, 36430, 277, 4158, 635, 45411, 369, 4976, 13427, 1690, 45069, 289, 13897, 12218, 369, 51390], "temperature": 0.0, "avg_logprob": -0.27258408069610596, "compression_ratio": 1.87109375, "no_speech_prob": 0.009853391908109188}, {"id": 304, "seek": 191252, "start": 1933.04, "end": 1940.4, "text": " basa mucho en encontrar derivadas y vamos a dotar de ver por qu\u00e9 bien entonces para entrenar", "tokens": [51390, 987, 64, 9824, 465, 17525, 10151, 6872, 288, 5295, 257, 5893, 289, 368, 1306, 1515, 8057, 3610, 13003, 1690, 45069, 289, 51758], "temperature": 0.0, "avg_logprob": -0.27258408069610596, "compression_ratio": 1.87109375, "no_speech_prob": 0.009853391908109188}, {"id": 305, "seek": 194040, "start": 1940.4, "end": 1948.24, "text": " una de estas redes recordemos que digamos para entrenar estas redes yo recordemos que tengo", "tokens": [50364, 2002, 368, 13897, 16762, 2136, 4485, 631, 36430, 1690, 45069, 289, 13897, 16762, 5290, 2136, 4485, 631, 13989, 50756], "temperature": 0.0, "avg_logprob": -0.21255126366248497, "compression_ratio": 2.00531914893617, "no_speech_prob": 0.001365447766147554}, {"id": 306, "seek": 194040, "start": 1948.24, "end": 1955.4, "text": " conjunto de entrenamiento, un conjunto de desarrollo, un conjunto de test y me interesa tratar", "tokens": [50756, 37776, 368, 45069, 16971, 11, 517, 37776, 368, 38295, 11, 517, 37776, 368, 1500, 288, 385, 728, 13708, 42549, 51114], "temperature": 0.0, "avg_logprob": -0.21255126366248497, "compression_ratio": 2.00531914893617, "no_speech_prob": 0.001365447766147554}, {"id": 307, "seek": 194040, "start": 1955.4, "end": 1963.96, "text": " de minimizar esto o sea yo tengo que la red se calcula como dependiendo de el valor de entrada", "tokens": [51114, 368, 4464, 9736, 7433, 277, 4158, 5290, 13989, 631, 635, 2182, 369, 4322, 64, 2617, 5672, 7304, 368, 806, 15367, 368, 37119, 51542], "temperature": 0.0, "avg_logprob": -0.21255126366248497, "compression_ratio": 2.00531914893617, "no_speech_prob": 0.001365447766147554}, {"id": 308, "seek": 194040, "start": 1963.96, "end": 1969.48, "text": " y el conjunto de pesos que tengo yo voy a multiplicar ese valor de entrada por una matriz y por", "tokens": [51542, 288, 806, 37776, 368, 33204, 631, 13989, 5290, 7552, 257, 17596, 289, 10167, 15367, 368, 37119, 1515, 2002, 3803, 24959, 288, 1515, 51818], "temperature": 0.0, "avg_logprob": -0.21255126366248497, "compression_ratio": 2.00531914893617, "no_speech_prob": 0.001365447766147554}, {"id": 309, "seek": 196948, "start": 1969.48, "end": 1975.04, "text": " otra por la funcional activaci\u00f3n etc\u00e9tera hasta obtener un resultado pero entonces notar que", "tokens": [50364, 13623, 1515, 635, 1019, 42395, 2430, 3482, 5183, 526, 23833, 10764, 28326, 260, 517, 28047, 4768, 13003, 406, 289, 631, 50642], "temperature": 0.0, "avg_logprob": -0.2628969344417606, "compression_ratio": 1.9065040650406504, "no_speech_prob": 0.0012464963365346193}, {"id": 310, "seek": 196948, "start": 1975.04, "end": 1980.92, "text": " este valor est\u00e1 en funci\u00f3n de la entrada que es que es que es subir y el conjunto de pesos", "tokens": [50642, 4065, 15367, 3192, 465, 43735, 368, 635, 37119, 631, 785, 631, 785, 631, 785, 34785, 288, 806, 37776, 368, 33204, 50936], "temperature": 0.0, "avg_logprob": -0.2628969344417606, "compression_ratio": 1.9065040650406504, "no_speech_prob": 0.0012464963365346193}, {"id": 311, "seek": 196948, "start": 1980.92, "end": 1986.08, "text": " o leve, no ac\u00e1 yo tengo una funci\u00f3n que es que est\u00e1n funci\u00f3n de dos cosas estas son las", "tokens": [50936, 277, 33076, 11, 572, 23496, 5290, 13989, 2002, 43735, 631, 785, 631, 10368, 43735, 368, 4491, 12218, 13897, 1872, 2439, 51194], "temperature": 0.0, "avg_logprob": -0.2628969344417606, "compression_ratio": 1.9065040650406504, "no_speech_prob": 0.0012464963365346193}, {"id": 312, "seek": 196948, "start": 1986.08, "end": 1991.08, "text": " entradas de conjunto de entrenamiento o del conjunto que estoy mediendo y estos son los pesos que", "tokens": [51194, 948, 48906, 368, 37776, 368, 45069, 16971, 277, 1103, 37776, 631, 15796, 17269, 3999, 288, 12585, 1872, 1750, 33204, 631, 51444], "temperature": 0.0, "avg_logprob": -0.2628969344417606, "compression_ratio": 1.9065040650406504, "no_speech_prob": 0.0012464963365346193}, {"id": 313, "seek": 196948, "start": 1991.08, "end": 1997.64, "text": " yo le puedo dar a cada una de las capas entonces una cosa interesante es que yo puedo mirar", "tokens": [51444, 5290, 476, 21612, 4072, 257, 8411, 2002, 368, 2439, 1410, 296, 13003, 2002, 10163, 36396, 785, 631, 5290, 21612, 3149, 289, 51772], "temperature": 0.0, "avg_logprob": -0.2628969344417606, "compression_ratio": 1.9065040650406504, "no_speech_prob": 0.0012464963365346193}, {"id": 314, "seek": 199764, "start": 1997.64, "end": 2001.8400000000001, "text": " este problema desde el punto de vista de que estos valores los dej\u00f3 fijos digo mi conjunto", "tokens": [50364, 4065, 12395, 10188, 806, 14326, 368, 22553, 368, 631, 12585, 38790, 1750, 21259, 812, 283, 1718, 329, 22990, 2752, 37776, 50574], "temperature": 0.0, "avg_logprob": -0.21113350516871401, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.006556649226695299}, {"id": 315, "seek": 199764, "start": 2001.8400000000001, "end": 2006.2800000000002, "text": " de entrenamiento lo conozco entonces los valores est\u00e1n fijos y yo puedo ir cambiando los pesos", "tokens": [50574, 368, 45069, 16971, 450, 416, 15151, 1291, 13003, 1750, 38790, 10368, 283, 1718, 329, 288, 5290, 21612, 3418, 19569, 1806, 1750, 33204, 50796], "temperature": 0.0, "avg_logprob": -0.21113350516871401, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.006556649226695299}, {"id": 316, "seek": 199764, "start": 2006.2800000000002, "end": 2011.92, "text": " hasta encontrar el conjunto de pesos ideales que permita que los valores de entrenamiento multiplicados", "tokens": [50796, 10764, 17525, 806, 37776, 368, 33204, 1153, 4229, 631, 4784, 2786, 631, 1750, 38790, 368, 45069, 16971, 17596, 4181, 51078], "temperature": 0.0, "avg_logprob": -0.21113350516871401, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.006556649226695299}, {"id": 317, "seek": 199764, "start": 2011.92, "end": 2016.96, "text": " por esos pesos me den la sal\u00eda que yo quiero entonces ah\u00ed eso se transforma en un problema como", "tokens": [51078, 1515, 22411, 33204, 385, 1441, 635, 1845, 2686, 631, 5290, 16811, 13003, 12571, 7287, 369, 4088, 64, 465, 517, 12395, 2617, 51330], "temperature": 0.0, "avg_logprob": -0.21113350516871401, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.006556649226695299}, {"id": 318, "seek": 199764, "start": 2016.96, "end": 2022.3600000000001, "text": " dec\u00edan por ah\u00ed un problema de demonizaci\u00f3n, un problema de optimizaci\u00f3n en el cual lo que", "tokens": [51330, 979, 11084, 1515, 12571, 517, 12395, 368, 14283, 27603, 11, 517, 12395, 368, 5028, 27603, 465, 806, 10911, 450, 631, 51600], "temperature": 0.0, "avg_logprob": -0.21113350516871401, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.006556649226695299}, {"id": 319, "seek": 202236, "start": 2022.36, "end": 2030.1599999999999, "text": " voy a hacer es tomar esto como variable entonces yo lo que quiero encontrar es el argmin para la", "tokens": [50364, 7552, 257, 6720, 785, 22048, 7433, 2617, 3034, 712, 13003, 5290, 450, 631, 16811, 17525, 785, 806, 3882, 2367, 1690, 635, 50754], "temperature": 0.0, "avg_logprob": -0.30278780619303386, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.0035167739260941744}, {"id": 320, "seek": 202236, "start": 2030.1599999999999, "end": 2037.12, "text": " familia posible de pesos de las distintas matrices lo leve de esta funci\u00f3n ac\u00e1 que es uno sobre", "tokens": [50754, 24050, 26644, 368, 33204, 368, 2439, 31489, 296, 32284, 450, 33076, 368, 5283, 43735, 23496, 631, 785, 8526, 5473, 51102], "temperature": 0.0, "avg_logprob": -0.30278780619303386, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.0035167739260941744}, {"id": 321, "seek": 202236, "start": 2037.12, "end": 2047.6799999999998, "text": " n por sumatoria nn y subitecho menos y sub\u00ed al cuadrado bien y voy a encontrar el argmin en", "tokens": [51102, 297, 1515, 2408, 1639, 654, 297, 77, 288, 1422, 642, 5738, 8902, 288, 1422, 870, 419, 34434, 14974, 3610, 288, 7552, 257, 17525, 806, 3882, 2367, 465, 51630], "temperature": 0.0, "avg_logprob": -0.30278780619303386, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.0035167739260941744}, {"id": 322, "seek": 204768, "start": 2047.68, "end": 2057.16, "text": " w o sea lo que est\u00e1 ac\u00e1 dentro que es rn de xc w le voy variando estos w hasta que hasta", "tokens": [50364, 261, 277, 4158, 450, 631, 3192, 23496, 10856, 631, 785, 367, 77, 368, 2031, 66, 261, 476, 7552, 3034, 1806, 12585, 261, 10764, 631, 10764, 50838], "temperature": 0.0, "avg_logprob": -0.25262369428362164, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.002228011842817068}, {"id": 323, "seek": 204768, "start": 2057.16, "end": 2066.2000000000003, "text": " encontrar el ideal bien entonces supongamos que tengo una funci\u00f3n as\u00ed no vamos a ver una funci\u00f3n", "tokens": [50838, 17525, 806, 7157, 3610, 13003, 9331, 556, 2151, 631, 13989, 2002, 43735, 8582, 572, 5295, 257, 1306, 2002, 43735, 51290], "temperature": 0.0, "avg_logprob": -0.25262369428362164, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.002228011842817068}, {"id": 324, "seek": 204768, "start": 2066.2000000000003, "end": 2072.84, "text": " bastante simple como para ver c\u00f3mo funciona esto el entrenamiento de una red se da utilizando", "tokens": [51290, 14651, 2199, 2617, 1690, 1306, 12826, 26210, 7433, 806, 45069, 16971, 368, 2002, 2182, 369, 1120, 19906, 1806, 51622], "temperature": 0.0, "avg_logprob": -0.25262369428362164, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.002228011842817068}, {"id": 325, "seek": 207284, "start": 2072.84, "end": 2076.84, "text": " una t\u00e9cnica de llama de senso por gradiente hay otras t\u00e9cnicas pero estas por lejos la m\u00e1s", "tokens": [50364, 2002, 45411, 368, 23272, 368, 3151, 539, 1515, 2771, 8413, 4842, 20244, 25564, 40672, 4768, 13897, 1515, 476, 19136, 635, 3573, 50564], "temperature": 0.0, "avg_logprob": -0.24507599270220884, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.02238798700273037}, {"id": 326, "seek": 207284, "start": 2076.84, "end": 2083.04, "text": " utilizada de todas y la t\u00e9cnica de senso por gradiente funcione la ciente manera si yo tuviera una", "tokens": [50564, 19906, 1538, 368, 10906, 288, 635, 45411, 368, 3151, 539, 1515, 2771, 8413, 1019, 66, 5328, 635, 269, 8413, 13913, 1511, 5290, 38177, 10609, 2002, 50874], "temperature": 0.0, "avg_logprob": -0.24507599270220884, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.02238798700273037}, {"id": 327, "seek": 207284, "start": 2083.04, "end": 2088.08, "text": " funci\u00f3n que va solamente en una dimensi\u00f3n y quiero minimizarla y arranco con un punto por ac\u00e1", "tokens": [50874, 43735, 631, 2773, 27814, 465, 2002, 5013, 694, 2560, 288, 16811, 4464, 9736, 875, 288, 50235, 1291, 416, 517, 14326, 1515, 23496, 51126], "temperature": 0.0, "avg_logprob": -0.24507599270220884, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.02238798700273037}, {"id": 328, "seek": 207284, "start": 2088.08, "end": 2094.04, "text": " digo bueno mi peso inicial me dice que voy a terminar en este lado entonces yo puedo calcular", "tokens": [51126, 22990, 11974, 2752, 28149, 44076, 385, 10313, 631, 7552, 257, 36246, 465, 4065, 11631, 13003, 5290, 21612, 2104, 17792, 51424], "temperature": 0.0, "avg_logprob": -0.24507599270220884, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.02238798700273037}, {"id": 329, "seek": 209404, "start": 2094.7599999999998, "end": 2103.0, "text": " la derivada en ese lado y decir bueno para aquel lado voy bajando mi funci\u00f3n de costo o sea", "tokens": [50400, 635, 10151, 1538, 465, 10167, 11631, 288, 10235, 11974, 1690, 2373, 338, 11631, 7552, 23589, 1806, 2752, 43735, 368, 2063, 78, 277, 4158, 50812], "temperature": 0.0, "avg_logprob": -0.19694586626188024, "compression_ratio": 2.074235807860262, "no_speech_prob": 0.013473166152834892}, {"id": 330, "seek": 209404, "start": 2103.0, "end": 2107.6, "text": " suponiendo que esta es la funci\u00f3n de p\u00e9rdida o funci\u00f3n de costo puedo decir para aquel lado", "tokens": [50812, 9331, 266, 7304, 631, 5283, 785, 635, 43735, 368, 280, 4198, 67, 2887, 277, 43735, 368, 2063, 78, 21612, 10235, 1690, 2373, 338, 11631, 51042], "temperature": 0.0, "avg_logprob": -0.19694586626188024, "compression_ratio": 2.074235807860262, "no_speech_prob": 0.013473166152834892}, {"id": 331, "seek": 209404, "start": 2107.6, "end": 2112.2799999999997, "text": " voy bajando mi funci\u00f3n de p\u00e9rdida y dice bueno lo voy bajando si bajo por esta dimensi\u00f3n si", "tokens": [51042, 7552, 23589, 1806, 2752, 43735, 368, 280, 4198, 67, 2887, 288, 10313, 11974, 450, 7552, 23589, 1806, 1511, 30139, 1515, 5283, 5013, 694, 2560, 1511, 51276], "temperature": 0.0, "avg_logprob": -0.19694586626188024, "compression_ratio": 2.074235807860262, "no_speech_prob": 0.013473166152834892}, {"id": 332, "seek": 209404, "start": 2112.2799999999997, "end": 2117.64, "text": " bajo por esta direcci\u00f3n entonces ah\u00ed le digo bueno baja un poquito por ah\u00ed y calculame otro", "tokens": [51276, 30139, 1515, 5283, 1264, 14735, 13003, 12571, 476, 22990, 11974, 49427, 517, 28229, 1515, 12571, 288, 4322, 529, 11921, 51544], "temperature": 0.0, "avg_logprob": -0.19694586626188024, "compression_ratio": 2.074235807860262, "no_speech_prob": 0.013473166152834892}, {"id": 333, "seek": 209404, "start": 2117.64, "end": 2121.64, "text": " valor que va a estar ac\u00e1 y ah\u00ed devuelta voy a calcular la derivada y digo bueno en qu\u00e9 sentido", "tokens": [51544, 15367, 631, 2773, 257, 8755, 23496, 288, 12571, 1905, 3483, 1328, 7552, 257, 2104, 17792, 635, 10151, 1538, 288, 22990, 11974, 465, 8057, 19850, 51744], "temperature": 0.0, "avg_logprob": -0.19694586626188024, "compression_ratio": 2.074235807860262, "no_speech_prob": 0.013473166152834892}, {"id": 334, "seek": 212164, "start": 2121.64, "end": 2125.66, "text": " voy bajando y se voy bajando si voy para all\u00e1 entonces ah\u00ed me encuentro tu valor que este", "tokens": [50364, 7552, 23589, 1806, 288, 369, 7552, 23589, 1806, 1511, 7552, 1690, 30642, 13003, 12571, 385, 23708, 340, 2604, 15367, 631, 4065, 50565], "temperature": 0.0, "avg_logprob": -0.2384811706542969, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0018947981297969818}, {"id": 335, "seek": 212164, "start": 2125.66, "end": 2130.64, "text": " en esa direcci\u00f3n calculo de vuelta la derivada y as\u00ed o sea yo puedo ir iterando de esta manera", "tokens": [50565, 465, 11342, 1264, 14735, 4322, 78, 368, 41542, 635, 10151, 1538, 288, 8582, 277, 4158, 5290, 21612, 3418, 17138, 1806, 368, 5283, 13913, 50814], "temperature": 0.0, "avg_logprob": -0.2384811706542969, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0018947981297969818}, {"id": 336, "seek": 212164, "start": 2130.64, "end": 2137.16, "text": " hasta llegar a un m\u00ednimo bien eso me llama de senso por gradiente porque yo tengo quiero encontrar", "tokens": [50814, 10764, 24892, 257, 517, 47393, 3610, 7287, 385, 23272, 368, 3151, 539, 1515, 2771, 8413, 4021, 5290, 13989, 16811, 17525, 51140], "temperature": 0.0, "avg_logprob": -0.2384811706542969, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0018947981297969818}, {"id": 337, "seek": 212164, "start": 2137.16, "end": 2143.44, "text": " el m\u00ednimo de una funci\u00f3n supongamos que esta es mi funci\u00f3n de p\u00e9rdida y empec\u00e9 teniendo este", "tokens": [51140, 806, 47393, 368, 2002, 43735, 9331, 556, 2151, 631, 5283, 785, 2752, 43735, 368, 280, 4198, 67, 2887, 288, 846, 494, 13523, 2064, 7304, 4065, 51454], "temperature": 0.0, "avg_logprob": -0.2384811706542969, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0018947981297969818}, {"id": 338, "seek": 212164, "start": 2143.44, "end": 2149.08, "text": " valor calculo donde est\u00e1 la direcci\u00f3n en la cual puedo bajar m\u00e1s y voy movi\u00e9ndome por ah\u00ed hasta", "tokens": [51454, 15367, 4322, 78, 10488, 3192, 635, 1264, 14735, 465, 635, 10911, 21612, 23589, 289, 3573, 288, 7552, 2402, 72, 34577, 423, 1515, 12571, 10764, 51736], "temperature": 0.0, "avg_logprob": -0.2384811706542969, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0018947981297969818}, {"id": 339, "seek": 214908, "start": 2149.08, "end": 2156.6, "text": " llegar al punto bajo esto es un caso ideal en el cual yo tengo una sola variable que estoy tratando", "tokens": [50364, 24892, 419, 14326, 30139, 7433, 785, 517, 9666, 7157, 465, 806, 10911, 5290, 13989, 2002, 34162, 7006, 631, 15796, 21507, 1806, 50740], "temperature": 0.0, "avg_logprob": -0.2064113188325689, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002583811292424798}, {"id": 340, "seek": 214908, "start": 2156.6, "end": 2163.72, "text": " de encontrar en el caso real yo estoy minimizando digamos minimizando esta funci\u00f3n respecto a", "tokens": [50740, 368, 17525, 465, 806, 9666, 957, 5290, 15796, 4464, 590, 1806, 36430, 4464, 590, 1806, 5283, 43735, 35694, 257, 51096], "temperature": 0.0, "avg_logprob": -0.2064113188325689, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002583811292424798}, {"id": 341, "seek": 214908, "start": 2163.72, "end": 2168.64, "text": " W que es una cosa que son muchas matrices con muchos pesos con muchas cosas y pueden llegar a", "tokens": [51096, 343, 631, 785, 2002, 10163, 631, 1872, 16072, 32284, 416, 17061, 33204, 416, 16072, 12218, 288, 14714, 24892, 257, 51342], "temperature": 0.0, "avg_logprob": -0.2064113188325689, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002583811292424798}, {"id": 342, "seek": 214908, "start": 2168.64, "end": 2176.7999999999997, "text": " hacer miles de millones de pesos pero bueno en un caso ideal si yo estuviera solamente minimizando", "tokens": [51342, 6720, 6193, 368, 22416, 368, 33204, 4768, 11974, 465, 517, 9666, 7157, 1511, 5290, 49777, 10609, 27814, 4464, 590, 1806, 51750], "temperature": 0.0, "avg_logprob": -0.2064113188325689, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.002583811292424798}, {"id": 343, "seek": 217680, "start": 2176.8, "end": 2181.48, "text": " una sever\u00eda de esta manera cuando yo estoy minimizando millones de variables a la vez lo que pasa", "tokens": [50364, 2002, 2802, 2686, 368, 5283, 13913, 7767, 5290, 15796, 4464, 590, 1806, 22416, 368, 9102, 257, 635, 5715, 450, 631, 20260, 50598], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 344, "seek": 217680, "start": 2181.48, "end": 2185.5600000000004, "text": " es que esta superficie digamos lo que tengo ac\u00e1 no va a ser una curva tan linda sino que va a ser", "tokens": [50598, 785, 631, 5283, 23881, 414, 36430, 450, 631, 13989, 23496, 572, 2773, 257, 816, 2002, 1262, 2757, 7603, 287, 6837, 18108, 631, 2773, 257, 816, 50802], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 345, "seek": 217680, "start": 2185.5600000000004, "end": 2190.96, "text": " una superficie rusa que tiene un mont\u00f3n de de de \u00f3ptimos locales que no me van a servir pero", "tokens": [50802, 2002, 23881, 414, 367, 20318, 631, 7066, 517, 45259, 368, 368, 368, 11857, 662, 8372, 2654, 279, 631, 572, 385, 3161, 257, 29463, 4768, 51072], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 346, "seek": 217680, "start": 2190.96, "end": 2194.5600000000004, "text": " cuando yo hago este algoritmo lo que va a hacer es caerse en un \u00f3ptimo local imag\u00ednense que si", "tokens": [51072, 7767, 5290, 38721, 4065, 3501, 50017, 3280, 450, 631, 2773, 257, 6720, 785, 1335, 260, 405, 465, 517, 11857, 662, 6934, 2654, 2576, 10973, 1288, 631, 1511, 51252], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 347, "seek": 217680, "start": 2194.5600000000004, "end": 2200.44, "text": " esta curva tuviera esta forma entonces este algoritmo llegar\u00eda a un \u00f3ptimo local por ac\u00e1 pero", "tokens": [51252, 5283, 1262, 2757, 38177, 10609, 5283, 8366, 13003, 4065, 3501, 50017, 3280, 24892, 2686, 257, 517, 11857, 662, 6934, 2654, 1515, 23496, 4768, 51546], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 348, "seek": 217680, "start": 2200.44, "end": 2205.5600000000004, "text": " se perder\u00eda el \u00f3ptimo global que estaba por ac\u00e1 bien eso es algo que puede pasar entonces bueno", "tokens": [51546, 369, 26971, 2686, 806, 11857, 662, 6934, 4338, 631, 17544, 1515, 23496, 3610, 7287, 785, 8655, 631, 8919, 25344, 13003, 11974, 51802], "temperature": 0.0, "avg_logprob": -0.18145484924316407, "compression_ratio": 2.0103092783505154, "no_speech_prob": 0.0015699169598519802}, {"id": 349, "seek": 220556, "start": 2205.56, "end": 2209.88, "text": " no se asusten que cuando uno entra en una rena uronal nunca va a estar seguro de que encontr\u00e9 el", "tokens": [50364, 572, 369, 382, 381, 268, 631, 7767, 8526, 22284, 465, 2002, 319, 629, 4038, 21523, 13768, 2773, 257, 8755, 31424, 368, 631, 10176, 10521, 806, 50580], "temperature": 0.0, "avg_logprob": -0.2493570799468666, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.0034316405653953552}, {"id": 350, "seek": 220556, "start": 2209.88, "end": 2214.64, "text": " \u00f3ptimo posible de toda la red de todas las posibles sino que bueno tengo que conformarme con encontrar", "tokens": [50580, 11857, 662, 6934, 26644, 368, 11687, 635, 2182, 368, 10906, 2439, 1366, 14428, 18108, 631, 11974, 13989, 631, 18975, 35890, 416, 17525, 50818], "temperature": 0.0, "avg_logprob": -0.2493570799468666, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.0034316405653953552}, {"id": 351, "seek": 220556, "start": 2214.64, "end": 2221.36, "text": " una bastante buena probando varias veces bueno entonces dec\u00edamos esto sobre entrenamiento", "tokens": [50818, 2002, 14651, 25710, 1239, 1806, 37496, 17054, 11974, 13003, 979, 16275, 7433, 5473, 45069, 16971, 51154], "temperature": 0.0, "avg_logprob": -0.2493570799468666, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.0034316405653953552}, {"id": 352, "seek": 220556, "start": 2225.2, "end": 2230.64, "text": " el entrenamiento intenta encontrar los pesos que minimizan esta funci\u00f3n de perdiado o sea la", "tokens": [51346, 806, 45069, 16971, 8446, 64, 17525, 1750, 33204, 631, 4464, 590, 282, 5283, 43735, 368, 680, 4504, 1573, 277, 4158, 635, 51618], "temperature": 0.0, "avg_logprob": -0.2493570799468666, "compression_ratio": 1.7545454545454546, "no_speech_prob": 0.0034316405653953552}, {"id": 353, "seek": 223064, "start": 2230.64, "end": 2238.16, "text": " combinaci\u00f3n de matricios olv que hace que esta funci\u00f3n sea lo menor posible la t\u00e9cnica se utiliza", "tokens": [50364, 38514, 3482, 368, 3803, 1341, 2717, 2545, 85, 631, 10032, 631, 5283, 43735, 4158, 450, 26343, 26644, 635, 45411, 369, 4976, 13427, 50740], "temperature": 0.0, "avg_logprob": -0.327432781457901, "compression_ratio": 1.9147286821705427, "no_speech_prob": 0.0029651904478669167}, {"id": 354, "seek": 223064, "start": 2238.16, "end": 2243.48, "text": " el senso por gradiente que es lo que est\u00e1 mencionando ac\u00e1 se usa una cosa de llamas de senso por", "tokens": [50740, 806, 3151, 539, 1515, 2771, 8413, 631, 785, 450, 631, 3192, 37030, 1806, 23496, 369, 29909, 2002, 10163, 368, 16848, 296, 368, 3151, 539, 1515, 51006], "temperature": 0.0, "avg_logprob": -0.327432781457901, "compression_ratio": 1.9147286821705427, "no_speech_prob": 0.0029651904478669167}, {"id": 355, "seek": 223064, "start": 2243.48, "end": 2250.24, "text": " dancias estoc\u00e1stico que se trata de agarrar cada punto yo agarr\u00f3 cada punto de entrada y", "tokens": [51006, 3277, 12046, 871, 905, 44855, 631, 369, 31920, 368, 623, 2284, 289, 8411, 14326, 5290, 623, 2284, 812, 8411, 14326, 368, 37119, 288, 51344], "temperature": 0.0, "avg_logprob": -0.327432781457901, "compression_ratio": 1.9147286821705427, "no_speech_prob": 0.0029651904478669167}, {"id": 356, "seek": 223064, "start": 2250.24, "end": 2254.44, "text": " trato de hacer el senso por gradiente consiguiendo solamente ese punto y despu\u00e9s agarr\u00f3 otro punto de", "tokens": [51344, 504, 2513, 368, 6720, 806, 3151, 539, 1515, 2771, 8413, 1014, 16397, 7304, 27814, 10167, 14326, 288, 15283, 623, 2284, 812, 11921, 14326, 368, 51554], "temperature": 0.0, "avg_logprob": -0.327432781457901, "compression_ratio": 1.9147286821705427, "no_speech_prob": 0.0029651904478669167}, {"id": 357, "seek": 223064, "start": 2254.44, "end": 2259.12, "text": " entrada y luego varias veces el problema que tiene eso es que es superlento o sea es como que tiene", "tokens": [51554, 37119, 288, 17222, 37496, 17054, 806, 12395, 631, 7066, 7287, 785, 631, 785, 1687, 75, 15467, 277, 4158, 785, 2617, 631, 7066, 51788], "temperature": 0.0, "avg_logprob": -0.327432781457901, "compression_ratio": 1.9147286821705427, "no_speech_prob": 0.0029651904478669167}, {"id": 358, "seek": 225912, "start": 2259.12, "end": 2263.2799999999997, "text": " buena propiedad de convergencia pero es superlento entonces lo que se hace es hacer de senso por gradiente", "tokens": [50364, 25710, 2365, 1091, 345, 368, 9652, 1766, 2755, 4768, 785, 1687, 75, 15467, 13003, 450, 631, 369, 10032, 785, 6720, 368, 3151, 539, 1515, 2771, 8413, 50572], "temperature": 0.0, "avg_logprob": -0.2783276117764987, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0006121441256254911}, {"id": 359, "seek": 225912, "start": 2264.2799999999997, "end": 2271.04, "text": " en lote o en batches que significa bueno en vez de tomar todo el conjunto de entrenamiento que", "tokens": [50622, 465, 688, 68, 277, 465, 15245, 279, 631, 19957, 11974, 465, 5715, 368, 22048, 5149, 806, 37776, 368, 45069, 16971, 631, 50960], "temperature": 0.0, "avg_logprob": -0.2783276117764987, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0006121441256254911}, {"id": 360, "seek": 225912, "start": 2271.04, "end": 2277.3599999999997, "text": " puede tener 100 mil millones de ejemplos tomo de a 120 o no s\u00e9 200 o elijo un batch que digo bueno", "tokens": [50960, 8919, 11640, 2319, 1962, 22416, 368, 10012, 5895, 329, 2916, 78, 368, 257, 10411, 277, 572, 7910, 2331, 277, 806, 24510, 517, 15245, 631, 22990, 11974, 51276], "temperature": 0.0, "avg_logprob": -0.2783276117764987, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0006121441256254911}, {"id": 361, "seek": 225912, "start": 2277.3599999999997, "end": 2281.12, "text": " tomo este conjunto de ejemplos y hago de senso por ah\u00ed despu\u00e9s tomo otro conjunto de", "tokens": [51276, 2916, 78, 4065, 37776, 368, 10012, 5895, 329, 288, 38721, 368, 3151, 539, 1515, 12571, 15283, 2916, 78, 11921, 37776, 368, 51464], "temperature": 0.0, "avg_logprob": -0.2783276117764987, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.0006121441256254911}, {"id": 362, "seek": 228112, "start": 2281.8399999999997, "end": 2292.12, "text": " senso por la gente por ah\u00ed y hasta llegar a un \u00f3ptimo bien los siguientes backpropagation entonces", "tokens": [50400, 3151, 539, 1515, 635, 3788, 1515, 12571, 288, 10764, 24892, 257, 517, 11857, 662, 6934, 3610, 1750, 21152, 20135, 646, 79, 1513, 559, 399, 13003, 50914], "temperature": 0.0, "avg_logprob": -0.24092065911543997, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.000474966800538823}, {"id": 363, "seek": 228112, "start": 2292.12, "end": 2299.3199999999997, "text": " yo les dije hasta ahora que todas las cosas ten\u00edan que ser derivables y el hecho de que sean", "tokens": [50914, 5290, 1512, 39414, 10764, 9923, 631, 10906, 2439, 12218, 47596, 631, 816, 10151, 2965, 288, 806, 13064, 368, 631, 37670, 51274], "temperature": 0.0, "avg_logprob": -0.24092065911543997, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.000474966800538823}, {"id": 364, "seek": 228112, "start": 2299.3199999999997, "end": 2303.3199999999997, "text": " derivables implica que lo vamos a derivar en alg\u00fan momento no vamos a hacer ac\u00e1 ninguna derivada", "tokens": [51274, 10151, 2965, 8484, 2262, 631, 450, 5295, 257, 10151, 289, 465, 26300, 9333, 572, 5295, 257, 6720, 23496, 36073, 10151, 1538, 51474], "temperature": 0.0, "avg_logprob": -0.24092065911543997, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.000474966800538823}, {"id": 365, "seek": 228112, "start": 2303.3199999999997, "end": 2308.8399999999997, "text": " digamos porque en realidad los paquetes que se utilizan para trabajar con estas con estas cosas", "tokens": [51474, 36430, 4021, 465, 25635, 1750, 2502, 19343, 279, 631, 369, 19906, 282, 1690, 30793, 416, 13897, 416, 13897, 12218, 51750], "temperature": 0.0, "avg_logprob": -0.24092065911543997, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.000474966800538823}, {"id": 366, "seek": 230884, "start": 2308.84, "end": 2313.1600000000003, "text": " en realidad son paquetes que permiten hacer derivaci\u00f3n autom\u00e1tica o sea toda la gracia de construir", "tokens": [50364, 465, 25635, 1872, 2502, 19343, 279, 631, 13423, 268, 6720, 10151, 3482, 3553, 23432, 277, 4158, 11687, 635, 11625, 654, 368, 38445, 50580], "temperature": 0.0, "avg_logprob": -0.2371022878599561, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.002075732219964266}, {"id": 367, "seek": 230884, "start": 2313.1600000000003, "end": 2317.8, "text": " redes neuronales utilizando ciertas librer\u00edas es que las librer\u00edas permiten definir todas estas", "tokens": [50580, 16762, 34090, 4229, 19906, 1806, 49252, 296, 4939, 260, 10025, 785, 631, 2439, 4939, 260, 10025, 13423, 268, 1561, 347, 10906, 13897, 50812], "temperature": 0.0, "avg_logprob": -0.2371022878599561, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.002075732219964266}, {"id": 368, "seek": 230884, "start": 2317.8, "end": 2321.6400000000003, "text": " cosas como vectores y despu\u00e9s ellos hacen las derivadas autom\u00e1ticamente calculan todo autom\u00e1ticamente", "tokens": [50812, 12218, 2617, 1241, 349, 2706, 288, 15283, 16353, 27434, 2439, 10151, 6872, 3553, 7656, 23653, 4322, 282, 5149, 3553, 7656, 23653, 51004], "temperature": 0.0, "avg_logprob": -0.2371022878599561, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.002075732219964266}, {"id": 369, "seek": 230884, "start": 2321.6400000000003, "end": 2328.0, "text": " pero en definitiva la t\u00e9cnica que se usa para calcular se llama propiedad que implica que cuando", "tokens": [51004, 4768, 465, 28781, 5931, 635, 45411, 631, 369, 29909, 1690, 2104, 17792, 369, 23272, 2365, 1091, 345, 631, 8484, 2262, 631, 7767, 51322], "temperature": 0.0, "avg_logprob": -0.2371022878599561, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.002075732219964266}, {"id": 370, "seek": 230884, "start": 2328.0, "end": 2334.0, "text": " yo voy calculando los pesos de una red para los valores de una red yo digo el lo que tornen", "tokens": [51322, 5290, 7552, 4322, 1806, 1750, 33204, 368, 2002, 2182, 1690, 1750, 38790, 368, 2002, 2182, 5290, 22990, 806, 450, 631, 3930, 2866, 51622], "temperature": 0.0, "avg_logprob": -0.2371022878599561, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.002075732219964266}, {"id": 371, "seek": 233400, "start": 2334.72, "end": 2338.96, "text": " lo multiplico por del V despu\u00e9s le paso la funci\u00f3n de activaci\u00f3n lo multiplico por otra V", "tokens": [50400, 450, 12788, 2789, 1515, 1103, 691, 15283, 476, 29212, 635, 43735, 368, 2430, 3482, 450, 12788, 2789, 1515, 13623, 691, 50612], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 372, "seek": 233400, "start": 2338.96, "end": 2343.12, "text": " le paso la funci\u00f3n de activaci\u00f3n a medida que voy calculando eso voy dejando como todos los", "tokens": [50612, 476, 29212, 635, 43735, 368, 2430, 3482, 257, 32984, 631, 7552, 2104, 2444, 1806, 7287, 7552, 21259, 1806, 2617, 6321, 1750, 50820], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 373, "seek": 233400, "start": 2343.12, "end": 2348.76, "text": " valores intermedios esos valores se usan de atr\u00e1s para adelante por el llamado propiedad", "tokens": [50820, 38790, 728, 1912, 2717, 22411, 38790, 369, 505, 282, 368, 22906, 1690, 40214, 1515, 806, 47055, 2365, 1091, 345, 51102], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 374, "seek": 233400, "start": 2348.76, "end": 2353.4, "text": " y son para calcular las derivadas porque en realidad todos los valores de sumas multiplicaciones", "tokens": [51102, 288, 1872, 1690, 2104, 17792, 2439, 10151, 6872, 4021, 465, 25635, 6321, 1750, 38790, 368, 2408, 296, 17596, 9188, 51334], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 375, "seek": 233400, "start": 2353.4, "end": 2357.16, "text": " etc\u00e9tera que yo fui dejando el medio se utilizan como que siempre calculan para despu\u00e9s", "tokens": [51334, 5183, 526, 23833, 631, 5290, 27863, 21259, 1806, 806, 22123, 369, 19906, 282, 2617, 631, 12758, 4322, 282, 1690, 15283, 51522], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 376, "seek": 233400, "start": 2357.16, "end": 2361.56, "text": " calcular la derivada y el vaculopadillo es una t\u00e9cnica que me ayuda a hacer eso r\u00e1pidamente", "tokens": [51522, 2104, 17792, 635, 10151, 1538, 288, 806, 2773, 2444, 404, 345, 15831, 785, 2002, 45411, 631, 385, 30737, 257, 6720, 7287, 18213, 49663, 51742], "temperature": 0.0, "avg_logprob": -0.32669863981359143, "compression_ratio": 1.9822064056939501, "no_speech_prob": 0.013406593352556229}, {"id": 377, "seek": 236156, "start": 2362.56, "end": 2367.88, "text": " bien entonces esta es la pregunta que le dec\u00eda hoy yo puedo encontrar la mejor funci\u00f3n posible", "tokens": [50414, 3610, 13003, 5283, 785, 635, 24252, 631, 476, 37599, 13775, 5290, 21612, 17525, 635, 11479, 43735, 26644, 50680], "temperature": 0.0, "avg_logprob": -0.2398322896754488, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.007138556335121393}, {"id": 378, "seek": 236156, "start": 2367.88, "end": 2373.96, "text": " puedo contar la mejor reneuronal que explique mi problema 100% bien la verdad que no porque en general", "tokens": [50680, 21612, 27045, 635, 11479, 319, 716, 374, 21523, 631, 1490, 1925, 2752, 12395, 2319, 4, 3610, 635, 13692, 631, 572, 4021, 465, 2674, 50984], "temperature": 0.0, "avg_logprob": -0.2398322896754488, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.007138556335121393}, {"id": 379, "seek": 236156, "start": 2373.96, "end": 2380.16, "text": " este proceso se cae en \u00f3ptimos locales y este tipo de funciones que tienen miles de millones", "tokens": [50984, 4065, 29314, 369, 1335, 68, 465, 11857, 662, 8372, 2654, 279, 288, 4065, 9746, 368, 1019, 23469, 631, 12536, 6193, 368, 22416, 51294], "temperature": 0.0, "avg_logprob": -0.2398322896754488, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.007138556335121393}, {"id": 380, "seek": 236156, "start": 2380.16, "end": 2385.88, "text": " de par\u00e1metros lo que pasa que tiene much\u00edsimos \u00faltimos locales y bueno el entrenamiento se va a", "tokens": [51294, 368, 971, 842, 29570, 450, 631, 20260, 631, 7066, 29353, 8372, 33013, 2654, 279, 288, 11974, 806, 45069, 16971, 369, 2773, 257, 51580], "temperature": 0.0, "avg_logprob": -0.2398322896754488, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.007138556335121393}, {"id": 381, "seek": 238588, "start": 2385.88, "end": 2391.2400000000002, "text": " caer siempre en un \u00f3ptimo local lo que no hace para evitar eso de alguna manera es por ejemplo", "tokens": [50364, 1335, 260, 12758, 465, 517, 11857, 662, 6934, 2654, 450, 631, 572, 10032, 1690, 31326, 7287, 368, 20651, 13913, 785, 1515, 13358, 50632], "temperature": 0.0, "avg_logprob": -0.24897003173828125, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.003139680717140436}, {"id": 382, "seek": 238588, "start": 2391.2400000000002, "end": 2395.36, "text": " entrenar varias veces una misma red diciendo bueno tengo una misma r\u00e9cola, los mismos par\u00e1metros", "tokens": [50632, 45069, 289, 37496, 17054, 2002, 24946, 2182, 42797, 11974, 13989, 2002, 24946, 3960, 66, 4711, 11, 1750, 47458, 971, 842, 29570, 50838], "temperature": 0.0, "avg_logprob": -0.24897003173828125, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.003139680717140436}, {"id": 383, "seek": 238588, "start": 2395.36, "end": 2399.44, "text": " le entren\u00f3 muchas veces y veo cual cual le fue mejor de todos los entrenamientos esa es una de", "tokens": [50838, 476, 45069, 812, 16072, 17054, 288, 41319, 10911, 10911, 476, 9248, 11479, 368, 6321, 1750, 45069, 43466, 11342, 785, 2002, 368, 51042], "temperature": 0.0, "avg_logprob": -0.24897003173828125, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.003139680717140436}, {"id": 384, "seek": 238588, "start": 2399.44, "end": 2405.6400000000003, "text": " las formas y el otro problema detiene es el sobre ajuste creo que no lo mencionamos en la", "tokens": [51042, 2439, 33463, 288, 806, 11921, 12395, 1141, 10174, 785, 806, 5473, 41023, 68, 14336, 631, 572, 450, 37030, 2151, 465, 635, 51352], "temperature": 0.0, "avg_logprob": -0.24897003173828125, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.003139680717140436}, {"id": 385, "seek": 238588, "start": 2405.6400000000003, "end": 2411.12, "text": " clase anterior sobre ajuste significa que las reneuronales tienen un problema que lo tienen", "tokens": [51352, 44578, 22272, 5473, 41023, 68, 19957, 631, 2439, 319, 716, 374, 21523, 279, 12536, 517, 12395, 631, 450, 12536, 51626], "temperature": 0.0, "avg_logprob": -0.24897003173828125, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.003139680717140436}, {"id": 386, "seek": 241112, "start": 2411.12, "end": 2415.92, "text": " otro m\u00e9todo de clasificaci\u00f3n pero las reneuronales es en particular porque como que son muy", "tokens": [50364, 11921, 20275, 17423, 368, 596, 296, 40802, 4768, 2439, 319, 716, 374, 21523, 279, 785, 465, 1729, 4021, 2617, 631, 1872, 5323, 50604], "temperature": 0.0, "avg_logprob": -0.24247732758522034, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.011350465007126331}, {"id": 387, "seek": 241112, "start": 2415.92, "end": 2420.48, "text": " vers\u00e1tiles y es que se pueden aprender muy f\u00e1cil todo el conjunto de entrenamiento yo puedo", "tokens": [50604, 1774, 7656, 4680, 288, 785, 631, 369, 14714, 24916, 5323, 17474, 5149, 806, 37776, 368, 45069, 16971, 5290, 21612, 50832], "temperature": 0.0, "avg_logprob": -0.24247732758522034, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.011350465007126331}, {"id": 388, "seek": 241112, "start": 2420.48, "end": 2424.88, "text": " entrenar una red que se aprenda muy bien en conjunto de entrenamiento y me diga s\u00ed para este X le", "tokens": [50832, 45069, 289, 2002, 2182, 631, 369, 21003, 64, 5323, 3610, 465, 37776, 368, 45069, 16971, 288, 385, 2528, 64, 8600, 1690, 4065, 1783, 476, 51052], "temperature": 0.0, "avg_logprob": -0.24247732758522034, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.011350465007126331}, {"id": 389, "seek": 241112, "start": 2424.88, "end": 2430.52, "text": " corresponde este I y anda b\u00e1rbaro y el la funci\u00f3n de los vea casi cero y sin embargo lo pruebo en", "tokens": [51052, 6805, 68, 4065, 286, 288, 21851, 272, 20335, 5356, 78, 288, 806, 635, 43735, 368, 1750, 1241, 64, 22567, 269, 2032, 288, 3343, 23955, 450, 32820, 1763, 465, 51334], "temperature": 0.0, "avg_logprob": -0.24247732758522034, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.011350465007126331}, {"id": 390, "seek": 241112, "start": 2430.52, "end": 2436.7999999999997, "text": " conjunto de test y le va horrible y eso es muy f\u00e1cil porque como les dec\u00eda como las reneuronales", "tokens": [51334, 37776, 368, 1500, 288, 476, 2773, 9263, 288, 7287, 785, 5323, 17474, 4021, 2617, 1512, 37599, 2617, 2439, 319, 716, 374, 21523, 279, 51648], "temperature": 0.0, "avg_logprob": -0.24247732758522034, "compression_ratio": 1.8582375478927202, "no_speech_prob": 0.011350465007126331}, {"id": 391, "seek": 243680, "start": 2436.8, "end": 2440.2000000000003, "text": " pueden modelar cualquier tipo de funci\u00f3n entonces es muy f\u00e1cil que se aprendan todo el conjunto", "tokens": [50364, 14714, 2316, 289, 21004, 9746, 368, 43735, 13003, 785, 5323, 17474, 631, 369, 21003, 282, 5149, 806, 37776, 50534], "temperature": 0.0, "avg_logprob": -0.22997105776608645, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.019062917679548264}, {"id": 392, "seek": 243680, "start": 2440.2000000000003, "end": 2445.48, "text": " de entrenamiento y despu\u00e9s para el conjunto de tele vaya espantoso ese ese fen\u00f3meno se llama", "tokens": [50534, 368, 45069, 16971, 288, 15283, 1690, 806, 37776, 368, 4304, 47682, 7089, 394, 9869, 10167, 10167, 26830, 812, 43232, 369, 23272, 50798], "temperature": 0.0, "avg_logprob": -0.22997105776608645, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.019062917679548264}, {"id": 393, "seek": 243680, "start": 2445.48, "end": 2450.0800000000004, "text": " sobre ajuste entonces bueno hay como distintas t\u00e9cnicas para tratar de evitarlo y que la red no", "tokens": [50798, 5473, 41023, 68, 13003, 11974, 4842, 2617, 31489, 296, 25564, 40672, 1690, 42549, 368, 31326, 752, 288, 631, 635, 2182, 572, 51028], "temperature": 0.0, "avg_logprob": -0.22997105776608645, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.019062917679548264}, {"id": 394, "seek": 243680, "start": 2450.0800000000004, "end": 2458.6400000000003, "text": " digamos no sea ajustes a los datos sino que se va a generalizar m\u00e1s etc\u00e9tera bien entonces s\u00ed", "tokens": [51028, 36430, 572, 4158, 41023, 279, 257, 1750, 27721, 18108, 631, 369, 2773, 257, 2674, 9736, 3573, 5183, 526, 23833, 3610, 13003, 8600, 51456], "temperature": 0.0, "avg_logprob": -0.22997105776608645, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.019062917679548264}, {"id": 395, "seek": 246680, "start": 2466.8, "end": 2475.52, "text": " es una pregunta interesante en realidad hay un conjunto de t\u00e9cnicas que sirven para decir yo", "tokens": [50364, 785, 2002, 24252, 36396, 465, 25635, 4842, 517, 37776, 368, 25564, 40672, 631, 4735, 553, 1690, 10235, 5290, 50800], "temperature": 0.0, "avg_logprob": -0.20400848388671874, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.01950984075665474}, {"id": 396, "seek": 246680, "start": 2475.52, "end": 2481.0800000000004, "text": " puedo entrenar una red con un conjunto de datos m\u00e1s amplio que capaz que no est\u00e1 el todo correcto y", "tokens": [50800, 21612, 45069, 289, 2002, 2182, 416, 517, 37776, 368, 27721, 3573, 9731, 1004, 631, 35453, 631, 572, 3192, 806, 5149, 3006, 78, 288, 51078], "temperature": 0.0, "avg_logprob": -0.20400848388671874, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.01950984075665474}, {"id": 397, "seek": 246680, "start": 2481.0800000000004, "end": 2485.36, "text": " despu\u00e9s una vez que tengo una red de entrenada la entreno de vuelta con un conjunto m\u00e1s chico pero", "tokens": [51078, 15283, 2002, 5715, 631, 13989, 2002, 2182, 368, 45069, 1538, 635, 45069, 78, 368, 41542, 416, 517, 37776, 3573, 417, 2789, 4768, 51292], "temperature": 0.0, "avg_logprob": -0.20400848388671874, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.01950984075665474}, {"id": 398, "seek": 246680, "start": 2485.36, "end": 2490.0800000000004, "text": " que tiene mejor calidad y eso da mejor resultado que entrenarla directamente con el conjunto m\u00e1s chico", "tokens": [51292, 631, 7066, 11479, 42955, 288, 7287, 1120, 11479, 28047, 631, 45069, 34148, 46230, 416, 806, 37776, 3573, 417, 2789, 51528], "temperature": 0.0, "avg_logprob": -0.20400848388671874, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.01950984075665474}, {"id": 399, "seek": 246680, "start": 2490.0800000000004, "end": 2494.8, "text": " o con otro tipo de datos entonces de ah\u00ed hay variante es cierto que una red una vez que ya", "tokens": [51528, 277, 416, 11921, 9746, 368, 27721, 13003, 368, 12571, 4842, 3034, 2879, 785, 28558, 631, 2002, 2182, 2002, 5715, 631, 2478, 51764], "temperature": 0.0, "avg_logprob": -0.20400848388671874, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.01950984075665474}, {"id": 400, "seek": 249480, "start": 2494.8, "end": 2498.7000000000003, "text": " consegu\u00ed los pesos de la red lo puedo seguir entrenando usando otros conjuntos y eso es valido", "tokens": [50364, 12706, 870, 1750, 33204, 368, 635, 2182, 450, 21612, 18584, 45069, 1806, 29798, 16422, 20295, 2760, 329, 288, 7287, 785, 1323, 2925, 50559], "temperature": 0.0, "avg_logprob": -0.33074315388997394, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0013963575474917889}, {"id": 401, "seek": 249480, "start": 2500.7000000000003, "end": 2506.6000000000004, "text": " o sea se usa es una t\u00e9cnica que se usa y est\u00e1 buena porque da buenos resultados bien igual en", "tokens": [50659, 277, 4158, 369, 29909, 785, 2002, 45411, 631, 369, 29909, 288, 3192, 25710, 4021, 1120, 49617, 36796, 3610, 10953, 465, 50954], "temperature": 0.0, "avg_logprob": -0.33074315388997394, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0013963575474917889}, {"id": 402, "seek": 249480, "start": 2506.6000000000004, "end": 2512.2000000000003, "text": " atare de ustedes no s\u00e9 no s\u00e9 si va a la pena hacerlo o sea probablemente si van a entrenar", "tokens": [50954, 412, 543, 368, 17110, 572, 7910, 572, 7910, 1511, 2773, 257, 635, 29222, 32039, 277, 4158, 21759, 4082, 1511, 3161, 257, 45069, 289, 51234], "temperature": 0.0, "avg_logprob": -0.33074315388997394, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0013963575474917889}, {"id": 403, "seek": 249480, "start": 2512.2000000000003, "end": 2516.44, "text": " reneurales lo hacen lo van con los datos que tienen no no creo que sean necesarios a mucha", "tokens": [51234, 319, 716, 1807, 279, 450, 27434, 450, 3161, 416, 1750, 27721, 631, 12536, 572, 572, 14336, 631, 37670, 11909, 9720, 257, 25248, 51446], "temperature": 0.0, "avg_logprob": -0.33074315388997394, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0013963575474917889}, {"id": 404, "seek": 249480, "start": 2516.44, "end": 2523.48, "text": " cosa m\u00e1s pero s\u00ed tratar de ver un poco lo que vamos a ver ahora que hasta ahora vieron que", "tokens": [51446, 10163, 3573, 4768, 8600, 42549, 368, 1306, 517, 10639, 450, 631, 5295, 257, 1306, 9923, 631, 10764, 9923, 371, 14440, 631, 51798], "temperature": 0.0, "avg_logprob": -0.33074315388997394, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0013963575474917889}, {"id": 405, "seek": 252348, "start": 2523.48, "end": 2527.48, "text": " estamos viendo n\u00fameros reales o sea entra a un vector de n\u00fameros reales sal\u00edan n\u00fameros reales", "tokens": [50364, 10382, 34506, 36545, 957, 279, 277, 4158, 22284, 257, 517, 8062, 368, 36545, 957, 279, 1845, 11084, 36545, 957, 279, 50564], "temperature": 0.0, "avg_logprob": -0.3541384008195665, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0012644215021282434}, {"id": 406, "seek": 252348, "start": 2527.48, "end": 2546.32, "text": " vectores de n\u00fameros reales s\u00ed s\u00ed s\u00ed s\u00ed s\u00ed se usan a veces en la pr\u00e1ctica da mejor resultado", "tokens": [50564, 1241, 349, 2706, 368, 36545, 957, 279, 8600, 8600, 8600, 8600, 8600, 369, 505, 282, 257, 17054, 465, 635, 27300, 29041, 1120, 11479, 28047, 51506], "temperature": 0.0, "avg_logprob": -0.3541384008195665, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0012644215021282434}, {"id": 407, "seek": 252348, "start": 2546.32, "end": 2552.36, "text": " probar varias veces y o hacer una prueba digamos tipo grid search en el cual digo tengo tantos", "tokens": [51506, 1239, 289, 37496, 17054, 288, 277, 6720, 2002, 48241, 36430, 9746, 10748, 3164, 465, 806, 10911, 22990, 13989, 12095, 329, 51808], "temperature": 0.0, "avg_logprob": -0.3541384008195665, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0012644215021282434}, {"id": 408, "seek": 255236, "start": 2552.36, "end": 2558.84, "text": " par\u00e1metros y probar con todos o aleatoriamente probar asampliando distintos par\u00e1metros y entrenar es", "tokens": [50364, 971, 842, 29570, 288, 1239, 289, 416, 6321, 277, 6775, 1639, 16855, 1239, 289, 382, 335, 564, 72, 1806, 49337, 971, 842, 29570, 288, 45069, 289, 785, 50688], "temperature": 0.0, "avg_logprob": -0.3435970468724028, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.00805383175611496}, {"id": 409, "seek": 255236, "start": 2558.84, "end": 2563.6, "text": " cierto que tambi\u00e9n se usan meteor\u00edsticas evolutivos y algunas otras para tratar de optimizar la", "tokens": [50688, 28558, 631, 6407, 369, 505, 282, 25313, 19512, 9150, 1073, 2308, 16501, 288, 27316, 20244, 1690, 42549, 368, 5028, 9736, 635, 50926], "temperature": 0.0, "avg_logprob": -0.3435970468724028, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.00805383175611496}, {"id": 410, "seek": 255236, "start": 2563.6, "end": 2569.28, "text": " red pero no s\u00e9 en la pr\u00e1ctica si es que dan tan buenos resultados o simplemente ir probando", "tokens": [50926, 2182, 4768, 572, 7910, 465, 635, 27300, 29041, 1511, 785, 631, 3277, 7603, 49617, 36796, 277, 33190, 3418, 1239, 1806, 51210], "temperature": 0.0, "avg_logprob": -0.3435970468724028, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.00805383175611496}, {"id": 411, "seek": 255236, "start": 2569.28, "end": 2573.92, "text": " con distintas combinaciones andando mejor bueno o general encontrar buenos resultados igual s\u00ed", "tokens": [51210, 416, 31489, 296, 38514, 9188, 293, 1806, 11479, 11974, 277, 2674, 17525, 49617, 36796, 10953, 8600, 51442], "temperature": 0.0, "avg_logprob": -0.3435970468724028, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.00805383175611496}, {"id": 412, "seek": 257392, "start": 2573.92, "end": 2594.52, "text": " s\u00ed s\u00ed s\u00ed bueno claro pero el problema es que la funci\u00f3n de p\u00e9rdida no va a tener un", "tokens": [50364, 8600, 8600, 8600, 11974, 16742, 4768, 806, 12395, 785, 631, 635, 43735, 368, 280, 4198, 67, 2887, 572, 2773, 257, 11640, 517, 51394], "temperature": 0.0, "avg_logprob": -0.3230021233652152, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.005057014524936676}, {"id": 413, "seek": 257392, "start": 2594.52, "end": 2600.08, "text": " \u00f3ptimo global normalmente no va a tener porque la funci\u00f3n de p\u00e9rdida tiene esta cosa en el medio", "tokens": [51394, 11857, 662, 6934, 4338, 38217, 572, 2773, 257, 11640, 4021, 635, 43735, 368, 280, 4198, 67, 2887, 7066, 5283, 10163, 465, 806, 22123, 51672], "temperature": 0.0, "avg_logprob": -0.3230021233652152, "compression_ratio": 1.5798319327731092, "no_speech_prob": 0.005057014524936676}, {"id": 414, "seek": 260008, "start": 2600.64, "end": 2606.96, "text": " no estoy minimizando una cosa que es algo no lineal y que tiene millones de par\u00e1metros y yo", "tokens": [50392, 572, 15796, 4464, 590, 1806, 2002, 10163, 631, 785, 8655, 572, 1622, 304, 288, 631, 7066, 22416, 368, 971, 842, 29570, 288, 5290, 50708], "temperature": 0.0, "avg_logprob": -0.28460066389329364, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.0027691058348864317}, {"id": 415, "seek": 260008, "start": 2606.96, "end": 2610.72, "text": " puedo ir en la direcci\u00f3n de cualquiera de los millones de par\u00e1metros entonces por eso normalmente", "tokens": [50708, 21612, 3418, 465, 635, 1264, 14735, 368, 10911, 35134, 368, 1750, 22416, 368, 971, 842, 29570, 13003, 1515, 7287, 38217, 50896], "temperature": 0.0, "avg_logprob": -0.28460066389329364, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.0027691058348864317}, {"id": 416, "seek": 260008, "start": 2610.72, "end": 2616.16, "text": " digamos eso te genera una superficie super rubosa que tiene un mont\u00f3n de de su d\u00eda as\u00ed bajada por", "tokens": [50896, 36430, 7287, 535, 1337, 64, 2002, 23881, 414, 1687, 5915, 6447, 631, 7066, 517, 45259, 368, 368, 459, 12271, 8582, 23589, 1538, 1515, 51168], "temperature": 0.0, "avg_logprob": -0.28460066389329364, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.0027691058348864317}, {"id": 417, "seek": 260008, "start": 2616.16, "end": 2621.7999999999997, "text": " todos lados y justo en boca la el \u00f3ptimo global es muy dif\u00edcil o sea nada te garantiza que puedas tener", "tokens": [51168, 6321, 40301, 288, 40534, 465, 34624, 635, 806, 11857, 662, 6934, 4338, 785, 5323, 17258, 277, 4158, 8096, 535, 22251, 13427, 631, 10947, 296, 11640, 51450], "temperature": 0.0, "avg_logprob": -0.28460066389329364, "compression_ratio": 1.6906779661016949, "no_speech_prob": 0.0027691058348864317}, {"id": 418, "seek": 262180, "start": 2621.8, "end": 2632.0, "text": " el \u00f3ptimo global claro s\u00ed s\u00ed pero ac\u00e1 queremos esplicitamente que la funci\u00f3n de activaci\u00f3n sea algo", "tokens": [50364, 806, 11857, 662, 6934, 4338, 16742, 8600, 8600, 4768, 23496, 26813, 785, 4770, 270, 3439, 631, 635, 43735, 368, 2430, 3482, 4158, 8655, 50874], "temperature": 0.0, "avg_logprob": -0.18986239378479705, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0015914324903860688}, {"id": 419, "seek": 262180, "start": 2632.0, "end": 2637.88, "text": " que me deje la funci\u00f3n complicada digamos si vos claro si claro si vos hace que la funci\u00f3n", "tokens": [50874, 631, 385, 368, 2884, 635, 43735, 16060, 1538, 36430, 1511, 13845, 16742, 1511, 16742, 1511, 13845, 10032, 631, 635, 43735, 51168], "temperature": 0.0, "avg_logprob": -0.18986239378479705, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0015914324903860688}, {"id": 420, "seek": 262180, "start": 2637.88, "end": 2643.28, "text": " de activaci\u00f3n sea tan simple que esto queda como una funci\u00f3n convexa entonces pierde", "tokens": [51168, 368, 2430, 3482, 4158, 7603, 2199, 631, 7433, 23314, 2617, 2002, 43735, 42432, 64, 13003, 9766, 1479, 51438], "temperature": 0.0, "avg_logprob": -0.18986239378479705, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0015914324903860688}, {"id": 421, "seek": 262180, "start": 2643.28, "end": 2648.76, "text": " capacidad de generalizaci\u00f3n la red por eso se dice tambi\u00e9n que esto es un problema de", "tokens": [51438, 43507, 368, 2674, 27603, 635, 2182, 1515, 7287, 369, 10313, 6407, 631, 7433, 785, 517, 12395, 368, 51712], "temperature": 0.0, "avg_logprob": -0.18986239378479705, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0015914324903860688}, {"id": 422, "seek": 264876, "start": 2648.76, "end": 2653.5200000000004, "text": " optimizaci\u00f3n no convexa entonces en optimizaci\u00f3n convexa uno puede asegurar que siempre tenemos un", "tokens": [50364, 5028, 27603, 572, 42432, 64, 13003, 465, 5028, 27603, 42432, 64, 8526, 8919, 38174, 28586, 631, 12758, 9914, 517, 50602], "temperature": 0.0, "avg_logprob": -0.32494204268496263, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0008276027510873973}, {"id": 423, "seek": 264876, "start": 2653.5200000000004, "end": 2657.1200000000003, "text": " \u00f3ptimo global y lo podr\u00edamos llegar a encontrar con alguna t\u00e9cnica pero esto es la minimizaci\u00f3n no", "tokens": [50602, 11857, 662, 6934, 4338, 288, 450, 15305, 16275, 24892, 257, 17525, 416, 20651, 45411, 4768, 7433, 785, 635, 4464, 27603, 572, 50782], "temperature": 0.0, "avg_logprob": -0.32494204268496263, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0008276027510873973}, {"id": 424, "seek": 264876, "start": 2657.1200000000003, "end": 2661.6000000000004, "text": " convexa la forma de la gr\u00e1fica siempre va a tener subidas y bajadas en alg\u00fan lado", "tokens": [50782, 42432, 64, 635, 8366, 368, 635, 34613, 64, 12758, 2773, 257, 11640, 1422, 11382, 288, 23589, 6872, 465, 26300, 11631, 51006], "temperature": 0.0, "avg_logprob": -0.32494204268496263, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0008276027510873973}, {"id": 425, "seek": 264876, "start": 2664.1600000000003, "end": 2670.92, "text": " bien m\u00e1s preguntas ac\u00e1 entonces pasemos a la parte del lenguaje bien dec\u00edamos hasta el momento", "tokens": [51134, 3610, 3573, 39722, 23496, 13003, 1736, 4485, 257, 635, 6975, 1103, 35044, 84, 11153, 3610, 979, 16275, 10764, 806, 9333, 51472], "temperature": 0.0, "avg_logprob": -0.32494204268496263, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0008276027510873973}, {"id": 426, "seek": 264876, "start": 2671.8, "end": 2678.36, "text": " ten\u00edamos una reneuronal que a la cual le entraban valores reales y sal\u00edan valores reales", "tokens": [51516, 2064, 16275, 2002, 319, 716, 374, 21523, 631, 257, 635, 10911, 476, 948, 424, 5144, 1323, 2706, 957, 279, 288, 1845, 11084, 1323, 2706, 957, 279, 51844], "temperature": 0.0, "avg_logprob": -0.32494204268496263, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0008276027510873973}, {"id": 427, "seek": 267876, "start": 2678.84, "end": 2683.6400000000003, "text": " pero nosotros en realidad nos interesa trabajar con texto nos interesa trabajar con palabras oraciones", "tokens": [50368, 4768, 13863, 465, 25635, 3269, 728, 13708, 30793, 416, 35503, 3269, 728, 13708, 30793, 416, 35240, 420, 9188, 50608], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 428, "seek": 267876, "start": 2683.6400000000003, "end": 2690.7200000000003, "text": " documentos tweets en el caso del oriatorio y el problema de este que tenemos una red que le entra", "tokens": [50608, 4166, 329, 25671, 465, 806, 9666, 1103, 420, 72, 48028, 288, 806, 12395, 368, 4065, 631, 9914, 2002, 2182, 631, 476, 948, 424, 50962], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 429, "seek": 267876, "start": 2690.7200000000003, "end": 2694.8, "text": " valores reales no es un problema raro digamos un problema que le pasa a la mayor\u00eda de los m\u00e9todos", "tokens": [50962, 1323, 2706, 957, 279, 572, 785, 517, 12395, 367, 9708, 36430, 517, 12395, 631, 476, 20260, 257, 635, 35342, 368, 1750, 20275, 378, 329, 51166], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 430, "seek": 267876, "start": 2694.8, "end": 2698.28, "text": " de prenses autom\u00e1ticos y estuvieron mirando algo de regresi\u00f3n log\u00edstica etc\u00e9tera siempre yo", "tokens": [51166, 368, 659, 3695, 279, 3553, 7656, 9940, 288, 49777, 14440, 3149, 1806, 8655, 368, 47108, 2560, 3565, 19512, 2262, 5183, 526, 23833, 12758, 5290, 51340], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 431, "seek": 267876, "start": 2698.28, "end": 2704.0800000000004, "text": " tengo que mandarle valores reales a las cosas salvo en la iglesia es que m\u00e1s o menos uno puede decir bueno", "tokens": [51340, 13989, 631, 7411, 36153, 38790, 957, 279, 257, 2439, 12218, 1845, 3080, 465, 635, 8508, 48507, 785, 631, 3573, 277, 8902, 8526, 8919, 10235, 11974, 51630], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 432, "seek": 267876, "start": 2704.0800000000004, "end": 2708.5200000000004, "text": " trabajo con palabras o sea como en la extracci\u00f3n esto trabaja en nivel de palabras en el resto", "tokens": [51630, 18099, 416, 35240, 277, 4158, 2617, 465, 635, 1279, 12080, 5687, 7433, 9618, 64, 465, 24423, 368, 35240, 465, 806, 28247, 51852], "temperature": 0.0, "avg_logprob": -0.26128991658255557, "compression_ratio": 1.8927444794952681, "no_speech_prob": 0.0003976819571107626}, {"id": 433, "seek": 270852, "start": 2708.52, "end": 2714.0, "text": " siempre est\u00e1 esperando que yo le mande valores num\u00e9ricos entonces yo necesito poder tener una", "tokens": [50364, 12758, 3192, 46587, 631, 5290, 476, 7411, 68, 38790, 1031, 27578, 329, 13003, 5290, 11909, 3528, 8152, 11640, 2002, 50638], "temperature": 0.0, "avg_logprob": -0.19252327051055565, "compression_ratio": 1.8106796116504855, "no_speech_prob": 0.0006502727046608925}, {"id": 434, "seek": 270852, "start": 2714.0, "end": 2721.36, "text": " buena representaci\u00f3n num\u00e9rica de los textos y de paso voy a pedir una propiedad m\u00e1s que es", "tokens": [50638, 25710, 2906, 3482, 1031, 32716, 368, 1750, 2487, 329, 288, 368, 29212, 7552, 257, 33533, 2002, 2365, 1091, 345, 3573, 631, 785, 51006], "temperature": 0.0, "avg_logprob": -0.19252327051055565, "compression_ratio": 1.8106796116504855, "no_speech_prob": 0.0006502727046608925}, {"id": 435, "seek": 270852, "start": 2721.36, "end": 2726.38, "text": " que esa representaci\u00f3n num\u00e9rica tenga algunas propiedades interesantes como por ejemplo una", "tokens": [51006, 631, 11342, 2906, 3482, 1031, 32716, 36031, 27316, 2365, 1091, 2977, 20157, 9327, 2617, 1515, 13358, 2002, 51257], "temperature": 0.0, "avg_logprob": -0.19252327051055565, "compression_ratio": 1.8106796116504855, "no_speech_prob": 0.0006502727046608925}, {"id": 436, "seek": 270852, "start": 2726.38, "end": 2731.28, "text": " m\u00e9trica de distancia que haga que las palabras m\u00e1s cercan las palabras m\u00e1s similares y", "tokens": [51257, 275, 4051, 15192, 368, 1483, 22862, 631, 46726, 631, 2439, 35240, 3573, 36099, 282, 2439, 35240, 3573, 1034, 7371, 495, 288, 51502], "temperature": 0.0, "avg_logprob": -0.19252327051055565, "compression_ratio": 1.8106796116504855, "no_speech_prob": 0.0006502727046608925}, {"id": 437, "seek": 273128, "start": 2731.8, "end": 2736.84, "text": " este m\u00e1s cerca y la m\u00e1s diferente de este m\u00e1s lejos por ejemplo puedo pedir eso en una", "tokens": [50390, 4065, 3573, 26770, 288, 635, 3573, 20973, 368, 4065, 3573, 476, 19136, 1515, 13358, 21612, 33533, 7287, 465, 2002, 50642], "temperature": 0.0, "avg_logprob": -0.30724539808047713, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0032597987446933985}, {"id": 438, "seek": 273128, "start": 2736.84, "end": 2744.2400000000002, "text": " en una representaci\u00f3n entonces vamos a ver una t\u00e9cnica de llamar warden bedings o", "tokens": [50642, 465, 2002, 2906, 3482, 13003, 5295, 257, 1306, 2002, 45411, 368, 16848, 289, 15234, 268, 2901, 1109, 277, 51012], "temperature": 0.0, "avg_logprob": -0.30724539808047713, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0032597987446933985}, {"id": 439, "seek": 273128, "start": 2744.2400000000002, "end": 2748.6800000000003, "text": " vectores de palabras que se utiliza para representar las palabras y despu\u00e9s eso lo pudo", "tokens": [51012, 1241, 349, 2706, 368, 35240, 631, 369, 4976, 13427, 1690, 2906, 289, 2439, 35240, 288, 15283, 7287, 450, 280, 6207, 51234], "temperature": 0.0, "avg_logprob": -0.30724539808047713, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0032597987446933985}, {"id": 440, "seek": 273128, "start": 2748.6800000000003, "end": 2754.1200000000003, "text": " utilizar como entrada una red y la t\u00e9cnica se basa en la hip\u00f3tesis distribucional que son hip\u00f3tesis", "tokens": [51234, 24060, 2617, 37119, 2002, 2182, 288, 635, 45411, 369, 987, 64, 465, 635, 8103, 812, 7269, 271, 4400, 1311, 1966, 631, 1872, 8103, 812, 7269, 271, 51506], "temperature": 0.0, "avg_logprob": -0.30724539808047713, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0032597987446933985}, {"id": 441, "seek": 275412, "start": 2754.12, "end": 2762.02, "text": " que surgi\u00f3 en los 50 con este Firth que era un linguista l\u00f3gico etc\u00e9tera y dec\u00edan lo", "tokens": [50364, 631, 19560, 7138, 465, 1750, 2625, 416, 4065, 28164, 392, 631, 4249, 517, 21766, 5236, 48475, 2789, 5183, 526, 23833, 288, 979, 11084, 450, 50759], "temperature": 0.0, "avg_logprob": -0.27939218328904736, "compression_ratio": 1.7890625, "no_speech_prob": 0.021916624158620834}, {"id": 442, "seek": 275412, "start": 2762.02, "end": 2765.88, "text": " siguiente bueno las palabras que aparecen en contextos similares tienden a tener significados", "tokens": [50759, 25666, 11974, 2439, 35240, 631, 15004, 13037, 465, 4319, 329, 1034, 7371, 495, 256, 1174, 268, 257, 11640, 3350, 4181, 50952], "temperature": 0.0, "avg_logprob": -0.27939218328904736, "compression_ratio": 1.7890625, "no_speech_prob": 0.021916624158620834}, {"id": 443, "seek": 275412, "start": 2765.88, "end": 2772.12, "text": " similares y ac\u00e1 tenemos un ejemplito que dice este ejemplito tiene como algunas palabras y", "tokens": [50952, 1034, 7371, 495, 288, 23496, 9914, 517, 10012, 5895, 3528, 631, 10313, 4065, 10012, 5895, 3528, 7066, 2617, 27316, 35240, 288, 51264], "temperature": 0.0, "avg_logprob": -0.27939218328904736, "compression_ratio": 1.7890625, "no_speech_prob": 0.021916624158620834}, {"id": 444, "seek": 275412, "start": 2772.12, "end": 2776.68, "text": " algunas ideas de contexto no la milanesa con queso m\u00e1s rica la uruguayas si es rica la", "tokens": [51264, 27316, 3487, 368, 47685, 572, 635, 1962, 12779, 64, 416, 421, 41189, 3573, 367, 2262, 635, 4038, 13705, 320, 296, 1511, 785, 367, 2262, 635, 51492], "temperature": 0.0, "avg_logprob": -0.27939218328904736, "compression_ratio": 1.7890625, "no_speech_prob": 0.021916624158620834}, {"id": 445, "seek": 275412, "start": 2776.68, "end": 2781.7999999999997, "text": " hamburguesa con queso la milanesa con queso musarelas le decimos una politana no s\u00e9 qu\u00e9 est\u00e1", "tokens": [51492, 25172, 5476, 1247, 64, 416, 421, 41189, 635, 1962, 12779, 64, 416, 421, 41189, 1038, 543, 7743, 476, 979, 8372, 2002, 2453, 2095, 572, 7910, 8057, 3192, 51748], "temperature": 0.0, "avg_logprob": -0.27939218328904736, "compression_ratio": 1.7890625, "no_speech_prob": 0.021916624158620834}, {"id": 446, "seek": 278180, "start": 2781.8, "end": 2785.5600000000004, "text": " eso como que est\u00e1 hablando de milanesas hamburguesas comida y despu\u00e9s el otro dice el", "tokens": [50364, 7287, 2617, 631, 3192, 29369, 368, 1962, 12779, 296, 25172, 5476, 1247, 296, 30779, 288, 15283, 806, 11921, 10313, 806, 50552], "temperature": 0.0, "avg_logprob": -0.24904285928477413, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.0007100077345967293}, {"id": 447, "seek": 278180, "start": 2785.5600000000004, "end": 2788.84, "text": " auto\u00f1o es una de las citaciones del a\u00f1o el verano es mi situaci\u00f3n de favoritas el", "tokens": [50552, 8399, 7716, 785, 2002, 368, 2439, 4814, 9188, 1103, 15984, 806, 1306, 3730, 785, 2752, 29343, 368, 2294, 14182, 806, 50716], "temperature": 0.0, "avg_logprob": -0.24904285928477413, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.0007100077345967293}, {"id": 448, "seek": 278180, "start": 2788.84, "end": 2793.0800000000004, "text": " invierno en invierno hace pila de fr\u00edo en verano nunca hace fr\u00edo y est\u00e1 hablando como de otra", "tokens": [50716, 1048, 19689, 465, 1048, 19689, 10032, 6429, 64, 368, 431, 20492, 465, 1306, 3730, 13768, 10032, 431, 20492, 288, 3192, 29369, 2617, 368, 13623, 50928], "temperature": 0.0, "avg_logprob": -0.24904285928477413, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.0007100077345967293}, {"id": 449, "seek": 278180, "start": 2793.0800000000004, "end": 2797.88, "text": " cosa no claramente las palabras rojas se parecen m\u00e1s entre s\u00ed las palabras azules se", "tokens": [50928, 10163, 572, 6093, 3439, 2439, 35240, 744, 19221, 369, 7448, 13037, 3573, 3962, 8600, 2439, 35240, 7883, 3473, 369, 51168], "temperature": 0.0, "avg_logprob": -0.24904285928477413, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.0007100077345967293}, {"id": 450, "seek": 278180, "start": 2797.88, "end": 2802.1600000000003, "text": " parecen m\u00e1s entre s\u00ed entonces idealmente yo quer\u00eda tener una representaci\u00f3n que a las rojas las", "tokens": [51168, 7448, 13037, 3573, 3962, 8600, 13003, 7157, 4082, 5290, 37869, 11640, 2002, 2906, 3482, 631, 257, 2439, 744, 19221, 2439, 51382], "temperature": 0.0, "avg_logprob": -0.24904285928477413, "compression_ratio": 1.8612244897959183, "no_speech_prob": 0.0007100077345967293}, {"id": 451, "seek": 280216, "start": 2802.16, "end": 2807.68, "text": " deje m\u00e1s o menos cerca y a las azules violetas las deje m\u00e1s o menos en otro lado", "tokens": [50364, 368, 2884, 3573, 277, 8902, 26770, 288, 257, 2439, 7883, 3473, 3448, 35120, 2439, 368, 2884, 3573, 277, 8902, 465, 11921, 11631, 50640], "temperature": 0.0, "avg_logprob": -0.2329700681898329, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0013158870860934258}, {"id": 452, "seek": 280216, "start": 2811.48, "end": 2817.3999999999996, "text": " bueno una primera idea que surg\u00eda es lo que se conoce como matriz t\u00e9rmino t\u00e9rmino que", "tokens": [50830, 11974, 2002, 17382, 1558, 631, 19560, 2686, 785, 450, 631, 369, 33029, 384, 2617, 3803, 24959, 45198, 78, 45198, 78, 631, 51126], "temperature": 0.0, "avg_logprob": -0.2329700681898329, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0013158870860934258}, {"id": 453, "seek": 280216, "start": 2819.3999999999996, "end": 2825.04, "text": " se se realiza contando palabras contando cuando una palabra parece cu\u00e1nta vez aparece una", "tokens": [51226, 369, 369, 957, 13427, 660, 1806, 35240, 660, 1806, 7767, 2002, 31702, 14120, 44256, 64, 5715, 37863, 2002, 51508], "temperature": 0.0, "avg_logprob": -0.2329700681898329, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0013158870860934258}, {"id": 454, "seek": 280216, "start": 2825.04, "end": 2831.3999999999996, "text": " palabra en el contexto de otra entonces por ejemplo en este caso yo digo yo tomo alrededor de", "tokens": [51508, 31702, 465, 806, 47685, 368, 13623, 13003, 1515, 13358, 465, 4065, 9666, 5290, 22990, 5290, 2916, 78, 43663, 368, 51826], "temperature": 0.0, "avg_logprob": -0.2329700681898329, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0013158870860934258}, {"id": 455, "seek": 283140, "start": 2831.4, "end": 2836.52, "text": " una palabra en palabras de contexto alrededor y cuento cu\u00e1nta vez se aparece otra en ese contexto", "tokens": [50364, 2002, 31702, 465, 35240, 368, 47685, 43663, 288, 2702, 15467, 44256, 64, 5715, 369, 37863, 13623, 465, 10167, 47685, 50620], "temperature": 0.0, "avg_logprob": -0.17558507417377672, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.00020284911443013698}, {"id": 456, "seek": 283140, "start": 2836.52, "end": 2843.48, "text": " entonces como ejemplo tenemos bueno estos son los ejemplos anteriores no la milanesa con queso", "tokens": [50620, 13003, 2617, 13358, 9914, 11974, 12585, 1872, 1750, 10012, 5895, 329, 364, 34345, 2706, 572, 635, 1962, 12779, 64, 416, 421, 41189, 50968], "temperature": 0.0, "avg_logprob": -0.17558507417377672, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.00020284911443013698}, {"id": 457, "seek": 283140, "start": 2843.48, "end": 2848.4, "text": " m\u00e1s rica la hamburguesa no s\u00e9 qu\u00e9 el auto\u00f1o tal cosa y pregunta c\u00f3mo quedar\u00eda la matriz", "tokens": [50968, 3573, 367, 2262, 635, 25172, 5476, 1247, 64, 572, 7910, 8057, 806, 8399, 7716, 4023, 10163, 288, 24252, 12826, 13617, 21178, 635, 3803, 24959, 51214], "temperature": 0.0, "avg_logprob": -0.17558507417377672, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.00020284911443013698}, {"id": 458, "seek": 283140, "start": 2848.4, "end": 2854.7200000000003, "text": " utilizando un contexto de cuatro palabras y ac\u00e1 no s\u00e9 si lo llevan a ver todos pero me", "tokens": [51214, 19906, 1806, 517, 47685, 368, 28795, 35240, 288, 23496, 572, 7910, 1511, 450, 12038, 9768, 257, 1306, 6321, 4768, 385, 51530], "temperature": 0.0, "avg_logprob": -0.17558507417377672, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.00020284911443013698}, {"id": 459, "seek": 285472, "start": 2854.72, "end": 2862.3199999999997, "text": " aparece que por ejemplo la palabra milanesa tiene las palabras rica y queso en su contexto", "tokens": [50364, 37863, 631, 1515, 13358, 635, 31702, 1962, 12779, 64, 7066, 2439, 35240, 367, 2262, 288, 421, 41189, 465, 459, 47685, 50744], "temperature": 0.0, "avg_logprob": -0.1737288608345934, "compression_ratio": 1.9578947368421054, "no_speech_prob": 0.003336822148412466}, {"id": 460, "seek": 285472, "start": 2862.3199999999997, "end": 2867.12, "text": " de la palabra hamburguesa tambi\u00e9n pero la palabra to\u00f1o no la palabra to\u00f1o tiene en su contexto", "tokens": [50744, 368, 635, 31702, 25172, 5476, 1247, 64, 6407, 4768, 635, 31702, 281, 7716, 572, 635, 31702, 281, 7716, 7066, 465, 459, 47685, 50984], "temperature": 0.0, "avg_logprob": -0.1737288608345934, "compression_ratio": 1.9578947368421054, "no_speech_prob": 0.003336822148412466}, {"id": 461, "seek": 285472, "start": 2867.9199999999996, "end": 2872.3599999999997, "text": " bueno ac\u00e1 justo como estoy tomando en igual cuatro no pasa pero las palabras verano y invierno", "tokens": [51024, 11974, 23496, 40534, 2617, 15796, 2916, 1806, 465, 10953, 28795, 572, 20260, 4768, 2439, 35240, 1306, 3730, 288, 1048, 19689, 51246], "temperature": 0.0, "avg_logprob": -0.1737288608345934, "compression_ratio": 1.9578947368421054, "no_speech_prob": 0.003336822148412466}, {"id": 462, "seek": 285472, "start": 2872.3599999999997, "end": 2881.24, "text": " tienen en su contexto la palabra fr\u00edo y no tienen ni rica ni queso entonces eso es con", "tokens": [51246, 12536, 465, 459, 47685, 635, 31702, 431, 20492, 288, 572, 12536, 3867, 367, 2262, 3867, 421, 41189, 13003, 7287, 785, 416, 51690], "temperature": 0.0, "avg_logprob": -0.1737288608345934, "compression_ratio": 1.9578947368421054, "no_speech_prob": 0.003336822148412466}, {"id": 463, "seek": 288124, "start": 2881.24, "end": 2886.12, "text": " en igual cuatro no contando cuatro palabras alrededor si yo considerara en igual cinco entonces ah\u00ed", "tokens": [50364, 465, 10953, 28795, 572, 660, 1806, 28795, 35240, 43663, 1511, 5290, 1949, 2419, 465, 10953, 21350, 13003, 12571, 50608], "temperature": 0.0, "avg_logprob": -0.2074938857037088, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.0027080990839749575}, {"id": 464, "seek": 288124, "start": 2886.12, "end": 2894.2, "text": " si aparecer\u00eda o to\u00f1o tiene la palabra estaciones en su en su contexto y verano tambi\u00e9n tiene", "tokens": [50608, 1511, 43336, 2686, 277, 281, 7716, 7066, 635, 31702, 871, 9188, 465, 459, 465, 459, 47685, 288, 1306, 3730, 6407, 7066, 51012], "temperature": 0.0, "avg_logprob": -0.2074938857037088, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.0027080990839749575}, {"id": 465, "seek": 288124, "start": 2894.2, "end": 2898.8799999999997, "text": " estaciones en su contexto entonces es como que me van quedando zonas de la matriz que est\u00e1n", "tokens": [51012, 871, 9188, 465, 459, 47685, 13003, 785, 2617, 631, 385, 3161, 13617, 1806, 710, 38027, 368, 635, 3803, 24959, 631, 10368, 51246], "temperature": 0.0, "avg_logprob": -0.2074938857037088, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.0027080990839749575}, {"id": 466, "seek": 288124, "start": 2898.8799999999997, "end": 2904.52, "text": " como m\u00e1s acopladas entre s\u00ed no como que tienen mayor nivel de proximidad y otras zonas que no", "tokens": [51246, 2617, 3573, 696, 33224, 6872, 3962, 8600, 572, 2617, 631, 12536, 10120, 24423, 368, 21932, 4580, 288, 20244, 710, 38027, 631, 572, 51528], "temperature": 0.0, "avg_logprob": -0.2074938857037088, "compression_ratio": 1.7660550458715596, "no_speech_prob": 0.0027080990839749575}, {"id": 467, "seek": 290452, "start": 2904.52, "end": 2911.68, "text": " entonces ah\u00ed ya tendr\u00eda como una especie de primera aproximaci\u00f3n a lo que ser\u00eda en", "tokens": [50364, 13003, 12571, 2478, 3928, 37183, 2617, 2002, 49368, 368, 17382, 31270, 3482, 257, 450, 631, 23679, 465, 50722], "temperature": 0.0, "avg_logprob": -0.19348634299585374, "compression_ratio": 1.8359375, "no_speech_prob": 0.014092056080698967}, {"id": 468, "seek": 290452, "start": 2911.68, "end": 2915.44, "text": " vectores de palabras que es decir bueno yo puedo representar cada palabra con una fila de esta", "tokens": [50722, 1241, 349, 2706, 368, 35240, 631, 785, 10235, 11974, 5290, 21612, 2906, 289, 8411, 31702, 416, 2002, 1387, 64, 368, 5283, 50910], "temperature": 0.0, "avg_logprob": -0.19348634299585374, "compression_ratio": 1.8359375, "no_speech_prob": 0.014092056080698967}, {"id": 469, "seek": 290452, "start": 2915.44, "end": 2919.4, "text": " matriz y esa fila de la matriz va a tener ciertas propiedades cosas de que palabras que est\u00e1n", "tokens": [50910, 3803, 24959, 288, 11342, 1387, 64, 368, 635, 3803, 24959, 2773, 257, 11640, 49252, 296, 2365, 1091, 2977, 12218, 368, 631, 35240, 631, 10368, 51108], "temperature": 0.0, "avg_logprob": -0.19348634299585374, "compression_ratio": 1.8359375, "no_speech_prob": 0.014092056080698967}, {"id": 470, "seek": 290452, "start": 2919.4, "end": 2925.36, "text": " cerca van a sem\u00e1nticamente similares van a estar cerca en esas en esas filas un problema que tiene", "tokens": [51108, 26770, 3161, 257, 4361, 27525, 23653, 1034, 7371, 495, 3161, 257, 8755, 26770, 465, 23388, 465, 23388, 1387, 296, 517, 12395, 631, 7066, 51406], "temperature": 0.0, "avg_logprob": -0.19348634299585374, "compression_ratio": 1.8359375, "no_speech_prob": 0.014092056080698967}, {"id": 471, "seek": 290452, "start": 2925.36, "end": 2929.12, "text": " esta representaci\u00f3n que dice ah\u00ed abajo es que son vectores muy grandes yo tengo vectores de", "tokens": [51406, 5283, 2906, 3482, 631, 10313, 12571, 30613, 785, 631, 1872, 1241, 349, 2706, 5323, 16640, 5290, 13989, 1241, 349, 2706, 368, 51594], "temperature": 0.0, "avg_logprob": -0.19348634299585374, "compression_ratio": 1.8359375, "no_speech_prob": 0.014092056080698967}, {"id": 472, "seek": 292912, "start": 2929.24, "end": 2933.92, "text": " tama\u00f1o b\u00e1sicamente el tama\u00f1o del vocabulario si yo tengo considero 10 mil para", "tokens": [50370, 45342, 7716, 48282, 806, 45342, 7716, 1103, 2329, 455, 1040, 1004, 1511, 5290, 13989, 1949, 78, 1266, 1962, 1690, 50604], "temperature": 0.0, "avg_logprob": -0.2586181285017628, "compression_ratio": 1.8125, "no_speech_prob": 0.0025373450480401516}, {"id": 473, "seek": 292912, "start": 2933.92, "end": 2938.64, "text": " ver vocabulario o tener vectores de tama\u00f1o de 10 mil donde la mayor\u00eda de los de los n\u00fameros", "tokens": [50604, 1306, 2329, 455, 1040, 1004, 277, 11640, 1241, 349, 2706, 368, 45342, 7716, 368, 1266, 1962, 10488, 635, 35342, 368, 1750, 368, 1750, 36545, 50840], "temperature": 0.0, "avg_logprob": -0.2586181285017628, "compression_ratio": 1.8125, "no_speech_prob": 0.0025373450480401516}, {"id": 474, "seek": 292912, "start": 2938.64, "end": 2943.14, "text": " van a ser cero y algunos van a ser valores distintos de cero entonces me va a pasar que los", "tokens": [50840, 3161, 257, 816, 269, 2032, 288, 21078, 3161, 257, 816, 38790, 49337, 368, 269, 2032, 13003, 385, 2773, 257, 25344, 631, 1750, 51065], "temperature": 0.0, "avg_logprob": -0.2586181285017628, "compression_ratio": 1.8125, "no_speech_prob": 0.0025373450480401516}, {"id": 475, "seek": 292912, "start": 2943.14, "end": 2951.72, "text": " vectores son dispersos o spars bien entonces ah\u00ed como refinaciones esta t\u00e9cnica que se utiliza", "tokens": [51065, 1241, 349, 2706, 1872, 24631, 329, 277, 637, 685, 3610, 13003, 12571, 2617, 44395, 9188, 5283, 45411, 631, 369, 4976, 13427, 51494], "temperature": 0.0, "avg_logprob": -0.2586181285017628, "compression_ratio": 1.8125, "no_speech_prob": 0.0025373450480401516}, {"id": 476, "seek": 292912, "start": 2951.72, "end": 2957.44, "text": " bastante o sea esta esta t\u00e9cnica de de construir matriz y determinos t\u00e9rminos se puede usar como", "tokens": [51494, 14651, 277, 4158, 5283, 5283, 45411, 368, 368, 38445, 3803, 24959, 288, 15957, 329, 45198, 329, 369, 8919, 14745, 2617, 51780], "temperature": 0.0, "avg_logprob": -0.2586181285017628, "compression_ratio": 1.8125, "no_speech_prob": 0.0025373450480401516}, {"id": 477, "seek": 295744, "start": 2957.44, "end": 2962.0, "text": " base para calcular ciertos tipos de vectores de palabras el algoritmo glob se basa en", "tokens": [50364, 3096, 1690, 2104, 17792, 49252, 329, 37105, 368, 1241, 349, 2706, 368, 35240, 806, 3501, 50017, 3280, 16125, 369, 987, 64, 465, 50592], "temperature": 0.0, "avg_logprob": -0.27046600977579754, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0031109105329960585}, {"id": 478, "seek": 295744, "start": 2962.0, "end": 2968.8, "text": " comentar comenzar en esta matriz los algoritmos de pca de principal componente an\u00e1lisis se pueden", "tokens": [50592, 14541, 289, 29564, 289, 465, 5283, 3803, 24959, 1750, 3501, 50017, 3415, 368, 280, 496, 368, 9716, 4026, 1576, 44113, 28436, 369, 14714, 50932], "temperature": 0.0, "avg_logprob": -0.27046600977579754, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0031109105329960585}, {"id": 479, "seek": 295744, "start": 2968.8, "end": 2973.64, "text": " usar para reducir la dimensionelidad de esta matriz en realidad este tipo de matrices tiene sus", "tokens": [50932, 14745, 1690, 2783, 23568, 635, 10139, 338, 4580, 368, 5283, 3803, 24959, 465, 25635, 4065, 9746, 368, 3803, 24373, 7066, 3291, 51174], "temperature": 0.0, "avg_logprob": -0.27046600977579754, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0031109105329960585}, {"id": 480, "seek": 295744, "start": 2973.64, "end": 2979.6, "text": " usos pero la que vamos a ver es una t\u00e9cnica un poco posterior a las matrices tambi\u00e9n", "tokens": [51174, 505, 329, 4768, 635, 631, 5295, 257, 1306, 785, 2002, 45411, 517, 10639, 33529, 257, 2439, 3803, 24373, 6407, 51472], "temperature": 0.0, "avg_logprob": -0.27046600977579754, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0031109105329960585}, {"id": 481, "seek": 295744, "start": 2979.6, "end": 2986.16, "text": " o t\u00e9rmino que digamos que est\u00e1 como en el inicio de lo que fue las revoluciones que se han dado", "tokens": [51472, 277, 45198, 78, 631, 36430, 631, 3192, 2617, 465, 806, 294, 18322, 368, 450, 631, 9248, 2439, 16908, 46649, 631, 369, 7276, 29568, 51800], "temperature": 0.0, "avg_logprob": -0.27046600977579754, "compression_ratio": 1.7816091954022988, "no_speech_prob": 0.0031109105329960585}, {"id": 482, "seek": 298616, "start": 2986.16, "end": 2992.3599999999997, "text": " en pelea en los \u00faltimos a\u00f1os no este este es un trabajo de 2013 un trabajo de bueno un", "tokens": [50364, 465, 41615, 64, 465, 1750, 33013, 11424, 572, 4065, 4065, 785, 517, 18099, 368, 9012, 517, 18099, 368, 11974, 517, 50674], "temperature": 0.0, "avg_logprob": -0.32668422250186696, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.005065137520432472}, {"id": 483, "seek": 298616, "start": 2992.3599999999997, "end": 2997.2799999999997, "text": " investigador que ya no es mi collode que propuso en 2013 una t\u00e9cnica que en realidad son dos", "tokens": [50674, 4557, 5409, 631, 2478, 572, 785, 2752, 1263, 1429, 631, 2365, 24431, 465, 9012, 2002, 45411, 631, 465, 25635, 1872, 4491, 50920], "temperature": 0.0, "avg_logprob": -0.32668422250186696, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.005065137520432472}, {"id": 484, "seek": 298616, "start": 2997.2799999999997, "end": 3003.64, "text": " acorimos distintos que se llama Word to back o sea ir acorribo para ir de palabras a vectores y", "tokens": [50920, 696, 284, 8372, 49337, 631, 369, 23272, 8725, 281, 646, 277, 4158, 3418, 696, 284, 470, 1763, 1690, 3418, 368, 35240, 257, 1241, 349, 2706, 288, 51238], "temperature": 0.0, "avg_logprob": -0.32668422250186696, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.005065137520432472}, {"id": 485, "seek": 298616, "start": 3003.64, "end": 3009.48, "text": " que su idea era construir vectores de ensos o sea vectores que tuviera una dimensi\u00f3n mucho m\u00e1s", "tokens": [51238, 631, 459, 1558, 4249, 38445, 1241, 349, 2706, 368, 3489, 329, 277, 4158, 1241, 349, 2706, 631, 38177, 10609, 2002, 5013, 694, 2560, 9824, 3573, 51530], "temperature": 0.0, "avg_logprob": -0.32668422250186696, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.005065137520432472}, {"id": 486, "seek": 298616, "start": 3009.48, "end": 3013.6, "text": " chica de vocabulario en vez de tener un vectore tama\u00f1o de 10 mil yo voy a tener un vectore tama\u00f1o 100 o", "tokens": [51530, 417, 2262, 368, 2329, 455, 1040, 1004, 465, 5715, 368, 11640, 517, 1241, 349, 418, 45342, 7716, 368, 1266, 1962, 5290, 7552, 257, 11640, 517, 1241, 349, 418, 45342, 7716, 2319, 277, 51736], "temperature": 0.0, "avg_logprob": -0.32668422250186696, "compression_ratio": 1.7554744525547445, "no_speech_prob": 0.005065137520432472}, {"id": 487, "seek": 301360, "start": 3013.6, "end": 3020.36, "text": " 250 o 300 y por el hecho de comprimir todo el vocabulario en esos vectores m\u00e1s densos entonces", "tokens": [50364, 11650, 277, 6641, 288, 1515, 806, 13064, 368, 715, 5565, 347, 5149, 806, 2329, 455, 1040, 1004, 465, 22411, 1241, 349, 2706, 3573, 24505, 329, 13003, 50702], "temperature": 0.0, "avg_logprob": -0.2280496597290039, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0034466164652258158}, {"id": 488, "seek": 301360, "start": 3020.36, "end": 3027.44, "text": " gan\u00f3 esas propiedades de que palabras m\u00e1s cercanas son sim\u00e1nticamente similares entonces bueno", "tokens": [50702, 7574, 812, 23388, 2365, 1091, 2977, 368, 631, 35240, 3573, 36099, 14292, 1872, 1034, 27525, 23653, 1034, 7371, 495, 13003, 11974, 51056], "temperature": 0.0, "avg_logprob": -0.2280496597290039, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0034466164652258158}, {"id": 489, "seek": 301360, "start": 3027.44, "end": 3032.8399999999997, "text": " obviamente no lo van s\u00f3lo por comprimir sino por c\u00f3mo se entrena esto entonces la idea de los", "tokens": [51056, 36325, 572, 450, 3161, 22885, 1515, 715, 5565, 347, 18108, 1515, 12826, 369, 3962, 629, 7433, 13003, 635, 1558, 368, 1750, 51326], "temperature": 0.0, "avg_logprob": -0.2280496597290039, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0034466164652258158}, {"id": 490, "seek": 301360, "start": 3032.8399999999997, "end": 3040.0, "text": " algoritmos de Word to back es decir bueno en vez de contar como la matriz determin\u00f3 t\u00e9rmino", "tokens": [51326, 3501, 50017, 3415, 368, 8725, 281, 646, 785, 10235, 11974, 465, 5715, 368, 27045, 2617, 635, 3803, 24959, 15957, 812, 45198, 78, 51684], "temperature": 0.0, "avg_logprob": -0.2280496597290039, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0034466164652258158}, {"id": 491, "seek": 304000, "start": 3040.0, "end": 3043.68, "text": " de las palabras dentro de un contexto yo lo voy a ver con un problema de clasificaci\u00f3n un", "tokens": [50364, 368, 2439, 35240, 10856, 368, 517, 47685, 5290, 450, 7552, 257, 1306, 416, 517, 12395, 368, 596, 296, 40802, 517, 50548], "temperature": 0.0, "avg_logprob": -0.2276000335436909, "compression_ratio": 2.046808510638298, "no_speech_prob": 0.03670342639088631}, {"id": 492, "seek": 304000, "start": 3043.68, "end": 3049.96, "text": " problema de probabil\u00edstico en el cual voy a predecir qu\u00e9 tan probable es que la palabra C aparezca", "tokens": [50548, 12395, 368, 31959, 19512, 2789, 465, 806, 10911, 7552, 257, 24874, 23568, 8057, 7603, 21759, 785, 631, 635, 31702, 383, 15004, 89, 496, 50862], "temperature": 0.0, "avg_logprob": -0.2276000335436909, "compression_ratio": 2.046808510638298, "no_speech_prob": 0.03670342639088631}, {"id": 493, "seek": 304000, "start": 3049.96, "end": 3057.88, "text": " en el contexto de la palabra W bien entonces voy a tener una predicci\u00f3n la producci\u00f3n de que es", "tokens": [50862, 465, 806, 47685, 368, 635, 31702, 343, 3610, 13003, 7552, 257, 11640, 2002, 47336, 5687, 635, 48586, 368, 631, 785, 51258], "temperature": 0.0, "avg_logprob": -0.2276000335436909, "compression_ratio": 2.046808510638298, "no_speech_prob": 0.03670342639088631}, {"id": 494, "seek": 304000, "start": 3057.88, "end": 3062.36, "text": " cierto que aparece la palabra W en el contexto de la palabra C en el contexto de la palabra W", "tokens": [51258, 28558, 631, 37863, 635, 31702, 343, 465, 806, 47685, 368, 635, 31702, 383, 465, 806, 47685, 368, 635, 31702, 343, 51482], "temperature": 0.0, "avg_logprob": -0.2276000335436909, "compression_ratio": 2.046808510638298, "no_speech_prob": 0.03670342639088631}, {"id": 495, "seek": 304000, "start": 3062.36, "end": 3067.56, "text": " eso ser\u00eda P de m\u00e1s WS pero a su vez tengo que tener una predicci\u00f3n negativa o sea yo tengo que", "tokens": [51482, 7287, 23679, 430, 368, 3573, 343, 50, 4768, 257, 459, 5715, 13989, 631, 11640, 2002, 47336, 5687, 2485, 18740, 277, 4158, 5290, 13989, 631, 51742], "temperature": 0.0, "avg_logprob": -0.2276000335436909, "compression_ratio": 2.046808510638298, "no_speech_prob": 0.03670342639088631}, {"id": 496, "seek": 306756, "start": 3067.56, "end": 3072.32, "text": " saber cu\u00e1les son los ejemplos positivos y cu\u00e1les son los ejemplos negativos entonces", "tokens": [50364, 12489, 2702, 842, 904, 1872, 1750, 10012, 5895, 329, 11218, 16501, 288, 2702, 842, 904, 1872, 1750, 10012, 5895, 329, 2485, 36945, 13003, 50602], "temperature": 0.0, "avg_logprob": -0.1681583435809026, "compression_ratio": 1.978902953586498, "no_speech_prob": 0.00224034464918077}, {"id": 497, "seek": 306756, "start": 3073.96, "end": 3078.92, "text": " lo que se hace para esto es decir bueno yo tengo un gran corpus una gran colecci\u00f3n de palabras y", "tokens": [50684, 450, 631, 369, 10032, 1690, 7433, 785, 10235, 11974, 5290, 13989, 517, 9370, 1181, 31624, 2002, 9370, 45139, 14735, 368, 35240, 288, 50932], "temperature": 0.0, "avg_logprob": -0.1681583435809026, "compression_ratio": 1.978902953586498, "no_speech_prob": 0.00224034464918077}, {"id": 498, "seek": 306756, "start": 3078.92, "end": 3085.44, "text": " yo puedo medir puedo llegar a medir cu\u00e1les son los contextos donde aparece la palabra C en el", "tokens": [50932, 5290, 21612, 1205, 347, 21612, 24892, 257, 1205, 347, 2702, 842, 904, 1872, 1750, 4319, 329, 10488, 37863, 635, 31702, 383, 465, 806, 51258], "temperature": 0.0, "avg_logprob": -0.1681583435809026, "compression_ratio": 1.978902953586498, "no_speech_prob": 0.00224034464918077}, {"id": 499, "seek": 306756, "start": 3085.44, "end": 3091.0, "text": " contexto de la palabra W pero adem\u00e1s puedo llegar a medir los casos en los cuales no pasa o sea", "tokens": [51258, 47685, 368, 635, 31702, 343, 4768, 21251, 21612, 24892, 257, 1205, 347, 1750, 25135, 465, 1750, 46932, 572, 20260, 277, 4158, 51536], "temperature": 0.0, "avg_logprob": -0.1681583435809026, "compression_ratio": 1.978902953586498, "no_speech_prob": 0.00224034464918077}, {"id": 500, "seek": 306756, "start": 3091.0, "end": 3095.7999999999997, "text": " yo puedo soltear palabra solatoria si decir bueno una palabra aleatoria no siempre est\u00e1n en", "tokens": [51536, 5290, 21612, 1404, 975, 289, 31702, 1404, 1639, 654, 1511, 10235, 11974, 2002, 31702, 6775, 1639, 654, 572, 12758, 10368, 465, 51776], "temperature": 0.0, "avg_logprob": -0.1681583435809026, "compression_ratio": 1.978902953586498, "no_speech_prob": 0.00224034464918077}, {"id": 501, "seek": 309580, "start": 3095.8, "end": 3100.96, "text": " contexto de una palabra W entonces con eso me invento ejemplos negativos tengo ejemplos", "tokens": [50364, 47685, 368, 2002, 31702, 343, 13003, 416, 7287, 385, 7962, 78, 10012, 5895, 329, 2485, 36945, 13989, 10012, 5895, 329, 50622], "temperature": 0.0, "avg_logprob": -0.20707248412456708, "compression_ratio": 2.0604395604395602, "no_speech_prob": 0.002482751617208123}, {"id": 502, "seek": 309580, "start": 3100.96, "end": 3106.76, "text": " positivos que son bueno la palabra queso aparece en el contexto de la palabra burbesa ejemplos", "tokens": [50622, 11218, 16501, 631, 1872, 11974, 635, 31702, 421, 41189, 37863, 465, 806, 47685, 368, 635, 31702, 2779, 6446, 64, 10012, 5895, 329, 50912], "temperature": 0.0, "avg_logprob": -0.20707248412456708, "compression_ratio": 2.0604395604395602, "no_speech_prob": 0.002482751617208123}, {"id": 503, "seek": 309580, "start": 3106.76, "end": 3111.88, "text": " negativos son sortes de una palabra cualquiera y sali\u00f3 yo que se \u00e1rbol bueno la palabra \u00e1rbol", "tokens": [50912, 2485, 36945, 1872, 1333, 279, 368, 2002, 31702, 10911, 35134, 288, 1845, 7138, 5290, 631, 369, 35349, 17460, 11974, 635, 31702, 35349, 17460, 51168], "temperature": 0.0, "avg_logprob": -0.20707248412456708, "compression_ratio": 2.0604395604395602, "no_speech_prob": 0.002482751617208123}, {"id": 504, "seek": 309580, "start": 3111.88, "end": 3121.44, "text": " no aparece en el contexto de la palabra burbesa bien entonces el algoritmo skip gran que es uno", "tokens": [51168, 572, 37863, 465, 806, 47685, 368, 635, 31702, 2779, 6446, 64, 3610, 13003, 806, 3501, 50017, 3280, 10023, 9370, 631, 785, 8526, 51646], "temperature": 0.0, "avg_logprob": -0.20707248412456708, "compression_ratio": 2.0604395604395602, "no_speech_prob": 0.002482751617208123}, {"id": 505, "seek": 312144, "start": 3121.44, "end": 3128.88, "text": " de los algoritmos de portubec m\u00e1s m\u00e1s utilizados utiliza este ese principio y lo ve como una red", "tokens": [50364, 368, 1750, 3501, 50017, 3415, 368, 2436, 1977, 66, 3573, 3573, 19906, 4181, 4976, 13427, 4065, 10167, 34308, 288, 450, 1241, 2617, 2002, 2182, 50736], "temperature": 0.0, "avg_logprob": -0.2480369783797354, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.012749702669680119}, {"id": 506, "seek": 312144, "start": 3128.88, "end": 3134.32, "text": " neuronal intenta modelar esto como una renebronal en la cual yo tengo una capa de entrada y la capa", "tokens": [50736, 12087, 21523, 8446, 64, 2316, 289, 7433, 2617, 2002, 319, 716, 1443, 21523, 465, 635, 10911, 5290, 13989, 2002, 1410, 64, 368, 37119, 288, 635, 1410, 64, 51008], "temperature": 0.0, "avg_logprob": -0.2480369783797354, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.012749702669680119}, {"id": 507, "seek": 312144, "start": 3134.32, "end": 3138.76, "text": " de entrada va a ser una representaci\u00f3n one hot esto lo mencionamos la de pasada la representaci\u00f3n", "tokens": [51008, 368, 37119, 2773, 257, 816, 2002, 2906, 3482, 472, 2368, 7433, 450, 37030, 2151, 635, 368, 1736, 1538, 635, 2906, 3482, 51230], "temperature": 0.0, "avg_logprob": -0.2480369783797354, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.012749702669680119}, {"id": 508, "seek": 312144, "start": 3138.76, "end": 3145.84, "text": " one hot es as\u00ed no en la representaci\u00f3n one hot yo voy a tener un vector para la palabra queso y un", "tokens": [51230, 472, 2368, 785, 8582, 572, 465, 635, 2906, 3482, 472, 2368, 5290, 7552, 257, 11640, 517, 8062, 1690, 635, 31702, 421, 41189, 288, 517, 51584], "temperature": 0.0, "avg_logprob": -0.2480369783797354, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.012749702669680119}, {"id": 509, "seek": 314584, "start": 3145.84, "end": 3156.2400000000002, "text": " vector para la palabra hamburguesa donde voy a tener una columna para cada una de las palabras", "tokens": [50364, 8062, 1690, 635, 31702, 25172, 5476, 1247, 64, 10488, 7552, 257, 11640, 2002, 5970, 629, 1690, 8411, 2002, 368, 2439, 35240, 50884], "temperature": 0.0, "avg_logprob": -0.23932077407836913, "compression_ratio": 1.9576719576719577, "no_speech_prob": 0.016137253493070602}, {"id": 510, "seek": 314584, "start": 3156.2400000000002, "end": 3162.28, "text": " posibles entonces voy a tener ac\u00e1 perro ac\u00e1 voy a tener comer ac\u00e1 voy a tener \u00e1rbol", "tokens": [50884, 1366, 14428, 13003, 7552, 257, 11640, 23496, 680, 340, 23496, 7552, 257, 11640, 16510, 23496, 7552, 257, 11640, 35349, 17460, 51186], "temperature": 0.0, "avg_logprob": -0.23932077407836913, "compression_ratio": 1.9576719576719577, "no_speech_prob": 0.016137253493070602}, {"id": 511, "seek": 314584, "start": 3162.28, "end": 3168.0, "text": " tan tata y ac\u00e1 va a estar queso en angulado y ac\u00e1 va a estar hamburguesa en otro lado y ac\u00e1", "tokens": [51186, 7603, 256, 3274, 288, 23496, 2773, 257, 8755, 421, 41189, 465, 2562, 425, 1573, 288, 23496, 2773, 257, 8755, 25172, 5476, 1247, 64, 465, 11921, 11631, 288, 23496, 51472], "temperature": 0.0, "avg_logprob": -0.23932077407836913, "compression_ratio": 1.9576719576719577, "no_speech_prob": 0.016137253493070602}, {"id": 512, "seek": 314584, "start": 3168.0, "end": 3173.76, "text": " va a dar m\u00e1s cosas y entonces la representaci\u00f3n de la palabra queso es cero en todos lados", "tokens": [51472, 2773, 257, 4072, 3573, 12218, 288, 13003, 635, 2906, 3482, 368, 635, 31702, 421, 41189, 785, 269, 2032, 465, 6321, 40301, 51760], "temperature": 0.0, "avg_logprob": -0.23932077407836913, "compression_ratio": 1.9576719576719577, "no_speech_prob": 0.016137253493070602}, {"id": 513, "seek": 317376, "start": 3174.7200000000003, "end": 3181.6400000000003, "text": " y un uno ac\u00e1 y cero en todo el resto la palabra burbesa es cero en todos lados cero ac\u00e1 y", "tokens": [50412, 288, 517, 8526, 23496, 288, 269, 2032, 465, 5149, 806, 28247, 635, 31702, 2779, 6446, 64, 785, 269, 2032, 465, 6321, 40301, 269, 2032, 23496, 288, 50758], "temperature": 0.0, "avg_logprob": -0.22453730961061874, "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.0005952798528596759}, {"id": 514, "seek": 317376, "start": 3181.6400000000003, "end": 3187.0800000000004, "text": " un uno en la burbesa y cero en todo el resto esto es la representaci\u00f3n one hot entonces esta red", "tokens": [50758, 517, 8526, 465, 635, 2779, 6446, 64, 288, 269, 2032, 465, 5149, 806, 28247, 7433, 785, 635, 2906, 3482, 472, 2368, 13003, 5283, 2182, 51030], "temperature": 0.0, "avg_logprob": -0.22453730961061874, "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.0005952798528596759}, {"id": 515, "seek": 317376, "start": 3187.0800000000004, "end": 3192.32, "text": " neuronal en realidad digamos es una renebronal que intenta predecir este problema probabil\u00edstico", "tokens": [51030, 12087, 21523, 465, 25635, 36430, 785, 2002, 319, 716, 1443, 21523, 631, 8446, 64, 24874, 23568, 4065, 12395, 31959, 19512, 2789, 51292], "temperature": 0.0, "avg_logprob": -0.22453730961061874, "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.0005952798528596759}, {"id": 516, "seek": 317376, "start": 3192.32, "end": 3199.28, "text": " toma como entrada ese vector de cero y uno es el vector one hot donde la entrada es todo el vocabulario", "tokens": [51292, 39728, 2617, 37119, 10167, 8062, 368, 269, 2032, 288, 8526, 785, 806, 8062, 472, 2368, 10488, 635, 37119, 785, 5149, 806, 2329, 455, 1040, 1004, 51640], "temperature": 0.0, "avg_logprob": -0.22453730961061874, "compression_ratio": 1.8798076923076923, "no_speech_prob": 0.0005952798528596759}, {"id": 517, "seek": 319928, "start": 3199.28, "end": 3206.0, "text": " posible tiene una capa oculta en el medio es una red que tiene una sola capa oculta y como salida", "tokens": [50364, 26644, 7066, 2002, 1410, 64, 10409, 723, 64, 465, 806, 22123, 785, 2002, 2182, 631, 7066, 2002, 34162, 1410, 64, 10409, 723, 64, 288, 2617, 1845, 2887, 50700], "temperature": 0.0, "avg_logprob": -0.16006144432172384, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.005425579380244017}, {"id": 518, "seek": 319928, "start": 3206.0, "end": 3212.0, "text": " tiene una distribuci\u00f3n de probabilidades de todas las palabras en contexto entonces la entrada", "tokens": [50700, 7066, 2002, 4400, 30813, 368, 31959, 10284, 368, 10906, 2439, 35240, 465, 47685, 13003, 635, 37119, 51000], "temperature": 0.0, "avg_logprob": -0.16006144432172384, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.005425579380244017}, {"id": 519, "seek": 319928, "start": 3212.0, "end": 3220.0400000000004, "text": " es supongamos que esto tiene tama\u00f1o 10 mil no tengo 10 mil palabras posibles 10 mil palabras en", "tokens": [51000, 785, 9331, 556, 2151, 631, 7433, 7066, 45342, 7716, 1266, 1962, 572, 13989, 1266, 1962, 35240, 1366, 14428, 1266, 1962, 35240, 465, 51402], "temperature": 0.0, "avg_logprob": -0.16006144432172384, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.005425579380244017}, {"id": 520, "seek": 322004, "start": 3220.04, "end": 3231.44, "text": " el vocabulario entonces la entrada de la red va a ser una cosa de tama\u00f1o 10 mil entrada tiene", "tokens": [50364, 806, 2329, 455, 1040, 1004, 13003, 635, 37119, 368, 635, 2182, 2773, 257, 816, 2002, 10163, 368, 45342, 7716, 1266, 1962, 37119, 7066, 50934], "temperature": 0.0, "avg_logprob": -0.16164246583596253, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0010268627665936947}, {"id": 521, "seek": 322004, "start": 3231.44, "end": 3242.32, "text": " tama\u00f1o 10 mil y la salida va a tener c por 10 mil c es cu\u00e1ntas palabras de contexto estoy contando", "tokens": [50934, 45342, 7716, 1266, 1962, 288, 635, 1845, 2887, 2773, 257, 11640, 269, 1515, 1266, 1962, 269, 785, 44256, 296, 35240, 368, 47685, 15796, 660, 1806, 51478], "temperature": 0.0, "avg_logprob": -0.16164246583596253, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0010268627665936947}, {"id": 522, "seek": 322004, "start": 3242.32, "end": 3248.12, "text": " o sea si yo estoy contando no s\u00e9 10 palabras alrededor de la que estoy mirando entonces va a ser", "tokens": [51478, 277, 4158, 1511, 5290, 15796, 660, 1806, 572, 7910, 1266, 35240, 43663, 368, 635, 631, 15796, 3149, 1806, 13003, 2773, 257, 816, 51768], "temperature": 0.0, "avg_logprob": -0.16164246583596253, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.0010268627665936947}, {"id": 523, "seek": 324812, "start": 3248.12, "end": 3254.72, "text": " una salida c por 10 mil esto c por 10 mil representan cu\u00e1l es la probabilidad de que una palabra", "tokens": [50364, 2002, 1845, 2887, 269, 1515, 1266, 1962, 7433, 269, 1515, 1266, 1962, 2906, 282, 44318, 785, 635, 31959, 4580, 368, 631, 2002, 31702, 50694], "temperature": 0.0, "avg_logprob": -0.20911651296713918, "compression_ratio": 2.0425531914893615, "no_speech_prob": 0.002954813651740551}, {"id": 524, "seek": 324812, "start": 3254.72, "end": 3260.12, "text": " cualquiera por ejemplo hamburguesa est\u00e9 en un contexto de tres palabras para atr\u00e1s de la palabra", "tokens": [50694, 10911, 35134, 1515, 13358, 25172, 5476, 1247, 64, 34584, 465, 517, 47685, 368, 15890, 35240, 1690, 22906, 368, 635, 31702, 50964], "temperature": 0.0, "avg_logprob": -0.20911651296713918, "compression_ratio": 2.0425531914893615, "no_speech_prob": 0.002954813651740551}, {"id": 525, "seek": 324812, "start": 3260.12, "end": 3264.68, "text": " queso cu\u00e1l es la probabilidad que la palabra perro est\u00e9 en un contexto de dos palabras para", "tokens": [50964, 421, 41189, 44318, 785, 635, 31959, 4580, 631, 635, 31702, 680, 340, 34584, 465, 517, 47685, 368, 4491, 35240, 1690, 51192], "temperature": 0.0, "avg_logprob": -0.20911651296713918, "compression_ratio": 2.0425531914893615, "no_speech_prob": 0.002954813651740551}, {"id": 526, "seek": 324812, "start": 3264.68, "end": 3270.6, "text": " adelante la palabra queso y as\u00ed eso es las c por 10 mil salidas y en el medio tiene una capa", "tokens": [51192, 40214, 635, 31702, 421, 41189, 288, 8582, 7287, 785, 2439, 269, 1515, 1266, 1962, 1845, 11382, 288, 465, 806, 22123, 7066, 2002, 1410, 64, 51488], "temperature": 0.0, "avg_logprob": -0.20911651296713918, "compression_ratio": 2.0425531914893615, "no_speech_prob": 0.002954813651740551}, {"id": 527, "seek": 327060, "start": 3270.6, "end": 3287.7999999999997, "text": " que ah\u00ed dice en edim la capa oculta que tiene tama\u00f1o 10 mil por dim y dim es la dimensi\u00f3n", "tokens": [50364, 631, 12571, 10313, 465, 1257, 332, 635, 1410, 64, 10409, 723, 64, 631, 7066, 45342, 7716, 1266, 1962, 1515, 5013, 288, 5013, 785, 635, 5013, 694, 2560, 51224], "temperature": 0.0, "avg_logprob": -0.25357742309570314, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.000663197017274797}, {"id": 528, "seek": 327060, "start": 3287.7999999999997, "end": 3292.6, "text": " de los vectores que eso que les dec\u00eda que pod\u00eda hacer dimensi\u00f3n 100 o dimensi\u00f3n 300 o dimensi\u00f3n", "tokens": [51224, 368, 1750, 1241, 349, 2706, 631, 7287, 631, 1512, 37599, 631, 45588, 6720, 5013, 694, 2560, 2319, 277, 5013, 694, 2560, 6641, 277, 5013, 694, 2560, 51464], "temperature": 0.0, "avg_logprob": -0.25357742309570314, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.000663197017274797}, {"id": 529, "seek": 327060, "start": 3292.6, "end": 3300.48, "text": " 150 es un n\u00famero mucho m\u00e1s chico que vocabulario entonces pensem\u00f3lo como esto la tano mientras", "tokens": [51464, 8451, 785, 517, 14959, 9824, 3573, 417, 2789, 631, 2329, 455, 1040, 1004, 13003, 11209, 76, 812, 752, 2617, 7433, 635, 256, 3730, 26010, 51858], "temperature": 0.0, "avg_logprob": -0.25357742309570314, "compression_ratio": 1.5815217391304348, "no_speech_prob": 0.000663197017274797}, {"id": 530, "seek": 330048, "start": 3300.48, "end": 3306.52, "text": " es un vector o un hot que tiene un uno y un mont\u00f3n de ceros y despu\u00e9s lo paso por una", "tokens": [50364, 785, 517, 8062, 277, 517, 2368, 631, 7066, 517, 8526, 288, 517, 45259, 368, 10146, 329, 288, 15283, 450, 29212, 1515, 2002, 50666], "temperature": 0.0, "avg_logprob": -0.18162620544433594, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.002919470425695181}, {"id": 531, "seek": 330048, "start": 3306.52, "end": 3313.04, "text": " matriz de pesos que tiene este tama\u00f1o 10 mil por por ejemplo 300 10 mil por 300 entonces al", "tokens": [50666, 3803, 24959, 368, 33204, 631, 7066, 4065, 45342, 7716, 1266, 1962, 1515, 1515, 13358, 6641, 1266, 1962, 1515, 6641, 13003, 419, 50992], "temperature": 0.0, "avg_logprob": -0.18162620544433594, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.002919470425695181}, {"id": 532, "seek": 330048, "start": 3313.04, "end": 3319.84, "text": " multiplicar eso por mi vector ac\u00e1 esto me devuelve una sola fila de esa matriz que tiene dimensi\u00f3n", "tokens": [50992, 17596, 289, 7287, 1515, 2752, 8062, 23496, 7433, 385, 1905, 3483, 303, 2002, 34162, 1387, 64, 368, 11342, 3803, 24959, 631, 7066, 5013, 694, 2560, 51332], "temperature": 0.0, "avg_logprob": -0.18162620544433594, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.002919470425695181}, {"id": 533, "seek": 330048, "start": 3319.84, "end": 3328.32, "text": " 300 y eso se lo voy a pasar a la funci\u00f3n de activaci\u00f3n a su vez eso tiene como una especie", "tokens": [51332, 6641, 288, 7287, 369, 450, 7552, 257, 25344, 257, 635, 43735, 368, 2430, 3482, 257, 459, 5715, 7287, 7066, 2617, 2002, 49368, 51756], "temperature": 0.0, "avg_logprob": -0.18162620544433594, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.002919470425695181}, {"id": 534, "seek": 332832, "start": 3328.32, "end": 3333.48, "text": " de segunda capa en la cual aparece m\u00e1s peso para poder calcular estas salidas pero en realidad al", "tokens": [50364, 368, 21978, 1410, 64, 465, 635, 10911, 37863, 3573, 28149, 1690, 8152, 2104, 17792, 13897, 1845, 11382, 4768, 465, 25635, 419, 50622], "temperature": 0.0, "avg_logprob": -0.2576167309870485, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0331120565533638}, {"id": 535, "seek": 332832, "start": 3333.48, "end": 3338.0, "text": " m\u00e9todo despu\u00e9s de que se entrena con un mont\u00f3n de valores positivos un mont\u00f3n de valores negativos", "tokens": [50622, 20275, 17423, 15283, 368, 631, 369, 3962, 629, 416, 517, 45259, 368, 38790, 11218, 16501, 517, 45259, 368, 38790, 2485, 36945, 50848], "temperature": 0.0, "avg_logprob": -0.2576167309870485, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0331120565533638}, {"id": 536, "seek": 332832, "start": 3338.0, "end": 3342.04, "text": " dice bueno que eso parece en el contexto de muruesas pero perro no aparece en el contexto de", "tokens": [50848, 10313, 11974, 631, 7287, 14120, 465, 806, 47685, 368, 5257, 1247, 296, 4768, 680, 340, 572, 37863, 465, 806, 47685, 368, 51050], "temperature": 0.0, "avg_logprob": -0.2576167309870485, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0331120565533638}, {"id": 537, "seek": 332832, "start": 3342.04, "end": 3347.8, "text": " la muruesa etc\u00e9tera tengo un mont\u00f3n de valores de este estilo cuando termina de entrenar y", "tokens": [51050, 635, 5257, 1247, 64, 5183, 526, 23833, 13989, 517, 45259, 368, 38790, 368, 4065, 37470, 7767, 1433, 1426, 368, 45069, 289, 288, 51338], "temperature": 0.0, "avg_logprob": -0.2576167309870485, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0331120565533638}, {"id": 538, "seek": 332832, "start": 3347.8, "end": 3352.6400000000003, "text": " se bueno llegu\u00e9 al mejor c\u00e1lculo de probabilidades en realidad yo tiro todo el resto de las capas y me", "tokens": [51338, 369, 11974, 11234, 42423, 419, 11479, 6476, 75, 25436, 368, 31959, 10284, 465, 25635, 5290, 44188, 5149, 806, 28247, 368, 2439, 1410, 296, 288, 385, 51580], "temperature": 0.0, "avg_logprob": -0.2576167309870485, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.0331120565533638}, {"id": 539, "seek": 335264, "start": 3352.64, "end": 3359.16, "text": " quedo solamente con esta de ac\u00e1 con la capa oculta la capa oculta es una tabla que me dice para", "tokens": [50364, 13617, 78, 27814, 416, 5283, 368, 23496, 416, 635, 1410, 64, 10409, 723, 64, 635, 1410, 64, 10409, 723, 64, 785, 2002, 4421, 875, 631, 385, 10313, 1690, 50690], "temperature": 0.0, "avg_logprob": -0.23998899841308594, "compression_ratio": 1.9404761904761905, "no_speech_prob": 0.0013361101737245917}, {"id": 540, "seek": 335264, "start": 3359.16, "end": 3364.8799999999997, "text": " cada una de las palabras hay 300 valores reales que le representan bien entonces me dice bueno para", "tokens": [50690, 8411, 2002, 368, 2439, 35240, 4842, 6641, 38790, 957, 279, 631, 476, 2906, 282, 3610, 13003, 385, 10313, 11974, 1690, 50976], "temperature": 0.0, "avg_logprob": -0.23998899841308594, "compression_ratio": 1.9404761904761905, "no_speech_prob": 0.0013361101737245917}, {"id": 541, "seek": 335264, "start": 3364.8799999999997, "end": 3369.92, "text": " la palabra que eso esto 300 valores van a ser menos uno tres con cuatro ocho con seis no s\u00e9 qu\u00e9", "tokens": [50976, 635, 31702, 631, 7287, 7433, 6641, 38790, 3161, 257, 816, 8902, 8526, 15890, 416, 28795, 3795, 78, 416, 28233, 572, 7910, 8057, 51228], "temperature": 0.0, "avg_logprob": -0.23998899841308594, "compression_ratio": 1.9404761904761905, "no_speech_prob": 0.0013361101737245917}, {"id": 542, "seek": 335264, "start": 3369.92, "end": 3374.7999999999997, "text": " est\u00e1 todo as\u00ed 300 valores y para las palabras muruesa menos dos tres con uno etc\u00e9tera etc\u00e9tera", "tokens": [51228, 3192, 5149, 8582, 6641, 38790, 288, 1690, 2439, 35240, 5257, 1247, 64, 8902, 4491, 15890, 416, 8526, 5183, 526, 23833, 5183, 526, 23833, 51472], "temperature": 0.0, "avg_logprob": -0.23998899841308594, "compression_ratio": 1.9404761904761905, "no_speech_prob": 0.0013361101737245917}, {"id": 543, "seek": 335264, "start": 3374.7999999999997, "end": 3379.16, "text": " o sea voy a tener un mont\u00f3n de valores reales que le representan que representan esos n\u00fameros", "tokens": [51472, 277, 4158, 7552, 257, 11640, 517, 45259, 368, 38790, 957, 279, 631, 476, 2906, 282, 631, 2906, 282, 22411, 36545, 51690], "temperature": 0.0, "avg_logprob": -0.23998899841308594, "compression_ratio": 1.9404761904761905, "no_speech_prob": 0.0013361101737245917}, {"id": 544, "seek": 337916, "start": 3379.16, "end": 3385.6, "text": " no lo s\u00e9 y nadie lo sabe pero sabemos que ah\u00ed est\u00e1 codificada la informaci\u00f3n importante para", "tokens": [50364, 572, 450, 7910, 288, 28060, 450, 12275, 4768, 27200, 631, 12571, 3192, 17656, 1089, 1538, 635, 21660, 9416, 1690, 50686], "temperature": 0.0, "avg_logprob": -0.30818714565700955, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0029643781017512083}, {"id": 545, "seek": 337916, "start": 3385.6, "end": 3393.44, "text": " poder despu\u00e9s trabajar con esos n\u00fameros con esos con esas palabras bien hay eso se le llama", "tokens": [50686, 8152, 15283, 30793, 416, 22411, 36545, 416, 22411, 416, 23388, 35240, 3610, 4842, 7287, 369, 476, 23272, 51078], "temperature": 0.0, "avg_logprob": -0.30818714565700955, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0029643781017512083}, {"id": 546, "seek": 337916, "start": 3393.44, "end": 3400.2, "text": " Word in badings esta capa oculta que est\u00e1 ac\u00e1 en esta en esta t\u00e9cnica de Wordback se le llama", "tokens": [51078, 8725, 294, 1578, 1109, 5283, 1410, 64, 10409, 723, 64, 631, 3192, 23496, 465, 5283, 465, 5283, 45411, 368, 8725, 3207, 369, 476, 23272, 51416], "temperature": 0.0, "avg_logprob": -0.30818714565700955, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0029643781017512083}, {"id": 547, "seek": 337916, "start": 3400.2, "end": 3404.7999999999997, "text": " capa de badings a la capa oculta que queda entrenada despu\u00e9s de esto bien preguntas", "tokens": [51416, 1410, 64, 368, 1578, 1109, 257, 635, 1410, 64, 10409, 723, 64, 631, 23314, 45069, 1538, 15283, 368, 7433, 3610, 39722, 51646], "temperature": 0.0, "avg_logprob": -0.30818714565700955, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0029643781017512083}, {"id": 548, "seek": 340916, "start": 3409.16, "end": 3417.2, "text": " ustedes que palabra que esto s\u00ed es para ir a la capa oculta y por el producto porque la", "tokens": [50364, 17110, 631, 31702, 631, 7433, 8600, 785, 1690, 3418, 257, 635, 1410, 64, 10409, 723, 64, 288, 1515, 806, 47583, 4021, 635, 50766], "temperature": 0.0, "avg_logprob": -0.3994411267732319, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.024189427495002747}, {"id": 549, "seek": 340916, "start": 3417.2, "end": 3422.7599999999998, "text": " matriz doble vez una matriz de 10 mil por dimensi\u00f3n y mi vector one hot es un vector que tiene", "tokens": [50766, 3803, 24959, 360, 638, 5715, 2002, 3803, 24959, 368, 1266, 1962, 1515, 5013, 694, 2560, 288, 2752, 8062, 472, 2368, 785, 517, 8062, 631, 7066, 51044], "temperature": 0.0, "avg_logprob": -0.3994411267732319, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.024189427495002747}, {"id": 550, "seek": 340916, "start": 3422.7599999999998, "end": 3427.04, "text": " tama\u00f1o de 10 mil pero hay un solo uno no son todos heros y uno entonces al hacer el producto me", "tokens": [51044, 45342, 7716, 368, 1266, 1962, 4768, 4842, 517, 6944, 8526, 572, 1872, 6321, 720, 329, 288, 8526, 13003, 419, 6720, 806, 47583, 385, 51258], "temperature": 0.0, "avg_logprob": -0.3994411267732319, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.024189427495002747}, {"id": 551, "seek": 340916, "start": 3427.04, "end": 3432.64, "text": " queda exclusivamente la fila que representa la matriz la palabra que eso", "tokens": [51258, 23314, 15085, 23957, 635, 1387, 64, 631, 49823, 635, 3803, 24959, 635, 31702, 631, 7287, 51538], "temperature": 0.0, "avg_logprob": -0.3994411267732319, "compression_ratio": 1.726829268292683, "no_speech_prob": 0.024189427495002747}, {"id": 552, "seek": 343264, "start": 3433.64, "end": 3442.44, "text": " bien entonces con esto se logra con esta t\u00e9cnica Wordback y otras t\u00e9cnicas de construcci\u00f3n", "tokens": [50414, 3610, 13003, 416, 7433, 369, 3565, 424, 416, 5283, 45411, 8725, 3207, 288, 20244, 25564, 40672, 368, 12946, 14735, 50854], "temperature": 0.0, "avg_logprob": -0.2051547811001162, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.00647829519584775}, {"id": 553, "seek": 343264, "start": 3442.44, "end": 3453.7999999999997, "text": " de Word in badings s\u00ed no el resultado de la capa oculta se lo pasas en esta t\u00e9cnica por lo", "tokens": [50854, 368, 8725, 294, 1578, 1109, 8600, 572, 806, 28047, 368, 635, 1410, 64, 10409, 723, 64, 369, 450, 1736, 296, 465, 5283, 45411, 1515, 450, 51422], "temperature": 0.0, "avg_logprob": -0.2051547811001162, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.00647829519584775}, {"id": 554, "seek": 343264, "start": 3453.7999999999997, "end": 3458.8399999999997, "text": " menos le pasas el resultado de la capa oculta a otros pesos que van a ir a la salida y esos pesos", "tokens": [51422, 8902, 476, 1736, 296, 806, 28047, 368, 635, 1410, 64, 10409, 723, 64, 257, 16422, 33204, 631, 3161, 257, 3418, 257, 635, 1845, 2887, 288, 22411, 33204, 51674], "temperature": 0.0, "avg_logprob": -0.2051547811001162, "compression_ratio": 1.763975155279503, "no_speech_prob": 0.00647829519584775}, {"id": 555, "seek": 345884, "start": 3458.84, "end": 3463.7200000000003, "text": " son los que calculan la probabilidad de salida pero en realidad despu\u00e9s todos esos pesos que aparecen", "tokens": [50364, 1872, 1750, 631, 4322, 282, 635, 31959, 4580, 368, 1845, 2887, 4768, 465, 25635, 15283, 6321, 22411, 33204, 631, 15004, 13037, 50608], "temperature": 0.0, "avg_logprob": -0.20405930132905314, "compression_ratio": 1.8832684824902723, "no_speech_prob": 0.005713170859962702}, {"id": 556, "seek": 345884, "start": 3463.7200000000003, "end": 3468.2400000000002, "text": " despu\u00e9s no me importa o sea despu\u00e9s de que yo termino de entrenar todo la \u00fanica capa con la", "tokens": [50608, 15283, 572, 385, 33218, 277, 4158, 15283, 368, 631, 5290, 1433, 2982, 368, 45069, 289, 5149, 635, 30104, 1410, 64, 416, 635, 50834], "temperature": 0.0, "avg_logprob": -0.20405930132905314, "compression_ratio": 1.8832684824902723, "no_speech_prob": 0.005713170859962702}, {"id": 557, "seek": 345884, "start": 3468.2400000000002, "end": 3471.6000000000004, "text": " que me voy a quedar es con la del medio que es la que me he interesado entrenar el resto es", "tokens": [50834, 631, 385, 7552, 257, 39244, 785, 416, 635, 1103, 22123, 631, 785, 635, 631, 385, 415, 20157, 1573, 45069, 289, 806, 28247, 785, 51002], "temperature": 0.0, "avg_logprob": -0.20405930132905314, "compression_ratio": 1.8832684824902723, "no_speech_prob": 0.005713170859962702}, {"id": 558, "seek": 345884, "start": 3471.6000000000004, "end": 3476.6800000000003, "text": " como una especie de excusa que se usa para esta tarea para poder encontrar la capa del medio", "tokens": [51002, 2617, 2002, 49368, 368, 20974, 64, 631, 369, 29909, 1690, 5283, 256, 35425, 1690, 8152, 17525, 635, 1410, 64, 1103, 22123, 51256], "temperature": 0.0, "avg_logprob": -0.20405930132905314, "compression_ratio": 1.8832684824902723, "no_speech_prob": 0.005713170859962702}, {"id": 559, "seek": 345884, "start": 3479.76, "end": 3485.92, "text": " la salida tiene c por 10 mil que significa yo estoy prediciendo cu\u00e1l es la probabilidad en todas las", "tokens": [51410, 635, 1845, 2887, 7066, 269, 1515, 1266, 1962, 631, 19957, 5290, 15796, 47336, 7304, 44318, 785, 635, 31959, 4580, 465, 10906, 2439, 51718], "temperature": 0.0, "avg_logprob": -0.20405930132905314, "compression_ratio": 1.8832684824902723, "no_speech_prob": 0.005713170859962702}, {"id": 560, "seek": 348592, "start": 3485.92, "end": 3488.12, "text": " seis palabras de contexto de caparesca alguna palabra", "tokens": [50364, 28233, 35240, 368, 47685, 368, 1410, 64, 495, 496, 20651, 31702, 50474], "temperature": 0.0, "avg_logprob": -0.3026364871433803, "compression_ratio": 2.042682926829268, "no_speech_prob": 0.01141616702079773}, {"id": 561, "seek": 348592, "start": 3492.96, "end": 3498.56, "text": " bien entonces les hicimos logramos nuestro objetivo que era decir que hago que puedo", "tokens": [50716, 3610, 13003, 1512, 23697, 8372, 3565, 30227, 14726, 29809, 631, 4249, 10235, 631, 38721, 631, 21612, 50996], "temperature": 0.0, "avg_logprob": -0.3026364871433803, "compression_ratio": 2.042682926829268, "no_speech_prob": 0.01141616702079773}, {"id": 562, "seek": 348592, "start": 3498.56, "end": 3505.2000000000003, "text": " asociar a una palabra a un string un vector de valores reales entonces tengo la palabra perro y", "tokens": [50996, 382, 78, 537, 289, 257, 2002, 31702, 257, 517, 6798, 517, 8062, 368, 38790, 957, 279, 13003, 13989, 635, 31702, 680, 340, 288, 51328], "temperature": 0.0, "avg_logprob": -0.3026364871433803, "compression_ratio": 2.042682926829268, "no_speech_prob": 0.01141616702079773}, {"id": 563, "seek": 348592, "start": 3505.2000000000003, "end": 3511.2400000000002, "text": " me va a dar un vector de valores reales la palabra comer y me va a dar otro vector de valores reales", "tokens": [51328, 385, 2773, 257, 4072, 517, 8062, 368, 38790, 957, 279, 635, 31702, 16510, 288, 385, 2773, 257, 4072, 11921, 8062, 368, 38790, 957, 279, 51630], "temperature": 0.0, "avg_logprob": -0.3026364871433803, "compression_ratio": 2.042682926829268, "no_speech_prob": 0.01141616702079773}, {"id": 564, "seek": 351124, "start": 3512.2, "end": 3518.9199999999996, "text": " adem\u00e1s se cumple que los vectores cuanto m\u00e1s cercanos est\u00e1n en ese espacio de dimensi\u00f3n", "tokens": [50412, 21251, 369, 12713, 781, 631, 1750, 1241, 349, 2706, 36685, 3573, 36099, 31035, 10368, 465, 10167, 33845, 368, 5013, 694, 2560, 50748], "temperature": 0.0, "avg_logprob": -0.2584207416635699, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.007363863755017519}, {"id": 565, "seek": 351124, "start": 3518.9199999999996, "end": 3524.0, "text": " 300 entonces significa las palabras son m\u00e1s similares en alg\u00fan sentido o si est\u00e1n m\u00e1s", "tokens": [50748, 6641, 13003, 19957, 2439, 35240, 1872, 3573, 1034, 7371, 495, 465, 26300, 19850, 277, 1511, 10368, 3573, 51002], "temperature": 0.0, "avg_logprob": -0.2584207416635699, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.007363863755017519}, {"id": 566, "seek": 351124, "start": 3524.0, "end": 3531.24, "text": " lejanos entonces son m\u00e1s dis\u00edmiles puedo utilizar por ejemplo la similiaridad coseno para", "tokens": [51002, 476, 73, 31035, 13003, 1872, 3573, 717, 14569, 4680, 21612, 24060, 1515, 13358, 635, 1034, 4600, 4580, 3792, 5808, 1690, 51364], "temperature": 0.0, "avg_logprob": -0.2584207416635699, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.007363863755017519}, {"id": 567, "seek": 351124, "start": 3531.24, "end": 3534.52, "text": " eso si yo calculo el coseno del \u00e1ngulo del otro lado vectores eso es una buena medida para", "tokens": [51364, 7287, 1511, 5290, 4322, 78, 806, 3792, 5808, 1103, 7352, 37308, 1103, 11921, 11631, 1241, 349, 2706, 7287, 785, 2002, 25710, 32984, 1690, 51528], "temperature": 0.0, "avg_logprob": -0.2584207416635699, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.007363863755017519}, {"id": 568, "seek": 351124, "start": 3534.52, "end": 3538.0, "text": " saber qu\u00e9 est\u00e1n parecidos son o incluso para usar la distancia o cl\u00eddea tambi\u00e9n para", "tokens": [51528, 12489, 8057, 10368, 7448, 46579, 1872, 277, 24018, 1690, 14745, 635, 1483, 22862, 277, 596, 870, 1479, 64, 6407, 1690, 51702], "temperature": 0.0, "avg_logprob": -0.2584207416635699, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.007363863755017519}, {"id": 569, "seek": 353800, "start": 3538.0, "end": 3544.52, "text": " calcular eso pero la similiaridad coseno es la que m\u00e1s se usa y adem\u00e1s de que tiene esa", "tokens": [50364, 2104, 17792, 7287, 4768, 635, 1034, 4600, 4580, 3792, 5808, 785, 635, 631, 3573, 369, 29909, 288, 21251, 368, 631, 7066, 11342, 50690], "temperature": 0.0, "avg_logprob": -0.17035322804604808, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.003052885876968503}, {"id": 570, "seek": 353800, "start": 3544.52, "end": 3550.96, "text": " propiedad de que las palabras m\u00e1s cercanas son m\u00e1s parecidas de alguna manera estas t\u00e9cnicas", "tokens": [50690, 2365, 1091, 345, 368, 631, 2439, 35240, 3573, 36099, 14292, 1872, 3573, 7448, 66, 11382, 368, 20651, 13913, 13897, 25564, 40672, 51012], "temperature": 0.0, "avg_logprob": -0.17035322804604808, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.003052885876968503}, {"id": 571, "seek": 353800, "start": 3550.96, "end": 3556.36, "text": " descubren cosas interesantes que uno no las entren\u00f3 para que las descubran digamos sino que aparecen", "tokens": [51012, 32592, 1095, 12218, 20157, 9327, 631, 8526, 572, 2439, 45069, 812, 1690, 631, 2439, 32592, 4257, 36430, 18108, 631, 15004, 13037, 51282], "temperature": 0.0, "avg_logprob": -0.17035322804604808, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.003052885876968503}, {"id": 572, "seek": 353800, "start": 3556.36, "end": 3561.28, "text": " como de yapa y aparecen cosas como que por ejemplo yo puedo hacer operaciones entre los vectores", "tokens": [51282, 2617, 368, 288, 7961, 288, 15004, 13037, 12218, 2617, 631, 1515, 13358, 5290, 21612, 6720, 2208, 9188, 3962, 1750, 1241, 349, 2706, 51528], "temperature": 0.0, "avg_logprob": -0.17035322804604808, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.003052885876968503}, {"id": 573, "seek": 353800, "start": 3561.28, "end": 3565.44, "text": " entonces si yo tengo el vector de rey y le resto el vector de hombre y le sumo el vector de", "tokens": [51528, 13003, 1511, 5290, 13989, 806, 1241, 1672, 368, 319, 88, 288, 476, 28247, 806, 1241, 1672, 368, 26102, 288, 476, 2408, 78, 806, 1241, 1672, 368, 51736], "temperature": 0.0, "avg_logprob": -0.17035322804604808, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.003052885876968503}, {"id": 574, "seek": 356544, "start": 3565.44, "end": 3569.92, "text": " mujer me queda el vector de rey y eso es una propiedad que aparece despu\u00e9s de que yo", "tokens": [50364, 32032, 385, 23314, 806, 1241, 1672, 368, 319, 88, 288, 7287, 785, 2002, 2365, 1091, 345, 631, 37863, 15283, 368, 631, 5290, 50588], "temperature": 0.0, "avg_logprob": -0.3056774419896743, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.011403177864849567}, {"id": 575, "seek": 356544, "start": 3569.92, "end": 3576.08, "text": " entren estos vectores suele suceder en alendenar estas colecciones de vectores que agarro el vector de", "tokens": [50588, 45069, 12585, 1241, 349, 2706, 459, 16884, 41928, 260, 465, 419, 8896, 289, 13897, 45139, 35560, 368, 1241, 349, 2706, 631, 623, 289, 340, 806, 1241, 1672, 368, 50896], "temperature": 0.0, "avg_logprob": -0.3056774419896743, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.011403177864849567}, {"id": 576, "seek": 356544, "start": 3576.08, "end": 3582.96, "text": " mujer le resto de hombre y le sumo rey y me queda rey o agarro el vector de Uruguay le resto", "tokens": [50896, 32032, 476, 28247, 368, 26102, 288, 476, 2408, 78, 319, 88, 288, 385, 23314, 319, 88, 277, 623, 289, 340, 806, 1241, 1672, 368, 9533, 13705, 320, 476, 28247, 51240], "temperature": 0.0, "avg_logprob": -0.3056774419896743, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.011403177864849567}, {"id": 577, "seek": 356544, "start": 3582.96, "end": 3588.28, "text": " donde veo le sumo Francia me da Par\u00eds no entonces ah\u00ed en un caso estoy haciendo una transformaci\u00f3n", "tokens": [51240, 10488, 41319, 476, 2408, 78, 17288, 2755, 385, 1120, 3457, 5113, 572, 13003, 12571, 465, 517, 9666, 15796, 20509, 2002, 4088, 3482, 51506], "temperature": 0.0, "avg_logprob": -0.3056774419896743, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.011403177864849567}, {"id": 578, "seek": 356544, "start": 3588.28, "end": 3593.52, "text": " un poco morfol\u00f3gica decir bueno este hombre es la mujer como rey esa rey y el otro estoy", "tokens": [51506, 517, 10639, 1896, 69, 27629, 2262, 10235, 11974, 4065, 26102, 785, 635, 32032, 2617, 319, 88, 11342, 319, 88, 288, 806, 11921, 15796, 51768], "temperature": 0.0, "avg_logprob": -0.3056774419896743, "compression_ratio": 1.8549019607843138, "no_speech_prob": 0.011403177864849567}, {"id": 579, "seek": 359352, "start": 3593.52, "end": 3597.48, "text": " haciendo una transformaci\u00f3n m\u00e1s sem\u00e1ntica como diciendo la capital de Uruguay y la capital", "tokens": [50364, 20509, 2002, 4088, 3482, 3573, 4361, 27525, 2262, 2617, 42797, 635, 4238, 368, 9533, 13705, 320, 288, 635, 4238, 50562], "temperature": 0.0, "avg_logprob": -0.24977494862453997, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.01686866022646427}, {"id": 580, "seek": 359352, "start": 3597.48, "end": 3602.28, "text": " de Francia es Par\u00eds y de alguna forma yo nunca le dije al sistema que tiene que aprender eso pero", "tokens": [50562, 368, 17288, 2755, 785, 3457, 5113, 288, 368, 20651, 8366, 5290, 13768, 476, 39414, 419, 13245, 631, 7066, 631, 24916, 7287, 4768, 50802], "temperature": 0.0, "avg_logprob": -0.24977494862453997, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.01686866022646427}, {"id": 581, "seek": 359352, "start": 3602.28, "end": 3609.2, "text": " por la forma que hayan creado los vectores suelen tener propiedad de este estilo bien eso fue como", "tokens": [50802, 1515, 635, 8366, 631, 4842, 282, 1197, 1573, 1750, 1241, 349, 2706, 459, 14818, 11640, 2365, 1091, 345, 368, 4065, 37470, 3610, 7287, 9248, 2617, 51148], "temperature": 0.0, "avg_logprob": -0.24977494862453997, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.01686866022646427}, {"id": 582, "seek": 359352, "start": 3609.2, "end": 3614.88, "text": " lo lo primero sorprendente que encontraron acerca de estos m\u00e9todos que es que se pueden como que", "tokens": [51148, 450, 450, 21289, 9359, 32725, 1576, 631, 17525, 266, 46321, 368, 12585, 20275, 378, 329, 631, 785, 631, 369, 14714, 2617, 631, 51432], "temperature": 0.0, "avg_logprob": -0.24977494862453997, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.01686866022646427}, {"id": 583, "seek": 359352, "start": 3614.88, "end": 3619.0, "text": " derrebo de aprender esas cosas pero no est\u00e1n excesos del problema como por ejemplo si yo tengo", "tokens": [51432, 1163, 265, 1763, 368, 24916, 23388, 12218, 4768, 572, 10368, 454, 887, 329, 1103, 12395, 2617, 1515, 13358, 1511, 5290, 13989, 51638], "temperature": 0.0, "avg_logprob": -0.24977494862453997, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.01686866022646427}, {"id": 584, "seek": 361900, "start": 3619.0, "end": 3624.08, "text": " una palabra la palabra vela voy a tener un solo vector que representa la palabra vela y vela", "tokens": [50364, 2002, 31702, 635, 31702, 14610, 64, 7552, 257, 11640, 517, 6944, 1241, 1672, 631, 49823, 635, 31702, 14610, 64, 288, 14610, 64, 50618], "temperature": 0.0, "avg_logprob": -0.21590662002563477, "compression_ratio": 2.1666666666666665, "no_speech_prob": 0.04027300700545311}, {"id": 585, "seek": 361900, "start": 3624.08, "end": 3629.36, "text": " es una palabra que es amigo o sea es polis\u00e9mica yo puedo tener una vela para aprender una vela", "tokens": [50618, 785, 2002, 31702, 631, 785, 24671, 277, 4158, 785, 1180, 271, 4011, 2262, 5290, 21612, 11640, 2002, 14610, 64, 1690, 24916, 2002, 14610, 64, 50882], "temperature": 0.0, "avg_logprob": -0.21590662002563477, "compression_ratio": 2.1666666666666665, "no_speech_prob": 0.04027300700545311}, {"id": 586, "seek": 361900, "start": 3631.36, "end": 3636.08, "text": " vamos para poner una vela de cumplea\u00f1os o sea una pag\u00f3n o puedo tener un barco a vela y bueno", "tokens": [50982, 5295, 1690, 19149, 2002, 14610, 64, 368, 12713, 781, 64, 8242, 277, 4158, 2002, 11812, 1801, 277, 21612, 11640, 517, 2159, 1291, 257, 14610, 64, 288, 11974, 51218], "temperature": 0.0, "avg_logprob": -0.21590662002563477, "compression_ratio": 2.1666666666666665, "no_speech_prob": 0.04027300700545311}, {"id": 587, "seek": 361900, "start": 3636.08, "end": 3641.12, "text": " en los dos casos tengo la misma representaci\u00f3n o el gato hidr\u00e1ulico y el gato animal tambi\u00e9n tengo", "tokens": [51218, 465, 1750, 4491, 25135, 13989, 635, 24946, 2906, 3482, 277, 806, 290, 2513, 16253, 30218, 425, 2789, 288, 806, 290, 2513, 5496, 6407, 13989, 51470], "temperature": 0.0, "avg_logprob": -0.21590662002563477, "compression_ratio": 2.1666666666666665, "no_speech_prob": 0.04027300700545311}, {"id": 588, "seek": 361900, "start": 3641.12, "end": 3645.64, "text": " la misma representaci\u00f3n el banco de sentarse y el banco de financiero tambi\u00e9n tengo la misma", "tokens": [51470, 635, 24946, 2906, 3482, 806, 45498, 368, 2279, 11668, 288, 806, 45498, 368, 24323, 2032, 6407, 13989, 635, 24946, 51696], "temperature": 0.0, "avg_logprob": -0.21590662002563477, "compression_ratio": 2.1666666666666665, "no_speech_prob": 0.04027300700545311}, {"id": 589, "seek": 364564, "start": 3645.64, "end": 3650.12, "text": " representaci\u00f3n etc\u00e9tera entonces eso es un problema que tienen estos estas t\u00e9cnicas y es que yo", "tokens": [50364, 2906, 3482, 5183, 526, 23833, 13003, 7287, 785, 517, 12395, 631, 12536, 12585, 13897, 25564, 40672, 288, 785, 631, 5290, 50588], "temperature": 0.0, "avg_logprob": -0.34281965272616494, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.0039664218202233315}, {"id": 590, "seek": 364564, "start": 3650.12, "end": 3654.24, "text": " no tengo digamos no estoy usando por ejemplo wordnet que vieron guarnas en una acci\u00f3n", "tokens": [50588, 572, 13989, 36430, 572, 15796, 29798, 1515, 13358, 1349, 7129, 631, 371, 14440, 695, 1083, 296, 465, 2002, 696, 5687, 50794], "temperature": 0.0, "avg_logprob": -0.34281965272616494, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.0039664218202233315}, {"id": 591, "seek": 364564, "start": 3654.24, "end": 3660.52, "text": " es clase no no tengo un repositorio significado de wordnet que me ayude a decir cu\u00e1l es cu\u00e1l sino", "tokens": [50794, 785, 44578, 572, 572, 13989, 517, 1085, 329, 3029, 1004, 3350, 1573, 368, 1349, 7129, 631, 385, 7494, 2303, 257, 10235, 44318, 785, 44318, 18108, 51108], "temperature": 0.0, "avg_logprob": -0.34281965272616494, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.0039664218202233315}, {"id": 592, "seek": 364564, "start": 3660.52, "end": 3668.72, "text": " que ac\u00e1 solamente tengo un representante para cada palabra bien y bueno esta esta t\u00e9cnica tiene", "tokens": [51108, 631, 23496, 27814, 13989, 517, 2906, 2879, 1690, 8411, 31702, 3610, 288, 11974, 5283, 5283, 45411, 7066, 51518], "temperature": 0.0, "avg_logprob": -0.34281965272616494, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.0039664218202233315}, {"id": 593, "seek": 364564, "start": 3668.72, "end": 3672.68, "text": " ese problema despu\u00e9s hay otras tecnicas me permiten crear vectores contextuales que d\u00eda bueno", "tokens": [51518, 10167, 12395, 15283, 4842, 20244, 20105, 9150, 385, 13423, 268, 31984, 1241, 349, 2706, 35526, 279, 631, 12271, 11974, 51716], "temperature": 0.0, "avg_logprob": -0.34281965272616494, "compression_ratio": 1.7610294117647058, "no_speech_prob": 0.0039664218202233315}, {"id": 594, "seek": 367268, "start": 3672.68, "end": 3679.12, "text": " es la palabra gato en esta oraci\u00f3n donde probablemente sea un gato animal y no un gato hidr\u00e1ulico", "tokens": [50364, 785, 635, 31702, 290, 2513, 465, 5283, 420, 3482, 10488, 21759, 4082, 4158, 517, 290, 2513, 5496, 288, 572, 517, 290, 2513, 16253, 30218, 425, 2789, 50686], "temperature": 0.0, "avg_logprob": -0.22243989682665058, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.004726517014205456}, {"id": 595, "seek": 367268, "start": 3682.12, "end": 3689.08, "text": " bien entonces una vez que construimos esta colecci\u00f3n de vectores como los evaluamos c\u00f3mo sabemos", "tokens": [50836, 3610, 13003, 2002, 5715, 631, 12946, 8372, 5283, 45139, 14735, 368, 1241, 349, 2706, 2617, 1750, 6133, 2151, 12826, 27200, 51184], "temperature": 0.0, "avg_logprob": -0.22243989682665058, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.004726517014205456}, {"id": 596, "seek": 367268, "start": 3689.08, "end": 3695.2799999999997, "text": " est\u00e1n bien bueno hay como dos formas de evaluarlos bastante comunes se habla de test intr\u00ednsecos y", "tokens": [51184, 10368, 3610, 11974, 4842, 2617, 4491, 33463, 368, 6133, 39734, 14651, 11040, 279, 369, 42135, 368, 1500, 17467, 10973, 405, 6877, 288, 51494], "temperature": 0.0, "avg_logprob": -0.22243989682665058, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.004726517014205456}, {"id": 597, "seek": 367268, "start": 3695.2799999999997, "end": 3700.6, "text": " test en extr\u00ednsecos que significan cosas distintas intr\u00ednsecos significa yo mido propiedades del", "tokens": [51494, 1500, 465, 16455, 10973, 405, 6877, 631, 3350, 282, 12218, 31489, 296, 17467, 10973, 405, 6877, 19957, 5290, 275, 2925, 2365, 1091, 2977, 1103, 51760], "temperature": 0.0, "avg_logprob": -0.22243989682665058, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.004726517014205456}, {"id": 598, "seek": 370060, "start": 3700.6, "end": 3707.12, "text": " conjunto de vectores que constru\u00ed entonces una de las que se miden es exactamente lo que dec\u00eda", "tokens": [50364, 37776, 368, 1241, 349, 2706, 631, 12946, 870, 13003, 2002, 368, 2439, 631, 369, 2062, 268, 785, 48686, 450, 631, 37599, 50690], "temperature": 0.0, "avg_logprob": -0.21803972672443, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0013943027006462216}, {"id": 599, "seek": 370060, "start": 3707.12, "end": 3713.6, "text": " no reci\u00e9n me diamos que aparece una propiedad que es que yo puedo hacer dibujar como en", "tokens": [50690, 572, 4214, 3516, 385, 1026, 2151, 631, 37863, 2002, 2365, 1091, 345, 631, 785, 631, 5290, 21612, 6720, 46621, 289, 2617, 465, 51014], "temperature": 0.0, "avg_logprob": -0.21803972672443, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0013943027006462216}, {"id": 600, "seek": 370060, "start": 3713.6, "end": 3718.72, "text": " especie para el logramos en el cual digo que hombre es a mujer como rey esa y espero que", "tokens": [51014, 49368, 1690, 806, 3565, 30227, 465, 806, 10911, 22990, 631, 26102, 785, 257, 32032, 2617, 319, 88, 11342, 288, 26823, 631, 51270], "temperature": 0.0, "avg_logprob": -0.21803972672443, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0013943027006462216}, {"id": 601, "seek": 370060, "start": 3718.72, "end": 3725.7999999999997, "text": " es mi colecci\u00f3n de vectores haya quedado reina digamos como resultado de su operaci\u00f3n o Uruguay", "tokens": [51270, 785, 2752, 45139, 14735, 368, 1241, 349, 2706, 24693, 13617, 1573, 319, 1426, 36430, 2617, 28047, 368, 459, 2208, 3482, 277, 9533, 13705, 320, 51624], "temperature": 0.0, "avg_logprob": -0.21803972672443, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0013943027006462216}, {"id": 602, "seek": 372580, "start": 3725.8, "end": 3731.5600000000004, "text": " esa montevideo como francia esa y espero que haya quedado par\u00eds en ese lugar entonces bueno una", "tokens": [50364, 11342, 8143, 13379, 24589, 2617, 431, 22862, 11342, 288, 26823, 631, 24693, 13617, 1573, 971, 5113, 465, 10167, 11467, 13003, 11974, 2002, 50652], "temperature": 0.0, "avg_logprob": -0.3106646586939232, "compression_ratio": 1.7763157894736843, "no_speech_prob": 0.005652845837175846}, {"id": 603, "seek": 372580, "start": 3731.5600000000004, "end": 3737.1600000000003, "text": " forma de valor estos estos sistemas es construirme una colecci\u00f3n grande de estos test se llaman test de", "tokens": [50652, 8366, 368, 15367, 12585, 12585, 48720, 785, 38445, 1398, 2002, 45139, 14735, 8883, 368, 12585, 1500, 369, 4849, 6147, 1500, 368, 50932], "temperature": 0.0, "avg_logprob": -0.3106646586939232, "compression_ratio": 1.7763157894736843, "no_speech_prob": 0.005652845837175846}, {"id": 604, "seek": 372580, "start": 3737.1600000000003, "end": 3744.1600000000003, "text": " analog\u00edas entonces me puedo hacer una colecci\u00f3n grande estos test y ver a cu\u00e1ntos le moca mi colecci\u00f3n", "tokens": [50932, 16660, 10025, 13003, 385, 21612, 6720, 2002, 45139, 14735, 8883, 12585, 1500, 288, 1306, 257, 44256, 329, 476, 705, 496, 2752, 45139, 14735, 51282], "temperature": 0.0, "avg_logprob": -0.3106646586939232, "compression_ratio": 1.7763157894736843, "no_speech_prob": 0.005652845837175846}, {"id": 605, "seek": 372580, "start": 3744.1600000000003, "end": 3747.96, "text": " entonces con yo tengo varias colecciones en vez de distintas veo que este le invoco m\u00e1s veces y", "tokens": [51282, 13003, 416, 5290, 13989, 37496, 45139, 35560, 465, 5715, 368, 31489, 296, 41319, 631, 4065, 476, 1048, 11198, 3573, 17054, 288, 51472], "temperature": 0.0, "avg_logprob": -0.3106646586939232, "compression_ratio": 1.7763157894736843, "no_speech_prob": 0.005652845837175846}, {"id": 606, "seek": 374796, "start": 3747.96, "end": 3755.64, "text": " el invoco menos veces otro son los test de similitud o similaridad que esto se hacen con", "tokens": [50364, 806, 1048, 11198, 8902, 17054, 11921, 1872, 1750, 1500, 368, 1034, 388, 21875, 277, 2531, 4580, 631, 7433, 369, 27434, 416, 50748], "temperature": 0.0, "avg_logprob": -0.2871653564974793, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.049431104212999344}, {"id": 607, "seek": 374796, "start": 3755.64, "end": 3760.12, "text": " intervenci\u00f3n humana un poco m\u00e1s fuerte que es preguntar un mont\u00f3n de personas por ejemplo", "tokens": [50748, 17104, 5687, 1952, 64, 517, 10639, 3573, 37129, 631, 785, 19860, 289, 517, 45259, 368, 12019, 1515, 13358, 50972], "temperature": 0.0, "avg_logprob": -0.2871653564974793, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.049431104212999344}, {"id": 608, "seek": 374796, "start": 3760.12, "end": 3766.92, "text": " que es m\u00e1s parecido a un durasno una silla una mesa o una manzana a un avestrus o cosas de", "tokens": [50972, 631, 785, 3573, 7448, 17994, 257, 517, 4861, 296, 1771, 2002, 262, 5291, 2002, 37024, 277, 2002, 587, 89, 2095, 257, 517, 1305, 377, 13783, 277, 12218, 368, 51312], "temperature": 0.0, "avg_logprob": -0.2871653564974793, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.049431104212999344}, {"id": 609, "seek": 374796, "start": 3766.92, "end": 3772.36, "text": " estilo entonces tal le dicen a la gente trata de arranquear estas cuatro cinco palabras de cu\u00e1l es", "tokens": [51312, 37470, 13003, 4023, 476, 33816, 257, 635, 3788, 31920, 368, 50235, 1077, 289, 13897, 28795, 21350, 35240, 368, 44318, 785, 51584], "temperature": 0.0, "avg_logprob": -0.2871653564974793, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.049431104212999344}, {"id": 610, "seek": 374796, "start": 3772.36, "end": 3776.2, "text": " m\u00e1s parecida menos parecida entonces le preguntar un mont\u00f3n de personas las personas hacen sus", "tokens": [51584, 3573, 7448, 37200, 8902, 7448, 37200, 13003, 476, 19860, 289, 517, 45259, 368, 12019, 2439, 12019, 27434, 3291, 51776], "temperature": 0.0, "avg_logprob": -0.2871653564974793, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.049431104212999344}, {"id": 611, "seek": 377620, "start": 3776.2, "end": 3781.12, "text": " listas y despu\u00e9s mir\u00e1s dentro de tu colecci\u00f3n de vectores si las distancias relativas entre esas", "tokens": [50364, 1329, 296, 288, 15283, 3149, 2490, 10856, 368, 2604, 45139, 14735, 368, 1241, 349, 2706, 1511, 2439, 1483, 282, 12046, 21960, 296, 3962, 23388, 50610], "temperature": 0.0, "avg_logprob": -0.2636193859484769, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.012786068953573704}, {"id": 612, "seek": 377620, "start": 3781.12, "end": 3785.8799999999997, "text": " palabras son similares o no a la que esperaban los humanos entonces cuanto m\u00e1s similar sea haciendo", "tokens": [50610, 35240, 1872, 1034, 7371, 495, 277, 572, 257, 635, 631, 10045, 18165, 1750, 34555, 13003, 36685, 3573, 2531, 4158, 20509, 50848], "temperature": 0.0, "avg_logprob": -0.2636193859484769, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.012786068953573704}, {"id": 613, "seek": 377620, "start": 3785.8799999999997, "end": 3791.2799999999997, "text": " el el test de Spirman para eso el descorrelaci\u00f3n de Spirman se puede sacar una medida de qu\u00e9 tanto", "tokens": [50848, 806, 806, 1500, 368, 1738, 347, 1601, 1690, 7287, 806, 7471, 284, 4419, 3482, 368, 1738, 347, 1601, 369, 8919, 43823, 2002, 32984, 368, 8057, 10331, 51118], "temperature": 0.0, "avg_logprob": -0.2636193859484769, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.012786068953573704}, {"id": 614, "seek": 377620, "start": 3791.2799999999997, "end": 3797.08, "text": " se parece a la intuici\u00f3n humana lo que el sistema dice eso es llamante es intr\u00ednseco porque yo", "tokens": [51118, 369, 14120, 257, 635, 560, 84, 15534, 1952, 64, 450, 631, 806, 13245, 10313, 7287, 785, 16848, 2879, 785, 17467, 10973, 405, 1291, 4021, 5290, 51408], "temperature": 0.0, "avg_logprob": -0.2636193859484769, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.012786068953573704}, {"id": 615, "seek": 377620, "start": 3797.08, "end": 3802.52, "text": " estoy abarrando la colecci\u00f3n de vectores que constru\u00ed y las estoy testeando sola los test", "tokens": [51408, 15796, 410, 289, 19845, 635, 45139, 14735, 368, 1241, 349, 2706, 631, 12946, 870, 288, 2439, 15796, 49586, 1806, 34162, 1750, 1500, 51680], "temperature": 0.0, "avg_logprob": -0.2636193859484769, "compression_ratio": 1.8014705882352942, "no_speech_prob": 0.012786068953573704}, {"id": 616, "seek": 380252, "start": 3802.52, "end": 3808.92, "text": " extr\u00ednsecos se refieren a agarro mi colecci\u00f3n de vectores y la meto en una tarea de p l n un", "tokens": [50364, 16455, 10973, 405, 6877, 369, 1895, 5695, 257, 623, 289, 340, 2752, 45139, 14735, 368, 1241, 349, 2706, 288, 635, 1131, 78, 465, 2002, 256, 35425, 368, 280, 287, 297, 517, 50684], "temperature": 0.0, "avg_logprob": -0.2035912486994378, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.0080042639747262}, {"id": 617, "seek": 380252, "start": 3808.92, "end": 3814.64, "text": " poco m\u00e1s grande y veo qu\u00e9 tal le va entonces ac\u00e1 significa bueno yo supongamos que tengo un", "tokens": [50684, 10639, 3573, 8883, 288, 41319, 8057, 4023, 476, 2773, 13003, 23496, 19957, 11974, 5290, 9331, 556, 2151, 631, 13989, 517, 50970], "temperature": 0.0, "avg_logprob": -0.2035912486994378, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.0080042639747262}, {"id": 618, "seek": 380252, "start": 3814.64, "end": 3820.68, "text": " sistema de p l n que hace traducci\u00f3n autom\u00e1tica o an\u00e1lisis de sentimiento o recuperaci\u00f3n de informaci\u00f3n", "tokens": [50970, 13245, 368, 280, 287, 297, 631, 10032, 2479, 1311, 5687, 3553, 23432, 277, 44113, 28436, 368, 2279, 14007, 277, 25692, 3482, 368, 21660, 51272], "temperature": 0.0, "avg_logprob": -0.2035912486994378, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.0080042639747262}, {"id": 619, "seek": 380252, "start": 3820.68, "end": 3827.64, "text": " o un chatbot o lo que sea si yo tengo un sistema que ya funciona y le cambio su capa de", "tokens": [51272, 277, 517, 5081, 18870, 277, 450, 631, 4158, 1511, 5290, 13989, 517, 13245, 631, 2478, 26210, 288, 476, 28731, 459, 1410, 64, 368, 51620], "temperature": 0.0, "avg_logprob": -0.2035912486994378, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.0080042639747262}, {"id": 620, "seek": 382764, "start": 3827.7999999999997, "end": 3832.3599999999997, "text": " su colecci\u00f3n de vectores por la m\u00eda que yo entren\u00e9 y el sistema mejora en su performance entonces", "tokens": [50372, 459, 45139, 14735, 368, 1241, 349, 2706, 1515, 635, 275, 2686, 631, 5290, 45069, 526, 288, 806, 13245, 11479, 64, 465, 459, 3389, 13003, 50600], "temperature": 0.0, "avg_logprob": -0.24336219787597657, "compression_ratio": 1.976284584980237, "no_speech_prob": 0.024288516491651535}, {"id": 621, "seek": 382764, "start": 3832.3599999999997, "end": 3837.4, "text": " digo que puedo decir que mi colecci\u00f3n de vectores mejora la performance entonces puedo decir que la", "tokens": [50600, 22990, 631, 21612, 10235, 631, 2752, 45139, 14735, 368, 1241, 349, 2706, 11479, 64, 635, 3389, 13003, 21612, 10235, 631, 635, 50852], "temperature": 0.0, "avg_logprob": -0.24336219787597657, "compression_ratio": 1.976284584980237, "no_speech_prob": 0.024288516491651535}, {"id": 622, "seek": 382764, "start": 3837.4, "end": 3842.04, "text": " colecci\u00f3n de vectores es buena eso de llamas test extr\u00ednseco o sea no estoy probando directamente", "tokens": [50852, 45139, 14735, 368, 1241, 349, 2706, 785, 25710, 7287, 368, 16848, 296, 1500, 16455, 10973, 405, 1291, 277, 4158, 572, 15796, 1239, 1806, 46230, 51084], "temperature": 0.0, "avg_logprob": -0.24336219787597657, "compression_ratio": 1.976284584980237, "no_speech_prob": 0.024288516491651535}, {"id": 623, "seek": 382764, "start": 3842.04, "end": 3846.2799999999997, "text": " las propiedades de los en vectores sino que estoy probando c\u00f3mo se comportan en un sistema m\u00e1s grande", "tokens": [51084, 2439, 2365, 1091, 2977, 368, 1750, 465, 1241, 349, 2706, 18108, 631, 15796, 1239, 1806, 12826, 369, 25883, 282, 465, 517, 13245, 3573, 8883, 51296], "temperature": 0.0, "avg_logprob": -0.24336219787597657, "compression_ratio": 1.976284584980237, "no_speech_prob": 0.024288516491651535}, {"id": 624, "seek": 382764, "start": 3850.7599999999998, "end": 3856.08, "text": " bien entonces otra forma de evaluar esto m\u00e1s bien no creo que lleguen a ver nada porque est\u00e1", "tokens": [51520, 3610, 13003, 13623, 8366, 368, 6133, 289, 7433, 3573, 3610, 572, 14336, 631, 11234, 7801, 257, 1306, 8096, 4021, 3192, 51786], "temperature": 0.0, "avg_logprob": -0.24336219787597657, "compression_ratio": 1.976284584980237, "no_speech_prob": 0.024288516491651535}, {"id": 625, "seek": 385608, "start": 3856.08, "end": 3860.96, "text": " muy chiquito pero bueno vamos a mencionarlo es visualizarlos en bedings recuerden que esto ten\u00eda", "tokens": [50364, 5323, 417, 3221, 3528, 4768, 11974, 5295, 257, 37030, 19457, 785, 5056, 590, 39734, 465, 2901, 1109, 39092, 1556, 631, 7433, 23718, 50608], "temperature": 0.0, "avg_logprob": -0.2586809414536206, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.0010033148573711514}, {"id": 626, "seek": 385608, "start": 3860.96, "end": 3868.84, "text": " dimensi\u00f3n 100 350 que era una dimensi\u00f3n mucho m\u00e1s chica que el vocabulario pero igual es una", "tokens": [50608, 5013, 694, 2560, 2319, 18065, 631, 4249, 2002, 5013, 694, 2560, 9824, 3573, 417, 2262, 631, 806, 2329, 455, 1040, 1004, 4768, 10953, 785, 2002, 51002], "temperature": 0.0, "avg_logprob": -0.2586809414536206, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.0010033148573711514}, {"id": 627, "seek": 385608, "start": 3868.84, "end": 3872.7599999999998, "text": " dimensi\u00f3n muy grande o sea lo sumano podemos visualizar dos tres dimensiones de lo sumo y m\u00e1s de", "tokens": [51002, 5013, 694, 2560, 5323, 8883, 277, 4158, 450, 2408, 3730, 12234, 5056, 9736, 4491, 15890, 10139, 279, 368, 450, 2408, 78, 288, 3573, 368, 51198], "temperature": 0.0, "avg_logprob": -0.2586809414536206, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.0010033148573711514}, {"id": 628, "seek": 385608, "start": 3872.7599999999998, "end": 3878.44, "text": " eso ya nos mareamos y estos son vectores de 300 dimensiones pero una forma de visualizarlos es", "tokens": [51198, 7287, 2478, 3269, 31471, 2151, 288, 12585, 1872, 1241, 349, 2706, 368, 6641, 10139, 279, 4768, 2002, 8366, 368, 5056, 590, 39734, 785, 51482], "temperature": 0.0, "avg_logprob": -0.2586809414536206, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.0010033148573711514}, {"id": 629, "seek": 385608, "start": 3878.44, "end": 3884.0, "text": " usar las t\u00e9cnicas de reducci\u00f3n de dimensionalidad por ejemplo p c a y t s n s son de las m\u00e1s comunes", "tokens": [51482, 14745, 2439, 25564, 40672, 368, 2783, 14735, 368, 5013, 694, 1966, 4580, 1515, 13358, 280, 269, 257, 288, 256, 262, 297, 262, 1872, 368, 2439, 3573, 11040, 279, 51760], "temperature": 0.0, "avg_logprob": -0.2586809414536206, "compression_ratio": 1.811808118081181, "no_speech_prob": 0.0010033148573711514}, {"id": 630, "seek": 388400, "start": 3885.0, "end": 3889.16, "text": " son t\u00e9cnicas que me permiten agarrar 300 dimensiones y bajarlas a dos para poder dibujarlo en un", "tokens": [50414, 1872, 25564, 40672, 631, 385, 13423, 268, 623, 2284, 289, 6641, 10139, 279, 288, 23589, 6843, 296, 257, 4491, 1690, 8152, 46621, 19457, 465, 517, 50622], "temperature": 0.0, "avg_logprob": -0.268202273050944, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.0003551761037670076}, {"id": 631, "seek": 388400, "start": 3889.16, "end": 3893.44, "text": " plano entonces ac\u00e1 no llegan a ver estos son dos trabajos que hicimos en el grupo para distintos", "tokens": [50622, 40259, 13003, 23496, 572, 11234, 282, 257, 1306, 12585, 1872, 4491, 9618, 329, 631, 23697, 8372, 465, 806, 20190, 1690, 49337, 50836], "temperature": 0.0, "avg_logprob": -0.268202273050944, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.0003551761037670076}, {"id": 632, "seek": 388400, "start": 3893.44, "end": 3900.84, "text": " colecciones en bedings en distintos idiomas voy a agarrar esto ahora s\u00ed s\u00ed queda bien entonces en", "tokens": [50836, 45139, 35560, 465, 2901, 1109, 465, 49337, 18014, 7092, 7552, 257, 623, 2284, 289, 7433, 9923, 8600, 8600, 23314, 3610, 13003, 465, 51206], "temperature": 0.0, "avg_logprob": -0.268202273050944, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.0003551761037670076}, {"id": 633, "seek": 388400, "start": 3900.84, "end": 3906.2, "text": " este tenemos un trabajo hecho para el espa\u00f1ol son vectores de palabras en espa\u00f1ol y", "tokens": [51206, 4065, 9914, 517, 18099, 13064, 1690, 806, 31177, 1872, 1241, 349, 2706, 368, 35240, 465, 31177, 288, 51474], "temperature": 0.0, "avg_logprob": -0.268202273050944, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.0003551761037670076}, {"id": 634, "seek": 388400, "start": 3906.2, "end": 3910.2, "text": " est\u00e1n no van a llegar a verlo lo que est\u00e1n ac\u00e1 porque se ve muy chiquito pero por ejemplo ac\u00e1", "tokens": [51474, 10368, 572, 3161, 257, 24892, 257, 1306, 752, 450, 631, 10368, 23496, 4021, 369, 1241, 5323, 417, 3221, 3528, 4768, 1515, 13358, 23496, 51674], "temperature": 0.0, "avg_logprob": -0.268202273050944, "compression_ratio": 1.7292418772563176, "no_speech_prob": 0.0003551761037670076}, {"id": 635, "seek": 391020, "start": 3910.2, "end": 3916.08, "text": " aparece un cl\u00e1ster de a\u00f1os que est\u00e1n todos juntos ac\u00e1 aparecen nombres de personas que", "tokens": [50364, 37863, 517, 596, 842, 3120, 368, 11424, 631, 10368, 6321, 33868, 23496, 15004, 13037, 297, 29947, 368, 12019, 631, 50658], "temperature": 0.0, "avg_logprob": -0.2008637612865817, "compression_ratio": 1.8533834586466165, "no_speech_prob": 0.008851748891174793}, {"id": 636, "seek": 391020, "start": 3916.08, "end": 3922.72, "text": " est\u00e1n todos juntos abajo aparecen lugares per\u00fa, Uruguay, Bolivia que aparecen como cl\u00e1sterizados", "tokens": [50658, 10368, 6321, 33868, 30613, 15004, 13037, 33105, 680, 2481, 11, 9533, 13705, 320, 11, 14331, 18503, 631, 15004, 13037, 2617, 596, 842, 3120, 590, 4181, 50990], "temperature": 0.0, "avg_logprob": -0.2008637612865817, "compression_ratio": 1.8533834586466165, "no_speech_prob": 0.008851748891174793}, {"id": 637, "seek": 391020, "start": 3922.72, "end": 3927.04, "text": " todos juntos entonces uno espera que una colecci\u00f3n de vectores que haya quedado bien entrenada aparezcan", "tokens": [50990, 6321, 33868, 13003, 8526, 37862, 631, 2002, 45139, 14735, 368, 1241, 349, 2706, 631, 24693, 13617, 1573, 3610, 45069, 1538, 15004, 89, 7035, 51206], "temperature": 0.0, "avg_logprob": -0.2008637612865817, "compression_ratio": 1.8533834586466165, "no_speech_prob": 0.008851748891174793}, {"id": 638, "seek": 391020, "start": 3927.04, "end": 3932.2, "text": " como cl\u00e1sters con cosas que son sem\u00e1nticamente similares y el trabajo de la derecha es un trabajo", "tokens": [51206, 2617, 596, 842, 10130, 416, 12218, 631, 1872, 4361, 27525, 23653, 1034, 7371, 495, 288, 806, 18099, 368, 635, 15969, 4413, 785, 517, 18099, 51464], "temperature": 0.0, "avg_logprob": -0.2008637612865817, "compression_ratio": 1.8533834586466165, "no_speech_prob": 0.008851748891174793}, {"id": 639, "seek": 391020, "start": 3932.2, "end": 3936.8799999999997, "text": " similar pero que est\u00e1 hecho para el Guarani y bueno ac\u00e1 se ve tambi\u00e9n m\u00e1s claro que aparecen", "tokens": [51464, 2531, 4768, 631, 3192, 13064, 1690, 806, 2694, 289, 3782, 288, 11974, 23496, 369, 1241, 6407, 3573, 16742, 631, 15004, 13037, 51698], "temperature": 0.0, "avg_logprob": -0.2008637612865817, "compression_ratio": 1.8533834586466165, "no_speech_prob": 0.008851748891174793}, {"id": 640, "seek": 393688, "start": 3936.88, "end": 3942.76, "text": " cosas como relacionadas con fechas est\u00e1n en h\u00e9roes las relacionadas con colores est\u00e1n en", "tokens": [50364, 12218, 2617, 27189, 6872, 416, 579, 41299, 10368, 465, 276, 26913, 279, 2439, 27189, 6872, 416, 1173, 2706, 10368, 465, 50658], "temperature": 0.0, "avg_logprob": -0.30314795176188153, "compression_ratio": 1.8768472906403941, "no_speech_prob": 0.0064418432302773}, {"id": 641, "seek": 393688, "start": 3942.76, "end": 3952.96, "text": " en cian las relacionadas con no se bien que dice ah\u00ed animales est\u00e1n en verde etc\u00e9tera pa\u00edses", "tokens": [50658, 465, 269, 952, 2439, 27189, 6872, 416, 572, 369, 3610, 631, 10313, 12571, 45102, 10368, 465, 29653, 5183, 526, 23833, 23070, 51168], "temperature": 0.0, "avg_logprob": -0.30314795176188153, "compression_ratio": 1.8768472906403941, "no_speech_prob": 0.0064418432302773}, {"id": 642, "seek": 393688, "start": 3952.96, "end": 3957.92, "text": " est\u00e1n en azul etc\u00e9tera como que no puede estar en esas regiones obviamente esto no es perfecto", "tokens": [51168, 10368, 465, 39580, 5183, 526, 23833, 2617, 631, 572, 8919, 8755, 465, 23388, 4458, 279, 36325, 7433, 572, 785, 2176, 78, 51416], "temperature": 0.0, "avg_logprob": -0.30314795176188153, "compression_ratio": 1.8768472906403941, "no_speech_prob": 0.0064418432302773}, {"id": 643, "seek": 393688, "start": 3957.92, "end": 3963.28, "text": " van a quedar alguna cosa por fuera etc\u00e9tera pero si uno logra ver que m\u00e1s o menos cl\u00e1steriza", "tokens": [51416, 3161, 257, 39244, 20651, 10163, 1515, 24818, 5183, 526, 23833, 4768, 1511, 8526, 3565, 424, 1306, 631, 3573, 277, 8902, 596, 842, 3120, 13427, 51684], "temperature": 0.0, "avg_logprob": -0.30314795176188153, "compression_ratio": 1.8768472906403941, "no_speech_prob": 0.0064418432302773}, {"id": 644, "seek": 396328, "start": 3963.28, "end": 3970.92, "text": " entonces tiene como cierta cierta entuici\u00f3n de que andan mejor esos vectores bien preguntas", "tokens": [50364, 13003, 7066, 2617, 39769, 1328, 39769, 1328, 948, 84, 15534, 368, 631, 293, 282, 11479, 22411, 1241, 349, 2706, 3610, 39722, 50746], "temperature": 0.0, "avg_logprob": -0.29759196017650846, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.00481336610391736}, {"id": 645, "seek": 396328, "start": 3973.48, "end": 3979.76, "text": " entonces los guerden beings fueron en definitiva una de las primeras revoluciones que ocurrieron los", "tokens": [50874, 13003, 1750, 290, 5486, 1556, 8958, 28739, 465, 28781, 5931, 2002, 368, 2439, 2886, 6985, 16908, 46649, 631, 26430, 7326, 266, 1750, 51188], "temperature": 0.0, "avg_logprob": -0.29759196017650846, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.00481336610391736}, {"id": 646, "seek": 396328, "start": 3979.76, "end": 3986.32, "text": " \u00faltimos a\u00f1os en lo cual es pln y posible que despu\u00e9s se empezaron a utilizar arquitecturas de", "tokens": [51188, 33013, 11424, 465, 450, 10911, 785, 499, 77, 288, 26644, 631, 15283, 369, 18730, 6372, 257, 24060, 40258, 5739, 12907, 368, 51516], "temperature": 0.0, "avg_logprob": -0.29759196017650846, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.00481336610391736}, {"id": 647, "seek": 396328, "start": 3986.32, "end": 3990.76, "text": " redes m\u00e1s complejas o sea gracias a que tenemos en bedings y decimos puedo representar una", "tokens": [51516, 16762, 3573, 44424, 19221, 277, 4158, 16611, 257, 631, 9914, 465, 2901, 1109, 288, 979, 8372, 21612, 2906, 289, 2002, 51738], "temperature": 0.0, "avg_logprob": -0.29759196017650846, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.00481336610391736}, {"id": 648, "seek": 399076, "start": 3990.76, "end": 3995.0, "text": " palabra como un vector de 30 dimensiones ese vector de 30 dimensiones que son n\u00fameros reales", "tokens": [50364, 31702, 2617, 517, 8062, 368, 2217, 10139, 279, 10167, 8062, 368, 2217, 10139, 279, 631, 1872, 36545, 957, 279, 50576], "temperature": 0.0, "avg_logprob": -0.22264403003757283, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0029738815501332283}, {"id": 649, "seek": 399076, "start": 3995.0, "end": 4000.1600000000003, "text": " se lo pueden chufar como entrada a una red neuronal y puedo obtener cosas m\u00e1s complicadas a m\u00ed me", "tokens": [50576, 369, 450, 14714, 417, 2947, 289, 2617, 37119, 257, 2002, 2182, 12087, 21523, 288, 21612, 28326, 260, 12218, 3573, 16060, 6872, 257, 14692, 385, 50834], "temperature": 0.0, "avg_logprob": -0.22264403003757283, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0029738815501332283}, {"id": 650, "seek": 399076, "start": 4000.1600000000003, "end": 4006.6800000000003, "text": " interesaba de hace un rato dijimos tener representaciones de palabras pero adem\u00e1s de oraciones o de", "tokens": [50834, 20157, 5509, 368, 10032, 517, 367, 2513, 47709, 8372, 11640, 2906, 9188, 368, 35240, 4768, 21251, 368, 420, 9188, 277, 368, 51160], "temperature": 0.0, "avg_logprob": -0.22264403003757283, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0029738815501332283}, {"id": 651, "seek": 399076, "start": 4006.6800000000003, "end": 4012.48, "text": " tweets o de documentos enteros y bueno por lo menos yo tengo representaci\u00f3n de palabras usando", "tokens": [51160, 25671, 277, 368, 4166, 329, 3242, 329, 288, 11974, 1515, 450, 8902, 5290, 13989, 2906, 3482, 368, 35240, 29798, 51450], "temperature": 0.0, "avg_logprob": -0.22264403003757283, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0029738815501332283}, {"id": 652, "seek": 399076, "start": 4012.48, "end": 4018.0, "text": " guerden bedings como que eso est\u00e1 bastante bien resuelto y gracias a que ahora tengo guerden", "tokens": [51450, 290, 5486, 1556, 2901, 1109, 2617, 631, 7287, 3192, 14651, 3610, 725, 3483, 1353, 288, 16611, 257, 631, 9923, 13989, 290, 5486, 1556, 51726], "temperature": 0.0, "avg_logprob": -0.22264403003757283, "compression_ratio": 1.7992565055762082, "no_speech_prob": 0.0029738815501332283}, {"id": 653, "seek": 401800, "start": 4018.0, "end": 4022.48, "text": " bedings para usar arquitecturas m\u00e1s complejas como las redes convolucionales las redes", "tokens": [50364, 2901, 1109, 1690, 14745, 40258, 5739, 12907, 3573, 44424, 19221, 2617, 2439, 16762, 3754, 401, 1311, 1966, 279, 2439, 16762, 50588], "temperature": 0.0, "avg_logprob": -0.3203946163779811, "compression_ratio": 1.776, "no_speech_prob": 0.002214128617197275}, {"id": 654, "seek": 401800, "start": 4022.48, "end": 4028.68, "text": " lstm las redes tipo transformers los transformers son lo que m\u00e1s se utiliza bien d\u00eda pero adem\u00e1s", "tokens": [50588, 287, 372, 76, 2439, 16762, 9746, 4088, 433, 1750, 4088, 433, 1872, 450, 631, 3573, 369, 4976, 13427, 3610, 12271, 4768, 21251, 50898], "temperature": 0.0, "avg_logprob": -0.3203946163779811, "compression_ratio": 1.776, "no_speech_prob": 0.002214128617197275}, {"id": 655, "seek": 401800, "start": 4028.68, "end": 4032.76, "text": " puedo hacer otra cosa con los en bedings algo un poco m\u00e1s simple pero que a su vez me sirve para", "tokens": [50898, 21612, 6720, 13623, 10163, 416, 1750, 465, 2901, 1109, 8655, 517, 10639, 3573, 2199, 4768, 631, 257, 459, 5715, 385, 4735, 303, 1690, 51102], "temperature": 0.0, "avg_logprob": -0.3203946163779811, "compression_ratio": 1.776, "no_speech_prob": 0.002214128617197275}, {"id": 656, "seek": 401800, "start": 4034.36, "end": 4037.36, "text": " resolver otras problemas y es usar la t\u00e9cnica de centr\u00f3ide", "tokens": [51182, 34480, 20244, 20720, 288, 785, 14745, 635, 45411, 368, 1489, 11721, 482, 51332], "temperature": 0.0, "avg_logprob": -0.3203946163779811, "compression_ratio": 1.776, "no_speech_prob": 0.002214128617197275}, {"id": 657, "seek": 401800, "start": 4038.84, "end": 4043.16, "text": " que es as\u00ed esta les va a servir en la tarea salvo que quieran entrenar una red m\u00e1s compleja que", "tokens": [51406, 631, 785, 8582, 5283, 1512, 2773, 257, 29463, 465, 635, 256, 35425, 1845, 3080, 631, 23572, 282, 45069, 289, 2002, 2182, 3573, 44424, 2938, 631, 51622], "temperature": 0.0, "avg_logprob": -0.3203946163779811, "compression_ratio": 1.776, "no_speech_prob": 0.002214128617197275}, {"id": 658, "seek": 404316, "start": 4043.16, "end": 4048.7999999999997, "text": " tambi\u00e9n son bienvenidos si quieren entrenar una lstm un transformer pero el centr\u00f3ide es una", "tokens": [50364, 6407, 1872, 3610, 40668, 1511, 36706, 45069, 289, 2002, 287, 372, 76, 517, 4088, 260, 4768, 806, 1489, 11721, 482, 785, 2002, 50646], "temperature": 0.0, "avg_logprob": -0.24867970148722332, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.007059324532747269}, {"id": 659, "seek": 404316, "start": 4048.7999999999997, "end": 4054.2, "text": " t\u00e9cnica es muy sencilla supongamos que yo tengo mi mi capa en bedings que tiene bueno dice quesos", "tokens": [50646, 45411, 785, 5323, 3151, 66, 5291, 9331, 556, 2151, 631, 5290, 13989, 2752, 2752, 1410, 64, 465, 2901, 1109, 631, 7066, 11974, 10313, 421, 279, 329, 50916], "temperature": 0.0, "avg_logprob": -0.24867970148722332, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.007059324532747269}, {"id": 660, "seek": 404316, "start": 4054.2, "end": 4060.04, "text": " representas y hamburguesas representas y perro es as\u00ed gato es as\u00ed etc\u00e9tera tengo", "tokens": [50916, 2906, 296, 288, 25172, 5476, 1247, 296, 2906, 296, 288, 680, 340, 785, 8582, 290, 2513, 785, 8582, 5183, 526, 23833, 13989, 51208], "temperature": 0.0, "avg_logprob": -0.24867970148722332, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.007059324532747269}, {"id": 661, "seek": 404316, "start": 4060.04, "end": 4066.2, "text": " vectores para cada palabra y tengo ahora un tweet que le quiero representar utilizando la", "tokens": [51208, 1241, 349, 2706, 1690, 8411, 31702, 288, 13989, 9923, 517, 15258, 631, 476, 16811, 2906, 289, 19906, 1806, 635, 51516], "temperature": 0.0, "avg_logprob": -0.24867970148722332, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.007059324532747269}, {"id": 662, "seek": 404316, "start": 4066.2, "end": 4070.56, "text": " colecci\u00f3n en bedings yo simplemente puedo agarrar todas las palabras del tweet buscar todos los", "tokens": [51516, 45139, 14735, 465, 2901, 1109, 5290, 33190, 21612, 623, 2284, 289, 10906, 2439, 35240, 1103, 15258, 26170, 6321, 1750, 51734], "temperature": 0.0, "avg_logprob": -0.24867970148722332, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.007059324532747269}, {"id": 663, "seek": 407056, "start": 4070.56, "end": 4075.64, "text": " vectores correspondientes y hacer el promedio a eso se llama hacer un centr\u00f3ide de todos los", "tokens": [50364, 1241, 349, 2706, 6805, 20135, 288, 6720, 806, 2234, 292, 1004, 257, 7287, 369, 23272, 6720, 517, 1489, 11721, 482, 368, 6321, 1750, 50618], "temperature": 0.0, "avg_logprob": -0.2574106463949189, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.015723941847682}, {"id": 664, "seek": 407056, "start": 4075.64, "end": 4081.72, "text": " en bedings del tweet y uno dice est\u00e1 apreciado el promedio de perro gato no o sea el tweet dice", "tokens": [50618, 465, 2901, 1109, 1103, 15258, 288, 8526, 10313, 3192, 1882, 3326, 1573, 806, 2234, 292, 1004, 368, 680, 340, 290, 2513, 572, 277, 4158, 806, 15258, 10313, 50922], "temperature": 0.0, "avg_logprob": -0.2574106463949189, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.015723941847682}, {"id": 665, "seek": 407056, "start": 4081.72, "end": 4087.88, "text": " este no me gust\u00f3 la pel\u00edcula se hago el promedio no me gust\u00f3 la pel\u00edcula y a\u00fan promedio todos", "tokens": [50922, 4065, 572, 385, 9679, 812, 635, 40154, 369, 38721, 806, 2234, 292, 1004, 572, 385, 9679, 812, 635, 40154, 288, 31676, 2234, 292, 1004, 6321, 51230], "temperature": 0.0, "avg_logprob": -0.2574106463949189, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.015723941847682}, {"id": 666, "seek": 407056, "start": 4087.88, "end": 4094.16, "text": " en bedin mediar papa frita pero sin embargo funciona bastante bien es como un poco antintuitivo pero", "tokens": [51230, 465, 2901, 259, 1205, 9448, 31015, 431, 2786, 4768, 3343, 23955, 26210, 14651, 3610, 785, 2617, 517, 10639, 2511, 686, 1983, 6340, 4768, 51544], "temperature": 0.0, "avg_logprob": -0.2574106463949189, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.015723941847682}, {"id": 667, "seek": 407056, "start": 4094.16, "end": 4099.4, "text": " hacer el promedio de todas esas 300 dimensiones de las distintas palabras despu\u00e9s yo utilizo eso", "tokens": [51544, 6720, 806, 2234, 292, 1004, 368, 10906, 23388, 6641, 10139, 279, 368, 2439, 31489, 296, 35240, 15283, 5290, 4976, 19055, 7287, 51806], "temperature": 0.0, "avg_logprob": -0.2574106463949189, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.015723941847682}, {"id": 668, "seek": 409940, "start": 4099.4, "end": 4103.879999999999, "text": " como entrada para otro otro sistema de clasificaci\u00f3n no s\u00f3lo una rena urnal sino que ah\u00ed ya", "tokens": [50364, 2617, 37119, 1690, 11921, 11921, 13245, 368, 596, 296, 40802, 572, 22885, 2002, 319, 629, 4038, 4660, 18108, 631, 12571, 2478, 50588], "temperature": 0.0, "avg_logprob": -0.2648764237113621, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0026894928887486458}, {"id": 669, "seek": 409940, "start": 4103.879999999999, "end": 4108.5199999999995, "text": " puede utilizar otro tipo de cosas como su proyecto en machines o regresi\u00f3n log\u00edstica y", "tokens": [50588, 8919, 24060, 11921, 9746, 368, 12218, 2617, 459, 32285, 465, 8379, 277, 47108, 2560, 3565, 19512, 2262, 288, 50820], "temperature": 0.0, "avg_logprob": -0.2648764237113621, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0026894928887486458}, {"id": 670, "seek": 409940, "start": 4108.5199999999995, "end": 4112.839999999999, "text": " anda bastante bien o sea es como extra\u00f1o pero sobre todo para el problema de an\u00e1lisis de", "tokens": [50820, 21851, 14651, 3610, 277, 4158, 785, 2617, 2857, 7716, 4768, 5473, 5149, 1690, 806, 12395, 368, 44113, 28436, 368, 51036], "temperature": 0.0, "avg_logprob": -0.2648764237113621, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0026894928887486458}, {"id": 671, "seek": 409940, "start": 4112.839999999999, "end": 4118.16, "text": " sentimiento anda bastante bien bueno esa es la t\u00e9cnica del centr\u00f3ide es una t\u00e9cnica f\u00e1cil de decir", "tokens": [51036, 2279, 14007, 21851, 14651, 3610, 11974, 11342, 785, 635, 45411, 1103, 1489, 11721, 482, 785, 2002, 45411, 17474, 368, 10235, 51302], "temperature": 0.0, "avg_logprob": -0.2648764237113621, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0026894928887486458}, {"id": 672, "seek": 409940, "start": 4118.16, "end": 4123.92, "text": " si yo tengo una colecci\u00f3n en bedings puedo hacerme en bedings de oraciones o en bedings de textos", "tokens": [51302, 1511, 5290, 13989, 2002, 45139, 14735, 465, 2901, 1109, 21612, 46093, 31081, 465, 2901, 1109, 368, 420, 9188, 277, 465, 2901, 1109, 368, 2487, 329, 51590], "temperature": 0.0, "avg_logprob": -0.2648764237113621, "compression_ratio": 1.7564575645756457, "no_speech_prob": 0.0026894928887486458}, {"id": 673, "seek": 412392, "start": 4123.92, "end": 4131.4800000000005, "text": " un poco m\u00e1s grandes simplemente promediendo los en bedings que tengo bien entonces ahora lo que", "tokens": [50364, 517, 10639, 3573, 16640, 33190, 2234, 292, 7304, 1750, 465, 2901, 1109, 631, 13989, 3610, 13003, 9923, 450, 631, 50742], "temperature": 0.0, "avg_logprob": -0.15362824334038627, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.0015892918454483151}, {"id": 674, "seek": 412392, "start": 4131.4800000000005, "end": 4137.88, "text": " vamos a ver en el resto de la clase en unos minutos son ejemplos de c\u00f3mo funcionan estas", "tokens": [50742, 5295, 257, 1306, 465, 806, 28247, 368, 635, 44578, 465, 17780, 19421, 1872, 10012, 5895, 329, 368, 12826, 14186, 282, 13897, 51062], "temperature": 0.0, "avg_logprob": -0.15362824334038627, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.0015892918454483151}, {"id": 675, "seek": 412392, "start": 4137.88, "end": 4142.28, "text": " arquitecturas m\u00e1s complejas que puede utilizar gracias a que tengo en bedings no las vamos a", "tokens": [51062, 40258, 5739, 12907, 3573, 44424, 19221, 631, 8919, 24060, 16611, 257, 631, 13989, 465, 2901, 1109, 572, 2439, 5295, 257, 51282], "temperature": 0.0, "avg_logprob": -0.15362824334038627, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.0015892918454483151}, {"id": 676, "seek": 412392, "start": 4142.28, "end": 4146.32, "text": " ver en profundidad sino que simplemente vamos a pasar por arriba pero es una idea para ver qu\u00e9 clase", "tokens": [51282, 1306, 465, 40958, 4580, 18108, 631, 33190, 5295, 257, 25344, 1515, 28469, 4768, 785, 2002, 1558, 1690, 1306, 8057, 44578, 51484], "temperature": 0.0, "avg_logprob": -0.15362824334038627, "compression_ratio": 1.7285067873303168, "no_speech_prob": 0.0015892918454483151}, {"id": 677, "seek": 414632, "start": 4146.32, "end": 4154.639999999999, "text": " de cosas se pueden hacer y empecemos por las convolutivas las redes tipo CNN se llaman", "tokens": [50364, 368, 12218, 369, 14714, 6720, 288, 846, 494, 38173, 1515, 2439, 3754, 2308, 24759, 2439, 16762, 9746, 14589, 45, 369, 4849, 6147, 50780], "temperature": 0.0, "avg_logprob": -0.207349758881789, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.005565685220062733}, {"id": 678, "seek": 414632, "start": 4154.639999999999, "end": 4160.799999999999, "text": " redes convolutivas o convolucionales y originalmente se utilizaban como para procesar im\u00e1genes o sea", "tokens": [50780, 16762, 3754, 2308, 24759, 277, 3754, 401, 1311, 1966, 279, 288, 3380, 4082, 369, 19906, 18165, 2617, 1690, 17565, 289, 566, 842, 47986, 277, 4158, 51088], "temperature": 0.0, "avg_logprob": -0.207349758881789, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.005565685220062733}, {"id": 679, "seek": 414632, "start": 4160.799999999999, "end": 4166.5199999999995, "text": " tambi\u00e9n se utilizan todav\u00eda en d\u00eda para procesar im\u00e1genes y lo que hacen es ir recorriendo como que", "tokens": [51088, 6407, 369, 19906, 282, 28388, 465, 12271, 1690, 17565, 289, 566, 842, 47986, 288, 450, 631, 27434, 785, 3418, 850, 284, 470, 3999, 2617, 631, 51374], "temperature": 0.0, "avg_logprob": -0.207349758881789, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.005565685220062733}, {"id": 680, "seek": 414632, "start": 4166.5199999999995, "end": 4171.12, "text": " se aumenta una imagen en cuadraditos y lo van recorriendo digamos y despu\u00e9s obtienen como", "tokens": [51374, 369, 17128, 64, 2002, 40652, 465, 34434, 6206, 11343, 288, 450, 3161, 850, 284, 470, 3999, 36430, 288, 15283, 7464, 22461, 2617, 51604], "temperature": 0.0, "avg_logprob": -0.207349758881789, "compression_ratio": 1.7330316742081449, "no_speech_prob": 0.005565685220062733}, {"id": 681, "seek": 417112, "start": 4171.12, "end": 4177.96, "text": " informaci\u00f3n de cada uno de los cuadraditos bueno pero tambi\u00e9n se han aplicado al lenguaje y la", "tokens": [50364, 21660, 368, 8411, 8526, 368, 1750, 34434, 6206, 11343, 11974, 4768, 6407, 369, 7276, 18221, 1573, 419, 35044, 84, 11153, 288, 635, 50706], "temperature": 0.0, "avg_logprob": -0.21788771947224936, "compression_ratio": 1.8511450381679388, "no_speech_prob": 0.009366330690681934}, {"id": 682, "seek": 417112, "start": 4177.96, "end": 4182.0, "text": " forma que se aplica el lenguaje es como decir va tomando de enegramos y va viendo yo que se", "tokens": [50706, 8366, 631, 369, 25522, 2262, 806, 35044, 84, 11153, 785, 2617, 10235, 2773, 2916, 1806, 368, 465, 1146, 30227, 288, 2773, 34506, 5290, 631, 369, 50908], "temperature": 0.0, "avg_logprob": -0.21788771947224936, "compression_ratio": 1.8511450381679388, "no_speech_prob": 0.009366330690681934}, {"id": 683, "seek": 417112, "start": 4182.0, "end": 4187.08, "text": " por ejemplo tres palabras a la vez y va obteniendo datos de cada una de las tres palabras a la vez y", "tokens": [50908, 1515, 13358, 15890, 35240, 257, 635, 5715, 288, 2773, 28326, 7304, 27721, 368, 8411, 2002, 368, 2439, 15890, 35240, 257, 635, 5715, 288, 51162], "temperature": 0.0, "avg_logprob": -0.21788771947224936, "compression_ratio": 1.8511450381679388, "no_speech_prob": 0.009366330690681934}, {"id": 684, "seek": 417112, "start": 4187.08, "end": 4195.24, "text": " despu\u00e9s con eso despu\u00e9s saca un total entonces lo interesante es que digamos puedo pasar a tener", "tokens": [51162, 15283, 416, 7287, 15283, 4899, 64, 517, 3217, 13003, 450, 36396, 785, 631, 36430, 21612, 25344, 257, 11640, 51570], "temperature": 0.0, "avg_logprob": -0.21788771947224936, "compression_ratio": 1.8511450381679388, "no_speech_prob": 0.009366330690681934}, {"id": 685, "seek": 417112, "start": 4195.24, "end": 4199.0, "text": " cosas de orden m\u00e1s grande que una palabra o sea ahora en bedes para usar una sola palabra estoy", "tokens": [51570, 12218, 368, 28615, 3573, 8883, 631, 2002, 31702, 277, 4158, 9923, 465, 2901, 279, 1690, 14745, 2002, 34162, 31702, 15796, 51758], "temperature": 0.0, "avg_logprob": -0.21788771947224936, "compression_ratio": 1.8511450381679388, "no_speech_prob": 0.009366330690681934}, {"id": 686, "seek": 419900, "start": 4199.0, "end": 4204.52, "text": " produciendo toda una variaci\u00f3n entonces tenias una pregunta bien entonces un ejemplo", "tokens": [50364, 1082, 16830, 11687, 2002, 3034, 3482, 13003, 2064, 4609, 2002, 24252, 3610, 13003, 517, 13358, 50640], "temperature": 0.0, "avg_logprob": -0.2235969478248531, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0022922633215785027}, {"id": 687, "seek": 419900, "start": 4204.52, "end": 4209.36, "text": " como funciona esto supongamos que estoy tratando de clasificar tweets y digo la pel\u00edcula fue", "tokens": [50640, 2617, 26210, 7433, 9331, 556, 2151, 631, 15796, 21507, 1806, 368, 596, 296, 25625, 25671, 288, 22990, 635, 40154, 9248, 50882], "temperature": 0.0, "avg_logprob": -0.2235969478248531, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0022922633215785027}, {"id": 688, "seek": 419900, "start": 4209.36, "end": 4215.36, "text": " muy aburrida yo me puedo construir una red neuronal de tipo convolutiva que lo que va a ser es decir", "tokens": [50882, 5323, 410, 374, 81, 2887, 5290, 385, 21612, 38445, 2002, 2182, 12087, 21523, 368, 9746, 3754, 2308, 5931, 631, 450, 631, 2773, 257, 816, 785, 10235, 51182], "temperature": 0.0, "avg_logprob": -0.2235969478248531, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0022922633215785027}, {"id": 689, "seek": 419900, "start": 4215.36, "end": 4221.44, "text": " bueno a los embeddings de la de a tres palabras los voy tomando de a tres palabras considero", "tokens": [51182, 11974, 257, 1750, 12240, 29432, 368, 635, 368, 257, 15890, 35240, 1750, 7552, 2916, 1806, 368, 257, 15890, 35240, 1949, 78, 51486], "temperature": 0.0, "avg_logprob": -0.2235969478248531, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0022922633215785027}, {"id": 690, "seek": 419900, "start": 4221.44, "end": 4226.88, "text": " los embeddings de la pel\u00edcula fue y a esos tres embeddings se los paso a una red a esa unidad", "tokens": [51486, 1750, 12240, 29432, 368, 635, 40154, 9248, 288, 257, 22411, 15890, 12240, 29432, 369, 1750, 29212, 257, 2002, 2182, 257, 11342, 517, 4580, 51758], "temperature": 0.0, "avg_logprob": -0.2235969478248531, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.0022922633215785027}, {"id": 691, "seek": 422688, "start": 4226.88, "end": 4232.24, "text": " convolutiva que lo que va a ser es mirar estas tres palabras y tratar de sacar informaci\u00f3n de", "tokens": [50364, 3754, 2308, 5931, 631, 450, 631, 2773, 257, 816, 785, 3149, 289, 13897, 15890, 35240, 288, 42549, 368, 43823, 21660, 368, 50632], "temperature": 0.0, "avg_logprob": -0.12722402719350961, "compression_ratio": 1.9838709677419355, "no_speech_prob": 0.009750459343194962}, {"id": 692, "seek": 422688, "start": 4232.24, "end": 4237.64, "text": " las tres y devolverme una cosa que tenga cierto tama\u00f1o fijo y despu\u00e9s se va a mover la ventana y en", "tokens": [50632, 2439, 15890, 288, 1905, 401, 331, 1398, 2002, 10163, 631, 36031, 28558, 45342, 7716, 283, 24510, 288, 15283, 369, 2773, 257, 39945, 635, 6931, 2095, 288, 465, 50902], "temperature": 0.0, "avg_logprob": -0.12722402719350961, "compression_ratio": 1.9838709677419355, "no_speech_prob": 0.009750459343194962}, {"id": 693, "seek": 422688, "start": 4237.64, "end": 4242.24, "text": " vez de la pel\u00edcula fue va a considerar las palabras pel\u00edculas fue muy y de vuelta lo va a pasar por", "tokens": [50902, 5715, 368, 635, 40154, 9248, 2773, 257, 1949, 289, 2439, 35240, 31810, 296, 9248, 5323, 288, 368, 41542, 450, 2773, 257, 25344, 1515, 51132], "temperature": 0.0, "avg_logprob": -0.12722402719350961, "compression_ratio": 1.9838709677419355, "no_speech_prob": 0.009750459343194962}, {"id": 694, "seek": 422688, "start": 4242.24, "end": 4246.56, "text": " esa subred y va tratar de sacar salidas y despu\u00e9s fue muy aburrida lo va a pasar por la misma subred", "tokens": [51132, 11342, 1422, 986, 288, 2773, 42549, 368, 43823, 1845, 11382, 288, 15283, 9248, 5323, 410, 374, 81, 2887, 450, 2773, 257, 25344, 1515, 635, 24946, 1422, 986, 51348], "temperature": 0.0, "avg_logprob": -0.12722402719350961, "compression_ratio": 1.9838709677419355, "no_speech_prob": 0.009750459343194962}, {"id": 695, "seek": 422688, "start": 4246.56, "end": 4252.16, "text": " tratar de sacar salidas despu\u00e9s voy a tener una capa que dice bueno de todas estas salidas", "tokens": [51348, 42549, 368, 43823, 1845, 11382, 15283, 7552, 257, 11640, 2002, 1410, 64, 631, 10313, 11974, 368, 10906, 13897, 1845, 11382, 51628], "temperature": 0.0, "avg_logprob": -0.12722402719350961, "compression_ratio": 1.9838709677419355, "no_speech_prob": 0.009750459343194962}, {"id": 696, "seek": 425216, "start": 4252.16, "end": 4258.44, "text": " intermedias que tuve obtengo los m\u00e1ximos y esos m\u00e1ximos los uso para calcular mi salida que", "tokens": [50364, 15184, 296, 631, 2604, 303, 28326, 1571, 1750, 31031, 329, 288, 22411, 31031, 329, 1750, 22728, 1690, 2104, 17792, 2752, 1845, 2887, 631, 50678], "temperature": 0.0, "avg_logprob": -0.2425892782993004, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.005053531378507614}, {"id": 697, "seek": 425216, "start": 4258.44, "end": 4264.76, "text": " mi salida final ser\u00eda positivo o negativo en el otro o no no estas redes esta capa convolutiva", "tokens": [50678, 2752, 1845, 2887, 2572, 23679, 44710, 277, 2485, 18586, 465, 806, 11921, 277, 572, 572, 13897, 16762, 5283, 1410, 64, 3754, 2308, 5931, 50994], "temperature": 0.0, "avg_logprob": -0.2425892782993004, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.005053531378507614}, {"id": 698, "seek": 425216, "start": 4264.76, "end": 4269.44, "text": " que ah\u00ed en el medio parece como capa convolutiva es entonces a sus redes que estoy viendo ah\u00ed en", "tokens": [50994, 631, 12571, 465, 806, 22123, 14120, 2617, 1410, 64, 3754, 2308, 5931, 785, 13003, 257, 3291, 16762, 631, 15796, 34506, 12571, 465, 51228], "temperature": 0.0, "avg_logprob": -0.2425892782993004, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.005053531378507614}, {"id": 699, "seek": 425216, "start": 4269.44, "end": 4273.84, "text": " realidad son los mismos pesos no es como la misma que se va moviendo y me va dando resultados distintos", "tokens": [51228, 25635, 1872, 1750, 47458, 33204, 572, 785, 2617, 635, 24946, 631, 369, 2773, 2402, 7304, 288, 385, 2773, 29854, 36796, 49337, 51448], "temperature": 0.0, "avg_logprob": -0.2425892782993004, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.005053531378507614}, {"id": 700, "seek": 425216, "start": 4274.72, "end": 4279.92, "text": " bien entonces lo bueno que tiene es que yo agarr\u00f3 todo una entrada que son muchas palabras y me", "tokens": [51492, 3610, 13003, 450, 11974, 631, 7066, 785, 631, 5290, 623, 2284, 812, 5149, 2002, 37119, 631, 1872, 16072, 35240, 288, 385, 51752], "temperature": 0.0, "avg_logprob": -0.2425892782993004, "compression_ratio": 1.8735632183908046, "no_speech_prob": 0.005053531378507614}, {"id": 701, "seek": 427992, "start": 4279.92, "end": 4285.52, "text": " va a dar una salida \u00fanica digamos condensa todas las palabras se queda como con las digamos las", "tokens": [50364, 2773, 257, 4072, 2002, 1845, 2887, 30104, 36430, 2224, 23364, 10906, 2439, 35240, 369, 23314, 2617, 416, 2439, 36430, 2439, 50644], "temperature": 0.0, "avg_logprob": -0.19689846789743018, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.0023680655285716057}, {"id": 702, "seek": 427992, "start": 4285.52, "end": 4290.84, "text": " dimensiones m\u00e1ximas de cada una que le quede m\u00e1s le interesen y con eso calcula una salida bien esa es", "tokens": [50644, 10139, 279, 31031, 296, 368, 8411, 2002, 631, 476, 421, 4858, 3573, 476, 728, 17403, 288, 416, 7287, 4322, 64, 2002, 1845, 2887, 3610, 11342, 785, 50910], "temperature": 0.0, "avg_logprob": -0.19689846789743018, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.0023680655285716057}, {"id": 703, "seek": 427992, "start": 4290.84, "end": 4299.32, "text": " la red tipo convolutiva las redes el STM pertenecen a un grupo m\u00e1s grande de redes que se llama", "tokens": [50910, 635, 2182, 9746, 3754, 2308, 5931, 2439, 16762, 806, 4904, 44, 680, 1147, 3045, 268, 257, 517, 20190, 3573, 8883, 368, 16762, 631, 369, 23272, 51334], "temperature": 0.0, "avg_logprob": -0.19689846789743018, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.0023680655285716057}, {"id": 704, "seek": 427992, "start": 4299.32, "end": 4304.76, "text": " las redes recurrentes que significa son redes con memoria que van mirando una cada palabra a la", "tokens": [51334, 2439, 16762, 18680, 1753, 279, 631, 19957, 1872, 16762, 416, 1334, 8172, 631, 3161, 3149, 1806, 2002, 8411, 31702, 257, 635, 51606], "temperature": 0.0, "avg_logprob": -0.19689846789743018, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.0023680655285716057}, {"id": 705, "seek": 427992, "start": 4304.76, "end": 4309.2, "text": " vez y van recordando lo que viene hasta el momento entonces esto me sirve para obtener una salida final", "tokens": [51606, 5715, 288, 3161, 2136, 1806, 450, 631, 19561, 10764, 806, 9333, 13003, 7433, 385, 4735, 303, 1690, 28326, 260, 2002, 1845, 2887, 2572, 51828], "temperature": 0.0, "avg_logprob": -0.19689846789743018, "compression_ratio": 1.8308823529411764, "no_speech_prob": 0.0023680655285716057}, {"id": 706, "seek": 430920, "start": 4309.2, "end": 4313.72, "text": " o tambi\u00e9n para obtener salidas por palabras entonces vamos a ver c\u00f3mo funciona de estas", "tokens": [50364, 277, 6407, 1690, 28326, 260, 1845, 11382, 1515, 35240, 13003, 5295, 257, 1306, 12826, 26210, 368, 13897, 50590], "temperature": 0.0, "avg_logprob": -0.18173871501799552, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.0003179390914738178}, {"id": 707, "seek": 430920, "start": 4315.32, "end": 4321.08, "text": " esto como una especie de diagrama de c\u00f3mo ser\u00eda una una red recurrente similar a la que ve\u00edamos", "tokens": [50670, 7433, 2617, 2002, 49368, 368, 10686, 64, 368, 12826, 23679, 2002, 2002, 2182, 18680, 14772, 2531, 257, 635, 631, 1241, 16275, 50958], "temperature": 0.0, "avg_logprob": -0.18173871501799552, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.0003179390914738178}, {"id": 708, "seek": 430920, "start": 4321.08, "end": 4326.2, "text": " hace un rato digamos en capas pero ahora yo voy a tener una capa que tiene un enlace ese asimismo", "tokens": [50958, 10032, 517, 367, 2513, 36430, 465, 1410, 296, 4768, 9923, 5290, 7552, 257, 11640, 2002, 1410, 64, 631, 7066, 517, 465, 19837, 10167, 382, 332, 6882, 51214], "temperature": 0.0, "avg_logprob": -0.18173871501799552, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.0003179390914738178}, {"id": 709, "seek": 430920, "start": 4326.2, "end": 4330.8, "text": " digamos todas las neuronas de esa capa van a tener un enlace de vuelto de vuelta a ese asimismo se", "tokens": [51214, 36430, 10906, 2439, 34090, 296, 368, 11342, 1410, 64, 3161, 257, 11640, 517, 465, 19837, 368, 20126, 1353, 368, 41542, 257, 10167, 382, 332, 6882, 369, 51444], "temperature": 0.0, "avg_logprob": -0.18173871501799552, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.0003179390914738178}, {"id": 710, "seek": 430920, "start": 4330.8, "end": 4335.84, "text": " llama capa recurrente y bueno despu\u00e9s voy a tener una capa de salida entonces cuando yo voy a", "tokens": [51444, 23272, 1410, 64, 18680, 14772, 288, 11974, 15283, 7552, 257, 11640, 2002, 1410, 64, 368, 1845, 2887, 13003, 7767, 5290, 7552, 257, 51696], "temperature": 0.0, "avg_logprob": -0.18173871501799552, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.0003179390914738178}, {"id": 711, "seek": 433584, "start": 4335.84, "end": 4340.92, "text": " ver c\u00f3mo funciona eso con un tweet que quiero clasificar como la pel\u00edcula fue muy aburrida funcionar\u00eda", "tokens": [50364, 1306, 12826, 26210, 7287, 416, 517, 15258, 631, 16811, 596, 296, 25625, 2617, 635, 40154, 9248, 5323, 410, 374, 81, 2887, 14186, 21178, 50618], "temperature": 0.0, "avg_logprob": -0.14653087797619047, "compression_ratio": 2.0277777777777777, "no_speech_prob": 0.010385039262473583}, {"id": 712, "seek": 433584, "start": 4340.92, "end": 4345.26, "text": " esta manera yo digo bueno primero agarr\u00f3 la palabra a la el embedding de la palabra a la se lo", "tokens": [50618, 5283, 13913, 5290, 22990, 11974, 21289, 623, 2284, 812, 635, 31702, 257, 635, 806, 12240, 3584, 368, 635, 31702, 257, 635, 369, 450, 50835], "temperature": 0.0, "avg_logprob": -0.14653087797619047, "compression_ratio": 2.0277777777777777, "no_speech_prob": 0.010385039262473583}, {"id": 713, "seek": 433584, "start": 4345.26, "end": 4351.56, "text": " paso a la red y despu\u00e9s voy a agarrar el embedding de la palabra pel\u00edcula y se lo paso de vuelta a la", "tokens": [50835, 29212, 257, 635, 2182, 288, 15283, 7552, 257, 623, 2284, 289, 806, 12240, 3584, 368, 635, 31702, 40154, 288, 369, 450, 29212, 368, 41542, 257, 635, 51150], "temperature": 0.0, "avg_logprob": -0.14653087797619047, "compression_ratio": 2.0277777777777777, "no_speech_prob": 0.010385039262473583}, {"id": 714, "seek": 433584, "start": 4351.56, "end": 4356.64, "text": " red pero esta vez adem\u00e1s de poner el embedding de la palabra pel\u00edcula voy a poner tambi\u00e9n la salida", "tokens": [51150, 2182, 4768, 5283, 5715, 21251, 368, 19149, 806, 12240, 3584, 368, 635, 31702, 40154, 7552, 257, 19149, 6407, 635, 1845, 2887, 51404], "temperature": 0.0, "avg_logprob": -0.14653087797619047, "compression_ratio": 2.0277777777777777, "no_speech_prob": 0.010385039262473583}, {"id": 715, "seek": 433584, "start": 4356.64, "end": 4363.64, "text": " del paso anterior entonces esto va consumiendo una palabra a la vez y siempre consumiendo la salida de", "tokens": [51404, 1103, 29212, 22272, 13003, 7433, 2773, 3978, 7304, 2002, 31702, 257, 635, 5715, 288, 12758, 3978, 7304, 635, 1845, 2887, 368, 51754], "temperature": 0.0, "avg_logprob": -0.14653087797619047, "compression_ratio": 2.0277777777777777, "no_speech_prob": 0.010385039262473583}, {"id": 716, "seek": 436364, "start": 4363.64, "end": 4370.68, "text": " la etapa anterior entonces va consumiendo la pel\u00edcula fue muy aburrida cuando lleg\u00f3 aburrida ya", "tokens": [50364, 635, 1030, 7961, 22272, 13003, 2773, 3978, 7304, 635, 40154, 9248, 5323, 410, 374, 81, 2887, 7767, 46182, 410, 374, 81, 2887, 2478, 50716], "temperature": 0.0, "avg_logprob": -0.22723586960594253, "compression_ratio": 1.7706422018348624, "no_speech_prob": 0.0014372674049809575}, {"id": 717, "seek": 436364, "start": 4370.68, "end": 4376.8, "text": " consumi\u00f3 la salida de todas las capas anteriores y la palabra nueva y ah\u00ed es como que la salida de", "tokens": [50716, 3978, 7138, 635, 1845, 2887, 368, 10906, 2439, 1410, 296, 364, 34345, 2706, 288, 635, 31702, 28963, 288, 12571, 785, 2617, 631, 635, 1845, 2887, 368, 51022], "temperature": 0.0, "avg_logprob": -0.22723586960594253, "compression_ratio": 1.7706422018348624, "no_speech_prob": 0.0014372674049809575}, {"id": 718, "seek": 436364, "start": 4376.8, "end": 4380.360000000001, "text": " ese \u00faltimo paso ya medio tiene como una especie de versi\u00f3n condensada de todo lo que era la", "tokens": [51022, 10167, 21013, 29212, 2478, 22123, 7066, 2617, 2002, 49368, 368, 47248, 2224, 694, 1538, 368, 5149, 450, 631, 4249, 635, 51200], "temperature": 0.0, "avg_logprob": -0.22723586960594253, "compression_ratio": 1.7706422018348624, "no_speech_prob": 0.0014372674049809575}, {"id": 719, "seek": 436364, "start": 4380.360000000001, "end": 4386.08, "text": " elaboraci\u00f3n y ah\u00ed con esos \u00faltimos pesos calculo la salida positivo, negativo, neutro o no", "tokens": [51200, 16298, 3482, 288, 12571, 416, 22411, 33013, 33204, 4322, 78, 635, 1845, 2887, 44710, 11, 2485, 18586, 11, 7989, 340, 277, 572, 51486], "temperature": 0.0, "avg_logprob": -0.22723586960594253, "compression_ratio": 1.7706422018348624, "no_speech_prob": 0.0014372674049809575}, {"id": 720, "seek": 438608, "start": 4387.08, "end": 4394.72, "text": " adem\u00e1s si yo quisiera podr\u00eda ir sacando para ir sacando los pesos de cada una de las salidas", "tokens": [50414, 21251, 1511, 5290, 37945, 10609, 27246, 3418, 4899, 1806, 1690, 3418, 4899, 1806, 1750, 33204, 368, 8411, 2002, 368, 2439, 1845, 11382, 50796], "temperature": 0.0, "avg_logprob": -0.26088627597741915, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.009755238890647888}, {"id": 721, "seek": 438608, "start": 4394.72, "end": 4398.76, "text": " entonces ah\u00ed tendr\u00eda como una salida por palabra entonces esto podr\u00eda servir por ejemplo para", "tokens": [50796, 13003, 12571, 3928, 37183, 2617, 2002, 1845, 2887, 1515, 31702, 13003, 7433, 27246, 29463, 1515, 13358, 1690, 50998], "temperature": 0.0, "avg_logprob": -0.26088627597741915, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.009755238890647888}, {"id": 722, "seek": 438608, "start": 4398.76, "end": 4403.12, "text": " los problemas de clasificaci\u00f3n de secuencia que ve\u00edamos la despasada bueno con una red de estetilo se", "tokens": [50998, 1750, 20720, 368, 596, 296, 40802, 368, 907, 47377, 631, 1241, 16275, 635, 730, 20990, 1538, 11974, 416, 2002, 2182, 368, 871, 302, 10720, 369, 51216], "temperature": 0.0, "avg_logprob": -0.26088627597741915, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.009755238890647888}, {"id": 723, "seek": 438608, "start": 4403.12, "end": 4406.72, "text": " puede hacer clasificaci\u00f3n de secuencia sacando una salida por palabra s\u00ed ten\u00eda una pregunta", "tokens": [51216, 8919, 6720, 596, 296, 40802, 368, 907, 47377, 4899, 1806, 2002, 1845, 2887, 1515, 31702, 8600, 23718, 2002, 24252, 51396], "temperature": 0.0, "avg_logprob": -0.26088627597741915, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.009755238890647888}, {"id": 724, "seek": 438608, "start": 4409.72, "end": 4413.72, "text": " el embedding exacto s\u00ed s\u00ed la entrada en esto caso yo digo bueno asumo que tengo", "tokens": [51546, 806, 12240, 3584, 1900, 78, 8600, 8600, 635, 37119, 465, 7433, 9666, 5290, 22990, 11974, 382, 40904, 631, 13989, 51746], "temperature": 0.0, "avg_logprob": -0.26088627597741915, "compression_ratio": 1.895582329317269, "no_speech_prob": 0.009755238890647888}, {"id": 725, "seek": 441372, "start": 4413.72, "end": 4423.400000000001, "text": " bordemente yo ya puedo utilizar estas redes m\u00e1s complejas bien y la que es la arquitectura del", "tokens": [50364, 272, 15127, 4082, 5290, 2478, 21612, 24060, 13897, 16762, 3573, 44424, 19221, 3610, 288, 635, 631, 785, 635, 40258, 5739, 2991, 1103, 50848], "temperature": 0.0, "avg_logprob": -0.22916361626158369, "compression_ratio": 1.8883495145631068, "no_speech_prob": 0.0032441585790365934}, {"id": 726, "seek": 441372, "start": 4423.400000000001, "end": 4428.64, "text": " estado del arte hoy en d\u00eda es la arquitectura de tipo transformer que tambi\u00e9n es una arquitectura que", "tokens": [50848, 18372, 1103, 29159, 13775, 465, 12271, 785, 635, 40258, 5739, 2991, 368, 9746, 31782, 631, 6407, 785, 2002, 40258, 5739, 2991, 631, 51110], "temperature": 0.0, "avg_logprob": -0.22916361626158369, "compression_ratio": 1.8883495145631068, "no_speech_prob": 0.0032441585790365934}, {"id": 727, "seek": 441372, "start": 4428.64, "end": 4432.280000000001, "text": " utiliza secuencias de entrada pero es una arquitectura bastante m\u00e1s compleja ac\u00e1 vamos a", "tokens": [51110, 4976, 13427, 907, 7801, 12046, 368, 37119, 4768, 785, 2002, 40258, 5739, 2991, 14651, 3573, 44424, 2938, 23496, 5295, 257, 51292], "temperature": 0.0, "avg_logprob": -0.22916361626158369, "compression_ratio": 1.8883495145631068, "no_speech_prob": 0.0032441585790365934}, {"id": 728, "seek": 441372, "start": 4432.280000000001, "end": 4436.4800000000005, "text": " ver solamente una idea muy muy b\u00e1sica como funciona pero es una arquitectura que tiene con muchos", "tokens": [51292, 1306, 27814, 2002, 1558, 5323, 5323, 25545, 2262, 2617, 26210, 4768, 785, 2002, 40258, 5739, 2991, 631, 7066, 416, 17061, 51502], "temperature": 0.0, "avg_logprob": -0.22916361626158369, "compression_ratio": 1.8883495145631068, "no_speech_prob": 0.0032441585790365934}, {"id": 729, "seek": 443648, "start": 4436.799999999999, "end": 4443.44, "text": " muchos pedazos y hace muchas cosas distintas y bueno se basa en una cosa que se llama capas", "tokens": [50380, 17061, 5670, 921, 329, 288, 10032, 16072, 12218, 31489, 296, 288, 11974, 369, 987, 64, 465, 2002, 10163, 631, 369, 23272, 1410, 296, 50712], "temperature": 0.0, "avg_logprob": -0.2590931323396058, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0030365244019776583}, {"id": 730, "seek": 443648, "start": 4443.44, "end": 4447.759999999999, "text": " autotensionales ahora no vamos a ver qu\u00e9 es el modelo attentional pero lo vamos a ver la clase que", "tokens": [50712, 1476, 310, 3378, 4229, 9923, 572, 5295, 257, 1306, 8057, 785, 806, 27825, 3202, 304, 4768, 450, 5295, 257, 1306, 635, 44578, 631, 50928], "temperature": 0.0, "avg_logprob": -0.2590931323396058, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0030365244019776583}, {"id": 731, "seek": 443648, "start": 4447.759999999999, "end": 4454.24, "text": " viene normalmente como bueno un ejemplo de c\u00f3mo funciona el sistema de traducci\u00f3n autom\u00e1tica", "tokens": [50928, 19561, 38217, 2617, 11974, 517, 13358, 368, 12826, 26210, 806, 13245, 368, 2479, 1311, 5687, 3553, 23432, 51252], "temperature": 0.0, "avg_logprob": -0.2590931323396058, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0030365244019776583}, {"id": 732, "seek": 443648, "start": 4454.24, "end": 4460.0, "text": " que utiliza modelos autotensionales bueno una variante de eso es el modelo autotensional que", "tokens": [51252, 631, 4976, 13427, 2316, 329, 1476, 310, 3378, 4229, 11974, 2002, 3034, 2879, 368, 7287, 785, 806, 27825, 1476, 310, 3378, 304, 631, 51540], "temperature": 0.0, "avg_logprob": -0.2590931323396058, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0030365244019776583}, {"id": 733, "seek": 443648, "start": 4460.0, "end": 4465.5199999999995, "text": " lo que hace es construir una matriz entre las palabras de una oraci\u00f3n y s\u00ed misma yo tengo una", "tokens": [51540, 450, 631, 10032, 785, 38445, 2002, 3803, 24959, 3962, 2439, 35240, 368, 2002, 420, 3482, 288, 8600, 24946, 5290, 13989, 2002, 51816], "temperature": 0.0, "avg_logprob": -0.2590931323396058, "compression_ratio": 1.8098859315589353, "no_speech_prob": 0.0030365244019776583}, {"id": 734, "seek": 446552, "start": 4465.52, "end": 4470.8, "text": " oraci\u00f3n que tiene en palabras y va a tratar de cruzar las n palabras con las propias n palabras", "tokens": [50364, 420, 3482, 631, 7066, 465, 35240, 288, 2773, 257, 42549, 368, 5140, 26236, 2439, 297, 35240, 416, 2439, 2365, 4609, 297, 35240, 50628], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 735, "seek": 446552, "start": 4470.8, "end": 4475.120000000001, "text": " y tratar de establecer conexiones entre cada uno de los pares entonces termina calculando una", "tokens": [50628, 288, 42549, 368, 37444, 1776, 49509, 5411, 3962, 8411, 8526, 368, 1750, 2502, 495, 13003, 1433, 1426, 4322, 1806, 2002, 50844], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 736, "seek": 446552, "start": 4475.120000000001, "end": 4480.88, "text": " matriz y lo bueno que tiene es que me permite construir en beding contextuales por palabra o", "tokens": [50844, 3803, 24959, 288, 450, 11974, 631, 7066, 785, 631, 385, 31105, 38445, 465, 2901, 278, 35526, 279, 1515, 31702, 277, 51132], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 737, "seek": 446552, "start": 4480.88, "end": 4485.4400000000005, "text": " sea en bedings de una palabra vista en contexto y adem\u00e1s un embeding total de la oraci\u00f3n entonces", "tokens": [51132, 4158, 465, 2901, 1109, 368, 2002, 31702, 22553, 465, 47685, 288, 21251, 517, 846, 2883, 278, 3217, 368, 635, 420, 3482, 13003, 51360], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 738, "seek": 446552, "start": 4485.4400000000005, "end": 4489.4800000000005, "text": " funciona m\u00e1s o menos as\u00ed esto como una especie de representaci\u00f3n muy vaga de lo que es un", "tokens": [51360, 26210, 3573, 277, 8902, 8582, 7433, 2617, 2002, 49368, 368, 2906, 3482, 5323, 371, 9286, 368, 450, 631, 785, 517, 51562], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 739, "seek": 446552, "start": 4489.4800000000005, "end": 4494.84, "text": " transformer no o sea de forma de realidad tiene como muchas partes m\u00e1s complejas pero imag\u00ednense", "tokens": [51562, 31782, 572, 277, 4158, 368, 8366, 368, 25635, 7066, 2617, 16072, 31210, 3573, 44424, 19221, 4768, 2576, 10973, 1288, 51830], "temperature": 0.0, "avg_logprob": -0.19871949801479813, "compression_ratio": 1.910299003322259, "no_speech_prob": 0.0026358349714428186}, {"id": 740, "seek": 449484, "start": 4494.84, "end": 4499.64, "text": " que funciona esta manera no yo digo tengo una oraci\u00f3n en la pel\u00edcula fue muy aburrida entonces", "tokens": [50364, 631, 26210, 5283, 13913, 572, 5290, 22990, 13989, 2002, 420, 3482, 465, 635, 40154, 9248, 5323, 410, 374, 81, 2887, 13003, 50604], "temperature": 0.0, "avg_logprob": -0.16621216994065505, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001520755933597684}, {"id": 741, "seek": 449484, "start": 4499.64, "end": 4505.52, "text": " la voy a pasar por una capa autotensional que significa yo cruzo todas las palabras con todas y", "tokens": [50604, 635, 7552, 257, 25344, 1515, 2002, 1410, 64, 1476, 310, 3378, 304, 631, 19957, 5290, 5140, 4765, 10906, 2439, 35240, 416, 10906, 288, 50898], "temperature": 0.0, "avg_logprob": -0.16621216994065505, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001520755933597684}, {"id": 742, "seek": 449484, "start": 4505.52, "end": 4512.08, "text": " calculo la relevancia de cada palabra contra las dem\u00e1s eso me va a dar una serie de salidas y eso", "tokens": [50898, 4322, 78, 635, 2951, 9768, 2755, 368, 8411, 31702, 10742, 2439, 34682, 7287, 385, 2773, 257, 4072, 2002, 23030, 368, 1845, 11382, 288, 7287, 51226], "temperature": 0.0, "avg_logprob": -0.16621216994065505, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001520755933597684}, {"id": 743, "seek": 449484, "start": 4512.08, "end": 4516.68, "text": " lo que hace es construirme como una colecci\u00f3n de en bedings de nivel 1 o sea yo empec\u00e9 con los", "tokens": [51226, 450, 631, 10032, 785, 38445, 1398, 2617, 2002, 45139, 14735, 368, 465, 2901, 1109, 368, 24423, 502, 277, 4158, 5290, 846, 494, 13523, 416, 1750, 51456], "temperature": 0.0, "avg_logprob": -0.16621216994065505, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001520755933597684}, {"id": 744, "seek": 449484, "start": 4516.68, "end": 4522.08, "text": " borde en bedings de la pel\u00edcula fue una fue muy aburrida y ahora voy a tener una colecci\u00f3n de", "tokens": [51456, 272, 15127, 465, 2901, 1109, 368, 635, 40154, 9248, 2002, 9248, 5323, 410, 374, 81, 2887, 288, 9923, 7552, 257, 11640, 2002, 45139, 14735, 368, 51726], "temperature": 0.0, "avg_logprob": -0.16621216994065505, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001520755933597684}, {"id": 745, "seek": 452208, "start": 4522.08, "end": 4527.48, "text": " en beding de nivel 1 que ya mirando algo de contexto eso eso es en beding de nivel 1 a su vez", "tokens": [50364, 465, 2901, 278, 368, 24423, 502, 631, 2478, 3149, 1806, 8655, 368, 47685, 7287, 7287, 785, 465, 2901, 278, 368, 24423, 502, 257, 459, 5715, 50634], "temperature": 0.0, "avg_logprob": -0.19362320169045108, "compression_ratio": 2.0253164556962027, "no_speech_prob": 0.006372387055307627}, {"id": 746, "seek": 452208, "start": 4527.48, "end": 4532.2, "text": " de los pasos de vuelta a otra capa autotensional que devuelta los cruzos a todos con todos y me", "tokens": [50634, 368, 1750, 1736, 329, 368, 41542, 257, 13623, 1410, 64, 1476, 310, 3378, 304, 631, 1905, 3483, 1328, 1750, 5140, 27681, 257, 6321, 416, 6321, 288, 385, 50870], "temperature": 0.0, "avg_logprob": -0.19362320169045108, "compression_ratio": 2.0253164556962027, "no_speech_prob": 0.006372387055307627}, {"id": 747, "seek": 452208, "start": 4532.2, "end": 4537.32, "text": " devuelta a dar una salida que son los en beding de nivel 2 y eso lo sigo pasando por varias capas", "tokens": [50870, 1905, 3483, 1328, 257, 4072, 2002, 1845, 2887, 631, 1872, 1750, 465, 2901, 278, 368, 24423, 568, 288, 7287, 450, 4556, 78, 45412, 1515, 37496, 1410, 296, 51126], "temperature": 0.0, "avg_logprob": -0.19362320169045108, "compression_ratio": 2.0253164556962027, "no_speech_prob": 0.006372387055307627}, {"id": 748, "seek": 452208, "start": 4537.32, "end": 4542.36, "text": " autotensionales que los cruzan todos con todos hasta que al final me terminan dando o sea lo voy", "tokens": [51126, 1476, 310, 3378, 4229, 631, 1750, 5140, 21238, 6321, 416, 6321, 10764, 631, 419, 2572, 385, 10761, 282, 29854, 277, 4158, 450, 7552, 51378], "temperature": 0.0, "avg_logprob": -0.19362320169045108, "compression_ratio": 2.0253164556962027, "no_speech_prob": 0.006372387055307627}, {"id": 749, "seek": 452208, "start": 4542.36, "end": 4549.24, "text": " a pasar en el capas y me terminan dando una salida de nivel 5 digamos entonces al inicio ten\u00eda", "tokens": [51378, 257, 25344, 465, 806, 1410, 296, 288, 385, 10761, 282, 29854, 2002, 1845, 2887, 368, 24423, 1025, 36430, 13003, 419, 294, 18322, 23718, 51722], "temperature": 0.0, "avg_logprob": -0.19362320169045108, "compression_ratio": 2.0253164556962027, "no_speech_prob": 0.006372387055307627}, {"id": 750, "seek": 454924, "start": 4549.24, "end": 4554.48, "text": " borde en bedings que miraban solamente una palabra a la vez y lo que tengo al final ya son como", "tokens": [50364, 272, 15127, 465, 2901, 1109, 631, 3149, 18165, 27814, 2002, 31702, 257, 635, 5715, 288, 450, 631, 13989, 419, 2572, 2478, 1872, 2617, 50626], "temperature": 0.0, "avg_logprob": -0.20471069461009542, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004082547500729561}, {"id": 751, "seek": 454924, "start": 4554.48, "end": 4558.76, "text": " en bedings contextuales en los cuales ya considero varias veces cruzar todas las palabras con todas", "tokens": [50626, 465, 2901, 1109, 35526, 279, 465, 1750, 46932, 2478, 1949, 78, 37496, 17054, 5140, 26236, 10906, 2439, 35240, 416, 10906, 50840], "temperature": 0.0, "avg_logprob": -0.20471069461009542, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004082547500729561}, {"id": 752, "seek": 454924, "start": 4558.76, "end": 4566.0, "text": " entonces como que eso va ganando informaci\u00f3n en cada paso a su vez a bien despu\u00e9s de que yo", "tokens": [50840, 13003, 2617, 631, 7287, 2773, 7574, 1806, 21660, 465, 8411, 29212, 257, 459, 5715, 257, 3610, 15283, 368, 631, 5290, 51202], "temperature": 0.0, "avg_logprob": -0.20471069461009542, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004082547500729561}, {"id": 753, "seek": 454924, "start": 4566.0, "end": 4570.88, "text": " tengo estos en beding contextuales en general se utiliza otra red m\u00e1s de tipo de coder puede ser", "tokens": [51202, 13989, 12585, 465, 2901, 278, 35526, 279, 465, 2674, 369, 4976, 13427, 13623, 2182, 3573, 368, 9746, 368, 17656, 260, 8919, 816, 51446], "temperature": 0.0, "avg_logprob": -0.20471069461009542, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004082547500729561}, {"id": 754, "seek": 454924, "start": 4570.88, "end": 4575.36, "text": " un transforme puede ser una lstm algo m\u00e1s pero necesito otra cosa que es la que me diga por", "tokens": [51446, 517, 4088, 68, 8919, 816, 2002, 287, 82, 83, 76, 8655, 3573, 4768, 11909, 3528, 13623, 10163, 631, 785, 635, 631, 385, 2528, 64, 1515, 51670], "temperature": 0.0, "avg_logprob": -0.20471069461009542, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004082547500729561}, {"id": 755, "seek": 457536, "start": 4575.36, "end": 4580.12, "text": " ejemplo si es positivo negativa o neutro etc\u00e9tera pero es otro tipo de red que despu\u00e9s decodifica", "tokens": [50364, 13358, 1511, 785, 44710, 2485, 18740, 277, 7989, 340, 5183, 526, 23833, 4768, 785, 11921, 9746, 368, 2182, 631, 15283, 979, 378, 43377, 50602], "temperature": 0.0, "avg_logprob": -0.24981975555419922, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003925434313714504}, {"id": 756, "seek": 457536, "start": 4580.12, "end": 4585.44, "text": " esa informaci\u00f3n pero bueno por lo menos atacayo ya constru\u00ed en bedings de cosas pero bien lo que", "tokens": [50602, 11342, 21660, 4768, 11974, 1515, 450, 8902, 412, 326, 48947, 2478, 12946, 870, 465, 2901, 1109, 368, 12218, 4768, 3610, 450, 631, 50868], "temperature": 0.0, "avg_logprob": -0.24981975555419922, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003925434313714504}, {"id": 757, "seek": 457536, "start": 4585.44, "end": 4591.5199999999995, "text": " tengo ac\u00e1 son ten\u00eda la pel\u00edcula fue muy aburrida y eso lo transform\u00e9 en ten\u00eda cinco palabras y lo", "tokens": [50868, 13989, 23496, 1872, 23718, 635, 40154, 9248, 5323, 410, 374, 81, 2887, 288, 7287, 450, 4088, 526, 465, 23718, 21350, 35240, 288, 450, 51172], "temperature": 0.0, "avg_logprob": -0.24981975555419922, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003925434313714504}, {"id": 758, "seek": 457536, "start": 4591.5199999999995, "end": 4596.12, "text": " transform\u00e9 en cinco en bedings digamos que de distintos niveles pero siempre son cinco en bedings", "tokens": [51172, 4088, 526, 465, 21350, 465, 2901, 1109, 36430, 631, 368, 49337, 11461, 904, 4768, 12758, 1872, 21350, 465, 2901, 1109, 51402], "temperature": 0.0, "avg_logprob": -0.24981975555419922, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003925434313714504}, {"id": 759, "seek": 457536, "start": 4597.12, "end": 4601.599999999999, "text": " entonces yo dir\u00eda que el primero se corresponde con la el segundo con pel\u00edcula tercero con fue", "tokens": [51452, 13003, 5290, 4746, 2686, 631, 806, 21289, 369, 6805, 68, 416, 635, 806, 17954, 416, 40154, 38103, 78, 416, 9248, 51676], "temperature": 0.0, "avg_logprob": -0.24981975555419922, "compression_ratio": 1.8205128205128205, "no_speech_prob": 0.003925434313714504}, {"id": 760, "seek": 460160, "start": 4602.160000000001, "end": 4607.120000000001, "text": " es una una versi\u00f3n contextual del en beding porque significa la palabra pel\u00edcula en el contexto de", "tokens": [50392, 785, 2002, 2002, 47248, 35526, 1103, 465, 2901, 278, 4021, 19957, 635, 31702, 40154, 465, 806, 47685, 368, 50640], "temperature": 0.0, "avg_logprob": -0.3138786065773886, "compression_ratio": 1.963855421686747, "no_speech_prob": 0.009443060494959354}, {"id": 761, "seek": 460160, "start": 4607.120000000001, "end": 4611.6, "text": " la pel\u00edcula fue muy aburrida no es la palabra pel\u00edcula en general entonces si yo tuviera una", "tokens": [50640, 635, 40154, 9248, 5323, 410, 374, 81, 2887, 572, 785, 635, 31702, 40154, 465, 2674, 13003, 1511, 5290, 38177, 10609, 2002, 50864], "temperature": 0.0, "avg_logprob": -0.3138786065773886, "compression_ratio": 1.963855421686747, "no_speech_prob": 0.009443060494959354}, {"id": 762, "seek": 460160, "start": 4611.6, "end": 4616.4800000000005, "text": " braci\u00f3n que tiene gato ser\u00eda gato en el contexto de el gato como pescado que no ser\u00eda lo mismo que", "tokens": [50864, 1548, 5687, 631, 7066, 290, 2513, 23679, 290, 2513, 465, 806, 47685, 368, 806, 290, 2513, 2617, 9262, 27713, 631, 572, 23679, 450, 12461, 631, 51108], "temperature": 0.0, "avg_logprob": -0.3138786065773886, "compression_ratio": 1.963855421686747, "no_speech_prob": 0.009443060494959354}, {"id": 763, "seek": 460160, "start": 4616.4800000000005, "end": 4619.6, "text": " cuando estoy hablando un gato y un gato y un gato y un gato probablemente o sea los en bedings", "tokens": [51108, 7767, 15796, 29369, 517, 290, 2513, 288, 517, 290, 2513, 288, 517, 290, 2513, 288, 517, 290, 2513, 21759, 4082, 277, 4158, 1750, 465, 2901, 1109, 51264], "temperature": 0.0, "avg_logprob": -0.3138786065773886, "compression_ratio": 1.963855421686747, "no_speech_prob": 0.009443060494959354}, {"id": 764, "seek": 460160, "start": 4619.6, "end": 4626.68, "text": " que de distintos bien pero adem\u00e1s me interesa tener una representaci\u00f3n de la oraci\u00f3n entera y", "tokens": [51264, 631, 368, 49337, 3610, 4768, 21251, 385, 728, 13708, 11640, 2002, 2906, 3482, 368, 635, 420, 3482, 948, 1663, 288, 51618], "temperature": 0.0, "avg_logprob": -0.3138786065773886, "compression_ratio": 1.963855421686747, "no_speech_prob": 0.009443060494959354}, {"id": 765, "seek": 462668, "start": 4626.68, "end": 4631.4800000000005, "text": " para eso lo que se hace es agregar un toque en extra un toque en llamado celse se pone al", "tokens": [50364, 1690, 7287, 450, 631, 369, 10032, 785, 4554, 2976, 517, 281, 1077, 465, 2857, 517, 281, 1077, 465, 16848, 1573, 9277, 405, 369, 40192, 419, 50604], "temperature": 0.0, "avg_logprob": -0.1975599123737005, "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0032783716451376677}, {"id": 766, "seek": 462668, "start": 4631.4800000000005, "end": 4637.4400000000005, "text": " principio de la oraci\u00f3n y se lo hace jugar con todos los las capas atenci\u00f3nales del medio entonces", "tokens": [50604, 34308, 368, 635, 420, 3482, 288, 369, 450, 10032, 37692, 416, 6321, 1750, 2439, 1410, 296, 33488, 4229, 1103, 22123, 13003, 50902], "temperature": 0.0, "avg_logprob": -0.1975599123737005, "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0032783716451376677}, {"id": 767, "seek": 462668, "start": 4637.4400000000005, "end": 4642.64, "text": " yo tengo una palabra extra que como no es una palabra de la oraci\u00f3n no tiene un en beding contextual", "tokens": [50902, 5290, 13989, 2002, 31702, 2857, 631, 2617, 572, 785, 2002, 31702, 368, 635, 420, 3482, 572, 7066, 517, 465, 2901, 278, 35526, 51162], "temperature": 0.0, "avg_logprob": -0.1975599123737005, "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0032783716451376677}, {"id": 768, "seek": 462668, "start": 4642.64, "end": 4646.92, "text": " sino lo que hace es capturar la informaci\u00f3n de toda la oraci\u00f3n a la vez entonces es en beding que", "tokens": [51162, 18108, 450, 631, 10032, 785, 3770, 28586, 635, 21660, 368, 11687, 635, 420, 3482, 257, 635, 5715, 13003, 785, 465, 2901, 278, 631, 51376], "temperature": 0.0, "avg_logprob": -0.1975599123737005, "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0032783716451376677}, {"id": 769, "seek": 462668, "start": 4646.92, "end": 4652.68, "text": " me queda afuera el en beding que corresponde al toque en celse ese que despu\u00e9s yo puedo utilizar", "tokens": [51376, 385, 23314, 3238, 84, 1663, 806, 465, 2901, 278, 631, 6805, 68, 419, 281, 1077, 465, 9277, 405, 10167, 631, 15283, 5290, 21612, 24060, 51664], "temperature": 0.0, "avg_logprob": -0.1975599123737005, "compression_ratio": 1.9367588932806323, "no_speech_prob": 0.0032783716451376677}, {"id": 770, "seek": 465268, "start": 4652.68, "end": 4658.16, "text": " para predecir cosas yo lo utilizo como un en beding que tiene cierto tama\u00f1o y se lo paso una", "tokens": [50364, 1690, 24874, 23568, 12218, 5290, 450, 4976, 19055, 2617, 517, 465, 2901, 278, 631, 7066, 28558, 45342, 7716, 288, 369, 450, 29212, 2002, 50638], "temperature": 0.0, "avg_logprob": -0.2954036138390982, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.004127468913793564}, {"id": 771, "seek": 465268, "start": 4658.16, "end": 4666.96, "text": " capa de softmax para que me prediga as\u00ed esa es positiva negativo a neutra o no bien bueno y para", "tokens": [50638, 1410, 64, 368, 2787, 41167, 1690, 631, 385, 3852, 9900, 8582, 11342, 785, 11218, 5931, 2485, 18586, 257, 7989, 424, 277, 572, 3610, 11974, 288, 1690, 51078], "temperature": 0.0, "avg_logprob": -0.2954036138390982, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.004127468913793564}, {"id": 772, "seek": 465268, "start": 4666.96, "end": 4672.320000000001, "text": " terminar terminar comentarles lo el tipo de herramientas que pueden utilizar para trabajar con", "tokens": [51078, 36246, 36246, 14541, 289, 904, 450, 806, 9746, 368, 38271, 296, 631, 14714, 24060, 1690, 30793, 416, 51346], "temperature": 0.0, "avg_logprob": -0.2954036138390982, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.004127468913793564}, {"id": 773, "seek": 465268, "start": 4672.320000000001, "end": 4677.200000000001, "text": " redes neuronales obviamente para el segundo laboratorio van a poder utilizar redes neuronales si", "tokens": [51346, 16762, 34090, 4229, 36325, 1690, 806, 17954, 5938, 48028, 3161, 257, 8152, 24060, 16762, 34090, 4229, 1511, 51590], "temperature": 0.0, "avg_logprob": -0.2954036138390982, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.004127468913793564}, {"id": 774, "seek": 467720, "start": 4677.5199999999995, "end": 4683.36, "text": " quieren de todo tipo si quieren colecciones en bedings nosotros tambi\u00e9n les podemos dar o pueden", "tokens": [50380, 36706, 368, 5149, 9746, 1511, 36706, 45139, 35560, 465, 2901, 1109, 13863, 6407, 1512, 12234, 4072, 277, 14714, 50672], "temperature": 0.0, "avg_logprob": -0.31847254435221356, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.0032957587391138077}, {"id": 775, "seek": 467720, "start": 4683.36, "end": 4687.639999999999, "text": " bajar algunas que est\u00e9n disponibles en la web pero bueno herramientas habituales para trabajar con", "tokens": [50672, 23589, 289, 27316, 631, 871, 3516, 23311, 14428, 465, 635, 3670, 4768, 11974, 38271, 296, 46883, 279, 1690, 30793, 416, 50886], "temperature": 0.0, "avg_logprob": -0.31847254435221356, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.0032957587391138077}, {"id": 776, "seek": 467720, "start": 4687.639999999999, "end": 4692.5599999999995, "text": " esto son por ejemplo tensorflow y pator que son dos ilotecas el tensorflow de google y pator es", "tokens": [50886, 7433, 1872, 1515, 13358, 40863, 10565, 288, 280, 1639, 631, 1872, 4491, 1930, 1370, 16369, 806, 40863, 10565, 368, 20742, 288, 280, 1639, 785, 51132], "temperature": 0.0, "avg_logprob": -0.31847254435221356, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.0032957587391138077}, {"id": 777, "seek": 467720, "start": 4692.5599999999995, "end": 4698.2, "text": " de meta o de facebook y bueno queras en general trabaja contar sonflog y hanginfaces es un", "tokens": [51132, 368, 19616, 277, 368, 23372, 288, 11974, 7083, 296, 465, 2674, 9618, 64, 27045, 1872, 3423, 664, 288, 3967, 259, 69, 2116, 785, 517, 51414], "temperature": 0.0, "avg_logprob": -0.31847254435221356, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.0032957587391138077}, {"id": 778, "seek": 467720, "start": 4698.2, "end": 4701.96, "text": " repositorio que tiene un mont\u00f3n de modelos ya aprendrenados para muchos idiomas y para muchas", "tokens": [51414, 1085, 329, 3029, 1004, 631, 7066, 517, 45259, 368, 2316, 329, 2478, 21003, 1095, 4181, 1690, 17061, 18014, 7092, 288, 1690, 16072, 51602], "temperature": 0.0, "avg_logprob": -0.31847254435221356, "compression_ratio": 1.7355072463768115, "no_speech_prob": 0.0032957587391138077}, {"id": 779, "seek": 470196, "start": 4701.96, "end": 4708.16, "text": " cosas que ya se pueden utilizar autos de box y funciona muy bien y bueno estas son estas", "tokens": [50364, 12218, 631, 2478, 369, 14714, 24060, 1476, 329, 368, 2424, 288, 26210, 5323, 3610, 288, 11974, 13897, 1872, 13897, 50674], "temperature": 0.0, "avg_logprob": -0.24575268305264986, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.000333746982505545}, {"id": 780, "seek": 470196, "start": 4708.16, "end": 4713.84, "text": " herramientas y otras m\u00e1s las van a poder utilizar en laboratorio bueno por hoy eso la", "tokens": [50674, 38271, 296, 288, 20244, 3573, 2439, 3161, 257, 8152, 24060, 465, 5938, 48028, 11974, 1515, 13775, 7287, 635, 50958], "temperature": 0.0, "avg_logprob": -0.24575268305264986, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.000333746982505545}, {"id": 781, "seek": 470196, "start": 4713.84, "end": 4715.64, "text": " pr\u00f3xima vez vamos a ver producci\u00f3n autom\u00e1tica", "tokens": [50958, 24096, 5715, 5295, 257, 1306, 48586, 3553, 23432, 51048], "temperature": 0.0, "avg_logprob": -0.24575268305264986, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.000333746982505545}], "language": "es"}