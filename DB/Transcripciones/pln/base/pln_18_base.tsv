start	end	text
0	20760	La clase de hoy y la clase que viene, vamos a dar el tema de traducción automática.
20760	28880	Y bueno, vamos a arrancar. Por esto que se conoce como la nota de Weber,
28880	34480	o el memorando de Weber, Warren Weber era un matemático norteamericano de primera
34480	38560	mitad de siglo XX. Y el tipo trabajó durante la guerra, especialmente en cosas de
38560	42760	criptografía, en análisis estadístico, de códigos, etcétera. Entonces en un momento
42760	47920	dijo lo siguiente, dijo, es muy tentador decir que un libro escrito en chino, es simplemente un libro
47920	52560	escrito en inglés que ha sido codificado en el código chino. Si tenemos métodos útiles para
52560	56280	resolver casi cualquier problema criptográfico, no será que con la interpretación apropiada,
56280	63680	ya tendríamos métodos útiles para la traducción. El opinado, digamos, en este memorándum,
63680	70320	que los métodos que se utilizan para romper código criptográfico, que son métodos estadísticos,
70320	74960	se podían aplicar al problema de la traducción automática. Y bueno, esto introduce
74960	79520	algunas ideas clave como que puede existir un mapeo automático entre un lenguaje y otro,
79520	85440	y que codificar, de codificar en un lenguaje de sanálogo, a codificar, de codificar en
85440	93400	una ecorismo criptográfico. Y bueno, el tiro, esa idea es 1949, tomó como 50 años para que
93400	99680	esa idea madurar, digamos, y después de 50 años los métodos más utilizados, hoy en día son
99680	104800	métodos estadísticos que se basan un poco en estos principios. Pero claro, en esa época era
104800	111360	como muy difícil lugar que era lo que iba a ocurrir. Entonces, bueno, vamos a ver un poco esta
111360	115520	la agenda de lo que vamos a mirar. Vamos a llegarnos a menos hasta la mitad hoy y después la clase
115520	121120	siguiente. Y empecemos con un poco de historia de lo que es la traducción automática. Esto empezó
121120	126120	como muchas otras tecnologías, como una tecnología militar, con fines militares. Inicialmente era
126120	132200	durante la Guerra Fría, era resultado de interés traducir rápidamente y abajo costa traducir
132200	136840	entre el ruso y el inglés, digamos, los norteamericanos les convenía poder traducir entre el
136840	141160	inglés y el ruso. Y bueno, en aquella época se imaginan lo que era los inicios de la computación,
141160	145480	las computadoras serán caras, en las lentas, no tenía mucho poderos de computos, pero igual había
145480	148840	como mucho optimismo, de que en poco tiempo se iba a poder resolver los problemas y vamos a tener
148840	155040	sistemas que iban a traducir barbaros. Y bueno, era más o menos la época de desarrollo de la
155040	159640	lingüística computacional, inspirado un poco en las teorías de Chomsky, estaba la idea que se
159640	164480	podía escribir reglas para todo y que a partir de eso se podría llegar a hacer cosas muy muy buenas,
164480	171060	es particular para la traducción. Hasta que en 1964 pareció el reporte Alpac,
171060	176240	Alpac era un comité que estaba estudiando, cuáles eran los avances en ingüística computacional,
176240	181720	porque se estaba poniendo mucha plata en muchas esas cosas. Y ellos demostraron escepticos acerca de
181720	185720	la traducción automática, acerca de los logros que se habían logrado después de todos esos años
185720	191200	de meter plata. Y decía bueno, pero se puso mucho dinero, pasó en muchos años, pero todavía
191200	196000	los humanos lo hacen más barato, con mayor precisión, más rápido, entonces como que para que estamos
196000	200960	gastando en esto. Como resultado de eso, un reporte de fondos, especialmente en Estados Unidos,
200960	204560	para todo lo que la traducción automática y esto fue parte de lo que se conoció como el
204560	209400	invierno de la inteligencia artificial, que un montón de proyectos de inteligencia artificial también
209400	214400	no teníamos el resultado, entonces se paró la financiación que había para todo eso durante unos
214440	219240	cuantos años, entonces se tuvo desarrollado unas cuantas cosas durante unos cuantos años. Y bueno,
219240	226880	después empezaron a resurgir de apoco, pero después de esto, digamos, en los 70 y hasta los 90 más o menos,
226880	231240	eso le hubo que la investigación se frenar un poco en Estados Unidos, pero empezar a aparecer en
231240	236600	otros lados del mundo, como por ejemplo en Europa o en Japón. Y ahí empezó ya con filas bélicos,
236600	242480	sino más bien con fines comerciales, entonces había necesidad de tener traducciones o por lo menos
242480	246520	dar soporte a los traductores humanos con algunas traducciones, aunque no estuvieran de todo bien,
247800	251840	pero bueno, dar algunas traducciones de inicio para que los traductores puedan, los traductores humanos
251840	256040	puedan continuar, además las computadoras empezaron a bajar de precio, tener mayor hogar de computo,
256040	260000	y esta fue como la era de oro de los sistemas de traducción basados en reglas,
261720	265920	digamos acá hay unos ejemplos, sistemas distranques, todavía se desarrolla aunque ya no está completamente
265920	273080	basado en reglas, y bueno, hay sistemas que se realizaron en Japón y en Europa, y bueno,
273080	279560	o sea, estos sistemas tenían fines comerciales y no tanto fines militares, pero bueno,
279560	284800	fines de los 90 y después de 2000, en adelante empezaron a dejarse de usar un poco los sistemas
284800	289800	basados en reglas, porque empezó a haber mayor poder de computo y mayor cantidad de datos disponibles,
290360	296000	especialmente con la aparición de internet, empezaron a haber muchísimos datos de texto disponibles,
296000	301400	y eso permitía construir buenos modelos estadísticos que podrían explotar las regularidades
301400	305360	de los idiomas, entonces aparecieron distintos tipos de modelos estadísticos, los primeros,
305360	308800	los que se llamaron traducciones automáticas estadísticas, que es la otra traducción basada en
308800	314120	ejemplos, y aparecieron las primeras aplicaciones comerciales que funcionaban bien, que utilizaban
314120	317880	modelos estadísticos, la primera fue el English Weber, y después los traductores que más conocemos
317880	322680	hoy en día el Bing, translate de Microsoft, y bueno, el Google translate, que probablemente los
322680	327440	lo conozcan y lo hayan usado en algún momento, y son traductores que la verdad que hoy en día se
327440	333560	puede decir que funcionan bastante bien, entonces bueno, los métodos estadísticos empezaron subhum al
333560	340360	alrededor del año 2000 y siguen siendo el estado del arte, pero bueno, primero vamos a ver un poco de
340360	344840	lo que son los sistemas basados en reglas, que eran estos primeros sistemas que mencionamos antes,
345560	353840	en 1968 un investigador de traducción automática, se llamaba Bernard Boquah, y son relevamiento de todos
353840	359840	los sistemas que se habían construido, más o menos por la época, y los clasificó todos dentro
359840	364160	de este diagrama, el dibujo un triángulo que ahora se llama el triángulo de Boquah, y bueno,
364160	367920	en este triángulo se ubican los distintos tipos de sistemas de traducción basados en reglas,
367920	373920	se ponen como escalones dentro de este triángulo, y los lados del triángulo tienen como
373920	377920	distintas interpretaciones, el lado izquierdo, si yo voy subiendo por este lado, en realidad lo que
377920	383320	aumenta es la cantidad o el esfuerzo de análisis que tengo que hacer de lenguaje origen, yo siempre quiero
383320	387800	traducir de lenguaje origen en el lenguaje destino, bueno, entonces de este lado aumenta el esfuerzo
387800	392040	de traducción en el lenguaje origen, y si voy bajando del lado derecho aumenta, bueno,
392040	395800	si voy subiendo del lado derecho quiero decir, aumenta el esfuerzo de generación en el lenguaje
395800	403560	destino, entonces ¿qué quiere decir esto? Yo ubico distintos sistemas de traducción, la
403560	407280	traducción directa es simplemente buscar en el diccionario de las palabras y traducir
407280	412800	palabra palabra con poca información más, entonces eso casi no necesitan ningún tipo de análisis y
412800	418520	casi no necesitas generación, pero para que son debían, yo necesito ponerle muchas ganas a las
418520	422480	reglas, o sea, las reglas de traducción deben ser muy buenas y tienen que tomar en cuenta
422480	427040	muchos casos para que esa traducción llegue a ser buena, entonces es como que la flecha de la
427040	431040	transferencia, la flecha de la traducción es mucho más larga, en cambio, si yo hago un poco de
431120	436080	análisis, por ejemplo, llevo hasta al nivel de análisis intactico, tengo un parcer, puedo escribir
436080	440440	otro tipo de reglas que pueden ser un poco más expresivos, me resulta un poco más fácil y después,
440440	446040	si tengo un generador, puedo llegar a traducir, entonces si sigo subiendo de vuelta, voy a necesitar
446040	449880	mayor esfuerzo de análisis de generación, pero las reglas pueden ser más expresivas y más fáciles
449880	455840	de escribir y probablemente la traducción sea mejor, hasta que si llegamos al lo articel triángulo,
455840	461080	llegamos a la interlingua, que es una especie de noción en la cual no necesito ningún tipo
461080	466520	de transferencia, vamos a dar un poco dentro de un rato de que se trata eso, pero bueno,
466520	471320	empecemos a ver los distintos niveles de este triángulo de bocua, el demás abajo era la traducción
471320	476760	directa, es el enfoque más simple, lo único necesito para este enfoque es un diccionario de
476760	481720	lingüe, yo quiero traducir entre dos idiomas, si necesito un diccionario que tenga la correspondencia
481720	485760	entre palabras de un idioma y palabras del otro, y lo que voy a hacer es traducir palabra
485760	491200	palabra, o sea, puedo agregarle alguna cosa extra, como por ejemplo, algún reordenamiento local,
491200	495760	yo que es para traducir entre español inglés, yo diría que en español el nombre se siga el
495760	498960	adjetivo y en inglés se en realidad los han arreves, pone el adjetivo seguido el nombre,
498960	505080	entonces ese tipo de reglas simples se las puedo agregar al sistema, y bueno, el sistema
505080	509220	funcionaría un poco así, yo tengo una operación de entrada en el idioma origen, Mary
509220	515500	Tiden Slap de Green Witch, le paso un analisador morfológico bastante de superficie, que no hace
515500	519740	mucho en realidad, simplemente me dice que esto era el barbo du, en pasado y seguido por un
519740	525060	not, y bueno, el resto de los tokens sigue en igual, y acá viene la parte de diccionario,
525060	528660	digamos, lo siguiente que tengo que hacer es buscar en mi diccionario cada una de las palabras
528660	533100	y poner la palabra correspondiente del otro lado, entonces Mary queda María, duve en pasado
533100	538140	como en español no se usa el du, usamos simplemente el marcador de pasado, not es no, Slap es
538140	545420	dar una ofetada de Slap Green, es verde, Witch es Bruja, con el diccionario hoy poniendo
545420	551380	todas las traducciones, y después puedo usar mis reglas de ordenamiento local, de ordenamiento
551380	556460	simple como por ejemplo que el adjetivo seguido en nombre en inglés, en realidad en español
556460	559900	se corresponde con nombres seguido adjetivo, entonces verdad de Bruja lo cambio por Bruja
559900	563700	verde, acá hay otro ordenamiento, digamos, donde tengo una marca de pasado y se lo paso
563700	569220	para adelante a lo largo, y finalmente lo que hago es una pequeña generación morfológica
569220	575180	con estas marcas y digo bueno, este dar en pasado se transforma en dio, entonces me queda
575180	581340	María no dio una ofetada a la Bruja verde, así que partí de el texto en el idioma
581340	586300	Rige, Mary did and Slap de Green Witch y llegue a una oración en el idioma destino María
586300	589900	no dio una ofetada a la Bruja verde, que parece estar bastante bien digamos, bastante
589900	594380	bien la traducción, entonces así es como funcionaría un poco un sistema de traducción
594380	599260	directa, como les parece que funcionan estos sistemas en la práctica, digamos que también
599260	603900	se comportan en la práctica este tipo de sistemas, pues acá vimos un ejemplo que
603900	616300	quedan bastante bien digamos, pero no sé qué, claro, y hay otro problema más, y es
617300	621540	lo que, que no tenga todas las palabras, pero además que palabras que se pueden traducir
621540	627100	de más de una manera, entonces necesitas saber qué palabras tenés que usar, entonces bueno,
628300	633140	la web está llena de ejemplos de lo que puede salir más y yo utilizo un sistema de traducción
633140	638780	directa como este, entonces lo que estábamos viendo recién era los sistemas de traducción directa,
638780	644580	vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sintáctica,
645140	649620	entonces para la transferencia sintáctica, yo lo que voy a necesitar primero es tener un
649620	655220	parcer de lenguaje origen que me lleva a un análisis sintáctico y además voy a necesitar un
655220	660380	generador, lenguaje destino que agarra, un algo sintáctico de lenguaje destino y genera una
660380	666340	oración, entonces yo lo que puedo hacer es escribir reglas que transformar un árbol en el otro
666340	670900	y esas reglas son un poco más fáciles digamos que lo que necesitaría para un sistema de traducción
670900	674260	directa, entonces para el inglés, por ejemplo para todo el siguiente del inglés y el español,
674260	678820	yo diría que si tengo un nominal que es un adjetivo nombre, un adjetivo en un nombre en inglés,
678820	685260	lo transformaría en un nombre, seguí un adjetivo en español y la reglas escribiría algo así
685260	689260	diría, tengo nominal adjetivo nombre, entonces lo cambio por nominal nombre adjetivo,
691660	697460	entonces ahora que sabemos cómo funciona esto, tratemos de hacer el ejemplo en japonés,
697460	701860	digamos cómo serían las reglas para transformar el árbol en inglés de Geador, se le dicen en
701860	708460	tu music, a japonés, careja, ongaku, wokiku, no gada y suki de su, donde está, tenemos la
708460	712940	correspondencia de cada una de las palabras, pero claro los árboles son un poco distintos,
712940	720500	el inglés y el español se caracterizan por ser lenguajes de tipo, no sé si esto lo hemos visto
720500	725540	ya en el curso, pero son lenguajes de tipo SBO, que significa que habitualmente yo solo escribir
725540	730420	un sujeto se dio un verbo seguido de un objeto, el japonés en cambio es un lenguaje de tipo SBOB
730420	735540	porque habitualmente se escribió el sujeto, seguido del objeto, seguido del barbol, hay muchos lenguajes
735540	741980	que pertenecen a esta otra categoría, entonces bueno, queremos escribir reglas de transferencia
741980	746700	para transformar este árbol en aquel otro árbol, como escribiríamos esas reglas, que les parece,
749460	752220	que reglas utilizaría yo para transformar un árbol en el otro,
755540	775300	ahí está, una de esas, en inglés yo escribo, una fraseróbalo, un grupo verbal como un verbo seguido de un grupo
775300	787500	proporcional, esta es la que decías, y la cambio por que otra cosa, la cambio por un grupo
787500	796540	proporcional que sigue un verbo, esa es una, que otra regla tendría que agregar, cuál,
796540	802020	la elaboración, que tiene la elaboración, la elaboración según esto en inglés es un pronombre
802740	811700	seguido de un verbo, seguido de un grupo verbal, por qué tendría a cambiarlo, ahora en
811700	819140	japonés la elaboración va a ser el pronombre seguido del verphrase, seguido del verbo, bien,
819140	827860	alguna otra, ahí está, el grupo preposicional que está formado por un tú, seguido un nombre,
827860	835140	eso es en inglés y en japonés que va a pasar, voy a tener un grupo proporcional que es un nombre
835140	841700	seguido de tú, bien, entonces con eso más o menos creo que tendría las reglas suficientes para
841700	845740	transformar un árbol en el otro, los sistemas de traducción, vamos a ver si está bien,
847740	855220	son los que escribimos, esta es la solución del ejercicio, los sistemas de traducción basados en
855220	860380	síntaxis, en realidad los sistemas de traducciones de reglas, en síntaxis hacen esto a alto
860380	864860	nivel, digamos, tienen montones de pared de árboles, hay gente que los analiza y escriba reglas
864860	870660	como se transforma uno en el otro, a veces las reglas son complicadas porque se pueden superponer,
870660	875900	entonces hay que definir prioridades y ese tipo de cosas, bueno, esas transferencias
875900	881420	sintácticas, si seguimos subiendo en el triángulo de bocua, llegamos a lo que es la transferencia
881420	886100	semántica, tal vez es semántica uno puede pensarla un poco como lo que habíamos en la clase
886100	891180	pasada, utilizando roles semánticos, yo tengo un etiquetador de roles semánticos, que agarra
891180	896220	la relación Juan fue a la tienda y me devuelve los roles de los constituyentes, me dice que Juan
896220	902820	es el agente y a la tienda es el objetivo o goal, digamos, es el nombre del rol, entonces yo,
902820	908300	para ciertos idiomas podrías escribir reglas más específicas, por ejemplo, en chino ocurre que
908300	912740	los sintámas propulsionales, que son de tipo objetivo, se escriben antes del largo, pero los
912740	917460	demás sintámas propulsionales escriben después, o sea, el chino es un lenguaje de tipo SBO igual que
917460	924380	el inglés o el español, pero cuando el objeto es de tipo goal lo que hacen es ponerlo antes del
924380	930580	largo, entonces yo podría escribir una regla un poco más expresiva, para este caso del chino,
930580	937020	si yo tuviera los roles semánticos, yo diría que un grupo verbal es un verbo seguido de esto,
937020	942700	esto no está tachado, sino que era la barrita que quedó arriba, es un verbo seguido de un grupo
942700	948460	proporcional de tipo goal, en chino lo cambiaría por un verbo seguido de un verbo, por un grupo
948460	954700	proporcional de tipo goal seguido de un verbo, es más costoso para generar y para parcear,
954700	958340	digamos, necesito tener más esfuerzo de parcin y más esfuerzo de generación, pero puedes
958340	962100	escribir mejores reglas que capturan ciertas particularidades de los lenguajes,
962100	967740	y si yo sigo subiendo en el triángulo llego a lo que se conoce como interlingua,
967740	971980	cuál es la gracia de interlingua, cuál es la idea, esto sirve si nosotros estamos en un
971980	976820	contexto multicultural, estamos trabajando, por ejemplo, en la ONU o en el Palamento Europeo,
976820	981900	o algo de eso donde se hablan muchos idiomas, si yo quiero mantener un montón de documentos
981900	986300	que estén en todos los idiomas a la vez, voy a necesitar para los sistemas que estuve en
986300	991460	nuestro momento, voy a necesitar tener N parsers, uno para cada idioma, N generadores,
991460	995540	también uno para cada idioma, y después para cada par de idiomas, voy a necesitar reglas
995540	1000140	de transferencia, entonces voy a necesitar tener en total N por N menos 1, 7 de transferencia,
1000140	1005780	yo tengo 20 idiomas, voy a necesitar 380 conjuntos de reglas de transferencia, y esos
1005780	1009380	conjuntos de reglas de transferencia son largos, son grandes, son complejos, hay que mantener
1009380	1015060	los, pueden tener errores, entonces esto claramente no es cala, es como muy difícil poder mantener
1015060	1018940	un entorno de todos esos idiomas y poder mandar la traducción en base a reglas, entonces
1018940	1025740	la idea del interlingua es decir, ¿qué tal si pudiéramos parcear lo suficiente o analizar
1025740	1030540	lo suficiente como para llevar a una representación común, una representación que capturé el significado
1030540	1036540	de todos los idiomas a la vez, y además tuvieramos un generador para cada uno de los idiomas.
1036540	1040740	Si eso pasara, si nosotros pudiéramos capturar con una representación el significado de todos
1040740	1044380	los idiomas a la vez, no necesitaríamos transferencias, simplemente parceamos y llevamos
1044380	1050180	a esa interlingua y después generamos en el otro idioma. Esto está muy bien, digamos,
1050180	1056460	del punto de vista ideal, pero es muy difícil obtener la práctica. ¿Qué se podría usar
1056460	1060380	como representación de interlingua? ¿Qué podría hacer un candidato? Bueno, podríamos
1060380	1064860	usar la lógica de primer orden, que era lo que veíamos en las primeras clases de semántica,
1064860	1068340	como representar variaciones en la lógica de primer orden, o alguna de sus variantes
1068340	1072300	que da un cuenta mejor de lo que es la lógica de la lengua genatural, como las mínimos
1072300	1076420	con recursos semánticos o las whole semánticos. O si no, hay como parecido lo que veíamos
1076420	1081540	en la clase anterior de frames, construirme frames con el estado de las cosas, como por ejemplo
1081540	1085020	está la misma operación de hoy, Mary didn't slap the green witch, pero es crita como
1085020	1089940	un frame, es hay un evento de slapping, la gente es Mary, ocurre en pasado, la polaridad
1089940	1095180	negativa, el tema de ese evento es la bruja y la bruja de más es verde. Yo podría construir
1095180	1104740	este tipo de frames y usarlos como representaciones. Pero bueno, hay problema que tiene crear o
1104740	1109180	pensar en crear una interlingua, es que esa interlingua seguro que va a ser muy compleja
1109180	1114380	y seguro que va a tener que modelar las características de todos los idiomas al mismo tiempo. Y hay
1114380	1121100	características que son complicadas en los distintos idiomas, y algunas que ni nos imaginamos,
1121100	1126020	o sea, por ejemplo, en chino existen palabras distintas para decir hermano mayor y hermano
1126020	1129420	menor, y no hay una palabra para decir hermano. O sea, no hay una palabra que quiera decir
1129420	1134740	solamente hermano. En español sí, y en inglés también, en inglés puede decir brado, pero
1134740	1137500	en chino no, en chino tienes que elegir cuando vas a decir hermano, si es hermano mayor
1137500	1142740	o hermano menor. Entonces, imagínense que si yo estoy traduciendo del español al inglés
1142740	1147820	y estoy utilizando una interlingua, la interlingua en su parcer necesita poder distinguir en
1147900	1151340	algún momento, si estoy hablando de un hermano mayor o un hermano menor, porque tiene que
1151340	1155660	lograr la representación suficiente como para poder traducir al chino. Entonces, necesita
1155660	1158940	esa información y no sé dónde la va a sacar, la puedes sacar de contexto, lo puedes sacar
1158940	1163540	inventar de algún lado, pero en algún momento va a tener que averiguar el hermano que se
1163540	1167780	está hablando en español, si es un hermano mayor o menor, como para poder tener la representación,
1167780	1171700	y después esa información se va a perder, porque cuando baja de vuelta, al lado del inglés,
1171700	1176300	de vuelta vuelve a ser brada y no importa si es mayor o menor. Y esto es solamente un caso
1176300	1180660	de un fenómeno que ocurre en chino, pero, imagínense, los fenómenos que ocurren en el idioma
1180660	1186740	en todo el tiempo, digamos, y todas las pequeñas variantes que hay. Y como en realidad,
1186740	1191100	no es cierto que podamos traducir exactamente lo mismo conceptos, como que es muy difícil
1191100	1195100	encontrar conceptos que se correspondan 100% en idioma y otro. Hay una cosa que se llama
1195100	1198620	el principio de incertidumbre de la traducción y dice eso, que en realidad, cuando yo tengo
1198620	1202700	un idioma y otro, los conceptos no siempre se van a traducir 100% bien, o sea, no siempre
1203700	1207500	la traducción es exacta, sino que hay cierto suelopamiento y a veces se va a funcionar y a veces no.
1210700	1216660	Bien, pero a pesar de que es una utopía, tener un interlingo que funcione para todos los
1216660	1220900	lenguajes bien, este tipo de tecnología sí se utilizan para dominios más acotados, para
1220900	1225540	dominios pequeños, como por ejemplo, el de meteorología, yo puedo escribir perfectamente,
1225540	1229220	puedo construir una representación de todos los estados meteorológicos que hay, y si hay
1229740	1235740	lluvias y nievas, y hay granizo, la temperatura, la presión, etc. y traducirlo a las distintas
1235740	1239860	palabras, que son los distintos idiomas para dar cuenta de estos conceptos. Entonces, ese
1239860	1244940	dominio acotado es bastante bien manejable con una interlingua. Y otro ejemplo son los manuales
1244940	1250340	técnicos, hay empresas que, de un montón de documentación técnica, o describen las
1250340	1255660	apis de sus productos, etc. Y uno suele dar, cuando mira la página web, digamos que aparece como
1256380	1260340	con su fijo es, porque está en español, pero si se lo cambias por en, automáticamente
1260340	1263780	te genera otras páginas, exactamente igual, pero en inglés, y en realidad lo que hacen es
1263780	1267520	como mantener una representación abstracta de lo que están escribiendo y generarla en los
1267520	1274820	distintos idiomas. Bien, entonces, hasta ahí lo que vimos era como un paneo de lo que son
1274820	1279460	los distintos sistemas basados en reglas, ahora vamos a pasar a hablar de lo que es la traducción
1279460	1285380	estadística que es el estado del arte hoy en día, y vamos a empezar con un ejemplo, un ejemplo
1285380	1291460	de una frase en hebreo, que es Adonai Roy, que la traducción sería el señor a mi pastor
1291460	1298500	o del Lord Ismail Shepper, y esta frase, en realidad, funciona bien, porque nosotros conocemos
1298500	1302620	que son las ovejas, digamos, la cultura en la que surgió esta frase, conocía que eran
1302620	1306780	las ovejas, tenían pastores, los pastores cuidaban las ovejas, la llevaban a donde había
1306780	1313180	estado los mejores pastos, etc. Entonces, esta metáfora funcionaba bien, digamos, la
1313180	1317700	gente describía como se sentía en respecto a Dios utilizando esta metáfora. Pero
1317700	1323740	¿qué tal si quisieramos expresar esta misma frase a una cultura que no conoce a las ovejas?
1323740	1329020	Por ejemplo, los primeros misioneros que vendrían de Europa y tendrían contacto con los
1329020	1333420	indígenas americanos, los indígenas americanos no conocían ovejas, entonces, ¿cómo hacemos
1333420	1340900	para expresarles el concepto de Adonai Roy? Una forma de expresarlo es decir, bueno,
1340900	1346140	adusco la metáfora, el significador de la metáfora, digo, significa el señor me cuidará,
1346140	1349340	que en definitiva es un poco la metáfora que quiere decir eso, aunque pierda un poco
1349340	1355660	de contenido, o si no, lo que lo otro que puedo hacer es tratar de ser más fiel al significado
1355660	1359980	original y tratar de traducirlo más literalmente, es decir, bueno, el señor será para mí como
1359980	1367020	un hombre que cuida de animales que tiene el pelo como algodón, que es bastante más fiel
1367020	1371300	al original, pero sin embargo, se entiende mucho menos, es como que te van a mirar y decir
1371300	1376860	lo de qué me estás hablando. Y bueno, un poco, este es el problema que hay que
1376860	1382940	se enfrentan los traductores humanos todos los días, o sea, es muy difícil tener las dos
1382940	1389340	cosas, ser fiel al original y sonar natural que suene bien en el lenguaje destino. Una traducción
1389340	1393900	queremos que tenga esas dos propiedades, pero es muy difícil lograrlo a la vez, entonces
1393900	1397460	los traductores humanos saben que esto es imposible en la práctica y lo que hacen es tratar
1397460	1402660	de traducir de manera de encontrar un punto intermedio en el cual, bueno, suene bastante
1402660	1410220	bien, pero además sea fiel al significado original. Entonces, esto significa que lo que estamos
1410220	1415060	tratando de hacer al traducir es que estamos tratando de maximizar dos cosas a la vez,
1415060	1420940	como dos medidas que queremos maximizar. Una medida es que tan fiel es mi oración traducida
1420940	1425260	a la oración original, a esa medida le vamos a llamar adecuación o fidelidad y en inglés
1425260	1431460	es adecuación fidelity of faithfulness y la otra medida es que tan natural suena la oración
1431460	1436060	que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en inglés fluency.
1436060	1443260	Entonces, esta idea de que estoy tratando de maximizar dos medidas a la vez, después
1443260	1446380	vamos a ver que en realidad lo que vamos a tratar de maximizar es el producto de las dos medidas
1446380	1452580	porque eso significa maximizar ambas al mismo tiempo, es una idea que sirve para poder
1452580	1456740	inferir o para poder construir mecanismos para crear los traductores automáticos y también
1456740	1460980	mecanismos para testearlos. Y vamos a ver un poco cómo que funciona eso.
1460980	1466140	Yo voy a intentar traducir a partir de ahora el resto de la clase y la clase que
1466140	1470820	viene vamos a hablar siempre de que voy a traducir un lenguaje origen f a un lenguaje destino
1470820	1498380	f es el lenguaje origen y es el lenguaje destino. Eso es nombre surgen porque el paper inicial
1498380	1502420	donde se empezó a hablar de esta cosa de los métodos estadísticos traducía del francés
1502420	1507020	al inglés, entonces acolo nombre de ahí dijo bueno francés f el inglés e entonces traducimos
1507020	1513660	del origen al destino. Bueno, yo quiero traducir una frase del idioma f a otra frase del idioma
1513660	1520420	e lo que quiero tratar de encontrar es el mejor etecho que maximice a la vez la de ecuación
1520420	1524820	y la fluidez, o sea de todos los e posibles del lenguaje destino, quiero encontrar el que
1524820	1529620	maximice la fluidez de es, o sea que suene natural y además la de ecuación entre la
1529620	1537980	oración origen f y s e que estoy buscando. Esta fórmula así escrita de esa manera de
1537980	1541420	estás acordado a algo que hayamos visto ya en el curso en algún momento, les suena
1541420	1551100	algún lado. Entropía, sí. Valles, sí, o sea viene por ese lado, se parece al modelo
1551100	1554140	de valles porque esto es otra aplicación del modelo de canal ruidoso. El modelo de
1554140	1558100	canal ruidoso lo hayamos visto en el curso cuando vimos correcciones de errores, hace
1558100	1562100	ya bastante tiempo y también es una aplicación de lo que es la regla de valles.
1562100	1567260	Entonces, el modelo de canal ruidoso ha aplicado acá funciona de la siguiente manera. Yo
1567260	1573180	tengo una oración origen en el lenguaje f que es f chica que tiene m palabras y es bueno
1573180	1578580	f sub 1, f sub 2 hasta f sub m y quiero encontrar la mejor oración en el lenguaje destino
1578580	1585940	e techo que es sub 1 hasta f sub n, hasta f sub n, que maximiza y en realidad lo que quiero
1585940	1591340	maximizar originalmente como todos esperaríamos es decir, bueno, yo quiero encontrar la oración
1591340	1595700	e que maximiza la probabilidad de edad o f, digamos eso es lo que uno se lo ocurriría
1595700	1599680	primero, diría bueno, yo quiero estoy traduciendo la oración f, quiero encontrar la e que
1599680	1605380	me demáximo la probabilidad de edad o f. Bien, pero en realidad yo esto lo puedo descomponer
1605380	1609180	por valles, digamos, y por definición de probabilidad condicional, pues decir que la probabilidad
1609180	1614300	de edad o f es igual a la probabilidad de f de edad o f por la probabilidad de edad o f.
1614300	1621340	Y vamos a esa equivalencia directa por definición de probabilidad condicional y además como estoy
1621340	1626700	maximizando en e, esta f se mantiene constante, porque lo que voy variando es la e, entonces
1626700	1633700	la etacho, o sea maximizar sobre una constante no hace ningún cambio, entonces lo que me queda
1633700	1639580	el final es que yo busco un etacho que es el e que hace máximo la probabilidad de
1639580	1646180	f de edad o f por la probabilidad de. Y eso que tenemos escrito ahí, se parece mucho a la
1646180	1653100	otra ecuación que teníamos antes, digamos, se parece mucho a esta ecuación de f y fluidez
1653100	1663180	de e. Entonces, se conoce como la ecuación fundamental de la traducion automática estadística,
1663180	1669740	vamos a ver unas cuantas veces en estas dos clases, la vamos a estar refrescando y funcional
1669740	1675060	así de manera. Yo quiero encontrar el e techo que es el e que maximiza el producto de
1675060	1679620	estas dos probabilidades. La primera probabilidad pdf de edad o e es la que se encarga de medir
1679620	1683700	que tal la ecuación, digamos, de la frase, que tal adecuada es la frase f para la frase
1683700	1690460	e. La segunda probabilidad, la pdf es la que se encarga de la fluidez, que tal natural
1690460	1696060	suena esa frase en el lenguaje destino. Y se calculan con modelo distintos. La primera
1696060	1699420	se calcula con lo que se conoce como modelo de traducción y la segunda con lo que se conoce
1699420	1703860	como modelo de lenguaje. De hecho, los modelos del lenguaje ya lo hemos visto en el curso.
1703860	1709540	Vamos a dar un breve repaso de que se trataba. Bueno, ¿por qué esto es una aplicación
1709540	1714500	de canal ruidoso? Es una aplicación de canal ruidoso por lo siguiente. Nosotros estamos
1714500	1719180	tratando de traducir del lenguaje f, f, el lenguaje origen, al lenguaje e que es el lenguaje
1719180	1724020	destino. Y lo estamos pensando al revés. Estamos pensando como que alguien emitió los
1724020	1728100	sonidos de la elaboración e, la elaboración del lenguaje destino. Eso pasó a través de
1728100	1731940	un canal ruidoso. Y cuando llegó hasta mí, yo escuché los sonidos de la elaboración
1731940	1736620	f. Estoy pensando como esa especie de metáfora. Alguien emitió e pasó por un canal ruidoso
1736620	1741100	y llegaron los ruidos de f. Entonces, lo que yo trató de hacer como proceso de traducción
1741100	1746140	es encontrar cuál tiene que haber sido esa e original para que yo haya escuchado la
1746140	1754020	f, cuál es la e original que me da probabilidad máxima de que yo haya escuchado esta f. Y bueno,
1754020	1758660	por eso es una aplicación de canal ruidoso. Y bueno, la realidad es que en realidad damos
1758660	1762940	vuelta esta probabilidad porque nos da toda otra forma de calcularlo que no podríamos hacerlos
1762940	1768140	y calculamos la probabilidad directa. Es como que hay mejores herramientas para hacer eso.
1768140	1772260	Bueno, de vuelta, esto es la ecuación fundamental de la traducción automática estadística.
1772260	1777580	Y techo es el argumento que hace máximo la probabilidad de fedadoe por la probabilidad
1777580	1782780	de. Y para poder resolver esta ecuación necesitamos tres cosas. Necesitamos un modelo de
1782780	1790940	lenguaje p.d.e. que es el que se va a encargar de la fluidez. Esto se calcula mediante la técnica
1790940	1796620	de negramas en general. Los negramas son bastante fáciles de construir, digamos, porque yo
1796620	1804380	necesito texto en un solo idioma, solo en el idioma destino. p.d.e. es la componente
1804380	1808460	que se encarga de la adecuación y se resuelve mediante el modelo de traducción. El modelo
1808460	1812100	de traducción no es tan fácil de construir como el modelo de lenguaje, porque el modelo
1812100	1815140	de traducción voy a necesitar texto de bilíngue. De hecho, voy a necesitar un corpus
1815140	1819940	para el hilo que sea texto en dos idiomas que además tengan su correspondencia. Y además
1819940	1825020	necesito una tercer componente. Esta tercer componente se llama de codificador. Y se trata
1825020	1829740	de lo siguiente. Yo cuando estoy buscando, cuando estoy resolvido esta ecuación, yo veo
1829740	1834260	la oración F y quiero buscar la mejor E que maximizes esta ecuación. Pero en realidad
1834260	1838340	lo que tendría que hacer es probar con todas las oraciones E del idioma destino, todas
1838340	1844000	las oraciones posibles que cuantas son las oraciones del idioma destino. Son infinitas
1844000	1847300	oraciones posibles en el idioma destino. Entonces yo estaría probando con infinitas
1847300	1850840	oraciones hasta que una de ellas me dé el máximo. Obviamente esto no es un problema
1850840	1854920	atratable, yo no puedo probar con infinitas oraciones. Lo que necesito es un proceso
1854920	1859860	que me limites a cantidad de búsqueda de infinitas oraciones a algo atratable. Entonces
1859860	1865880	el codificador va a ser un algoritmo de búsqueda que va a agarrar la oración origen y
1865880	1871040	me va a devolver la cien, doscientas, mil oraciones destino, candidatas más probables que
1871040	1876680	alzelo curra para que yo pueda resolver y calcular esa ecuación para esas oraciones en
1876680	1881160	vez de para todas las posibles. Entonces lo que hace es volver este problema atratable.
1881160	1889960	Vamos a ver también una ecuación de codificación que se llama Binsarch. Bueno, entonces un
1889960	1893800	poco más sobre modelos del lenguaje. La componente pd de la ecuación era la que
1893800	1897760	medía las fluidez y se calculaba mediante un modelo del lenguaje. Los modelos del lenguaje
1897760	1902200	son relativamente fáciles de construir porque necesitamos información mono-lingue, información
1902200	1907920	solamente del lenguaje destino. Entonces en la web tenemos monton, toneladas de información,
1907920	1912960	bueno, de muchos idiomas. Entonces como sonetamos información idiomas, sacamos texto, web, noticias,
1912960	1920360	blogs, etcétera y compilamos un gran corpus del lenguaje destino. Los modelos que se utilizan
1920360	1923320	para traducción automática en general son modelos basados en enegramas que ya hemos
1923320	1929840	visto en el curso como funcionaban, se suele usar orden de 4 o 5, en otras tareas de pdn
1929840	1935240	suele usar ordenes más chicos, pero para acá da buenos resultados con 4 o 5. Y bueno,
1935240	1938920	el importante es tener una gran cantidad de material de entrenamiento. O sea, los mejores
1938920	1944360	modelos que usan Google Translate y otras empresas usan trisiones de palabras y bueno,
1944360	1949680	son necesitan hardware especial, especialmente diseñado para poder ir rápido y recuperar
1949680	1954440	la información. O si no, bueno, si estoy hablando de un dominio acotado, usar datos
1954440	1958200	de dominio para entrenar que también va a ser buenos resultados.
1958200	1960560	¿Qué es la de la técnica?
1960560	1964480	Las técnicas de Moodin es cuando hay alguna enegrama que no viste lo que te va a pasar
1964480	1968240	es que la probabilidad es cero. Y ahí te va a dar todo cero. En realidad, las mejores
1968240	1971560	técnicas es muy significado, darle una buena probabilidad a eso a pesar de que nunca
1971560	1977000	lo yo ha visto. Se dice que las mejores mejoras, digamos, las más grandes mejoras en los
1977000	1980480	modelos en la traducción automática de los últimos años se han dado porque hay
1980480	1986160	mejores modelos de lenguaje que me dan traducciones que son más fluidas. Y bueno,
1986160	1991240	usualmente hay como cierta correlación o cierta inclinación hacia las fluidas.
1991240	1995840	La gente prefiere cuando las oraciones son zonas más naturales.
1995840	2000560	Acá en ejemplo, esto era sacado un sistema de traducción del chino al inglés, un sistema
2000560	2005600	estadístico de San Staxis, que cuando no utilizaba modelo de lenguaje tenía un
2005600	2012280	puntaje de 25x2 al incorporar modelo de lenguaje subió como un 20% su performance y llegó
2012280	2017200	a 31x2 como 6 puntos. Esos puntos corresponden a una medida que vamos a ver dentro de un
2017200	2021080	rato que le llama medida blue, que es una medida muy utilizada en lo que es traducción
2021080	2028120	estadística. La traducción automática en general, pero bueno, ahora solamente saber
2028120	2034600	que 6 puntos es una mejora que es muchísimo. Y como es que mejora esto, mejora haciendo
2034600	2039000	que las traducciones que devuelven en general sean más fluidas, son más naturales en el
2039000	2043400	lenguaje de estino. Y acá hay un ejemplo de traducciones de ese mismo sistema. Yo tenía
2043400	2047040	una traducción de referencia que era, I don't have enough money with me to buy a new
2047040	2052100	airplane ticket. El sistema sin el modelo de lenguaje devolvía esta traducción, de
2052100	2057160	decir, I don't have enough bag on me change please go a new by plane. Que no, no se entiende
2057160	2061600	mucho que lo que dice, no es gramatical. Pero al agregar el modelo de traducción, su
2061600	2066280	traducción es la siguiente, I have enough money to buy a new one by air, que suena mucho
2066280	2076520	mejor ¿verdad? Que les parece acerca del significado. El significado es el opuesto, digamos, acá
2076520	2079720	está diciendo que tiene suficiente plata para comprar uno por aire y acá dice que
2079720	2084720	no tiene suficiente plata para comprar un pasaje de avión. O sea, este suena muchísimo
2084720	2088320	mejor porque está ni siquiera gramatical, pero esta por lo menos mantenía la negación,
2088320	2093000	digamos, mantenía que era una oración negativa. Entonces hay que tener cuidado con esto.
2093000	2097400	La traducción suena mucho mejor, pero a veces podemos estar sacrificando fidelidad,
2097400	2104760	sacrificando adecuación de la traducción. Bien, eso es sobre modelos de lenguaje. Ahora
2104760	2112480	pasemos a la otra, los modelos de traducción. La componente pdf de la ecuación mide lo que
2112480	2116960	es la adecuación o fidelidad de una traducción y la otra y para esto necesito corpos para
2116960	2122160	leylos o corpos bilíngües que para poder entrenar estos modelos. Los corpos bilíngües
2122160	2125960	son bastante más difíciles de construir que los corpos monolíngües, digamos, no alcanza
2125960	2130420	con hacer una pasada por la web y obtener texto de un idioma. Y bueno, los modelos que
2130420	2137680	vamos a ver son los propuestos por Brown y si equipo en 1993 que trabajan en IBM, ellos
2137680	2142000	construyeron cinco modelos de cómo construir cinco modelos, digamos, en creciente complejidad
2142000	2148280	de cómo construir un modelo de traducción para traducción estadística. Y bueno, los
2148280	2152400	modelos, las diferencias de cada modelo se es en la historia de generación de las
2152400	2156120	soldaciones candidatas. Y bueno, después vamos a ver también otro modelo un poco más
2156120	2161960	moderno, pero bueno, vamos a empezar viendo más bien los modelos de Brown. Aquí me refiero
2161960	2167040	con historia de generación de las soldaciones candidatas. Una historia de generación, esto
2167040	2170560	lo digo ahora, pero en realidad lo vamos a profundizar después. Una historia de generación
2170560	2173960	en realidad es como una especie de proceso mental que seguiría un traductor cuando
2173960	2179440	quiere pasar de una oración a la otra. Entonces, estas historias se basan en decir, bueno,
2179440	2184440	un traductor agarró una oración en el idioma origen y después elige la cantidad de palabras
2184440	2188200	que voy a tener el idioma de estino, reordena palabras, después va traduciendo una a una
2188200	2192240	según un diccionario, después agrega palabras nuevas que no estaban en la oración.
2192240	2197480	Ese tipo de cosas, digamos, ese tipo de pasos, me lo voy a escribir en la historia de generación
2197480	2201320	y para que sirve eso, sirve para que a cada uno de esos pasos yo le pudo dar un valor
2201320	2205680	numérico, un valor en cuanto a probabilidades y después lo que voy a hacer cuando entreno
2205680	2209960	mi sistema es tuñar esos valores numéricos, tuñar todas esas probabilidades para darme
2209960	2217480	el cálculo de probabilidad total. Vamos a profundizar más de en esto después, pero antes
2217480	2220800	de pasar a lo que son las modelos de traducción, vamos a hablar un poco de cómo se evaluan
2220800	2225520	estos sistemas. En general, siempre es importante evaluar todo en el PLN, digamos, porque no
2225520	2230080	hay soluciones perfectas, entonces voy a tener sistemas que andan mejor o peor que otros.
2230080	2235680	Y bueno, la traducción automática obviamente no es la excepción. Entonces, me sirve
2235680	2238920	poder evaluar los sistemas para poder saber qué sistema es mejor que el otro y además,
2238920	2243680	si yo hago cambios en mi sistema, poder evaluar de vuelta a ver si mejoré o no. Entonces,
2243680	2247960	¿qué puedo considerar una buena traducción? Para empezar, eso es una pregunta que es abierto
2247960	2255720	en su, digamos, esa abierta en su respuesta. O sea, yo tenía en un sistema de traducción
2255720	2259800	tenía una referencia, un candidato de referencia que era de CatSat on Demat, digamos,
2259800	2264920	esa era una traducción de referencia y un sistema medio seis posibles candidatos para
2264920	2270840	esa traducción. O sea, originalmente había una frase, por ejemplo, en China, la traducción
2270840	2276080	de referencia, la de CatSat on Demat y mi sistema a traducirme el chino medio estas opciones.
2276080	2281800	Tengo de CatSat on Demat Sat de Cat, de Cat on the floor, a CatSat on Demat, de CatSat
2281800	2288920	on Demat, con minúscula o de CatSat on the Stromat. ¿Cuáles les parecen que son buenas
2288920	2293440	traducciones de estos candidatos que me dio el sistema? ¿Cuáles les gusta más?
2293440	2301840	La E, que es de CatSat on Demat, pero con minúscula me dé como yo, ¿qué otra? La
2301840	2314840	B, on Demat Sat de Cat, ¿qué otra? La D les gusta también a CatSat on Demat. ¿Capaz que
2314840	2318680	no calienta tanto, dependiendo del uso que le vas a dar esa frase en contexto, capaz que
2318680	2323200	no calienta tanto? Y bueno, sí, la verdad no se ve nada cuando están las cosas marcadas
2323200	2326560	en rojo, pero bueno, en fin. Crea que acá las cosas marcadas en rojo son las que acaban
2326560	2332320	de decir. Una buena traducción, podemos decir que es una traducción que le gusta la gente,
2332320	2337720	que la gente dice si es una buena traducción. Entonces acá se elige on Demat Sat de Cat,
2337720	2344120	a CatSat on Demat, y de CatSat on Demat en minúscula. Y bueno, como decimos, le preguntamos
2344120	2347920	a la gente a ver que traducciones le gustan, y bueno, ya ahí ponemos cuales son las mejores
2347920	2353120	traducciones. O si no, le damos a un conjunto de jurados las traducciones y le decimos
2353120	2357400	que hagan un análisis un poco más preciso, y nos digan, bueno, cuánto le dan en uno
2357400	2364160	al diez de adecuación, y cuánto le dan en uno al diez de fluidez.
2364160	2369640	Esas otra forma de evaluar, digamos, y ahí ya nos están dando las dos medidas. En general,
2369640	2374360	los humanos nos cuesta realizar esta evaluación. En general, tenemos una preferencia de la fluidez,
2374360	2381680	como pasaba hoy con el caso de traducción del chino al inglés, por los pasajes de avión.
2381680	2385800	Además, la gente no se pone a acuerdo. Además, hay un problema que es que hacer este tipo
2385800	2389880	de evaluaciones con usuarios humanos, lleva tiempo, digamos, hay que pagarles a los usuarios
2389880	2395520	por hora para que estén evaluando sistemas. Y después, yo le dí un conjunto de traducciones,
2395520	2399560	ellos me la se evaluaron, hice algún cambio en mi sistema para mejorarlo, y devuelta
2399560	2403000	hacerle, de teo que dale conjunto de traducciones a los humanos, y devuelta lo tienen que evaluar,
2403000	2408080	y devuelta, tengo que pagar obras de usuarios humanos para que lo valúen.
2408600	2412400	Entonces, es difícil de reutilizar. Yo voy a estar haciendo cambios constantemente en mi sistema,
2412400	2417240	y bueno, y necesito tener una forma más rápida de evaluar a ver si estoy haciendo las cosas mejor.
2417240	2421160	Entonces, como este proceso de evaluación es largo, es engorroso, es caro,
2421160	2424800	lo que se ha vuelto más popular son los métodos automáticos de evaluación. Y,
2424800	2431080	a continuación, vamos a ver uno, que es muy utilizado en lo que es la traducción automática.
2431080	2439200	Bueno, ¿cómo funciona un método de evaluación? En realidad, lo que hace alguien,
2439200	2447200	alguien que está diseñando un sistema, es crearse un conjunto de oraciones con cada una
2447200	2450360	con una traducción de referencia que está bien, digamos, una traducción hecha mano.
2450360	2454320	Entonces, yo quiero evaluar un sistema que va del español al inglés, lo que tengo es un
2454320	2459320	conjunto de oraciones en español, y alguien, algún traductor humano me tradujo todas esas
2459320	2463080	oraciones en español, y medio un candidato, o más candidato está lo es para cada una,
2463080	2466360	digamos, a eso le voy a llamar referencias, traducciones de referencia.
2466360	2471320	Lo siguiente que tengo que hacer es poder diseñar una métrica de similitud para que,
2471320	2475800	cuando mi sistema me da un candidato de traducción, yo puedo establecer una similitud entre ese
2475800	2479760	candidato y alguna de las referencias. Y bueno, después lo que voy a hacer es aplicar esa
2479760	2486160	métrica para los pares, candidatos y referencias, y bueno, y sacar como un promedio de todos
2486240	2492280	los valores de similitud que tengo. Entonces, se han inmetado muchos métodos de este estilo,
2492280	2497560	muchos métodos automáticos, que vamos a ver en particular se llama Blue, que es una
2497560	2502560	métrica muy difundida en lo que es la traducción automática estadística. Y bueno,
2502560	2507120	primero hay algunas definiciones, le vamos a llamar referencia a una traducción que
2507120	2511440	está traducida manualmente, o sea, consideramos que es una oración correcta, eso es una referencia,
2511440	2515000	y le vamos a llamar candidato a una traducción que no tiene por qué estar correcta porque
2515000	2520320	la tradujo del sistema automático. Y le vamos a llamar documento al conjunto de todas
2520320	2525000	las oraciones candidatas, al conjunto de todas las oraciones traducidas por el sistema,
2525000	2529240	que es lo que vamos a estar evaluando. Así que recuerden, tenemos referencia, candidato
2529240	2535080	y documento. Y bueno, ¿qué es lo primero que se nos puede ocurrir hacer cuando queremos
2535080	2541360	saber si un candidato es bueno para la referencia o no? Lo primero que podemos hacer es tratar
2541360	2549080	de contar las palabras que ocurren en ambos. Entonces, yo puedo tratar de contar palabras
2549080	2552960	que ocurren en el candidato y palabras que ocurren en la referencia, y ahí diría que
2552960	2556640	la elección de las palabras de candidato, si están, la palabra candidato, si están,
2556640	2560400	también en la referencia, yo diría que eso se acerca un poco a la adecuación, se acerca
2560400	2565480	que, bueno, por lo menos, usó palabras que son fieles a la traducción de referencia.
2565480	2569520	Pero si además esas palabras están usadas en el mismo orden, ahí se acerca un poco más
2569520	2573360	a la fluidez, o sea, si están usadas en el mismo orden, puede sonar tan natural como
2573360	2581920	la referencia. Y esto se puede hacer automáticamente haciendo conteos de enegramas.
2581920	2586520	Acá yo tengo una referencia que es de CatSat, mi sistema me tenía que haber devuelto
2586520	2593280	de CatSat y tenía dos candidatos, candidato era de Cat y el candidato era SadCatD. Entonces,
2593280	2597600	lo que puedo hacer es conteo de enegramas, cuáles son enegramas de los candidatos pertenecen
2597600	2603540	a la referencia. Y entonces, para el caso de Cat, el enegrama D pertenece la referencia,
2603540	2607820	el enegrama Cat pertenece a la referencia y el enegrama D Cat, o sea, el Vigra Madecat
2607820	2613320	también pertenece a la referencia. Para el caso del candidato B, el unigrama Sad
2613320	2619520	pertenece el unigrama Cat pertenece el unigrama D pertenece. Pero SadCatD este Vigrama no
2619520	2623960	pertenece a la referencia y CatD tampoco pertenece a la referencia. Y además, el único
2623960	2627920	trigrama que hay, SadCatD tampoco está en la referencia. Entonces, lo que aparece
2627920	2633320	a la derecha son los enegramas que sí pertenecen tanto el candidato como a la referencia.
2633320	2640520	Así que, bueno, resumiendo, yo puedo contar la cantidad de hits de unigramas, de Vigramas,
2640520	2644960	de trigramas. Y para el candidato B se cumple que todos los unigramas que hay pertenece
2644960	2649280	a la referencia. Así que, voy a tener dos de dos hits. Para los Vigramas, voy a tener uno
2649280	2655920	de uno. Pero para el candidato B, los unigramas me dan 3 de 3, digamos, 3 hits. Los Vigramas
2655920	2660080	no. O sea, tengo dos Vigramas posibles y ninguno estaba bien. Y los trigramas tampoco.
2660080	2665040	Tengo un trigrama posible y no estaba bien. Entonces, por ahora, parece que le va ganando
2665040	2672200	de Cat, la el candidato B de Cat le va ganando a SadCatD como traducción. Bien, ¿qué
2672200	2678560	puedo hacer con los contegos de enegramas? Lo que hago habitualmente, o sea, contar enegramas,
2678560	2682880	para unigramas, vigramas, tiramas, se acerca un poco a lo que es la noción de una precisión
2682880	2686120	de algo. Entonces, lo que voy a hacer es contarlos
2686120	2689960	por separado. Voy a decir, voy a contar todos los unigramas por un lado, todos los Vigramas
2689960	2694080	por otro, todos los trigramas por otro. Y para cada uno de esos, me voy a armar una
2694080	2698120	precisión. Voy a decir que tengo. El candidato
2698120	2703520	se subí, digamos, un candidato que voy a considerar. Voy a contar los hits de orden N,
2703520	2709640	se subí, digamos, los hits de unigramas, se subí. Voy a llamar H, se subí. Y voy a contar
2709640	2715160	la cantidad de unigramas totales que hay y le voy a llamar T, se subí. Pero además,
2715160	2720480	voy a hacer esto, en vez de hacerlo para una sola oración, para un candidato y su referencia,
2720480	2724320	lo voy a hacer para todo el documento. Voy a contar todos los unigramas que estaban en mis
2724320	2729680	candidatos. Voy a ver cuánto eso está bien y voy a hacer esta división. Entonces, me va
2729680	2736520	a dar cuál es la precisión en unigramas. ¿Qué va a ser? Bueno, tanta cantidad de unigramas
2736520	2741600	estaban bien dividido, toda la cantidad de unigramas que genero en los candidatos. Después
2741600	2745400	voy a hacer eso para Vigramas. Voy a contar toda la cantidad de Vigramas que estaban bien,
2745400	2748700	porque estaban en el candidato en la referencia, dividido toda la cantidad de Vigramas que
2748700	2752600	en el candidato. Voy a hacer lo mismo para trigramas y voy a hacer lo mismo para 4igramas.
2752600	2757040	En general, se suele llegar hasta 4, digamos, en traducion automática estadística, la
2757040	2762480	medida blu llega a calcular hasta 4. Entonces, bueno, lo que me define ahí es lo que se llama
2762480	2768440	probabilidad de orden N, la probabilidad, precisión de orden N, la precisión para unigrama,
2768440	2775800	la precisión para Vigramas, la precisión para trigramas, etc. Bien, esta métrica que
2775800	2781000	estamos construyendo es bastante fácil engañar. En realidad, yo me definí una probabilidad,
2781000	2784600	por ejemplo, de la probabilidad de orden 1 y la puedo engañar muy fácil, porque yo me
2784600	2789760	puedo construir un candidato que tiene siempre la misma palabra. Puedes ir, bueno, un candidato
2789760	2797720	para la referencia de Catzato Nemat es el candidato DDDDD. Como yo justo le emboque a una palabra
2797720	2802360	que está en la referencia, entonces cuento los unigramas y me da que hay 6 hits de 6,
2802360	2807040	a pesar de que la traducción es horrible. Entonces, como hago para evitar esto, lo que se
2807040	2811840	suele hacer es clipping, lo que significa que cuento cuanto es la cantidad máxima de palabras
2811840	2815760	en la referencia y no permite que haya más de eso. Entonces, yo acá tengo hasta dos palabras
2815760	2822520	D, entonces no puedo contar 6 de 6, tendría que contar máximo 126. Entonces ahí evitamos ese
2822520	2830400	problema de que, bueno, alguien se haga el vivo y genera simplemente una sola palabra. Bien,
2830400	2836000	entonces, hasta ahora vimos dos cosas, calculamos la precisión de orden N, la precisión de cada uno
2836000	2840880	de los unigramas o diagramas, los segundos que vimos es que vamos a hacer clipping para evitar
2840880	2843960	pasarnos de conteo en las palabras que aparecen más de una vez.
2845960	2853720	Lo tercero que pasa es veíamos en este ejemplo de acá, acá tenemos dos candidatos de Catz
2853720	2859000	y Sad CatzD, y lo que pasaba acá era que le estaba haciendo mejor a la traducción de
2859000	2865000	Catz porque tenía todos los unigramas que están en la traducción, están también en la
2865000	2869360	referencia y todos los diagramas también, en cambio el candidato V no, el candidato V tiene
2869360	2873240	unigramas que están, pero diagramas y trilamas que no están. Entonces en cuanto a precisión
2873240	2878600	el candidato V va bastante mejor. ¿Por qué va bastante mejor el candidato V? Porque es
2878600	2886040	un candidato que es más corto que la referencia, o sea, es un candidato que tiene menos palabras.
2886040	2890040	Como venimos definiendo la métrica, si yo tengo una referencia y después tengo un candidato
2890040	2894680	que es justo un prefijo de la referencia, entonces va a cumplir que ese prefijo andaba
2894680	2898000	bien en todas las medidas de precisión, porque todos los enigramas que tiene van a
2898000	2903080	pertenecer a la referencia. Así que lo que hace la medida blue es penalizar ese tipo
2903080	2911920	de comportamientos. Penaliza los candidatos que son muy cortos para que digamos le de
2911920	2919280	menos puntaje. Entonces, ¿por qué se penaliza los candidatos cortos y no los candidatos largos?
2919280	2925360	¿Por qué les parece? Candidatos que son demasiado cortos se penalizan, pero les hemos
2925360	2931560	dado largos, ¿no? La respuesta está en las slides, pero bueno, se que se penaliza los
2931560	2935640	candidatos cortos porque los candidatos largos, si yo genero un candidato que es mucho más
2935640	2939960	largo que la referencia, lo que va a pasar es que ese candidato tiene enigramas, seguramente
2939960	2944720	tiene enigramas que no pertenece de la referencia. Entonces, en el contenido de precisión me
2944720	2949080	va a dar un puntaje más bajo. Candidatos largos ya están penalizados por la precisión,
2949080	2953600	candidatos cortos no están penalizados por la precisión. Entonces, necesito otro tipo
2953600	2959480	de penalización para evitar eso. Bien, entonces lo que vamos a dar es una cosa de
2959480	2965080	llama penalización propiedad o brevitipenal, que es un puntaje que se le da en referencia
2965080	2970840	que tan corto es un candidato respecto a la referencia y bueno, se calcula teniendo en
2970840	2974320	cuenta todo el largo del documento, todo el largo del documento traducido, entonces
2974320	2979800	acá yo defino que el reprima es el largo total de todas las referencias, se prima es
2979800	2987080	el largo total de todos los candidatos. Y entonces, si el largo de los candidatos es mayor
2987080	2991880	a largo de las referencias no hay penalización, le pongo uno, si el largo total de los candidatos
2991880	2997880	es menor a largo de las referencias, entonces lo calculo como e a la menos, e a la uno menos
2997880	3003880	la división entre los largos. Esto es una definición de probabilidad
3003880	3009800	exponencial, digamos, no es más que eso. Y en realidad lo que trata de hacer es penalizar
3009800	3015320	traducciones que son muy cortas, entonces si yo tenía un candidato que tenía cinco palabras
3015320	3020160	mientras la referencia tenía diez, lo voy a penalizar fuertemente, le voy a dar un 0.37
3020160	3025080	de penalización, si yo tenía un candidato que estaba que era menor pero era más cercano,
3025080	3030600	entonces la penalización no es tanta de 0.78 y después si los largos son iguales o si
3030600	3034040	el candidato es más largo, no penalizó nada, le doy uno de puntas.
3034040	3041840	Bueno, entonces la metrica blue, que es una metrica muy usada en traducción automática,
3041840	3045480	pone todo esto juntos, digamos, todos estos pedacitos que estuvimos viendo, los pone juntos
3045480	3050280	en un solo cálculo. Blue se calcula como la penalización por probabilidad, el breve
3050280	3062360	penal D, por E a la suma de las precisiones de orden N. ¿Qué palabras ruido?
3062360	3074840	Por ejemplo, esto es un unigrama que le va a dar 0 de precisión, digamos, por ejemplo,
3075400	3080320	bueno, esta palabra no va, o sea, es un unigrama que le va a dar 0 de precisión, digamos,
3080320	3084000	porque no está, además participan un diagrama que también le va a dar mala precisión porque
3084000	3089160	tampoco está el diagrama, entonces lo que, reestan realidad porque no está sumando la
3089160	3095160	impresión, acá yo tengo 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 es también, pero
3095160	3099840	hay uno que no, en cambio, en este tengo 6 unigrama de los cuales los 6 es también,
3099840	3104720	entonces acá el hecho de agregar palabras que no son, que no están bien, no están en la
3104720	3110920	referencia, ya te penaliza. La diferencia es cuando yo tengo una traducción que más corta,
3110920	3115680	si yo diría, solo de CatSatOn, entonces ahí es más corta y no tengo forma de penalizarlo
3115680	3119440	solo con la precisión, entonces tengo el otro penalizador que es porque la traducción es muy
3120440	3131440	corta. Bien, entonces les estaba comentando, la media blusa define como una media geometrica,
3131440	3138200	definición de media geometrica, de las precisiones de orden N, también tienes un peso por
3138200	3143800	precisión que se puede variar, pero en general se utiliza el mismo peso para todos, multiplicado
3143800	3156280	por la penalización pobrevedad. Bien, eso es la definición de la media blusa, que es una
3156280	3161680	media que se utiliza muchísimo, esos puntajes que vemos hoy de 25 con 2 y 31 con algo eran
3161680	3169120	ejemplos de media blusa aplicados en un sistema. Y bueno, una cosa importante, algunos comentarios
3169120	3173320	importantes sobre la metrica blusa es que en general cuando un sistema le da mejor, digamos,
3173320	3176640	con un conjunto de traducciones, le da mejor en metrica blusa, también le da mejor con un
3176640	3181280	conjunto de humanos que evaluan el sistema, o sea que tiene una correlación bastante buena con lo
3181280	3186960	que es la evaluación subjetiva humana, pero como contra es difícil de interpretar estos
3186960	3191360	puntajes, o sea, si yo tengo un puntaje de, como nos ha pasado hoy, tiene un puntaje de 31,
3191360	3195600	en realidad un 31 es un número que puede ser muy bueno, muy malo, dependiendo del idioma,
3195600	3202200	pero o sea, si todo saliera bien y yo tradujera exactamente lo mismo que están las referencias,
3202200	3206640	por construcción la media me daría uno, pero en realidad es muy difícil traducir exactamente
3206640	3210840	lo que están las referencias, porque no es cierto que exista una única traducción posible
3210840	3216960	en la traducción digamos humana. Horaciones se pueden traducir de manera distinta y estar
3216960	3220880	igualmente bien, entonces es muy difícil tener un conjunto de referencias que contempla
3220880	3225000	todas las posibilidades, así que en mi traducutor capaz que anda bárbaro, pero el puntaje
3225000	3231560	aún no es uno, no es 100 digamos, porque está eligiendo palabras distintas o eligiendo
3231560	3237000	formas de escribir las oraciones distintas, entonces bueno, por eso es difícil interpretar,
3237000	3244240	yo tengo un puntaje de 30 o de 50 o sea, de 0.3 o de 0.5 y puede ser buenísimo para
3244240	3253120	ese sistema, pero para algo que sí me sirve muchísimo el puntaje, digamos, el puntaje
3253120	3257320	de blu es para decir, yo tengo mi sistema, luego el lujo, después hago algunos cambios,
3257320	3261800	el lujo de vuelta y si subió la performance de un puntaje blu, entonces estoy seguro
3261800	3265000	de que mejoro, porque hay una correlación con la evaluación subjetiva.
3265000	3281440	Para pasar el español inglés, en realidad lo que pasa es que entrenás otro traducutor.
3281440	3288320	No, acá estoy volando solo, acá estoy volando solamente en un sentido, yo tenía un sistema
3288320	3298320	español, por ejemplo, digo una oración español, el gato se sentó, y alguien me dijo bueno,
3298320	3302640	la traducción de referencia a eso es de CatSat y mi sistema me dijo bueno, pero mis
3302640	3307840	traducciones posibles son de Cat y Sad Cat D, entonces yo tenía un sistema en español
3307840	3311640	pero que traduce al inglés, digamos, un sistema de traducción de español de inglés,
3311640	3316960	pero no, no estoy traduciendo en el otro sentido, no, no es como las canciones, acá partí
3316960	3320440	del español y llegué al inglés y estoy tratando de evaluar comparando las frases en
3320440	3327840	inglés esperadas con las frases en inglés generadas, claro, probablemente, claro, está en
3327840	3332840	el mismo idioma, o sea, lo que no mostramos acá era cual era la oración origen, porque para
3332840	3337720	evaluar no nos importa, para evaluar nos importa que comparar solamente la oración candidato
3337720	3342840	con la referencia y la origen nos olvidamos, sabemos que los dos intentaron traducir de
3342840	3351080	la misma oración y bueno, y alguno le fue mejor que a otro, bien, esos son comentarios
3351080	3356760	de blue, esto era evaluación de los sistemas, lo siguiente que vamos a ver es el problema
3356760	3360600	de los corpos paralelos, antes de pasar a lo que son modelos de traducción, vamos a
3360600	3365160	hablar un poco de lo que son los corpos paralelos, que son necesarios para construir un modelo
3365160	3370920	de traducción, un corpos paralelo consiste en pares de textos en dos idiomas, por ejemplo,
3370920	3375720	tener textos en español y en inglés, pero además yo tengo que tener algún nivel, tengo
3375720	3380100	que tener una correspondencia entre esos textos, de alguna forma, yo tengo que saber cómo
3380100	3386800	se corresponde un texto con el otro, entonces bueno, tiene que estar con juntos, digamos,
3386800	3391400	ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen en
3391400	3396400	el mundo, existen corpos paralelos para algunos idiomas, o sea, hay muchos idiomas en el mundo,
3396400	3400120	pero no todos los pares de idiomas tienen corpos paralelos construidos, entonces existen
3400120	3404640	para el lado de inglés, el chino inglés, para la mayoría de los lenguajes europeos,
3404640	3410360	debido a su uso en la unión europea, digamos, existen también corpos paralelos para ellos,
3410360	3416280	pero para la gran mayoría de pares de lenguas, no hay, digamos, no tengo un par que traduzca
3416280	3421080	entre el chino y el guaranismo, por ejemplo, o sea, es poco probable que se construye un
3421080	3431320	par de estilos, bien, que es un corpos paralelos, ya que no se ve nada, de vuelta, acá hay un ejemplo
3431320	3438800	que no sé si lo conocen, es un ejemplo famoso de corpos paralelos, tiene ni idea de lo que
3438800	3449520	es, lo han visto alguna vez, la piedra de roseta, la piedra de roseta, una piedra que la construyeron,
3449520	3455440	o por lo menos la tallaron el año 1996, antes de Cristo, y hablaba sobre la coronación de
3455440	3462480	Tolomeo Quinto, y tal, y su adoración como semi-dios, etcétera, etcétera, y bueno,
3462480	3467280	hasta estuvo perdida, tomo un montón de años, hasta que durante las campañas Napoleónicas,
3467280	3475080	1799, la encontraron en Egipto, en el lugar roseta, casualmente, y se lanzaron para Francia,
3475080	3479800	ahí le empezaron a analizar lingüistas, empezaron a tratar de entender que era lo que decía, y bueno,
3479800	3486200	descubrieron que tiene tres textos, vieron que tienen como tres regiones, tres textos, y después de
3486200	3490720	estudiarla un rato, seguiron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas
3490720	3496040	distintos, y los idiomas eran, el de arriba era en jeroglíficos egipcios del estilo de lo que
3496040	3500720	uno encuentra dentro de las pirámides, el del medio era egipcio demótico, que era el egipcio
3500760	3506840	vulgar que se usaba, digamos, en el día a día, y el de abajo el todo era griego antiguo. Entonces,
3506840	3510800	si bien, ninguno de los tres idiomas se hablaba en el momento que se encontró, la piedra,
3510800	3517440	los tres idiomas antiguos, el griego antiguo por lo menos sí se sabía, digamos, se conocía como
3517440	3521800	idiomas, se sabía qué significaba, y digamos, había gente que lo estudiaba, los otros dos no,
3521800	3527360	los otros dos eran lenguas completamente perdidas, que nadie sabía identificarlas. Pero gracias al
3527400	3531240	hecho de que en realidad se descubrió que los tres textos hablan de lo mismo, son el mismo
3531240	3537640	texto entre los idiomas. Entonces ahí se empezó a hacer un trabajo de alineación, digamos, los
3537640	3540480	arqueólogos, empezaron a decir, bueno, esta porción de texto acá se corresponde con esta
3540480	3544480	de acá, se corresponde con esta de acá, etcétera, y a tratar de encontrar correspondencias en los
3544480	3549120	idiomas, y cómo sabían qué quería decir en griego antiguo, empezaron a poder descubrir qué
3549120	3553320	querían decir en los otros idiomas. Entonces, a raíz de eso es que empezó, digamos, el
3553320	3558480	Egipto Elogía Moderno se pudo empezar a desifrar, qué dicen, por ejemplo, los geográficos
3558480	3562560	están en las pirámides, y bueno, un montón de cultura, egipcio antiguas, se conoce gracias
3562560	3566920	a que se pudo desifrar lo que decía esta piedra. Y en definitiva, esto es un ejemplo de corpus
3566920	3571080	paralelo, o sea, tengo el mismo texto entre los idiomas, y con un poco de esfuerzo logro al
3571080	3578720	alinear, cual son cada uno de los elementos de mis lenguajes, y logro saber la traducción
3578720	3586240	de los tres. Bueno, entonces, esto nos lleva el concepto de alineación. Los corpus paralelos
3586240	3590640	tienen distintos niveles de alineación. Lo más fácil de encontrar son corpus que están
3590640	3593680	alineados al nivel de documentos. Yo tengo una colección de documentos en español y una
3593680	3598480	colección de documentos en chino, y yo sé qué documentos se corresponde con qué otro,
3598480	3602720	pero no sé nada más. Sería mejor, incluso que estuvieran alineados a nivel de
3602720	3607360	elaboración, además de conocer los documentos, yo sé cuál elaboración español va con
3607360	3611160	cuál elaboración en chino, digamos. Tengo una correspondencia entre esas dos. Pero sería
3611160	3615600	aún mejor, y esto es lo que más nos serviría, si estuvieran alineados a nivel de palabra.
3615600	3618760	Cada uno de los caracteres que están en chino se corresponde con qué palabra en español,
3618760	3621920	lo que grupo de palabra, si cada uno de las palabras de español con qué grupo de caracteres
3621920	3627720	se corresponde en chino. Esto es el ideal, pero claro, o sea, si ya es difícil conseguir
3627720	3632280	cosas que estén alineadas a nivel de documentos, si imaginan que nadie va a ir a mano al
3632280	3638400	linear a nivel de palabra cada uno de las palabras de los idiomas. Entonces, en la práctica
3638400	3643360	nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que, como
3643360	3647880	resultado de la construcción de los modelos de lenguaje, se produce también como un producto
3647880	3652840	secundario, se produce la alineación de los corpus. Entonces, obtenes las dos cosas a
3652840	3657960	la vez. Bueno, yo otra cosa es que, a diferencia
3657960	3664080	de el texto monolíngue que yo usaba para los modelos de lenguaje, es muy raro que
3664080	3671480	naturalmente se produzcan textos en dos idiomas a la vez. O sea, hay que buscarlos bastante,
3671480	3676320	digamos, bastante cuidadosamente. Existen algunos contextos en donde eso se produce. Por
3676320	3680280	ejemplo, en algunos portales de noticias, puede pasar que tengan versiones en distintos
3680280	3684080	idiomas y lo que hagan sea traducir las noticias en distintos idiomas. Entonces, si yo
3684080	3688040	puedo encontrar uno de esos, es una buena fuente para construirme un corpus paralelo
3688040	3692000	anineado a nivel de documentos. O sea, esta noticia se corresponde con esta otra en el
3692000	3695800	otro idioma. Pero un lugar en donde se producen naturalmente
3695800	3702160	este tipo de textos es en los países que son bilíngües, o multilíngües. Por ejemplo,
3702160	3706800	en Canadá, que hablan inglés y francés, las discusiones del Parlamento Canadíense
3706800	3711880	siempre, por ley, tienen que transcribirse en los dos idiomas, tienen que traducirse
3711880	3718000	si está en inglés, se daus en francés, se daus en inglés. Y guardan una correspondencia
3718000	3720480	entre eso. Guardan el documento de todas las discusiones del Parlamento en los dos
3720480	3725600	idiomas. Entonces, ahí, naturalmente se produce un corpus paralelo anineado de documentos
3725600	3731120	para el inglés y el francés, que se se conoce como el corpus Hansard. Eso también ocurre
3731120	3735600	en concon, en conconciable inglés y chinos, son los dos idiomas oficiales. Entonces,
3735600	3739400	el corpus más grande que se tiene para inglés y chinos, está hecho como una compilación
3739400	3742880	de lo que son las discusiones del Parlamento de Hong Kong. Y también pasa en la Núneo
3742880	3748920	Europea, en el Parlamento Europeo, también tienen la costumbre de traducir todas las discusiones
3748920	3752920	a todos los idiomas o a muchos de los idiomas que se usan en la Unión Europea. Entonces,
3752920	3758200	hay corpus paralelo para casi todos los idiomas de la Unión Europea. Pero claro, todos
3758200	3762560	estos están alineados a nivel de documento. Yo sé qué documento se corresponde con
3762560	3770320	cual otro en el otro idioma, pero no anivel de oraciones y mucho menos anivel de palabras.
3770320	3776240	Pero bueno, partiendo de un corpus alineado a nivel de documentos, yo puedo llegar a construir
3776240	3780960	me, por lo menos, una alineación a nivel de oraciones, siendo un proceso relativamente
3780960	3790120	sencillo. Esto se conoce como el algoritmo de que él y Church, que es un algoritmo relativamente
3790120	3796880	fácil para alinear corpus, o sea, para pasar corpus que están alineados a nivel de documento,
3796880	3802680	pasarlos a que estén alineados a nivel de oración. Y bueno, esto es un algoritmo que funciona,
3802680	3806740	está un poco basado en lo que era el algoritmo de distancia de edición del EventTime, que
3806740	3816200	vimos hace bastante tiempo en el curso. Bueno, es como muy parecido, también es un
3816200	3820920	algoritmo de pronomación dinámica, similar a ese. Funciona de la siguiente manera, o
3820920	3825280	sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de cómo que funcione.
3825280	3829880	En el algoritmo de Gayley Church dice, yo voy a tener un conjunto de oraciones en un idioma
3829880	3841320	y otro conjunto de oraciones en el otro idioma. Entonces, considero que un traductor para
3841320	3846560	cada oración pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma.
3846560	3851160	Un traductor, suponga un traductor humano, agarró oraciones que estaban en español y
3851160	3856840	oraciones que estaban en francés. O sea, no ponerles EIF porque lo que puede confundir
3856840	3861360	con las otras cosas, así que vamos a decir el lenguaje de origen era F, francés y el
3861360	3867720	lenguaje de estino era español. Bien, entonces, un traductor humano cada vez que se enfrentaba
3867720	3872880	una oración tenía tres posibilidades. O bien, traducía una oración por otra oración,
3872880	3879960	o bien parte de esta oración en dos y traduce una oración por dos, o bien borra esta oración,
3879960	3884000	decide que no es tan importante y abarra y borra la oración. Entonces, las tres operaciones
3884000	3888560	que se hacen a nivel de oración son la de transformarla en cero, una o dos oraciones
3888560	3897680	del otro lado. Eso es una cosa. Lo otro es, el costo relativo de alinear
3897680	3902280	estas dos oraciones depende del largo relativo de las oraciones. Entonces, si yo tengo dos
3902280	3908040	oraciones que tienen un largo muy parecido, le voy a dar un costo menor para alinearlos,
3908040	3913200	era menor o mayor. Sí, menor. Si tiene un largo muy parecido, le voy a dar un valor menor
3913200	3917240	para alinear. Si tiene un largo muy distinto, una es muy corta y la otra muy larga, entonces
3917240	3923520	le voy a dar un valor mayor para alinear. Entonces, lo que ellos hacen es pensando en
3923520	3927600	todo este tipo de operaciones que hay, todas las combinaciones de operaciones posibles,
3927600	3936560	o sea, partir esta oración en dos o no partirla o eliminarla o dejarla como está. Entonces,
3936560	3941340	con programación dinámica, ven todas las posibilidades de operar distinto para llegar
3941340	3946080	al otro lado y calculan las que le da un costo menor. O sea, para cada una de las posibilidades
3946080	3952680	calculan cuál es el costo de cada par de oraciones suman todos los costos del documento.
3953280	3958720	Y se quedan con el caso que les dé un costo menor en alineación. Eso se puede hacer
3958720	3964360	eficientemente, usando programación dinámica lo mismo que hacíamos con la distancia de edición
3964360	3964920	de Leberstein.
3973920	3980400	Bueno, y este algoritmo que es relativamente sencillo, digamos, es una solución bastante simple,
3980840	3986000	logra una tasa de error muy buena, que es de un 4%, digamos, que, sobre todo, parede
3986000	3990640	más relacionado, parede más que se parecen como el inglés y el español, etcétera, logra
3990640	3994040	una tasa bastante baja de error de un 4%, hay algunas mejoras que se pueden hacer, pero
3994040	4000640	en realidad hay un 4% de algo que está bastante bien. Hay un catch que es que para sistemas
4000640	4004400	de traducción distintos, traducciones no literales, esto se rompe un poco, por ejemplo,
4004400	4008960	para traducir entre inglés y chino, que en chino ni siquiera está claro que les son los límites
4008960	4012680	de las palabras, eso es más difícil de ver. Entonces, bueno, este tipo de algoritmos
4012680	4016280	no funcionan también, y bueno, hay variantes que funcionan un poco mejor.
4016280	4024800	Así que bueno, hoy vamos a dejar por acá y vamos a continuar en la próxima con modelos
4024800	4025360	de traducción.
