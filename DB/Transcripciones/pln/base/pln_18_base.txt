La clase de hoy y la clase que viene, vamos a dar el tema de traducción automática.
Y bueno, vamos a arrancar. Por esto que se conoce como la nota de Weber,
o el memorando de Weber, Warren Weber era un matemático norteamericano de primera
mitad de siglo XX. Y el tipo trabajó durante la guerra, especialmente en cosas de
criptografía, en análisis estadístico, de códigos, etcétera. Entonces en un momento
dijo lo siguiente, dijo, es muy tentador decir que un libro escrito en chino, es simplemente un libro
escrito en inglés que ha sido codificado en el código chino. Si tenemos métodos útiles para
resolver casi cualquier problema criptográfico, no será que con la interpretación apropiada,
ya tendríamos métodos útiles para la traducción. El opinado, digamos, en este memorándum,
que los métodos que se utilizan para romper código criptográfico, que son métodos estadísticos,
se podían aplicar al problema de la traducción automática. Y bueno, esto introduce
algunas ideas clave como que puede existir un mapeo automático entre un lenguaje y otro,
y que codificar, de codificar en un lenguaje de sanálogo, a codificar, de codificar en
una ecorismo criptográfico. Y bueno, el tiro, esa idea es 1949, tomó como 50 años para que
esa idea madurar, digamos, y después de 50 años los métodos más utilizados, hoy en día son
métodos estadísticos que se basan un poco en estos principios. Pero claro, en esa época era
como muy difícil lugar que era lo que iba a ocurrir. Entonces, bueno, vamos a ver un poco esta
la agenda de lo que vamos a mirar. Vamos a llegarnos a menos hasta la mitad hoy y después la clase
siguiente. Y empecemos con un poco de historia de lo que es la traducción automática. Esto empezó
como muchas otras tecnologías, como una tecnología militar, con fines militares. Inicialmente era
durante la Guerra Fría, era resultado de interés traducir rápidamente y abajo costa traducir
entre el ruso y el inglés, digamos, los norteamericanos les convenía poder traducir entre el
inglés y el ruso. Y bueno, en aquella época se imaginan lo que era los inicios de la computación,
las computadoras serán caras, en las lentas, no tenía mucho poderos de computos, pero igual había
como mucho optimismo, de que en poco tiempo se iba a poder resolver los problemas y vamos a tener
sistemas que iban a traducir barbaros. Y bueno, era más o menos la época de desarrollo de la
lingüística computacional, inspirado un poco en las teorías de Chomsky, estaba la idea que se
podía escribir reglas para todo y que a partir de eso se podría llegar a hacer cosas muy muy buenas,
es particular para la traducción. Hasta que en 1964 pareció el reporte Alpac,
Alpac era un comité que estaba estudiando, cuáles eran los avances en ingüística computacional,
porque se estaba poniendo mucha plata en muchas esas cosas. Y ellos demostraron escepticos acerca de
la traducción automática, acerca de los logros que se habían logrado después de todos esos años
de meter plata. Y decía bueno, pero se puso mucho dinero, pasó en muchos años, pero todavía
los humanos lo hacen más barato, con mayor precisión, más rápido, entonces como que para que estamos
gastando en esto. Como resultado de eso, un reporte de fondos, especialmente en Estados Unidos,
para todo lo que la traducción automática y esto fue parte de lo que se conoció como el
invierno de la inteligencia artificial, que un montón de proyectos de inteligencia artificial también
no teníamos el resultado, entonces se paró la financiación que había para todo eso durante unos
cuantos años, entonces se tuvo desarrollado unas cuantas cosas durante unos cuantos años. Y bueno,
después empezaron a resurgir de apoco, pero después de esto, digamos, en los 70 y hasta los 90 más o menos,
eso le hubo que la investigación se frenar un poco en Estados Unidos, pero empezar a aparecer en
otros lados del mundo, como por ejemplo en Europa o en Japón. Y ahí empezó ya con filas bélicos,
sino más bien con fines comerciales, entonces había necesidad de tener traducciones o por lo menos
dar soporte a los traductores humanos con algunas traducciones, aunque no estuvieran de todo bien,
pero bueno, dar algunas traducciones de inicio para que los traductores puedan, los traductores humanos
puedan continuar, además las computadoras empezaron a bajar de precio, tener mayor hogar de computo,
y esta fue como la era de oro de los sistemas de traducción basados en reglas,
digamos acá hay unos ejemplos, sistemas distranques, todavía se desarrolla aunque ya no está completamente
basado en reglas, y bueno, hay sistemas que se realizaron en Japón y en Europa, y bueno,
o sea, estos sistemas tenían fines comerciales y no tanto fines militares, pero bueno,
fines de los 90 y después de 2000, en adelante empezaron a dejarse de usar un poco los sistemas
basados en reglas, porque empezó a haber mayor poder de computo y mayor cantidad de datos disponibles,
especialmente con la aparición de internet, empezaron a haber muchísimos datos de texto disponibles,
y eso permitía construir buenos modelos estadísticos que podrían explotar las regularidades
de los idiomas, entonces aparecieron distintos tipos de modelos estadísticos, los primeros,
los que se llamaron traducciones automáticas estadísticas, que es la otra traducción basada en
ejemplos, y aparecieron las primeras aplicaciones comerciales que funcionaban bien, que utilizaban
modelos estadísticos, la primera fue el English Weber, y después los traductores que más conocemos
hoy en día el Bing, translate de Microsoft, y bueno, el Google translate, que probablemente los
lo conozcan y lo hayan usado en algún momento, y son traductores que la verdad que hoy en día se
puede decir que funcionan bastante bien, entonces bueno, los métodos estadísticos empezaron subhum al
alrededor del año 2000 y siguen siendo el estado del arte, pero bueno, primero vamos a ver un poco de
lo que son los sistemas basados en reglas, que eran estos primeros sistemas que mencionamos antes,
en 1968 un investigador de traducción automática, se llamaba Bernard Boquah, y son relevamiento de todos
los sistemas que se habían construido, más o menos por la época, y los clasificó todos dentro
de este diagrama, el dibujo un triángulo que ahora se llama el triángulo de Boquah, y bueno,
en este triángulo se ubican los distintos tipos de sistemas de traducción basados en reglas,
se ponen como escalones dentro de este triángulo, y los lados del triángulo tienen como
distintas interpretaciones, el lado izquierdo, si yo voy subiendo por este lado, en realidad lo que
aumenta es la cantidad o el esfuerzo de análisis que tengo que hacer de lenguaje origen, yo siempre quiero
traducir de lenguaje origen en el lenguaje destino, bueno, entonces de este lado aumenta el esfuerzo
de traducción en el lenguaje origen, y si voy bajando del lado derecho aumenta, bueno,
si voy subiendo del lado derecho quiero decir, aumenta el esfuerzo de generación en el lenguaje
destino, entonces ¿qué quiere decir esto? Yo ubico distintos sistemas de traducción, la
traducción directa es simplemente buscar en el diccionario de las palabras y traducir
palabra palabra con poca información más, entonces eso casi no necesitan ningún tipo de análisis y
casi no necesitas generación, pero para que son debían, yo necesito ponerle muchas ganas a las
reglas, o sea, las reglas de traducción deben ser muy buenas y tienen que tomar en cuenta
muchos casos para que esa traducción llegue a ser buena, entonces es como que la flecha de la
transferencia, la flecha de la traducción es mucho más larga, en cambio, si yo hago un poco de
análisis, por ejemplo, llevo hasta al nivel de análisis intactico, tengo un parcer, puedo escribir
otro tipo de reglas que pueden ser un poco más expresivos, me resulta un poco más fácil y después,
si tengo un generador, puedo llegar a traducir, entonces si sigo subiendo de vuelta, voy a necesitar
mayor esfuerzo de análisis de generación, pero las reglas pueden ser más expresivas y más fáciles
de escribir y probablemente la traducción sea mejor, hasta que si llegamos al lo articel triángulo,
llegamos a la interlingua, que es una especie de noción en la cual no necesito ningún tipo
de transferencia, vamos a dar un poco dentro de un rato de que se trata eso, pero bueno,
empecemos a ver los distintos niveles de este triángulo de bocua, el demás abajo era la traducción
directa, es el enfoque más simple, lo único necesito para este enfoque es un diccionario de
lingüe, yo quiero traducir entre dos idiomas, si necesito un diccionario que tenga la correspondencia
entre palabras de un idioma y palabras del otro, y lo que voy a hacer es traducir palabra
palabra, o sea, puedo agregarle alguna cosa extra, como por ejemplo, algún reordenamiento local,
yo que es para traducir entre español inglés, yo diría que en español el nombre se siga el
adjetivo y en inglés se en realidad los han arreves, pone el adjetivo seguido el nombre,
entonces ese tipo de reglas simples se las puedo agregar al sistema, y bueno, el sistema
funcionaría un poco así, yo tengo una operación de entrada en el idioma origen, Mary
Tiden Slap de Green Witch, le paso un analisador morfológico bastante de superficie, que no hace
mucho en realidad, simplemente me dice que esto era el barbo du, en pasado y seguido por un
not, y bueno, el resto de los tokens sigue en igual, y acá viene la parte de diccionario,
digamos, lo siguiente que tengo que hacer es buscar en mi diccionario cada una de las palabras
y poner la palabra correspondiente del otro lado, entonces Mary queda María, duve en pasado
como en español no se usa el du, usamos simplemente el marcador de pasado, not es no, Slap es
dar una ofetada de Slap Green, es verde, Witch es Bruja, con el diccionario hoy poniendo
todas las traducciones, y después puedo usar mis reglas de ordenamiento local, de ordenamiento
simple como por ejemplo que el adjetivo seguido en nombre en inglés, en realidad en español
se corresponde con nombres seguido adjetivo, entonces verdad de Bruja lo cambio por Bruja
verde, acá hay otro ordenamiento, digamos, donde tengo una marca de pasado y se lo paso
para adelante a lo largo, y finalmente lo que hago es una pequeña generación morfológica
con estas marcas y digo bueno, este dar en pasado se transforma en dio, entonces me queda
María no dio una ofetada a la Bruja verde, así que partí de el texto en el idioma
Rige, Mary did and Slap de Green Witch y llegue a una oración en el idioma destino María
no dio una ofetada a la Bruja verde, que parece estar bastante bien digamos, bastante
bien la traducción, entonces así es como funcionaría un poco un sistema de traducción
directa, como les parece que funcionan estos sistemas en la práctica, digamos que también
se comportan en la práctica este tipo de sistemas, pues acá vimos un ejemplo que
quedan bastante bien digamos, pero no sé qué, claro, y hay otro problema más, y es
lo que, que no tenga todas las palabras, pero además que palabras que se pueden traducir
de más de una manera, entonces necesitas saber qué palabras tenés que usar, entonces bueno,
la web está llena de ejemplos de lo que puede salir más y yo utilizo un sistema de traducción
directa como este, entonces lo que estábamos viendo recién era los sistemas de traducción directa,
vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sintáctica,
entonces para la transferencia sintáctica, yo lo que voy a necesitar primero es tener un
parcer de lenguaje origen que me lleva a un análisis sintáctico y además voy a necesitar un
generador, lenguaje destino que agarra, un algo sintáctico de lenguaje destino y genera una
oración, entonces yo lo que puedo hacer es escribir reglas que transformar un árbol en el otro
y esas reglas son un poco más fáciles digamos que lo que necesitaría para un sistema de traducción
directa, entonces para el inglés, por ejemplo para todo el siguiente del inglés y el español,
yo diría que si tengo un nominal que es un adjetivo nombre, un adjetivo en un nombre en inglés,
lo transformaría en un nombre, seguí un adjetivo en español y la reglas escribiría algo así
diría, tengo nominal adjetivo nombre, entonces lo cambio por nominal nombre adjetivo,
entonces ahora que sabemos cómo funciona esto, tratemos de hacer el ejemplo en japonés,
digamos cómo serían las reglas para transformar el árbol en inglés de Geador, se le dicen en
tu music, a japonés, careja, ongaku, wokiku, no gada y suki de su, donde está, tenemos la
correspondencia de cada una de las palabras, pero claro los árboles son un poco distintos,
el inglés y el español se caracterizan por ser lenguajes de tipo, no sé si esto lo hemos visto
ya en el curso, pero son lenguajes de tipo SBO, que significa que habitualmente yo solo escribir
un sujeto se dio un verbo seguido de un objeto, el japonés en cambio es un lenguaje de tipo SBOB
porque habitualmente se escribió el sujeto, seguido del objeto, seguido del barbol, hay muchos lenguajes
que pertenecen a esta otra categoría, entonces bueno, queremos escribir reglas de transferencia
para transformar este árbol en aquel otro árbol, como escribiríamos esas reglas, que les parece,
que reglas utilizaría yo para transformar un árbol en el otro,
ahí está, una de esas, en inglés yo escribo, una fraseróbalo, un grupo verbal como un verbo seguido de un grupo
proporcional, esta es la que decías, y la cambio por que otra cosa, la cambio por un grupo
proporcional que sigue un verbo, esa es una, que otra regla tendría que agregar, cuál,
la elaboración, que tiene la elaboración, la elaboración según esto en inglés es un pronombre
seguido de un verbo, seguido de un grupo verbal, por qué tendría a cambiarlo, ahora en
japonés la elaboración va a ser el pronombre seguido del verphrase, seguido del verbo, bien,
alguna otra, ahí está, el grupo preposicional que está formado por un tú, seguido un nombre,
eso es en inglés y en japonés que va a pasar, voy a tener un grupo proporcional que es un nombre
seguido de tú, bien, entonces con eso más o menos creo que tendría las reglas suficientes para
transformar un árbol en el otro, los sistemas de traducción, vamos a ver si está bien,
son los que escribimos, esta es la solución del ejercicio, los sistemas de traducción basados en
síntaxis, en realidad los sistemas de traducciones de reglas, en síntaxis hacen esto a alto
nivel, digamos, tienen montones de pared de árboles, hay gente que los analiza y escriba reglas
como se transforma uno en el otro, a veces las reglas son complicadas porque se pueden superponer,
entonces hay que definir prioridades y ese tipo de cosas, bueno, esas transferencias
sintácticas, si seguimos subiendo en el triángulo de bocua, llegamos a lo que es la transferencia
semántica, tal vez es semántica uno puede pensarla un poco como lo que habíamos en la clase
pasada, utilizando roles semánticos, yo tengo un etiquetador de roles semánticos, que agarra
la relación Juan fue a la tienda y me devuelve los roles de los constituyentes, me dice que Juan
es el agente y a la tienda es el objetivo o goal, digamos, es el nombre del rol, entonces yo,
para ciertos idiomas podrías escribir reglas más específicas, por ejemplo, en chino ocurre que
los sintámas propulsionales, que son de tipo objetivo, se escriben antes del largo, pero los
demás sintámas propulsionales escriben después, o sea, el chino es un lenguaje de tipo SBO igual que
el inglés o el español, pero cuando el objeto es de tipo goal lo que hacen es ponerlo antes del
largo, entonces yo podría escribir una regla un poco más expresiva, para este caso del chino,
si yo tuviera los roles semánticos, yo diría que un grupo verbal es un verbo seguido de esto,
esto no está tachado, sino que era la barrita que quedó arriba, es un verbo seguido de un grupo
proporcional de tipo goal, en chino lo cambiaría por un verbo seguido de un verbo, por un grupo
proporcional de tipo goal seguido de un verbo, es más costoso para generar y para parcear,
digamos, necesito tener más esfuerzo de parcin y más esfuerzo de generación, pero puedes
escribir mejores reglas que capturan ciertas particularidades de los lenguajes,
y si yo sigo subiendo en el triángulo llego a lo que se conoce como interlingua,
cuál es la gracia de interlingua, cuál es la idea, esto sirve si nosotros estamos en un
contexto multicultural, estamos trabajando, por ejemplo, en la ONU o en el Palamento Europeo,
o algo de eso donde se hablan muchos idiomas, si yo quiero mantener un montón de documentos
que estén en todos los idiomas a la vez, voy a necesitar para los sistemas que estuve en
nuestro momento, voy a necesitar tener N parsers, uno para cada idioma, N generadores,
también uno para cada idioma, y después para cada par de idiomas, voy a necesitar reglas
de transferencia, entonces voy a necesitar tener en total N por N menos 1, 7 de transferencia,
yo tengo 20 idiomas, voy a necesitar 380 conjuntos de reglas de transferencia, y esos
conjuntos de reglas de transferencia son largos, son grandes, son complejos, hay que mantener
los, pueden tener errores, entonces esto claramente no es cala, es como muy difícil poder mantener
un entorno de todos esos idiomas y poder mandar la traducción en base a reglas, entonces
la idea del interlingua es decir, ¿qué tal si pudiéramos parcear lo suficiente o analizar
lo suficiente como para llevar a una representación común, una representación que capturé el significado
de todos los idiomas a la vez, y además tuvieramos un generador para cada uno de los idiomas.
Si eso pasara, si nosotros pudiéramos capturar con una representación el significado de todos
los idiomas a la vez, no necesitaríamos transferencias, simplemente parceamos y llevamos
a esa interlingua y después generamos en el otro idioma. Esto está muy bien, digamos,
del punto de vista ideal, pero es muy difícil obtener la práctica. ¿Qué se podría usar
como representación de interlingua? ¿Qué podría hacer un candidato? Bueno, podríamos
usar la lógica de primer orden, que era lo que veíamos en las primeras clases de semántica,
como representar variaciones en la lógica de primer orden, o alguna de sus variantes
que da un cuenta mejor de lo que es la lógica de la lengua genatural, como las mínimos
con recursos semánticos o las whole semánticos. O si no, hay como parecido lo que veíamos
en la clase anterior de frames, construirme frames con el estado de las cosas, como por ejemplo
está la misma operación de hoy, Mary didn't slap the green witch, pero es crita como
un frame, es hay un evento de slapping, la gente es Mary, ocurre en pasado, la polaridad
negativa, el tema de ese evento es la bruja y la bruja de más es verde. Yo podría construir
este tipo de frames y usarlos como representaciones. Pero bueno, hay problema que tiene crear o
pensar en crear una interlingua, es que esa interlingua seguro que va a ser muy compleja
y seguro que va a tener que modelar las características de todos los idiomas al mismo tiempo. Y hay
características que son complicadas en los distintos idiomas, y algunas que ni nos imaginamos,
o sea, por ejemplo, en chino existen palabras distintas para decir hermano mayor y hermano
menor, y no hay una palabra para decir hermano. O sea, no hay una palabra que quiera decir
solamente hermano. En español sí, y en inglés también, en inglés puede decir brado, pero
en chino no, en chino tienes que elegir cuando vas a decir hermano, si es hermano mayor
o hermano menor. Entonces, imagínense que si yo estoy traduciendo del español al inglés
y estoy utilizando una interlingua, la interlingua en su parcer necesita poder distinguir en
algún momento, si estoy hablando de un hermano mayor o un hermano menor, porque tiene que
lograr la representación suficiente como para poder traducir al chino. Entonces, necesita
esa información y no sé dónde la va a sacar, la puedes sacar de contexto, lo puedes sacar
inventar de algún lado, pero en algún momento va a tener que averiguar el hermano que se
está hablando en español, si es un hermano mayor o menor, como para poder tener la representación,
y después esa información se va a perder, porque cuando baja de vuelta, al lado del inglés,
de vuelta vuelve a ser brada y no importa si es mayor o menor. Y esto es solamente un caso
de un fenómeno que ocurre en chino, pero, imagínense, los fenómenos que ocurren en el idioma
en todo el tiempo, digamos, y todas las pequeñas variantes que hay. Y como en realidad,
no es cierto que podamos traducir exactamente lo mismo conceptos, como que es muy difícil
encontrar conceptos que se correspondan 100% en idioma y otro. Hay una cosa que se llama
el principio de incertidumbre de la traducción y dice eso, que en realidad, cuando yo tengo
un idioma y otro, los conceptos no siempre se van a traducir 100% bien, o sea, no siempre
la traducción es exacta, sino que hay cierto suelopamiento y a veces se va a funcionar y a veces no.
Bien, pero a pesar de que es una utopía, tener un interlingo que funcione para todos los
lenguajes bien, este tipo de tecnología sí se utilizan para dominios más acotados, para
dominios pequeños, como por ejemplo, el de meteorología, yo puedo escribir perfectamente,
puedo construir una representación de todos los estados meteorológicos que hay, y si hay
lluvias y nievas, y hay granizo, la temperatura, la presión, etc. y traducirlo a las distintas
palabras, que son los distintos idiomas para dar cuenta de estos conceptos. Entonces, ese
dominio acotado es bastante bien manejable con una interlingua. Y otro ejemplo son los manuales
técnicos, hay empresas que, de un montón de documentación técnica, o describen las
apis de sus productos, etc. Y uno suele dar, cuando mira la página web, digamos que aparece como
con su fijo es, porque está en español, pero si se lo cambias por en, automáticamente
te genera otras páginas, exactamente igual, pero en inglés, y en realidad lo que hacen es
como mantener una representación abstracta de lo que están escribiendo y generarla en los
distintos idiomas. Bien, entonces, hasta ahí lo que vimos era como un paneo de lo que son
los distintos sistemas basados en reglas, ahora vamos a pasar a hablar de lo que es la traducción
estadística que es el estado del arte hoy en día, y vamos a empezar con un ejemplo, un ejemplo
de una frase en hebreo, que es Adonai Roy, que la traducción sería el señor a mi pastor
o del Lord Ismail Shepper, y esta frase, en realidad, funciona bien, porque nosotros conocemos
que son las ovejas, digamos, la cultura en la que surgió esta frase, conocía que eran
las ovejas, tenían pastores, los pastores cuidaban las ovejas, la llevaban a donde había
estado los mejores pastos, etc. Entonces, esta metáfora funcionaba bien, digamos, la
gente describía como se sentía en respecto a Dios utilizando esta metáfora. Pero
¿qué tal si quisieramos expresar esta misma frase a una cultura que no conoce a las ovejas?
Por ejemplo, los primeros misioneros que vendrían de Europa y tendrían contacto con los
indígenas americanos, los indígenas americanos no conocían ovejas, entonces, ¿cómo hacemos
para expresarles el concepto de Adonai Roy? Una forma de expresarlo es decir, bueno,
adusco la metáfora, el significador de la metáfora, digo, significa el señor me cuidará,
que en definitiva es un poco la metáfora que quiere decir eso, aunque pierda un poco
de contenido, o si no, lo que lo otro que puedo hacer es tratar de ser más fiel al significado
original y tratar de traducirlo más literalmente, es decir, bueno, el señor será para mí como
un hombre que cuida de animales que tiene el pelo como algodón, que es bastante más fiel
al original, pero sin embargo, se entiende mucho menos, es como que te van a mirar y decir
lo de qué me estás hablando. Y bueno, un poco, este es el problema que hay que
se enfrentan los traductores humanos todos los días, o sea, es muy difícil tener las dos
cosas, ser fiel al original y sonar natural que suene bien en el lenguaje destino. Una traducción
queremos que tenga esas dos propiedades, pero es muy difícil lograrlo a la vez, entonces
los traductores humanos saben que esto es imposible en la práctica y lo que hacen es tratar
de traducir de manera de encontrar un punto intermedio en el cual, bueno, suene bastante
bien, pero además sea fiel al significado original. Entonces, esto significa que lo que estamos
tratando de hacer al traducir es que estamos tratando de maximizar dos cosas a la vez,
como dos medidas que queremos maximizar. Una medida es que tan fiel es mi oración traducida
a la oración original, a esa medida le vamos a llamar adecuación o fidelidad y en inglés
es adecuación fidelity of faithfulness y la otra medida es que tan natural suena la oración
que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en inglés fluency.
Entonces, esta idea de que estoy tratando de maximizar dos medidas a la vez, después
vamos a ver que en realidad lo que vamos a tratar de maximizar es el producto de las dos medidas
porque eso significa maximizar ambas al mismo tiempo, es una idea que sirve para poder
inferir o para poder construir mecanismos para crear los traductores automáticos y también
mecanismos para testearlos. Y vamos a ver un poco cómo que funciona eso.
Yo voy a intentar traducir a partir de ahora el resto de la clase y la clase que
viene vamos a hablar siempre de que voy a traducir un lenguaje origen f a un lenguaje destino
f es el lenguaje origen y es el lenguaje destino. Eso es nombre surgen porque el paper inicial
donde se empezó a hablar de esta cosa de los métodos estadísticos traducía del francés
al inglés, entonces acolo nombre de ahí dijo bueno francés f el inglés e entonces traducimos
del origen al destino. Bueno, yo quiero traducir una frase del idioma f a otra frase del idioma
e lo que quiero tratar de encontrar es el mejor etecho que maximice a la vez la de ecuación
y la fluidez, o sea de todos los e posibles del lenguaje destino, quiero encontrar el que
maximice la fluidez de es, o sea que suene natural y además la de ecuación entre la
oración origen f y s e que estoy buscando. Esta fórmula así escrita de esa manera de
estás acordado a algo que hayamos visto ya en el curso en algún momento, les suena
algún lado. Entropía, sí. Valles, sí, o sea viene por ese lado, se parece al modelo
de valles porque esto es otra aplicación del modelo de canal ruidoso. El modelo de
canal ruidoso lo hayamos visto en el curso cuando vimos correcciones de errores, hace
ya bastante tiempo y también es una aplicación de lo que es la regla de valles.
Entonces, el modelo de canal ruidoso ha aplicado acá funciona de la siguiente manera. Yo
tengo una oración origen en el lenguaje f que es f chica que tiene m palabras y es bueno
f sub 1, f sub 2 hasta f sub m y quiero encontrar la mejor oración en el lenguaje destino
e techo que es sub 1 hasta f sub n, hasta f sub n, que maximiza y en realidad lo que quiero
maximizar originalmente como todos esperaríamos es decir, bueno, yo quiero encontrar la oración
e que maximiza la probabilidad de edad o f, digamos eso es lo que uno se lo ocurriría
primero, diría bueno, yo quiero estoy traduciendo la oración f, quiero encontrar la e que
me demáximo la probabilidad de edad o f. Bien, pero en realidad yo esto lo puedo descomponer
por valles, digamos, y por definición de probabilidad condicional, pues decir que la probabilidad
de edad o f es igual a la probabilidad de f de edad o f por la probabilidad de edad o f.
Y vamos a esa equivalencia directa por definición de probabilidad condicional y además como estoy
maximizando en e, esta f se mantiene constante, porque lo que voy variando es la e, entonces
la etacho, o sea maximizar sobre una constante no hace ningún cambio, entonces lo que me queda
el final es que yo busco un etacho que es el e que hace máximo la probabilidad de
f de edad o f por la probabilidad de. Y eso que tenemos escrito ahí, se parece mucho a la
otra ecuación que teníamos antes, digamos, se parece mucho a esta ecuación de f y fluidez
de e. Entonces, se conoce como la ecuación fundamental de la traducion automática estadística,
vamos a ver unas cuantas veces en estas dos clases, la vamos a estar refrescando y funcional
así de manera. Yo quiero encontrar el e techo que es el e que maximiza el producto de
estas dos probabilidades. La primera probabilidad pdf de edad o e es la que se encarga de medir
que tal la ecuación, digamos, de la frase, que tal adecuada es la frase f para la frase
e. La segunda probabilidad, la pdf es la que se encarga de la fluidez, que tal natural
suena esa frase en el lenguaje destino. Y se calculan con modelo distintos. La primera
se calcula con lo que se conoce como modelo de traducción y la segunda con lo que se conoce
como modelo de lenguaje. De hecho, los modelos del lenguaje ya lo hemos visto en el curso.
Vamos a dar un breve repaso de que se trataba. Bueno, ¿por qué esto es una aplicación
de canal ruidoso? Es una aplicación de canal ruidoso por lo siguiente. Nosotros estamos
tratando de traducir del lenguaje f, f, el lenguaje origen, al lenguaje e que es el lenguaje
destino. Y lo estamos pensando al revés. Estamos pensando como que alguien emitió los
sonidos de la elaboración e, la elaboración del lenguaje destino. Eso pasó a través de
un canal ruidoso. Y cuando llegó hasta mí, yo escuché los sonidos de la elaboración
f. Estoy pensando como esa especie de metáfora. Alguien emitió e pasó por un canal ruidoso
y llegaron los ruidos de f. Entonces, lo que yo trató de hacer como proceso de traducción
es encontrar cuál tiene que haber sido esa e original para que yo haya escuchado la
f, cuál es la e original que me da probabilidad máxima de que yo haya escuchado esta f. Y bueno,
por eso es una aplicación de canal ruidoso. Y bueno, la realidad es que en realidad damos
vuelta esta probabilidad porque nos da toda otra forma de calcularlo que no podríamos hacerlos
y calculamos la probabilidad directa. Es como que hay mejores herramientas para hacer eso.
Bueno, de vuelta, esto es la ecuación fundamental de la traducción automática estadística.
Y techo es el argumento que hace máximo la probabilidad de fedadoe por la probabilidad
de. Y para poder resolver esta ecuación necesitamos tres cosas. Necesitamos un modelo de
lenguaje p.d.e. que es el que se va a encargar de la fluidez. Esto se calcula mediante la técnica
de negramas en general. Los negramas son bastante fáciles de construir, digamos, porque yo
necesito texto en un solo idioma, solo en el idioma destino. p.d.e. es la componente
que se encarga de la adecuación y se resuelve mediante el modelo de traducción. El modelo
de traducción no es tan fácil de construir como el modelo de lenguaje, porque el modelo
de traducción voy a necesitar texto de bilíngue. De hecho, voy a necesitar un corpus
para el hilo que sea texto en dos idiomas que además tengan su correspondencia. Y además
necesito una tercer componente. Esta tercer componente se llama de codificador. Y se trata
de lo siguiente. Yo cuando estoy buscando, cuando estoy resolvido esta ecuación, yo veo
la oración F y quiero buscar la mejor E que maximizes esta ecuación. Pero en realidad
lo que tendría que hacer es probar con todas las oraciones E del idioma destino, todas
las oraciones posibles que cuantas son las oraciones del idioma destino. Son infinitas
oraciones posibles en el idioma destino. Entonces yo estaría probando con infinitas
oraciones hasta que una de ellas me dé el máximo. Obviamente esto no es un problema
atratable, yo no puedo probar con infinitas oraciones. Lo que necesito es un proceso
que me limites a cantidad de búsqueda de infinitas oraciones a algo atratable. Entonces
el codificador va a ser un algoritmo de búsqueda que va a agarrar la oración origen y
me va a devolver la cien, doscientas, mil oraciones destino, candidatas más probables que
alzelo curra para que yo pueda resolver y calcular esa ecuación para esas oraciones en
vez de para todas las posibles. Entonces lo que hace es volver este problema atratable.
Vamos a ver también una ecuación de codificación que se llama Binsarch. Bueno, entonces un
poco más sobre modelos del lenguaje. La componente pd de la ecuación era la que
medía las fluidez y se calculaba mediante un modelo del lenguaje. Los modelos del lenguaje
son relativamente fáciles de construir porque necesitamos información mono-lingue, información
solamente del lenguaje destino. Entonces en la web tenemos monton, toneladas de información,
bueno, de muchos idiomas. Entonces como sonetamos información idiomas, sacamos texto, web, noticias,
blogs, etcétera y compilamos un gran corpus del lenguaje destino. Los modelos que se utilizan
para traducción automática en general son modelos basados en enegramas que ya hemos
visto en el curso como funcionaban, se suele usar orden de 4 o 5, en otras tareas de pdn
suele usar ordenes más chicos, pero para acá da buenos resultados con 4 o 5. Y bueno,
el importante es tener una gran cantidad de material de entrenamiento. O sea, los mejores
modelos que usan Google Translate y otras empresas usan trisiones de palabras y bueno,
son necesitan hardware especial, especialmente diseñado para poder ir rápido y recuperar
la información. O si no, bueno, si estoy hablando de un dominio acotado, usar datos
de dominio para entrenar que también va a ser buenos resultados.
¿Qué es la de la técnica?
Las técnicas de Moodin es cuando hay alguna enegrama que no viste lo que te va a pasar
es que la probabilidad es cero. Y ahí te va a dar todo cero. En realidad, las mejores
técnicas es muy significado, darle una buena probabilidad a eso a pesar de que nunca
lo yo ha visto. Se dice que las mejores mejoras, digamos, las más grandes mejoras en los
modelos en la traducción automática de los últimos años se han dado porque hay
mejores modelos de lenguaje que me dan traducciones que son más fluidas. Y bueno,
usualmente hay como cierta correlación o cierta inclinación hacia las fluidas.
La gente prefiere cuando las oraciones son zonas más naturales.
Acá en ejemplo, esto era sacado un sistema de traducción del chino al inglés, un sistema
estadístico de San Staxis, que cuando no utilizaba modelo de lenguaje tenía un
puntaje de 25x2 al incorporar modelo de lenguaje subió como un 20% su performance y llegó
a 31x2 como 6 puntos. Esos puntos corresponden a una medida que vamos a ver dentro de un
rato que le llama medida blue, que es una medida muy utilizada en lo que es traducción
estadística. La traducción automática en general, pero bueno, ahora solamente saber
que 6 puntos es una mejora que es muchísimo. Y como es que mejora esto, mejora haciendo
que las traducciones que devuelven en general sean más fluidas, son más naturales en el
lenguaje de estino. Y acá hay un ejemplo de traducciones de ese mismo sistema. Yo tenía
una traducción de referencia que era, I don't have enough money with me to buy a new
airplane ticket. El sistema sin el modelo de lenguaje devolvía esta traducción, de
decir, I don't have enough bag on me change please go a new by plane. Que no, no se entiende
mucho que lo que dice, no es gramatical. Pero al agregar el modelo de traducción, su
traducción es la siguiente, I have enough money to buy a new one by air, que suena mucho
mejor ¿verdad? Que les parece acerca del significado. El significado es el opuesto, digamos, acá
está diciendo que tiene suficiente plata para comprar uno por aire y acá dice que
no tiene suficiente plata para comprar un pasaje de avión. O sea, este suena muchísimo
mejor porque está ni siquiera gramatical, pero esta por lo menos mantenía la negación,
digamos, mantenía que era una oración negativa. Entonces hay que tener cuidado con esto.
La traducción suena mucho mejor, pero a veces podemos estar sacrificando fidelidad,
sacrificando adecuación de la traducción. Bien, eso es sobre modelos de lenguaje. Ahora
pasemos a la otra, los modelos de traducción. La componente pdf de la ecuación mide lo que
es la adecuación o fidelidad de una traducción y la otra y para esto necesito corpos para
leylos o corpos bilíngües que para poder entrenar estos modelos. Los corpos bilíngües
son bastante más difíciles de construir que los corpos monolíngües, digamos, no alcanza
con hacer una pasada por la web y obtener texto de un idioma. Y bueno, los modelos que
vamos a ver son los propuestos por Brown y si equipo en 1993 que trabajan en IBM, ellos
construyeron cinco modelos de cómo construir cinco modelos, digamos, en creciente complejidad
de cómo construir un modelo de traducción para traducción estadística. Y bueno, los
modelos, las diferencias de cada modelo se es en la historia de generación de las
soldaciones candidatas. Y bueno, después vamos a ver también otro modelo un poco más
moderno, pero bueno, vamos a empezar viendo más bien los modelos de Brown. Aquí me refiero
con historia de generación de las soldaciones candidatas. Una historia de generación, esto
lo digo ahora, pero en realidad lo vamos a profundizar después. Una historia de generación
en realidad es como una especie de proceso mental que seguiría un traductor cuando
quiere pasar de una oración a la otra. Entonces, estas historias se basan en decir, bueno,
un traductor agarró una oración en el idioma origen y después elige la cantidad de palabras
que voy a tener el idioma de estino, reordena palabras, después va traduciendo una a una
según un diccionario, después agrega palabras nuevas que no estaban en la oración.
Ese tipo de cosas, digamos, ese tipo de pasos, me lo voy a escribir en la historia de generación
y para que sirve eso, sirve para que a cada uno de esos pasos yo le pudo dar un valor
numérico, un valor en cuanto a probabilidades y después lo que voy a hacer cuando entreno
mi sistema es tuñar esos valores numéricos, tuñar todas esas probabilidades para darme
el cálculo de probabilidad total. Vamos a profundizar más de en esto después, pero antes
de pasar a lo que son las modelos de traducción, vamos a hablar un poco de cómo se evaluan
estos sistemas. En general, siempre es importante evaluar todo en el PLN, digamos, porque no
hay soluciones perfectas, entonces voy a tener sistemas que andan mejor o peor que otros.
Y bueno, la traducción automática obviamente no es la excepción. Entonces, me sirve
poder evaluar los sistemas para poder saber qué sistema es mejor que el otro y además,
si yo hago cambios en mi sistema, poder evaluar de vuelta a ver si mejoré o no. Entonces,
¿qué puedo considerar una buena traducción? Para empezar, eso es una pregunta que es abierto
en su, digamos, esa abierta en su respuesta. O sea, yo tenía en un sistema de traducción
tenía una referencia, un candidato de referencia que era de CatSat on Demat, digamos,
esa era una traducción de referencia y un sistema medio seis posibles candidatos para
esa traducción. O sea, originalmente había una frase, por ejemplo, en China, la traducción
de referencia, la de CatSat on Demat y mi sistema a traducirme el chino medio estas opciones.
Tengo de CatSat on Demat Sat de Cat, de Cat on the floor, a CatSat on Demat, de CatSat
on Demat, con minúscula o de CatSat on the Stromat. ¿Cuáles les parecen que son buenas
traducciones de estos candidatos que me dio el sistema? ¿Cuáles les gusta más?
La E, que es de CatSat on Demat, pero con minúscula me dé como yo, ¿qué otra? La
B, on Demat Sat de Cat, ¿qué otra? La D les gusta también a CatSat on Demat. ¿Capaz que
no calienta tanto, dependiendo del uso que le vas a dar esa frase en contexto, capaz que
no calienta tanto? Y bueno, sí, la verdad no se ve nada cuando están las cosas marcadas
en rojo, pero bueno, en fin. Crea que acá las cosas marcadas en rojo son las que acaban
de decir. Una buena traducción, podemos decir que es una traducción que le gusta la gente,
que la gente dice si es una buena traducción. Entonces acá se elige on Demat Sat de Cat,
a CatSat on Demat, y de CatSat on Demat en minúscula. Y bueno, como decimos, le preguntamos
a la gente a ver que traducciones le gustan, y bueno, ya ahí ponemos cuales son las mejores
traducciones. O si no, le damos a un conjunto de jurados las traducciones y le decimos
que hagan un análisis un poco más preciso, y nos digan, bueno, cuánto le dan en uno
al diez de adecuación, y cuánto le dan en uno al diez de fluidez.
Esas otra forma de evaluar, digamos, y ahí ya nos están dando las dos medidas. En general,
los humanos nos cuesta realizar esta evaluación. En general, tenemos una preferencia de la fluidez,
como pasaba hoy con el caso de traducción del chino al inglés, por los pasajes de avión.
Además, la gente no se pone a acuerdo. Además, hay un problema que es que hacer este tipo
de evaluaciones con usuarios humanos, lleva tiempo, digamos, hay que pagarles a los usuarios
por hora para que estén evaluando sistemas. Y después, yo le dí un conjunto de traducciones,
ellos me la se evaluaron, hice algún cambio en mi sistema para mejorarlo, y devuelta
hacerle, de teo que dale conjunto de traducciones a los humanos, y devuelta lo tienen que evaluar,
y devuelta, tengo que pagar obras de usuarios humanos para que lo valúen.
Entonces, es difícil de reutilizar. Yo voy a estar haciendo cambios constantemente en mi sistema,
y bueno, y necesito tener una forma más rápida de evaluar a ver si estoy haciendo las cosas mejor.
Entonces, como este proceso de evaluación es largo, es engorroso, es caro,
lo que se ha vuelto más popular son los métodos automáticos de evaluación. Y,
a continuación, vamos a ver uno, que es muy utilizado en lo que es la traducción automática.
Bueno, ¿cómo funciona un método de evaluación? En realidad, lo que hace alguien,
alguien que está diseñando un sistema, es crearse un conjunto de oraciones con cada una
con una traducción de referencia que está bien, digamos, una traducción hecha mano.
Entonces, yo quiero evaluar un sistema que va del español al inglés, lo que tengo es un
conjunto de oraciones en español, y alguien, algún traductor humano me tradujo todas esas
oraciones en español, y medio un candidato, o más candidato está lo es para cada una,
digamos, a eso le voy a llamar referencias, traducciones de referencia.
Lo siguiente que tengo que hacer es poder diseñar una métrica de similitud para que,
cuando mi sistema me da un candidato de traducción, yo puedo establecer una similitud entre ese
candidato y alguna de las referencias. Y bueno, después lo que voy a hacer es aplicar esa
métrica para los pares, candidatos y referencias, y bueno, y sacar como un promedio de todos
los valores de similitud que tengo. Entonces, se han inmetado muchos métodos de este estilo,
muchos métodos automáticos, que vamos a ver en particular se llama Blue, que es una
métrica muy difundida en lo que es la traducción automática estadística. Y bueno,
primero hay algunas definiciones, le vamos a llamar referencia a una traducción que
está traducida manualmente, o sea, consideramos que es una oración correcta, eso es una referencia,
y le vamos a llamar candidato a una traducción que no tiene por qué estar correcta porque
la tradujo del sistema automático. Y le vamos a llamar documento al conjunto de todas
las oraciones candidatas, al conjunto de todas las oraciones traducidas por el sistema,
que es lo que vamos a estar evaluando. Así que recuerden, tenemos referencia, candidato
y documento. Y bueno, ¿qué es lo primero que se nos puede ocurrir hacer cuando queremos
saber si un candidato es bueno para la referencia o no? Lo primero que podemos hacer es tratar
de contar las palabras que ocurren en ambos. Entonces, yo puedo tratar de contar palabras
que ocurren en el candidato y palabras que ocurren en la referencia, y ahí diría que
la elección de las palabras de candidato, si están, la palabra candidato, si están,
también en la referencia, yo diría que eso se acerca un poco a la adecuación, se acerca
que, bueno, por lo menos, usó palabras que son fieles a la traducción de referencia.
Pero si además esas palabras están usadas en el mismo orden, ahí se acerca un poco más
a la fluidez, o sea, si están usadas en el mismo orden, puede sonar tan natural como
la referencia. Y esto se puede hacer automáticamente haciendo conteos de enegramas.
Acá yo tengo una referencia que es de CatSat, mi sistema me tenía que haber devuelto
de CatSat y tenía dos candidatos, candidato era de Cat y el candidato era SadCatD. Entonces,
lo que puedo hacer es conteo de enegramas, cuáles son enegramas de los candidatos pertenecen
a la referencia. Y entonces, para el caso de Cat, el enegrama D pertenece la referencia,
el enegrama Cat pertenece a la referencia y el enegrama D Cat, o sea, el Vigra Madecat
también pertenece a la referencia. Para el caso del candidato B, el unigrama Sad
pertenece el unigrama Cat pertenece el unigrama D pertenece. Pero SadCatD este Vigrama no
pertenece a la referencia y CatD tampoco pertenece a la referencia. Y además, el único
trigrama que hay, SadCatD tampoco está en la referencia. Entonces, lo que aparece
a la derecha son los enegramas que sí pertenecen tanto el candidato como a la referencia.
Así que, bueno, resumiendo, yo puedo contar la cantidad de hits de unigramas, de Vigramas,
de trigramas. Y para el candidato B se cumple que todos los unigramas que hay pertenece
a la referencia. Así que, voy a tener dos de dos hits. Para los Vigramas, voy a tener uno
de uno. Pero para el candidato B, los unigramas me dan 3 de 3, digamos, 3 hits. Los Vigramas
no. O sea, tengo dos Vigramas posibles y ninguno estaba bien. Y los trigramas tampoco.
Tengo un trigrama posible y no estaba bien. Entonces, por ahora, parece que le va ganando
de Cat, la el candidato B de Cat le va ganando a SadCatD como traducción. Bien, ¿qué
puedo hacer con los contegos de enegramas? Lo que hago habitualmente, o sea, contar enegramas,
para unigramas, vigramas, tiramas, se acerca un poco a lo que es la noción de una precisión
de algo. Entonces, lo que voy a hacer es contarlos
por separado. Voy a decir, voy a contar todos los unigramas por un lado, todos los Vigramas
por otro, todos los trigramas por otro. Y para cada uno de esos, me voy a armar una
precisión. Voy a decir que tengo. El candidato
se subí, digamos, un candidato que voy a considerar. Voy a contar los hits de orden N,
se subí, digamos, los hits de unigramas, se subí. Voy a llamar H, se subí. Y voy a contar
la cantidad de unigramas totales que hay y le voy a llamar T, se subí. Pero además,
voy a hacer esto, en vez de hacerlo para una sola oración, para un candidato y su referencia,
lo voy a hacer para todo el documento. Voy a contar todos los unigramas que estaban en mis
candidatos. Voy a ver cuánto eso está bien y voy a hacer esta división. Entonces, me va
a dar cuál es la precisión en unigramas. ¿Qué va a ser? Bueno, tanta cantidad de unigramas
estaban bien dividido, toda la cantidad de unigramas que genero en los candidatos. Después
voy a hacer eso para Vigramas. Voy a contar toda la cantidad de Vigramas que estaban bien,
porque estaban en el candidato en la referencia, dividido toda la cantidad de Vigramas que
en el candidato. Voy a hacer lo mismo para trigramas y voy a hacer lo mismo para 4igramas.
En general, se suele llegar hasta 4, digamos, en traducion automática estadística, la
medida blu llega a calcular hasta 4. Entonces, bueno, lo que me define ahí es lo que se llama
probabilidad de orden N, la probabilidad, precisión de orden N, la precisión para unigrama,
la precisión para Vigramas, la precisión para trigramas, etc. Bien, esta métrica que
estamos construyendo es bastante fácil engañar. En realidad, yo me definí una probabilidad,
por ejemplo, de la probabilidad de orden 1 y la puedo engañar muy fácil, porque yo me
puedo construir un candidato que tiene siempre la misma palabra. Puedes ir, bueno, un candidato
para la referencia de Catzato Nemat es el candidato DDDDD. Como yo justo le emboque a una palabra
que está en la referencia, entonces cuento los unigramas y me da que hay 6 hits de 6,
a pesar de que la traducción es horrible. Entonces, como hago para evitar esto, lo que se
suele hacer es clipping, lo que significa que cuento cuanto es la cantidad máxima de palabras
en la referencia y no permite que haya más de eso. Entonces, yo acá tengo hasta dos palabras
D, entonces no puedo contar 6 de 6, tendría que contar máximo 126. Entonces ahí evitamos ese
problema de que, bueno, alguien se haga el vivo y genera simplemente una sola palabra. Bien,
entonces, hasta ahora vimos dos cosas, calculamos la precisión de orden N, la precisión de cada uno
de los unigramas o diagramas, los segundos que vimos es que vamos a hacer clipping para evitar
pasarnos de conteo en las palabras que aparecen más de una vez.
Lo tercero que pasa es veíamos en este ejemplo de acá, acá tenemos dos candidatos de Catz
y Sad CatzD, y lo que pasaba acá era que le estaba haciendo mejor a la traducción de
Catz porque tenía todos los unigramas que están en la traducción, están también en la
referencia y todos los diagramas también, en cambio el candidato V no, el candidato V tiene
unigramas que están, pero diagramas y trilamas que no están. Entonces en cuanto a precisión
el candidato V va bastante mejor. ¿Por qué va bastante mejor el candidato V? Porque es
un candidato que es más corto que la referencia, o sea, es un candidato que tiene menos palabras.
Como venimos definiendo la métrica, si yo tengo una referencia y después tengo un candidato
que es justo un prefijo de la referencia, entonces va a cumplir que ese prefijo andaba
bien en todas las medidas de precisión, porque todos los enigramas que tiene van a
pertenecer a la referencia. Así que lo que hace la medida blue es penalizar ese tipo
de comportamientos. Penaliza los candidatos que son muy cortos para que digamos le de
menos puntaje. Entonces, ¿por qué se penaliza los candidatos cortos y no los candidatos largos?
¿Por qué les parece? Candidatos que son demasiado cortos se penalizan, pero les hemos
dado largos, ¿no? La respuesta está en las slides, pero bueno, se que se penaliza los
candidatos cortos porque los candidatos largos, si yo genero un candidato que es mucho más
largo que la referencia, lo que va a pasar es que ese candidato tiene enigramas, seguramente
tiene enigramas que no pertenece de la referencia. Entonces, en el contenido de precisión me
va a dar un puntaje más bajo. Candidatos largos ya están penalizados por la precisión,
candidatos cortos no están penalizados por la precisión. Entonces, necesito otro tipo
de penalización para evitar eso. Bien, entonces lo que vamos a dar es una cosa de
llama penalización propiedad o brevitipenal, que es un puntaje que se le da en referencia
que tan corto es un candidato respecto a la referencia y bueno, se calcula teniendo en
cuenta todo el largo del documento, todo el largo del documento traducido, entonces
acá yo defino que el reprima es el largo total de todas las referencias, se prima es
el largo total de todos los candidatos. Y entonces, si el largo de los candidatos es mayor
a largo de las referencias no hay penalización, le pongo uno, si el largo total de los candidatos
es menor a largo de las referencias, entonces lo calculo como e a la menos, e a la uno menos
la división entre los largos. Esto es una definición de probabilidad
exponencial, digamos, no es más que eso. Y en realidad lo que trata de hacer es penalizar
traducciones que son muy cortas, entonces si yo tenía un candidato que tenía cinco palabras
mientras la referencia tenía diez, lo voy a penalizar fuertemente, le voy a dar un 0.37
de penalización, si yo tenía un candidato que estaba que era menor pero era más cercano,
entonces la penalización no es tanta de 0.78 y después si los largos son iguales o si
el candidato es más largo, no penalizó nada, le doy uno de puntas.
Bueno, entonces la metrica blue, que es una metrica muy usada en traducción automática,
pone todo esto juntos, digamos, todos estos pedacitos que estuvimos viendo, los pone juntos
en un solo cálculo. Blue se calcula como la penalización por probabilidad, el breve
penal D, por E a la suma de las precisiones de orden N. ¿Qué palabras ruido?
Por ejemplo, esto es un unigrama que le va a dar 0 de precisión, digamos, por ejemplo,
bueno, esta palabra no va, o sea, es un unigrama que le va a dar 0 de precisión, digamos,
porque no está, además participan un diagrama que también le va a dar mala precisión porque
tampoco está el diagrama, entonces lo que, reestan realidad porque no está sumando la
impresión, acá yo tengo 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 es también, pero
hay uno que no, en cambio, en este tengo 6 unigrama de los cuales los 6 es también,
entonces acá el hecho de agregar palabras que no son, que no están bien, no están en la
referencia, ya te penaliza. La diferencia es cuando yo tengo una traducción que más corta,
si yo diría, solo de CatSatOn, entonces ahí es más corta y no tengo forma de penalizarlo
solo con la precisión, entonces tengo el otro penalizador que es porque la traducción es muy
corta. Bien, entonces les estaba comentando, la media blusa define como una media geometrica,
definición de media geometrica, de las precisiones de orden N, también tienes un peso por
precisión que se puede variar, pero en general se utiliza el mismo peso para todos, multiplicado
por la penalización pobrevedad. Bien, eso es la definición de la media blusa, que es una
media que se utiliza muchísimo, esos puntajes que vemos hoy de 25 con 2 y 31 con algo eran
ejemplos de media blusa aplicados en un sistema. Y bueno, una cosa importante, algunos comentarios
importantes sobre la metrica blusa es que en general cuando un sistema le da mejor, digamos,
con un conjunto de traducciones, le da mejor en metrica blusa, también le da mejor con un
conjunto de humanos que evaluan el sistema, o sea que tiene una correlación bastante buena con lo
que es la evaluación subjetiva humana, pero como contra es difícil de interpretar estos
puntajes, o sea, si yo tengo un puntaje de, como nos ha pasado hoy, tiene un puntaje de 31,
en realidad un 31 es un número que puede ser muy bueno, muy malo, dependiendo del idioma,
pero o sea, si todo saliera bien y yo tradujera exactamente lo mismo que están las referencias,
por construcción la media me daría uno, pero en realidad es muy difícil traducir exactamente
lo que están las referencias, porque no es cierto que exista una única traducción posible
en la traducción digamos humana. Horaciones se pueden traducir de manera distinta y estar
igualmente bien, entonces es muy difícil tener un conjunto de referencias que contempla
todas las posibilidades, así que en mi traducutor capaz que anda bárbaro, pero el puntaje
aún no es uno, no es 100 digamos, porque está eligiendo palabras distintas o eligiendo
formas de escribir las oraciones distintas, entonces bueno, por eso es difícil interpretar,
yo tengo un puntaje de 30 o de 50 o sea, de 0.3 o de 0.5 y puede ser buenísimo para
ese sistema, pero para algo que sí me sirve muchísimo el puntaje, digamos, el puntaje
de blu es para decir, yo tengo mi sistema, luego el lujo, después hago algunos cambios,
el lujo de vuelta y si subió la performance de un puntaje blu, entonces estoy seguro
de que mejoro, porque hay una correlación con la evaluación subjetiva.
Para pasar el español inglés, en realidad lo que pasa es que entrenás otro traducutor.
No, acá estoy volando solo, acá estoy volando solamente en un sentido, yo tenía un sistema
español, por ejemplo, digo una oración español, el gato se sentó, y alguien me dijo bueno,
la traducción de referencia a eso es de CatSat y mi sistema me dijo bueno, pero mis
traducciones posibles son de Cat y Sad Cat D, entonces yo tenía un sistema en español
pero que traduce al inglés, digamos, un sistema de traducción de español de inglés,
pero no, no estoy traduciendo en el otro sentido, no, no es como las canciones, acá partí
del español y llegué al inglés y estoy tratando de evaluar comparando las frases en
inglés esperadas con las frases en inglés generadas, claro, probablemente, claro, está en
el mismo idioma, o sea, lo que no mostramos acá era cual era la oración origen, porque para
evaluar no nos importa, para evaluar nos importa que comparar solamente la oración candidato
con la referencia y la origen nos olvidamos, sabemos que los dos intentaron traducir de
la misma oración y bueno, y alguno le fue mejor que a otro, bien, esos son comentarios
de blue, esto era evaluación de los sistemas, lo siguiente que vamos a ver es el problema
de los corpos paralelos, antes de pasar a lo que son modelos de traducción, vamos a
hablar un poco de lo que son los corpos paralelos, que son necesarios para construir un modelo
de traducción, un corpos paralelo consiste en pares de textos en dos idiomas, por ejemplo,
tener textos en español y en inglés, pero además yo tengo que tener algún nivel, tengo
que tener una correspondencia entre esos textos, de alguna forma, yo tengo que saber cómo
se corresponde un texto con el otro, entonces bueno, tiene que estar con juntos, digamos,
ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen en
el mundo, existen corpos paralelos para algunos idiomas, o sea, hay muchos idiomas en el mundo,
pero no todos los pares de idiomas tienen corpos paralelos construidos, entonces existen
para el lado de inglés, el chino inglés, para la mayoría de los lenguajes europeos,
debido a su uso en la unión europea, digamos, existen también corpos paralelos para ellos,
pero para la gran mayoría de pares de lenguas, no hay, digamos, no tengo un par que traduzca
entre el chino y el guaranismo, por ejemplo, o sea, es poco probable que se construye un
par de estilos, bien, que es un corpos paralelos, ya que no se ve nada, de vuelta, acá hay un ejemplo
que no sé si lo conocen, es un ejemplo famoso de corpos paralelos, tiene ni idea de lo que
es, lo han visto alguna vez, la piedra de roseta, la piedra de roseta, una piedra que la construyeron,
o por lo menos la tallaron el año 1996, antes de Cristo, y hablaba sobre la coronación de
Tolomeo Quinto, y tal, y su adoración como semi-dios, etcétera, etcétera, y bueno,
hasta estuvo perdida, tomo un montón de años, hasta que durante las campañas Napoleónicas,
1799, la encontraron en Egipto, en el lugar roseta, casualmente, y se lanzaron para Francia,
ahí le empezaron a analizar lingüistas, empezaron a tratar de entender que era lo que decía, y bueno,
descubrieron que tiene tres textos, vieron que tienen como tres regiones, tres textos, y después de
estudiarla un rato, seguiron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas
distintos, y los idiomas eran, el de arriba era en jeroglíficos egipcios del estilo de lo que
uno encuentra dentro de las pirámides, el del medio era egipcio demótico, que era el egipcio
vulgar que se usaba, digamos, en el día a día, y el de abajo el todo era griego antiguo. Entonces,
si bien, ninguno de los tres idiomas se hablaba en el momento que se encontró, la piedra,
los tres idiomas antiguos, el griego antiguo por lo menos sí se sabía, digamos, se conocía como
idiomas, se sabía qué significaba, y digamos, había gente que lo estudiaba, los otros dos no,
los otros dos eran lenguas completamente perdidas, que nadie sabía identificarlas. Pero gracias al
hecho de que en realidad se descubrió que los tres textos hablan de lo mismo, son el mismo
texto entre los idiomas. Entonces ahí se empezó a hacer un trabajo de alineación, digamos, los
arqueólogos, empezaron a decir, bueno, esta porción de texto acá se corresponde con esta
de acá, se corresponde con esta de acá, etcétera, y a tratar de encontrar correspondencias en los
idiomas, y cómo sabían qué quería decir en griego antiguo, empezaron a poder descubrir qué
querían decir en los otros idiomas. Entonces, a raíz de eso es que empezó, digamos, el
Egipto Elogía Moderno se pudo empezar a desifrar, qué dicen, por ejemplo, los geográficos
están en las pirámides, y bueno, un montón de cultura, egipcio antiguas, se conoce gracias
a que se pudo desifrar lo que decía esta piedra. Y en definitiva, esto es un ejemplo de corpus
paralelo, o sea, tengo el mismo texto entre los idiomas, y con un poco de esfuerzo logro al
alinear, cual son cada uno de los elementos de mis lenguajes, y logro saber la traducción
de los tres. Bueno, entonces, esto nos lleva el concepto de alineación. Los corpus paralelos
tienen distintos niveles de alineación. Lo más fácil de encontrar son corpus que están
alineados al nivel de documentos. Yo tengo una colección de documentos en español y una
colección de documentos en chino, y yo sé qué documentos se corresponde con qué otro,
pero no sé nada más. Sería mejor, incluso que estuvieran alineados a nivel de
elaboración, además de conocer los documentos, yo sé cuál elaboración español va con
cuál elaboración en chino, digamos. Tengo una correspondencia entre esas dos. Pero sería
aún mejor, y esto es lo que más nos serviría, si estuvieran alineados a nivel de palabra.
Cada uno de los caracteres que están en chino se corresponde con qué palabra en español,
lo que grupo de palabra, si cada uno de las palabras de español con qué grupo de caracteres
se corresponde en chino. Esto es el ideal, pero claro, o sea, si ya es difícil conseguir
cosas que estén alineadas a nivel de documentos, si imaginan que nadie va a ir a mano al
linear a nivel de palabra cada uno de las palabras de los idiomas. Entonces, en la práctica
nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que, como
resultado de la construcción de los modelos de lenguaje, se produce también como un producto
secundario, se produce la alineación de los corpus. Entonces, obtenes las dos cosas a
la vez. Bueno, yo otra cosa es que, a diferencia
de el texto monolíngue que yo usaba para los modelos de lenguaje, es muy raro que
naturalmente se produzcan textos en dos idiomas a la vez. O sea, hay que buscarlos bastante,
digamos, bastante cuidadosamente. Existen algunos contextos en donde eso se produce. Por
ejemplo, en algunos portales de noticias, puede pasar que tengan versiones en distintos
idiomas y lo que hagan sea traducir las noticias en distintos idiomas. Entonces, si yo
puedo encontrar uno de esos, es una buena fuente para construirme un corpus paralelo
anineado a nivel de documentos. O sea, esta noticia se corresponde con esta otra en el
otro idioma. Pero un lugar en donde se producen naturalmente
este tipo de textos es en los países que son bilíngües, o multilíngües. Por ejemplo,
en Canadá, que hablan inglés y francés, las discusiones del Parlamento Canadíense
siempre, por ley, tienen que transcribirse en los dos idiomas, tienen que traducirse
si está en inglés, se daus en francés, se daus en inglés. Y guardan una correspondencia
entre eso. Guardan el documento de todas las discusiones del Parlamento en los dos
idiomas. Entonces, ahí, naturalmente se produce un corpus paralelo anineado de documentos
para el inglés y el francés, que se se conoce como el corpus Hansard. Eso también ocurre
en concon, en conconciable inglés y chinos, son los dos idiomas oficiales. Entonces,
el corpus más grande que se tiene para inglés y chinos, está hecho como una compilación
de lo que son las discusiones del Parlamento de Hong Kong. Y también pasa en la Núneo
Europea, en el Parlamento Europeo, también tienen la costumbre de traducir todas las discusiones
a todos los idiomas o a muchos de los idiomas que se usan en la Unión Europea. Entonces,
hay corpus paralelo para casi todos los idiomas de la Unión Europea. Pero claro, todos
estos están alineados a nivel de documento. Yo sé qué documento se corresponde con
cual otro en el otro idioma, pero no anivel de oraciones y mucho menos anivel de palabras.
Pero bueno, partiendo de un corpus alineado a nivel de documentos, yo puedo llegar a construir
me, por lo menos, una alineación a nivel de oraciones, siendo un proceso relativamente
sencillo. Esto se conoce como el algoritmo de que él y Church, que es un algoritmo relativamente
fácil para alinear corpus, o sea, para pasar corpus que están alineados a nivel de documento,
pasarlos a que estén alineados a nivel de oración. Y bueno, esto es un algoritmo que funciona,
está un poco basado en lo que era el algoritmo de distancia de edición del EventTime, que
vimos hace bastante tiempo en el curso. Bueno, es como muy parecido, también es un
algoritmo de pronomación dinámica, similar a ese. Funciona de la siguiente manera, o
sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de cómo que funcione.
En el algoritmo de Gayley Church dice, yo voy a tener un conjunto de oraciones en un idioma
y otro conjunto de oraciones en el otro idioma. Entonces, considero que un traductor para
cada oración pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma.
Un traductor, suponga un traductor humano, agarró oraciones que estaban en español y
oraciones que estaban en francés. O sea, no ponerles EIF porque lo que puede confundir
con las otras cosas, así que vamos a decir el lenguaje de origen era F, francés y el
lenguaje de estino era español. Bien, entonces, un traductor humano cada vez que se enfrentaba
una oración tenía tres posibilidades. O bien, traducía una oración por otra oración,
o bien parte de esta oración en dos y traduce una oración por dos, o bien borra esta oración,
decide que no es tan importante y abarra y borra la oración. Entonces, las tres operaciones
que se hacen a nivel de oración son la de transformarla en cero, una o dos oraciones
del otro lado. Eso es una cosa. Lo otro es, el costo relativo de alinear
estas dos oraciones depende del largo relativo de las oraciones. Entonces, si yo tengo dos
oraciones que tienen un largo muy parecido, le voy a dar un costo menor para alinearlos,
era menor o mayor. Sí, menor. Si tiene un largo muy parecido, le voy a dar un valor menor
para alinear. Si tiene un largo muy distinto, una es muy corta y la otra muy larga, entonces
le voy a dar un valor mayor para alinear. Entonces, lo que ellos hacen es pensando en
todo este tipo de operaciones que hay, todas las combinaciones de operaciones posibles,
o sea, partir esta oración en dos o no partirla o eliminarla o dejarla como está. Entonces,
con programación dinámica, ven todas las posibilidades de operar distinto para llegar
al otro lado y calculan las que le da un costo menor. O sea, para cada una de las posibilidades
calculan cuál es el costo de cada par de oraciones suman todos los costos del documento.
Y se quedan con el caso que les dé un costo menor en alineación. Eso se puede hacer
eficientemente, usando programación dinámica lo mismo que hacíamos con la distancia de edición
de Leberstein.
Bueno, y este algoritmo que es relativamente sencillo, digamos, es una solución bastante simple,
logra una tasa de error muy buena, que es de un 4%, digamos, que, sobre todo, parede
más relacionado, parede más que se parecen como el inglés y el español, etcétera, logra
una tasa bastante baja de error de un 4%, hay algunas mejoras que se pueden hacer, pero
en realidad hay un 4% de algo que está bastante bien. Hay un catch que es que para sistemas
de traducción distintos, traducciones no literales, esto se rompe un poco, por ejemplo,
para traducir entre inglés y chino, que en chino ni siquiera está claro que les son los límites
de las palabras, eso es más difícil de ver. Entonces, bueno, este tipo de algoritmos
no funcionan también, y bueno, hay variantes que funcionan un poco mejor.
Así que bueno, hoy vamos a dejar por acá y vamos a continuar en la próxima con modelos
de traducción.
