{"text": " La clase de hoy y la clase que viene, vamos a dar el tema de traducci\u00f3n autom\u00e1tica. Y bueno, vamos a arrancar. Por esto que se conoce como la nota de Weber, o el memorando de Weber, Warren Weber era un matem\u00e1tico norteamericano de primera mitad de siglo XX. Y el tipo trabaj\u00f3 durante la guerra, especialmente en cosas de criptograf\u00eda, en an\u00e1lisis estad\u00edstico, de c\u00f3digos, etc\u00e9tera. Entonces en un momento dijo lo siguiente, dijo, es muy tentador decir que un libro escrito en chino, es simplemente un libro escrito en ingl\u00e9s que ha sido codificado en el c\u00f3digo chino. Si tenemos m\u00e9todos \u00fatiles para resolver casi cualquier problema criptogr\u00e1fico, no ser\u00e1 que con la interpretaci\u00f3n apropiada, ya tendr\u00edamos m\u00e9todos \u00fatiles para la traducci\u00f3n. El opinado, digamos, en este memor\u00e1ndum, que los m\u00e9todos que se utilizan para romper c\u00f3digo criptogr\u00e1fico, que son m\u00e9todos estad\u00edsticos, se pod\u00edan aplicar al problema de la traducci\u00f3n autom\u00e1tica. Y bueno, esto introduce algunas ideas clave como que puede existir un mapeo autom\u00e1tico entre un lenguaje y otro, y que codificar, de codificar en un lenguaje de san\u00e1logo, a codificar, de codificar en una ecorismo criptogr\u00e1fico. Y bueno, el tiro, esa idea es 1949, tom\u00f3 como 50 a\u00f1os para que esa idea madurar, digamos, y despu\u00e9s de 50 a\u00f1os los m\u00e9todos m\u00e1s utilizados, hoy en d\u00eda son m\u00e9todos estad\u00edsticos que se basan un poco en estos principios. Pero claro, en esa \u00e9poca era como muy dif\u00edcil lugar que era lo que iba a ocurrir. Entonces, bueno, vamos a ver un poco esta la agenda de lo que vamos a mirar. Vamos a llegarnos a menos hasta la mitad hoy y despu\u00e9s la clase siguiente. Y empecemos con un poco de historia de lo que es la traducci\u00f3n autom\u00e1tica. Esto empez\u00f3 como muchas otras tecnolog\u00edas, como una tecnolog\u00eda militar, con fines militares. Inicialmente era durante la Guerra Fr\u00eda, era resultado de inter\u00e9s traducir r\u00e1pidamente y abajo costa traducir entre el ruso y el ingl\u00e9s, digamos, los norteamericanos les conven\u00eda poder traducir entre el ingl\u00e9s y el ruso. Y bueno, en aquella \u00e9poca se imaginan lo que era los inicios de la computaci\u00f3n, las computadoras ser\u00e1n caras, en las lentas, no ten\u00eda mucho poderos de computos, pero igual hab\u00eda como mucho optimismo, de que en poco tiempo se iba a poder resolver los problemas y vamos a tener sistemas que iban a traducir barbaros. Y bueno, era m\u00e1s o menos la \u00e9poca de desarrollo de la ling\u00fc\u00edstica computacional, inspirado un poco en las teor\u00edas de Chomsky, estaba la idea que se pod\u00eda escribir reglas para todo y que a partir de eso se podr\u00eda llegar a hacer cosas muy muy buenas, es particular para la traducci\u00f3n. Hasta que en 1964 pareci\u00f3 el reporte Alpac, Alpac era un comit\u00e9 que estaba estudiando, cu\u00e1les eran los avances en ing\u00fc\u00edstica computacional, porque se estaba poniendo mucha plata en muchas esas cosas. Y ellos demostraron escepticos acerca de la traducci\u00f3n autom\u00e1tica, acerca de los logros que se hab\u00edan logrado despu\u00e9s de todos esos a\u00f1os de meter plata. Y dec\u00eda bueno, pero se puso mucho dinero, pas\u00f3 en muchos a\u00f1os, pero todav\u00eda los humanos lo hacen m\u00e1s barato, con mayor precisi\u00f3n, m\u00e1s r\u00e1pido, entonces como que para que estamos gastando en esto. Como resultado de eso, un reporte de fondos, especialmente en Estados Unidos, para todo lo que la traducci\u00f3n autom\u00e1tica y esto fue parte de lo que se conoci\u00f3 como el invierno de la inteligencia artificial, que un mont\u00f3n de proyectos de inteligencia artificial tambi\u00e9n no ten\u00edamos el resultado, entonces se par\u00f3 la financiaci\u00f3n que hab\u00eda para todo eso durante unos cuantos a\u00f1os, entonces se tuvo desarrollado unas cuantas cosas durante unos cuantos a\u00f1os. Y bueno, despu\u00e9s empezaron a resurgir de apoco, pero despu\u00e9s de esto, digamos, en los 70 y hasta los 90 m\u00e1s o menos, eso le hubo que la investigaci\u00f3n se frenar un poco en Estados Unidos, pero empezar a aparecer en otros lados del mundo, como por ejemplo en Europa o en Jap\u00f3n. Y ah\u00ed empez\u00f3 ya con filas b\u00e9licos, sino m\u00e1s bien con fines comerciales, entonces hab\u00eda necesidad de tener traducciones o por lo menos dar soporte a los traductores humanos con algunas traducciones, aunque no estuvieran de todo bien, pero bueno, dar algunas traducciones de inicio para que los traductores puedan, los traductores humanos puedan continuar, adem\u00e1s las computadoras empezaron a bajar de precio, tener mayor hogar de computo, y esta fue como la era de oro de los sistemas de traducci\u00f3n basados en reglas, digamos ac\u00e1 hay unos ejemplos, sistemas distranques, todav\u00eda se desarrolla aunque ya no est\u00e1 completamente basado en reglas, y bueno, hay sistemas que se realizaron en Jap\u00f3n y en Europa, y bueno, o sea, estos sistemas ten\u00edan fines comerciales y no tanto fines militares, pero bueno, fines de los 90 y despu\u00e9s de 2000, en adelante empezaron a dejarse de usar un poco los sistemas basados en reglas, porque empez\u00f3 a haber mayor poder de computo y mayor cantidad de datos disponibles, especialmente con la aparici\u00f3n de internet, empezaron a haber much\u00edsimos datos de texto disponibles, y eso permit\u00eda construir buenos modelos estad\u00edsticos que podr\u00edan explotar las regularidades de los idiomas, entonces aparecieron distintos tipos de modelos estad\u00edsticos, los primeros, los que se llamaron traducciones autom\u00e1ticas estad\u00edsticas, que es la otra traducci\u00f3n basada en ejemplos, y aparecieron las primeras aplicaciones comerciales que funcionaban bien, que utilizaban modelos estad\u00edsticos, la primera fue el English Weber, y despu\u00e9s los traductores que m\u00e1s conocemos hoy en d\u00eda el Bing, translate de Microsoft, y bueno, el Google translate, que probablemente los lo conozcan y lo hayan usado en alg\u00fan momento, y son traductores que la verdad que hoy en d\u00eda se puede decir que funcionan bastante bien, entonces bueno, los m\u00e9todos estad\u00edsticos empezaron subhum al alrededor del a\u00f1o 2000 y siguen siendo el estado del arte, pero bueno, primero vamos a ver un poco de lo que son los sistemas basados en reglas, que eran estos primeros sistemas que mencionamos antes, en 1968 un investigador de traducci\u00f3n autom\u00e1tica, se llamaba Bernard Boquah, y son relevamiento de todos los sistemas que se hab\u00edan construido, m\u00e1s o menos por la \u00e9poca, y los clasific\u00f3 todos dentro de este diagrama, el dibujo un tri\u00e1ngulo que ahora se llama el tri\u00e1ngulo de Boquah, y bueno, en este tri\u00e1ngulo se ubican los distintos tipos de sistemas de traducci\u00f3n basados en reglas, se ponen como escalones dentro de este tri\u00e1ngulo, y los lados del tri\u00e1ngulo tienen como distintas interpretaciones, el lado izquierdo, si yo voy subiendo por este lado, en realidad lo que aumenta es la cantidad o el esfuerzo de an\u00e1lisis que tengo que hacer de lenguaje origen, yo siempre quiero traducir de lenguaje origen en el lenguaje destino, bueno, entonces de este lado aumenta el esfuerzo de traducci\u00f3n en el lenguaje origen, y si voy bajando del lado derecho aumenta, bueno, si voy subiendo del lado derecho quiero decir, aumenta el esfuerzo de generaci\u00f3n en el lenguaje destino, entonces \u00bfqu\u00e9 quiere decir esto? Yo ubico distintos sistemas de traducci\u00f3n, la traducci\u00f3n directa es simplemente buscar en el diccionario de las palabras y traducir palabra palabra con poca informaci\u00f3n m\u00e1s, entonces eso casi no necesitan ning\u00fan tipo de an\u00e1lisis y casi no necesitas generaci\u00f3n, pero para que son deb\u00edan, yo necesito ponerle muchas ganas a las reglas, o sea, las reglas de traducci\u00f3n deben ser muy buenas y tienen que tomar en cuenta muchos casos para que esa traducci\u00f3n llegue a ser buena, entonces es como que la flecha de la transferencia, la flecha de la traducci\u00f3n es mucho m\u00e1s larga, en cambio, si yo hago un poco de an\u00e1lisis, por ejemplo, llevo hasta al nivel de an\u00e1lisis intactico, tengo un parcer, puedo escribir otro tipo de reglas que pueden ser un poco m\u00e1s expresivos, me resulta un poco m\u00e1s f\u00e1cil y despu\u00e9s, si tengo un generador, puedo llegar a traducir, entonces si sigo subiendo de vuelta, voy a necesitar mayor esfuerzo de an\u00e1lisis de generaci\u00f3n, pero las reglas pueden ser m\u00e1s expresivas y m\u00e1s f\u00e1ciles de escribir y probablemente la traducci\u00f3n sea mejor, hasta que si llegamos al lo articel tri\u00e1ngulo, llegamos a la interlingua, que es una especie de noci\u00f3n en la cual no necesito ning\u00fan tipo de transferencia, vamos a dar un poco dentro de un rato de que se trata eso, pero bueno, empecemos a ver los distintos niveles de este tri\u00e1ngulo de bocua, el dem\u00e1s abajo era la traducci\u00f3n directa, es el enfoque m\u00e1s simple, lo \u00fanico necesito para este enfoque es un diccionario de ling\u00fce, yo quiero traducir entre dos idiomas, si necesito un diccionario que tenga la correspondencia entre palabras de un idioma y palabras del otro, y lo que voy a hacer es traducir palabra palabra, o sea, puedo agregarle alguna cosa extra, como por ejemplo, alg\u00fan reordenamiento local, yo que es para traducir entre espa\u00f1ol ingl\u00e9s, yo dir\u00eda que en espa\u00f1ol el nombre se siga el adjetivo y en ingl\u00e9s se en realidad los han arreves, pone el adjetivo seguido el nombre, entonces ese tipo de reglas simples se las puedo agregar al sistema, y bueno, el sistema funcionar\u00eda un poco as\u00ed, yo tengo una operaci\u00f3n de entrada en el idioma origen, Mary Tiden Slap de Green Witch, le paso un analisador morfol\u00f3gico bastante de superficie, que no hace mucho en realidad, simplemente me dice que esto era el barbo du, en pasado y seguido por un not, y bueno, el resto de los tokens sigue en igual, y ac\u00e1 viene la parte de diccionario, digamos, lo siguiente que tengo que hacer es buscar en mi diccionario cada una de las palabras y poner la palabra correspondiente del otro lado, entonces Mary queda Mar\u00eda, duve en pasado como en espa\u00f1ol no se usa el du, usamos simplemente el marcador de pasado, not es no, Slap es dar una ofetada de Slap Green, es verde, Witch es Bruja, con el diccionario hoy poniendo todas las traducciones, y despu\u00e9s puedo usar mis reglas de ordenamiento local, de ordenamiento simple como por ejemplo que el adjetivo seguido en nombre en ingl\u00e9s, en realidad en espa\u00f1ol se corresponde con nombres seguido adjetivo, entonces verdad de Bruja lo cambio por Bruja verde, ac\u00e1 hay otro ordenamiento, digamos, donde tengo una marca de pasado y se lo paso para adelante a lo largo, y finalmente lo que hago es una peque\u00f1a generaci\u00f3n morfol\u00f3gica con estas marcas y digo bueno, este dar en pasado se transforma en dio, entonces me queda Mar\u00eda no dio una ofetada a la Bruja verde, as\u00ed que part\u00ed de el texto en el idioma Rige, Mary did and Slap de Green Witch y llegue a una oraci\u00f3n en el idioma destino Mar\u00eda no dio una ofetada a la Bruja verde, que parece estar bastante bien digamos, bastante bien la traducci\u00f3n, entonces as\u00ed es como funcionar\u00eda un poco un sistema de traducci\u00f3n directa, como les parece que funcionan estos sistemas en la pr\u00e1ctica, digamos que tambi\u00e9n se comportan en la pr\u00e1ctica este tipo de sistemas, pues ac\u00e1 vimos un ejemplo que quedan bastante bien digamos, pero no s\u00e9 qu\u00e9, claro, y hay otro problema m\u00e1s, y es lo que, que no tenga todas las palabras, pero adem\u00e1s que palabras que se pueden traducir de m\u00e1s de una manera, entonces necesitas saber qu\u00e9 palabras ten\u00e9s que usar, entonces bueno, la web est\u00e1 llena de ejemplos de lo que puede salir m\u00e1s y yo utilizo un sistema de traducci\u00f3n directa como este, entonces lo que est\u00e1bamos viendo reci\u00e9n era los sistemas de traducci\u00f3n directa, vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sint\u00e1ctica, entonces para la transferencia sint\u00e1ctica, yo lo que voy a necesitar primero es tener un parcer de lenguaje origen que me lleva a un an\u00e1lisis sint\u00e1ctico y adem\u00e1s voy a necesitar un generador, lenguaje destino que agarra, un algo sint\u00e1ctico de lenguaje destino y genera una oraci\u00f3n, entonces yo lo que puedo hacer es escribir reglas que transformar un \u00e1rbol en el otro y esas reglas son un poco m\u00e1s f\u00e1ciles digamos que lo que necesitar\u00eda para un sistema de traducci\u00f3n directa, entonces para el ingl\u00e9s, por ejemplo para todo el siguiente del ingl\u00e9s y el espa\u00f1ol, yo dir\u00eda que si tengo un nominal que es un adjetivo nombre, un adjetivo en un nombre en ingl\u00e9s, lo transformar\u00eda en un nombre, segu\u00ed un adjetivo en espa\u00f1ol y la reglas escribir\u00eda algo as\u00ed dir\u00eda, tengo nominal adjetivo nombre, entonces lo cambio por nominal nombre adjetivo, entonces ahora que sabemos c\u00f3mo funciona esto, tratemos de hacer el ejemplo en japon\u00e9s, digamos c\u00f3mo ser\u00edan las reglas para transformar el \u00e1rbol en ingl\u00e9s de Geador, se le dicen en tu music, a japon\u00e9s, careja, ongaku, wokiku, no gada y suki de su, donde est\u00e1, tenemos la correspondencia de cada una de las palabras, pero claro los \u00e1rboles son un poco distintos, el ingl\u00e9s y el espa\u00f1ol se caracterizan por ser lenguajes de tipo, no s\u00e9 si esto lo hemos visto ya en el curso, pero son lenguajes de tipo SBO, que significa que habitualmente yo solo escribir un sujeto se dio un verbo seguido de un objeto, el japon\u00e9s en cambio es un lenguaje de tipo SBOB porque habitualmente se escribi\u00f3 el sujeto, seguido del objeto, seguido del barbol, hay muchos lenguajes que pertenecen a esta otra categor\u00eda, entonces bueno, queremos escribir reglas de transferencia para transformar este \u00e1rbol en aquel otro \u00e1rbol, como escribir\u00edamos esas reglas, que les parece, que reglas utilizar\u00eda yo para transformar un \u00e1rbol en el otro, ah\u00ed est\u00e1, una de esas, en ingl\u00e9s yo escribo, una fraser\u00f3balo, un grupo verbal como un verbo seguido de un grupo proporcional, esta es la que dec\u00edas, y la cambio por que otra cosa, la cambio por un grupo proporcional que sigue un verbo, esa es una, que otra regla tendr\u00eda que agregar, cu\u00e1l, la elaboraci\u00f3n, que tiene la elaboraci\u00f3n, la elaboraci\u00f3n seg\u00fan esto en ingl\u00e9s es un pronombre seguido de un verbo, seguido de un grupo verbal, por qu\u00e9 tendr\u00eda a cambiarlo, ahora en japon\u00e9s la elaboraci\u00f3n va a ser el pronombre seguido del verphrase, seguido del verbo, bien, alguna otra, ah\u00ed est\u00e1, el grupo preposicional que est\u00e1 formado por un t\u00fa, seguido un nombre, eso es en ingl\u00e9s y en japon\u00e9s que va a pasar, voy a tener un grupo proporcional que es un nombre seguido de t\u00fa, bien, entonces con eso m\u00e1s o menos creo que tendr\u00eda las reglas suficientes para transformar un \u00e1rbol en el otro, los sistemas de traducci\u00f3n, vamos a ver si est\u00e1 bien, son los que escribimos, esta es la soluci\u00f3n del ejercicio, los sistemas de traducci\u00f3n basados en s\u00edntaxis, en realidad los sistemas de traducciones de reglas, en s\u00edntaxis hacen esto a alto nivel, digamos, tienen montones de pared de \u00e1rboles, hay gente que los analiza y escriba reglas como se transforma uno en el otro, a veces las reglas son complicadas porque se pueden superponer, entonces hay que definir prioridades y ese tipo de cosas, bueno, esas transferencias sint\u00e1cticas, si seguimos subiendo en el tri\u00e1ngulo de bocua, llegamos a lo que es la transferencia sem\u00e1ntica, tal vez es sem\u00e1ntica uno puede pensarla un poco como lo que hab\u00edamos en la clase pasada, utilizando roles sem\u00e1nticos, yo tengo un etiquetador de roles sem\u00e1nticos, que agarra la relaci\u00f3n Juan fue a la tienda y me devuelve los roles de los constituyentes, me dice que Juan es el agente y a la tienda es el objetivo o goal, digamos, es el nombre del rol, entonces yo, para ciertos idiomas podr\u00edas escribir reglas m\u00e1s espec\u00edficas, por ejemplo, en chino ocurre que los sint\u00e1mas propulsionales, que son de tipo objetivo, se escriben antes del largo, pero los dem\u00e1s sint\u00e1mas propulsionales escriben despu\u00e9s, o sea, el chino es un lenguaje de tipo SBO igual que el ingl\u00e9s o el espa\u00f1ol, pero cuando el objeto es de tipo goal lo que hacen es ponerlo antes del largo, entonces yo podr\u00eda escribir una regla un poco m\u00e1s expresiva, para este caso del chino, si yo tuviera los roles sem\u00e1nticos, yo dir\u00eda que un grupo verbal es un verbo seguido de esto, esto no est\u00e1 tachado, sino que era la barrita que qued\u00f3 arriba, es un verbo seguido de un grupo proporcional de tipo goal, en chino lo cambiar\u00eda por un verbo seguido de un verbo, por un grupo proporcional de tipo goal seguido de un verbo, es m\u00e1s costoso para generar y para parcear, digamos, necesito tener m\u00e1s esfuerzo de parcin y m\u00e1s esfuerzo de generaci\u00f3n, pero puedes escribir mejores reglas que capturan ciertas particularidades de los lenguajes, y si yo sigo subiendo en el tri\u00e1ngulo llego a lo que se conoce como interlingua, cu\u00e1l es la gracia de interlingua, cu\u00e1l es la idea, esto sirve si nosotros estamos en un contexto multicultural, estamos trabajando, por ejemplo, en la ONU o en el Palamento Europeo, o algo de eso donde se hablan muchos idiomas, si yo quiero mantener un mont\u00f3n de documentos que est\u00e9n en todos los idiomas a la vez, voy a necesitar para los sistemas que estuve en nuestro momento, voy a necesitar tener N parsers, uno para cada idioma, N generadores, tambi\u00e9n uno para cada idioma, y despu\u00e9s para cada par de idiomas, voy a necesitar reglas de transferencia, entonces voy a necesitar tener en total N por N menos 1, 7 de transferencia, yo tengo 20 idiomas, voy a necesitar 380 conjuntos de reglas de transferencia, y esos conjuntos de reglas de transferencia son largos, son grandes, son complejos, hay que mantener los, pueden tener errores, entonces esto claramente no es cala, es como muy dif\u00edcil poder mantener un entorno de todos esos idiomas y poder mandar la traducci\u00f3n en base a reglas, entonces la idea del interlingua es decir, \u00bfqu\u00e9 tal si pudi\u00e9ramos parcear lo suficiente o analizar lo suficiente como para llevar a una representaci\u00f3n com\u00fan, una representaci\u00f3n que captur\u00e9 el significado de todos los idiomas a la vez, y adem\u00e1s tuvieramos un generador para cada uno de los idiomas. Si eso pasara, si nosotros pudi\u00e9ramos capturar con una representaci\u00f3n el significado de todos los idiomas a la vez, no necesitar\u00edamos transferencias, simplemente parceamos y llevamos a esa interlingua y despu\u00e9s generamos en el otro idioma. Esto est\u00e1 muy bien, digamos, del punto de vista ideal, pero es muy dif\u00edcil obtener la pr\u00e1ctica. \u00bfQu\u00e9 se podr\u00eda usar como representaci\u00f3n de interlingua? \u00bfQu\u00e9 podr\u00eda hacer un candidato? Bueno, podr\u00edamos usar la l\u00f3gica de primer orden, que era lo que ve\u00edamos en las primeras clases de sem\u00e1ntica, como representar variaciones en la l\u00f3gica de primer orden, o alguna de sus variantes que da un cuenta mejor de lo que es la l\u00f3gica de la lengua genatural, como las m\u00ednimos con recursos sem\u00e1nticos o las whole sem\u00e1nticos. O si no, hay como parecido lo que ve\u00edamos en la clase anterior de frames, construirme frames con el estado de las cosas, como por ejemplo est\u00e1 la misma operaci\u00f3n de hoy, Mary didn't slap the green witch, pero es crita como un frame, es hay un evento de slapping, la gente es Mary, ocurre en pasado, la polaridad negativa, el tema de ese evento es la bruja y la bruja de m\u00e1s es verde. Yo podr\u00eda construir este tipo de frames y usarlos como representaciones. Pero bueno, hay problema que tiene crear o pensar en crear una interlingua, es que esa interlingua seguro que va a ser muy compleja y seguro que va a tener que modelar las caracter\u00edsticas de todos los idiomas al mismo tiempo. Y hay caracter\u00edsticas que son complicadas en los distintos idiomas, y algunas que ni nos imaginamos, o sea, por ejemplo, en chino existen palabras distintas para decir hermano mayor y hermano menor, y no hay una palabra para decir hermano. O sea, no hay una palabra que quiera decir solamente hermano. En espa\u00f1ol s\u00ed, y en ingl\u00e9s tambi\u00e9n, en ingl\u00e9s puede decir brado, pero en chino no, en chino tienes que elegir cuando vas a decir hermano, si es hermano mayor o hermano menor. Entonces, imag\u00ednense que si yo estoy traduciendo del espa\u00f1ol al ingl\u00e9s y estoy utilizando una interlingua, la interlingua en su parcer necesita poder distinguir en alg\u00fan momento, si estoy hablando de un hermano mayor o un hermano menor, porque tiene que lograr la representaci\u00f3n suficiente como para poder traducir al chino. Entonces, necesita esa informaci\u00f3n y no s\u00e9 d\u00f3nde la va a sacar, la puedes sacar de contexto, lo puedes sacar inventar de alg\u00fan lado, pero en alg\u00fan momento va a tener que averiguar el hermano que se est\u00e1 hablando en espa\u00f1ol, si es un hermano mayor o menor, como para poder tener la representaci\u00f3n, y despu\u00e9s esa informaci\u00f3n se va a perder, porque cuando baja de vuelta, al lado del ingl\u00e9s, de vuelta vuelve a ser brada y no importa si es mayor o menor. Y esto es solamente un caso de un fen\u00f3meno que ocurre en chino, pero, imag\u00ednense, los fen\u00f3menos que ocurren en el idioma en todo el tiempo, digamos, y todas las peque\u00f1as variantes que hay. Y como en realidad, no es cierto que podamos traducir exactamente lo mismo conceptos, como que es muy dif\u00edcil encontrar conceptos que se correspondan 100% en idioma y otro. Hay una cosa que se llama el principio de incertidumbre de la traducci\u00f3n y dice eso, que en realidad, cuando yo tengo un idioma y otro, los conceptos no siempre se van a traducir 100% bien, o sea, no siempre la traducci\u00f3n es exacta, sino que hay cierto suelopamiento y a veces se va a funcionar y a veces no. Bien, pero a pesar de que es una utop\u00eda, tener un interlingo que funcione para todos los lenguajes bien, este tipo de tecnolog\u00eda s\u00ed se utilizan para dominios m\u00e1s acotados, para dominios peque\u00f1os, como por ejemplo, el de meteorolog\u00eda, yo puedo escribir perfectamente, puedo construir una representaci\u00f3n de todos los estados meteorol\u00f3gicos que hay, y si hay lluvias y nievas, y hay granizo, la temperatura, la presi\u00f3n, etc. y traducirlo a las distintas palabras, que son los distintos idiomas para dar cuenta de estos conceptos. Entonces, ese dominio acotado es bastante bien manejable con una interlingua. Y otro ejemplo son los manuales t\u00e9cnicos, hay empresas que, de un mont\u00f3n de documentaci\u00f3n t\u00e9cnica, o describen las apis de sus productos, etc. Y uno suele dar, cuando mira la p\u00e1gina web, digamos que aparece como con su fijo es, porque est\u00e1 en espa\u00f1ol, pero si se lo cambias por en, autom\u00e1ticamente te genera otras p\u00e1ginas, exactamente igual, pero en ingl\u00e9s, y en realidad lo que hacen es como mantener una representaci\u00f3n abstracta de lo que est\u00e1n escribiendo y generarla en los distintos idiomas. Bien, entonces, hasta ah\u00ed lo que vimos era como un paneo de lo que son los distintos sistemas basados en reglas, ahora vamos a pasar a hablar de lo que es la traducci\u00f3n estad\u00edstica que es el estado del arte hoy en d\u00eda, y vamos a empezar con un ejemplo, un ejemplo de una frase en hebreo, que es Adonai Roy, que la traducci\u00f3n ser\u00eda el se\u00f1or a mi pastor o del Lord Ismail Shepper, y esta frase, en realidad, funciona bien, porque nosotros conocemos que son las ovejas, digamos, la cultura en la que surgi\u00f3 esta frase, conoc\u00eda que eran las ovejas, ten\u00edan pastores, los pastores cuidaban las ovejas, la llevaban a donde hab\u00eda estado los mejores pastos, etc. Entonces, esta met\u00e1fora funcionaba bien, digamos, la gente describ\u00eda como se sent\u00eda en respecto a Dios utilizando esta met\u00e1fora. Pero \u00bfqu\u00e9 tal si quisieramos expresar esta misma frase a una cultura que no conoce a las ovejas? Por ejemplo, los primeros misioneros que vendr\u00edan de Europa y tendr\u00edan contacto con los ind\u00edgenas americanos, los ind\u00edgenas americanos no conoc\u00edan ovejas, entonces, \u00bfc\u00f3mo hacemos para expresarles el concepto de Adonai Roy? Una forma de expresarlo es decir, bueno, adusco la met\u00e1fora, el significador de la met\u00e1fora, digo, significa el se\u00f1or me cuidar\u00e1, que en definitiva es un poco la met\u00e1fora que quiere decir eso, aunque pierda un poco de contenido, o si no, lo que lo otro que puedo hacer es tratar de ser m\u00e1s fiel al significado original y tratar de traducirlo m\u00e1s literalmente, es decir, bueno, el se\u00f1or ser\u00e1 para m\u00ed como un hombre que cuida de animales que tiene el pelo como algod\u00f3n, que es bastante m\u00e1s fiel al original, pero sin embargo, se entiende mucho menos, es como que te van a mirar y decir lo de qu\u00e9 me est\u00e1s hablando. Y bueno, un poco, este es el problema que hay que se enfrentan los traductores humanos todos los d\u00edas, o sea, es muy dif\u00edcil tener las dos cosas, ser fiel al original y sonar natural que suene bien en el lenguaje destino. Una traducci\u00f3n queremos que tenga esas dos propiedades, pero es muy dif\u00edcil lograrlo a la vez, entonces los traductores humanos saben que esto es imposible en la pr\u00e1ctica y lo que hacen es tratar de traducir de manera de encontrar un punto intermedio en el cual, bueno, suene bastante bien, pero adem\u00e1s sea fiel al significado original. Entonces, esto significa que lo que estamos tratando de hacer al traducir es que estamos tratando de maximizar dos cosas a la vez, como dos medidas que queremos maximizar. Una medida es que tan fiel es mi oraci\u00f3n traducida a la oraci\u00f3n original, a esa medida le vamos a llamar adecuaci\u00f3n o fidelidad y en ingl\u00e9s es adecuaci\u00f3n fidelity of faithfulness y la otra medida es que tan natural suena la oraci\u00f3n que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en ingl\u00e9s fluency. Entonces, esta idea de que estoy tratando de maximizar dos medidas a la vez, despu\u00e9s vamos a ver que en realidad lo que vamos a tratar de maximizar es el producto de las dos medidas porque eso significa maximizar ambas al mismo tiempo, es una idea que sirve para poder inferir o para poder construir mecanismos para crear los traductores autom\u00e1ticos y tambi\u00e9n mecanismos para testearlos. Y vamos a ver un poco c\u00f3mo que funciona eso. Yo voy a intentar traducir a partir de ahora el resto de la clase y la clase que viene vamos a hablar siempre de que voy a traducir un lenguaje origen f a un lenguaje destino f es el lenguaje origen y es el lenguaje destino. Eso es nombre surgen porque el paper inicial donde se empez\u00f3 a hablar de esta cosa de los m\u00e9todos estad\u00edsticos traduc\u00eda del franc\u00e9s al ingl\u00e9s, entonces acolo nombre de ah\u00ed dijo bueno franc\u00e9s f el ingl\u00e9s e entonces traducimos del origen al destino. Bueno, yo quiero traducir una frase del idioma f a otra frase del idioma e lo que quiero tratar de encontrar es el mejor etecho que maximice a la vez la de ecuaci\u00f3n y la fluidez, o sea de todos los e posibles del lenguaje destino, quiero encontrar el que maximice la fluidez de es, o sea que suene natural y adem\u00e1s la de ecuaci\u00f3n entre la oraci\u00f3n origen f y s e que estoy buscando. Esta f\u00f3rmula as\u00ed escrita de esa manera de est\u00e1s acordado a algo que hayamos visto ya en el curso en alg\u00fan momento, les suena alg\u00fan lado. Entrop\u00eda, s\u00ed. Valles, s\u00ed, o sea viene por ese lado, se parece al modelo de valles porque esto es otra aplicaci\u00f3n del modelo de canal ruidoso. El modelo de canal ruidoso lo hayamos visto en el curso cuando vimos correcciones de errores, hace ya bastante tiempo y tambi\u00e9n es una aplicaci\u00f3n de lo que es la regla de valles. Entonces, el modelo de canal ruidoso ha aplicado ac\u00e1 funciona de la siguiente manera. Yo tengo una oraci\u00f3n origen en el lenguaje f que es f chica que tiene m palabras y es bueno f sub 1, f sub 2 hasta f sub m y quiero encontrar la mejor oraci\u00f3n en el lenguaje destino e techo que es sub 1 hasta f sub n, hasta f sub n, que maximiza y en realidad lo que quiero maximizar originalmente como todos esperar\u00edamos es decir, bueno, yo quiero encontrar la oraci\u00f3n e que maximiza la probabilidad de edad o f, digamos eso es lo que uno se lo ocurrir\u00eda primero, dir\u00eda bueno, yo quiero estoy traduciendo la oraci\u00f3n f, quiero encontrar la e que me dem\u00e1ximo la probabilidad de edad o f. Bien, pero en realidad yo esto lo puedo descomponer por valles, digamos, y por definici\u00f3n de probabilidad condicional, pues decir que la probabilidad de edad o f es igual a la probabilidad de f de edad o f por la probabilidad de edad o f. Y vamos a esa equivalencia directa por definici\u00f3n de probabilidad condicional y adem\u00e1s como estoy maximizando en e, esta f se mantiene constante, porque lo que voy variando es la e, entonces la etacho, o sea maximizar sobre una constante no hace ning\u00fan cambio, entonces lo que me queda el final es que yo busco un etacho que es el e que hace m\u00e1ximo la probabilidad de f de edad o f por la probabilidad de. Y eso que tenemos escrito ah\u00ed, se parece mucho a la otra ecuaci\u00f3n que ten\u00edamos antes, digamos, se parece mucho a esta ecuaci\u00f3n de f y fluidez de e. Entonces, se conoce como la ecuaci\u00f3n fundamental de la traducion autom\u00e1tica estad\u00edstica, vamos a ver unas cuantas veces en estas dos clases, la vamos a estar refrescando y funcional as\u00ed de manera. Yo quiero encontrar el e techo que es el e que maximiza el producto de estas dos probabilidades. La primera probabilidad pdf de edad o e es la que se encarga de medir que tal la ecuaci\u00f3n, digamos, de la frase, que tal adecuada es la frase f para la frase e. La segunda probabilidad, la pdf es la que se encarga de la fluidez, que tal natural suena esa frase en el lenguaje destino. Y se calculan con modelo distintos. La primera se calcula con lo que se conoce como modelo de traducci\u00f3n y la segunda con lo que se conoce como modelo de lenguaje. De hecho, los modelos del lenguaje ya lo hemos visto en el curso. Vamos a dar un breve repaso de que se trataba. Bueno, \u00bfpor qu\u00e9 esto es una aplicaci\u00f3n de canal ruidoso? Es una aplicaci\u00f3n de canal ruidoso por lo siguiente. Nosotros estamos tratando de traducir del lenguaje f, f, el lenguaje origen, al lenguaje e que es el lenguaje destino. Y lo estamos pensando al rev\u00e9s. Estamos pensando como que alguien emiti\u00f3 los sonidos de la elaboraci\u00f3n e, la elaboraci\u00f3n del lenguaje destino. Eso pas\u00f3 a trav\u00e9s de un canal ruidoso. Y cuando lleg\u00f3 hasta m\u00ed, yo escuch\u00e9 los sonidos de la elaboraci\u00f3n f. Estoy pensando como esa especie de met\u00e1fora. Alguien emiti\u00f3 e pas\u00f3 por un canal ruidoso y llegaron los ruidos de f. Entonces, lo que yo trat\u00f3 de hacer como proceso de traducci\u00f3n es encontrar cu\u00e1l tiene que haber sido esa e original para que yo haya escuchado la f, cu\u00e1l es la e original que me da probabilidad m\u00e1xima de que yo haya escuchado esta f. Y bueno, por eso es una aplicaci\u00f3n de canal ruidoso. Y bueno, la realidad es que en realidad damos vuelta esta probabilidad porque nos da toda otra forma de calcularlo que no podr\u00edamos hacerlos y calculamos la probabilidad directa. Es como que hay mejores herramientas para hacer eso. Bueno, de vuelta, esto es la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica. Y techo es el argumento que hace m\u00e1ximo la probabilidad de fedadoe por la probabilidad de. Y para poder resolver esta ecuaci\u00f3n necesitamos tres cosas. Necesitamos un modelo de lenguaje p.d.e. que es el que se va a encargar de la fluidez. Esto se calcula mediante la t\u00e9cnica de negramas en general. Los negramas son bastante f\u00e1ciles de construir, digamos, porque yo necesito texto en un solo idioma, solo en el idioma destino. p.d.e. es la componente que se encarga de la adecuaci\u00f3n y se resuelve mediante el modelo de traducci\u00f3n. El modelo de traducci\u00f3n no es tan f\u00e1cil de construir como el modelo de lenguaje, porque el modelo de traducci\u00f3n voy a necesitar texto de bil\u00edngue. De hecho, voy a necesitar un corpus para el hilo que sea texto en dos idiomas que adem\u00e1s tengan su correspondencia. Y adem\u00e1s necesito una tercer componente. Esta tercer componente se llama de codificador. Y se trata de lo siguiente. Yo cuando estoy buscando, cuando estoy resolvido esta ecuaci\u00f3n, yo veo la oraci\u00f3n F y quiero buscar la mejor E que maximizes esta ecuaci\u00f3n. Pero en realidad lo que tendr\u00eda que hacer es probar con todas las oraciones E del idioma destino, todas las oraciones posibles que cuantas son las oraciones del idioma destino. Son infinitas oraciones posibles en el idioma destino. Entonces yo estar\u00eda probando con infinitas oraciones hasta que una de ellas me d\u00e9 el m\u00e1ximo. Obviamente esto no es un problema atratable, yo no puedo probar con infinitas oraciones. Lo que necesito es un proceso que me limites a cantidad de b\u00fasqueda de infinitas oraciones a algo atratable. Entonces el codificador va a ser un algoritmo de b\u00fasqueda que va a agarrar la oraci\u00f3n origen y me va a devolver la cien, doscientas, mil oraciones destino, candidatas m\u00e1s probables que alzelo curra para que yo pueda resolver y calcular esa ecuaci\u00f3n para esas oraciones en vez de para todas las posibles. Entonces lo que hace es volver este problema atratable. Vamos a ver tambi\u00e9n una ecuaci\u00f3n de codificaci\u00f3n que se llama Binsarch. Bueno, entonces un poco m\u00e1s sobre modelos del lenguaje. La componente pd de la ecuaci\u00f3n era la que med\u00eda las fluidez y se calculaba mediante un modelo del lenguaje. Los modelos del lenguaje son relativamente f\u00e1ciles de construir porque necesitamos informaci\u00f3n mono-lingue, informaci\u00f3n solamente del lenguaje destino. Entonces en la web tenemos monton, toneladas de informaci\u00f3n, bueno, de muchos idiomas. Entonces como sonetamos informaci\u00f3n idiomas, sacamos texto, web, noticias, blogs, etc\u00e9tera y compilamos un gran corpus del lenguaje destino. Los modelos que se utilizan para traducci\u00f3n autom\u00e1tica en general son modelos basados en enegramas que ya hemos visto en el curso como funcionaban, se suele usar orden de 4 o 5, en otras tareas de pdn suele usar ordenes m\u00e1s chicos, pero para ac\u00e1 da buenos resultados con 4 o 5. Y bueno, el importante es tener una gran cantidad de material de entrenamiento. O sea, los mejores modelos que usan Google Translate y otras empresas usan trisiones de palabras y bueno, son necesitan hardware especial, especialmente dise\u00f1ado para poder ir r\u00e1pido y recuperar la informaci\u00f3n. O si no, bueno, si estoy hablando de un dominio acotado, usar datos de dominio para entrenar que tambi\u00e9n va a ser buenos resultados. \u00bfQu\u00e9 es la de la t\u00e9cnica? Las t\u00e9cnicas de Moodin es cuando hay alguna enegrama que no viste lo que te va a pasar es que la probabilidad es cero. Y ah\u00ed te va a dar todo cero. En realidad, las mejores t\u00e9cnicas es muy significado, darle una buena probabilidad a eso a pesar de que nunca lo yo ha visto. Se dice que las mejores mejoras, digamos, las m\u00e1s grandes mejoras en los modelos en la traducci\u00f3n autom\u00e1tica de los \u00faltimos a\u00f1os se han dado porque hay mejores modelos de lenguaje que me dan traducciones que son m\u00e1s fluidas. Y bueno, usualmente hay como cierta correlaci\u00f3n o cierta inclinaci\u00f3n hacia las fluidas. La gente prefiere cuando las oraciones son zonas m\u00e1s naturales. Ac\u00e1 en ejemplo, esto era sacado un sistema de traducci\u00f3n del chino al ingl\u00e9s, un sistema estad\u00edstico de San Staxis, que cuando no utilizaba modelo de lenguaje ten\u00eda un puntaje de 25x2 al incorporar modelo de lenguaje subi\u00f3 como un 20% su performance y lleg\u00f3 a 31x2 como 6 puntos. Esos puntos corresponden a una medida que vamos a ver dentro de un rato que le llama medida blue, que es una medida muy utilizada en lo que es traducci\u00f3n estad\u00edstica. La traducci\u00f3n autom\u00e1tica en general, pero bueno, ahora solamente saber que 6 puntos es una mejora que es much\u00edsimo. Y como es que mejora esto, mejora haciendo que las traducciones que devuelven en general sean m\u00e1s fluidas, son m\u00e1s naturales en el lenguaje de estino. Y ac\u00e1 hay un ejemplo de traducciones de ese mismo sistema. Yo ten\u00eda una traducci\u00f3n de referencia que era, I don't have enough money with me to buy a new airplane ticket. El sistema sin el modelo de lenguaje devolv\u00eda esta traducci\u00f3n, de decir, I don't have enough bag on me change please go a new by plane. Que no, no se entiende mucho que lo que dice, no es gramatical. Pero al agregar el modelo de traducci\u00f3n, su traducci\u00f3n es la siguiente, I have enough money to buy a new one by air, que suena mucho mejor \u00bfverdad? Que les parece acerca del significado. El significado es el opuesto, digamos, ac\u00e1 est\u00e1 diciendo que tiene suficiente plata para comprar uno por aire y ac\u00e1 dice que no tiene suficiente plata para comprar un pasaje de avi\u00f3n. O sea, este suena much\u00edsimo mejor porque est\u00e1 ni siquiera gramatical, pero esta por lo menos manten\u00eda la negaci\u00f3n, digamos, manten\u00eda que era una oraci\u00f3n negativa. Entonces hay que tener cuidado con esto. La traducci\u00f3n suena mucho mejor, pero a veces podemos estar sacrificando fidelidad, sacrificando adecuaci\u00f3n de la traducci\u00f3n. Bien, eso es sobre modelos de lenguaje. Ahora pasemos a la otra, los modelos de traducci\u00f3n. La componente pdf de la ecuaci\u00f3n mide lo que es la adecuaci\u00f3n o fidelidad de una traducci\u00f3n y la otra y para esto necesito corpos para leylos o corpos bil\u00edng\u00fces que para poder entrenar estos modelos. Los corpos bil\u00edng\u00fces son bastante m\u00e1s dif\u00edciles de construir que los corpos monol\u00edng\u00fces, digamos, no alcanza con hacer una pasada por la web y obtener texto de un idioma. Y bueno, los modelos que vamos a ver son los propuestos por Brown y si equipo en 1993 que trabajan en IBM, ellos construyeron cinco modelos de c\u00f3mo construir cinco modelos, digamos, en creciente complejidad de c\u00f3mo construir un modelo de traducci\u00f3n para traducci\u00f3n estad\u00edstica. Y bueno, los modelos, las diferencias de cada modelo se es en la historia de generaci\u00f3n de las soldaciones candidatas. Y bueno, despu\u00e9s vamos a ver tambi\u00e9n otro modelo un poco m\u00e1s moderno, pero bueno, vamos a empezar viendo m\u00e1s bien los modelos de Brown. Aqu\u00ed me refiero con historia de generaci\u00f3n de las soldaciones candidatas. Una historia de generaci\u00f3n, esto lo digo ahora, pero en realidad lo vamos a profundizar despu\u00e9s. Una historia de generaci\u00f3n en realidad es como una especie de proceso mental que seguir\u00eda un traductor cuando quiere pasar de una oraci\u00f3n a la otra. Entonces, estas historias se basan en decir, bueno, un traductor agarr\u00f3 una oraci\u00f3n en el idioma origen y despu\u00e9s elige la cantidad de palabras que voy a tener el idioma de estino, reordena palabras, despu\u00e9s va traduciendo una a una seg\u00fan un diccionario, despu\u00e9s agrega palabras nuevas que no estaban en la oraci\u00f3n. Ese tipo de cosas, digamos, ese tipo de pasos, me lo voy a escribir en la historia de generaci\u00f3n y para que sirve eso, sirve para que a cada uno de esos pasos yo le pudo dar un valor num\u00e9rico, un valor en cuanto a probabilidades y despu\u00e9s lo que voy a hacer cuando entreno mi sistema es tu\u00f1ar esos valores num\u00e9ricos, tu\u00f1ar todas esas probabilidades para darme el c\u00e1lculo de probabilidad total. Vamos a profundizar m\u00e1s de en esto despu\u00e9s, pero antes de pasar a lo que son las modelos de traducci\u00f3n, vamos a hablar un poco de c\u00f3mo se evaluan estos sistemas. En general, siempre es importante evaluar todo en el PLN, digamos, porque no hay soluciones perfectas, entonces voy a tener sistemas que andan mejor o peor que otros. Y bueno, la traducci\u00f3n autom\u00e1tica obviamente no es la excepci\u00f3n. Entonces, me sirve poder evaluar los sistemas para poder saber qu\u00e9 sistema es mejor que el otro y adem\u00e1s, si yo hago cambios en mi sistema, poder evaluar de vuelta a ver si mejor\u00e9 o no. Entonces, \u00bfqu\u00e9 puedo considerar una buena traducci\u00f3n? Para empezar, eso es una pregunta que es abierto en su, digamos, esa abierta en su respuesta. O sea, yo ten\u00eda en un sistema de traducci\u00f3n ten\u00eda una referencia, un candidato de referencia que era de CatSat on Demat, digamos, esa era una traducci\u00f3n de referencia y un sistema medio seis posibles candidatos para esa traducci\u00f3n. O sea, originalmente hab\u00eda una frase, por ejemplo, en China, la traducci\u00f3n de referencia, la de CatSat on Demat y mi sistema a traducirme el chino medio estas opciones. Tengo de CatSat on Demat Sat de Cat, de Cat on the floor, a CatSat on Demat, de CatSat on Demat, con min\u00fascula o de CatSat on the Stromat. \u00bfCu\u00e1les les parecen que son buenas traducciones de estos candidatos que me dio el sistema? \u00bfCu\u00e1les les gusta m\u00e1s? La E, que es de CatSat on Demat, pero con min\u00fascula me d\u00e9 como yo, \u00bfqu\u00e9 otra? La B, on Demat Sat de Cat, \u00bfqu\u00e9 otra? La D les gusta tambi\u00e9n a CatSat on Demat. \u00bfCapaz que no calienta tanto, dependiendo del uso que le vas a dar esa frase en contexto, capaz que no calienta tanto? Y bueno, s\u00ed, la verdad no se ve nada cuando est\u00e1n las cosas marcadas en rojo, pero bueno, en fin. Crea que ac\u00e1 las cosas marcadas en rojo son las que acaban de decir. Una buena traducci\u00f3n, podemos decir que es una traducci\u00f3n que le gusta la gente, que la gente dice si es una buena traducci\u00f3n. Entonces ac\u00e1 se elige on Demat Sat de Cat, a CatSat on Demat, y de CatSat on Demat en min\u00fascula. Y bueno, como decimos, le preguntamos a la gente a ver que traducciones le gustan, y bueno, ya ah\u00ed ponemos cuales son las mejores traducciones. O si no, le damos a un conjunto de jurados las traducciones y le decimos que hagan un an\u00e1lisis un poco m\u00e1s preciso, y nos digan, bueno, cu\u00e1nto le dan en uno al diez de adecuaci\u00f3n, y cu\u00e1nto le dan en uno al diez de fluidez. Esas otra forma de evaluar, digamos, y ah\u00ed ya nos est\u00e1n dando las dos medidas. En general, los humanos nos cuesta realizar esta evaluaci\u00f3n. En general, tenemos una preferencia de la fluidez, como pasaba hoy con el caso de traducci\u00f3n del chino al ingl\u00e9s, por los pasajes de avi\u00f3n. Adem\u00e1s, la gente no se pone a acuerdo. Adem\u00e1s, hay un problema que es que hacer este tipo de evaluaciones con usuarios humanos, lleva tiempo, digamos, hay que pagarles a los usuarios por hora para que est\u00e9n evaluando sistemas. Y despu\u00e9s, yo le d\u00ed un conjunto de traducciones, ellos me la se evaluaron, hice alg\u00fan cambio en mi sistema para mejorarlo, y devuelta hacerle, de teo que dale conjunto de traducciones a los humanos, y devuelta lo tienen que evaluar, y devuelta, tengo que pagar obras de usuarios humanos para que lo val\u00faen. Entonces, es dif\u00edcil de reutilizar. Yo voy a estar haciendo cambios constantemente en mi sistema, y bueno, y necesito tener una forma m\u00e1s r\u00e1pida de evaluar a ver si estoy haciendo las cosas mejor. Entonces, como este proceso de evaluaci\u00f3n es largo, es engorroso, es caro, lo que se ha vuelto m\u00e1s popular son los m\u00e9todos autom\u00e1ticos de evaluaci\u00f3n. Y, a continuaci\u00f3n, vamos a ver uno, que es muy utilizado en lo que es la traducci\u00f3n autom\u00e1tica. Bueno, \u00bfc\u00f3mo funciona un m\u00e9todo de evaluaci\u00f3n? En realidad, lo que hace alguien, alguien que est\u00e1 dise\u00f1ando un sistema, es crearse un conjunto de oraciones con cada una con una traducci\u00f3n de referencia que est\u00e1 bien, digamos, una traducci\u00f3n hecha mano. Entonces, yo quiero evaluar un sistema que va del espa\u00f1ol al ingl\u00e9s, lo que tengo es un conjunto de oraciones en espa\u00f1ol, y alguien, alg\u00fan traductor humano me tradujo todas esas oraciones en espa\u00f1ol, y medio un candidato, o m\u00e1s candidato est\u00e1 lo es para cada una, digamos, a eso le voy a llamar referencias, traducciones de referencia. Lo siguiente que tengo que hacer es poder dise\u00f1ar una m\u00e9trica de similitud para que, cuando mi sistema me da un candidato de traducci\u00f3n, yo puedo establecer una similitud entre ese candidato y alguna de las referencias. Y bueno, despu\u00e9s lo que voy a hacer es aplicar esa m\u00e9trica para los pares, candidatos y referencias, y bueno, y sacar como un promedio de todos los valores de similitud que tengo. Entonces, se han inmetado muchos m\u00e9todos de este estilo, muchos m\u00e9todos autom\u00e1ticos, que vamos a ver en particular se llama Blue, que es una m\u00e9trica muy difundida en lo que es la traducci\u00f3n autom\u00e1tica estad\u00edstica. Y bueno, primero hay algunas definiciones, le vamos a llamar referencia a una traducci\u00f3n que est\u00e1 traducida manualmente, o sea, consideramos que es una oraci\u00f3n correcta, eso es una referencia, y le vamos a llamar candidato a una traducci\u00f3n que no tiene por qu\u00e9 estar correcta porque la tradujo del sistema autom\u00e1tico. Y le vamos a llamar documento al conjunto de todas las oraciones candidatas, al conjunto de todas las oraciones traducidas por el sistema, que es lo que vamos a estar evaluando. As\u00ed que recuerden, tenemos referencia, candidato y documento. Y bueno, \u00bfqu\u00e9 es lo primero que se nos puede ocurrir hacer cuando queremos saber si un candidato es bueno para la referencia o no? Lo primero que podemos hacer es tratar de contar las palabras que ocurren en ambos. Entonces, yo puedo tratar de contar palabras que ocurren en el candidato y palabras que ocurren en la referencia, y ah\u00ed dir\u00eda que la elecci\u00f3n de las palabras de candidato, si est\u00e1n, la palabra candidato, si est\u00e1n, tambi\u00e9n en la referencia, yo dir\u00eda que eso se acerca un poco a la adecuaci\u00f3n, se acerca que, bueno, por lo menos, us\u00f3 palabras que son fieles a la traducci\u00f3n de referencia. Pero si adem\u00e1s esas palabras est\u00e1n usadas en el mismo orden, ah\u00ed se acerca un poco m\u00e1s a la fluidez, o sea, si est\u00e1n usadas en el mismo orden, puede sonar tan natural como la referencia. Y esto se puede hacer autom\u00e1ticamente haciendo conteos de enegramas. Ac\u00e1 yo tengo una referencia que es de CatSat, mi sistema me ten\u00eda que haber devuelto de CatSat y ten\u00eda dos candidatos, candidato era de Cat y el candidato era SadCatD. Entonces, lo que puedo hacer es conteo de enegramas, cu\u00e1les son enegramas de los candidatos pertenecen a la referencia. Y entonces, para el caso de Cat, el enegrama D pertenece la referencia, el enegrama Cat pertenece a la referencia y el enegrama D Cat, o sea, el Vigra Madecat tambi\u00e9n pertenece a la referencia. Para el caso del candidato B, el unigrama Sad pertenece el unigrama Cat pertenece el unigrama D pertenece. Pero SadCatD este Vigrama no pertenece a la referencia y CatD tampoco pertenece a la referencia. Y adem\u00e1s, el \u00fanico trigrama que hay, SadCatD tampoco est\u00e1 en la referencia. Entonces, lo que aparece a la derecha son los enegramas que s\u00ed pertenecen tanto el candidato como a la referencia. As\u00ed que, bueno, resumiendo, yo puedo contar la cantidad de hits de unigramas, de Vigramas, de trigramas. Y para el candidato B se cumple que todos los unigramas que hay pertenece a la referencia. As\u00ed que, voy a tener dos de dos hits. Para los Vigramas, voy a tener uno de uno. Pero para el candidato B, los unigramas me dan 3 de 3, digamos, 3 hits. Los Vigramas no. O sea, tengo dos Vigramas posibles y ninguno estaba bien. Y los trigramas tampoco. Tengo un trigrama posible y no estaba bien. Entonces, por ahora, parece que le va ganando de Cat, la el candidato B de Cat le va ganando a SadCatD como traducci\u00f3n. Bien, \u00bfqu\u00e9 puedo hacer con los contegos de enegramas? Lo que hago habitualmente, o sea, contar enegramas, para unigramas, vigramas, tiramas, se acerca un poco a lo que es la noci\u00f3n de una precisi\u00f3n de algo. Entonces, lo que voy a hacer es contarlos por separado. Voy a decir, voy a contar todos los unigramas por un lado, todos los Vigramas por otro, todos los trigramas por otro. Y para cada uno de esos, me voy a armar una precisi\u00f3n. Voy a decir que tengo. El candidato se sub\u00ed, digamos, un candidato que voy a considerar. Voy a contar los hits de orden N, se sub\u00ed, digamos, los hits de unigramas, se sub\u00ed. Voy a llamar H, se sub\u00ed. Y voy a contar la cantidad de unigramas totales que hay y le voy a llamar T, se sub\u00ed. Pero adem\u00e1s, voy a hacer esto, en vez de hacerlo para una sola oraci\u00f3n, para un candidato y su referencia, lo voy a hacer para todo el documento. Voy a contar todos los unigramas que estaban en mis candidatos. Voy a ver cu\u00e1nto eso est\u00e1 bien y voy a hacer esta divisi\u00f3n. Entonces, me va a dar cu\u00e1l es la precisi\u00f3n en unigramas. \u00bfQu\u00e9 va a ser? Bueno, tanta cantidad de unigramas estaban bien dividido, toda la cantidad de unigramas que genero en los candidatos. Despu\u00e9s voy a hacer eso para Vigramas. Voy a contar toda la cantidad de Vigramas que estaban bien, porque estaban en el candidato en la referencia, dividido toda la cantidad de Vigramas que en el candidato. Voy a hacer lo mismo para trigramas y voy a hacer lo mismo para 4igramas. En general, se suele llegar hasta 4, digamos, en traducion autom\u00e1tica estad\u00edstica, la medida blu llega a calcular hasta 4. Entonces, bueno, lo que me define ah\u00ed es lo que se llama probabilidad de orden N, la probabilidad, precisi\u00f3n de orden N, la precisi\u00f3n para unigrama, la precisi\u00f3n para Vigramas, la precisi\u00f3n para trigramas, etc. Bien, esta m\u00e9trica que estamos construyendo es bastante f\u00e1cil enga\u00f1ar. En realidad, yo me defin\u00ed una probabilidad, por ejemplo, de la probabilidad de orden 1 y la puedo enga\u00f1ar muy f\u00e1cil, porque yo me puedo construir un candidato que tiene siempre la misma palabra. Puedes ir, bueno, un candidato para la referencia de Catzato Nemat es el candidato DDDDD. Como yo justo le emboque a una palabra que est\u00e1 en la referencia, entonces cuento los unigramas y me da que hay 6 hits de 6, a pesar de que la traducci\u00f3n es horrible. Entonces, como hago para evitar esto, lo que se suele hacer es clipping, lo que significa que cuento cuanto es la cantidad m\u00e1xima de palabras en la referencia y no permite que haya m\u00e1s de eso. Entonces, yo ac\u00e1 tengo hasta dos palabras D, entonces no puedo contar 6 de 6, tendr\u00eda que contar m\u00e1ximo 126. Entonces ah\u00ed evitamos ese problema de que, bueno, alguien se haga el vivo y genera simplemente una sola palabra. Bien, entonces, hasta ahora vimos dos cosas, calculamos la precisi\u00f3n de orden N, la precisi\u00f3n de cada uno de los unigramas o diagramas, los segundos que vimos es que vamos a hacer clipping para evitar pasarnos de conteo en las palabras que aparecen m\u00e1s de una vez. Lo tercero que pasa es ve\u00edamos en este ejemplo de ac\u00e1, ac\u00e1 tenemos dos candidatos de Catz y Sad CatzD, y lo que pasaba ac\u00e1 era que le estaba haciendo mejor a la traducci\u00f3n de Catz porque ten\u00eda todos los unigramas que est\u00e1n en la traducci\u00f3n, est\u00e1n tambi\u00e9n en la referencia y todos los diagramas tambi\u00e9n, en cambio el candidato V no, el candidato V tiene unigramas que est\u00e1n, pero diagramas y trilamas que no est\u00e1n. Entonces en cuanto a precisi\u00f3n el candidato V va bastante mejor. \u00bfPor qu\u00e9 va bastante mejor el candidato V? Porque es un candidato que es m\u00e1s corto que la referencia, o sea, es un candidato que tiene menos palabras. Como venimos definiendo la m\u00e9trica, si yo tengo una referencia y despu\u00e9s tengo un candidato que es justo un prefijo de la referencia, entonces va a cumplir que ese prefijo andaba bien en todas las medidas de precisi\u00f3n, porque todos los enigramas que tiene van a pertenecer a la referencia. As\u00ed que lo que hace la medida blue es penalizar ese tipo de comportamientos. Penaliza los candidatos que son muy cortos para que digamos le de menos puntaje. Entonces, \u00bfpor qu\u00e9 se penaliza los candidatos cortos y no los candidatos largos? \u00bfPor qu\u00e9 les parece? Candidatos que son demasiado cortos se penalizan, pero les hemos dado largos, \u00bfno? La respuesta est\u00e1 en las slides, pero bueno, se que se penaliza los candidatos cortos porque los candidatos largos, si yo genero un candidato que es mucho m\u00e1s largo que la referencia, lo que va a pasar es que ese candidato tiene enigramas, seguramente tiene enigramas que no pertenece de la referencia. Entonces, en el contenido de precisi\u00f3n me va a dar un puntaje m\u00e1s bajo. Candidatos largos ya est\u00e1n penalizados por la precisi\u00f3n, candidatos cortos no est\u00e1n penalizados por la precisi\u00f3n. Entonces, necesito otro tipo de penalizaci\u00f3n para evitar eso. Bien, entonces lo que vamos a dar es una cosa de llama penalizaci\u00f3n propiedad o brevitipenal, que es un puntaje que se le da en referencia que tan corto es un candidato respecto a la referencia y bueno, se calcula teniendo en cuenta todo el largo del documento, todo el largo del documento traducido, entonces ac\u00e1 yo defino que el reprima es el largo total de todas las referencias, se prima es el largo total de todos los candidatos. Y entonces, si el largo de los candidatos es mayor a largo de las referencias no hay penalizaci\u00f3n, le pongo uno, si el largo total de los candidatos es menor a largo de las referencias, entonces lo calculo como e a la menos, e a la uno menos la divisi\u00f3n entre los largos. Esto es una definici\u00f3n de probabilidad exponencial, digamos, no es m\u00e1s que eso. Y en realidad lo que trata de hacer es penalizar traducciones que son muy cortas, entonces si yo ten\u00eda un candidato que ten\u00eda cinco palabras mientras la referencia ten\u00eda diez, lo voy a penalizar fuertemente, le voy a dar un 0.37 de penalizaci\u00f3n, si yo ten\u00eda un candidato que estaba que era menor pero era m\u00e1s cercano, entonces la penalizaci\u00f3n no es tanta de 0.78 y despu\u00e9s si los largos son iguales o si el candidato es m\u00e1s largo, no penaliz\u00f3 nada, le doy uno de puntas. Bueno, entonces la metrica blue, que es una metrica muy usada en traducci\u00f3n autom\u00e1tica, pone todo esto juntos, digamos, todos estos pedacitos que estuvimos viendo, los pone juntos en un solo c\u00e1lculo. Blue se calcula como la penalizaci\u00f3n por probabilidad, el breve penal D, por E a la suma de las precisiones de orden N. \u00bfQu\u00e9 palabras ruido? Por ejemplo, esto es un unigrama que le va a dar 0 de precisi\u00f3n, digamos, por ejemplo, bueno, esta palabra no va, o sea, es un unigrama que le va a dar 0 de precisi\u00f3n, digamos, porque no est\u00e1, adem\u00e1s participan un diagrama que tambi\u00e9n le va a dar mala precisi\u00f3n porque tampoco est\u00e1 el diagrama, entonces lo que, reestan realidad porque no est\u00e1 sumando la impresi\u00f3n, ac\u00e1 yo tengo 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 es tambi\u00e9n, pero hay uno que no, en cambio, en este tengo 6 unigrama de los cuales los 6 es tambi\u00e9n, entonces ac\u00e1 el hecho de agregar palabras que no son, que no est\u00e1n bien, no est\u00e1n en la referencia, ya te penaliza. La diferencia es cuando yo tengo una traducci\u00f3n que m\u00e1s corta, si yo dir\u00eda, solo de CatSatOn, entonces ah\u00ed es m\u00e1s corta y no tengo forma de penalizarlo solo con la precisi\u00f3n, entonces tengo el otro penalizador que es porque la traducci\u00f3n es muy corta. Bien, entonces les estaba comentando, la media blusa define como una media geometrica, definici\u00f3n de media geometrica, de las precisiones de orden N, tambi\u00e9n tienes un peso por precisi\u00f3n que se puede variar, pero en general se utiliza el mismo peso para todos, multiplicado por la penalizaci\u00f3n pobrevedad. Bien, eso es la definici\u00f3n de la media blusa, que es una media que se utiliza much\u00edsimo, esos puntajes que vemos hoy de 25 con 2 y 31 con algo eran ejemplos de media blusa aplicados en un sistema. Y bueno, una cosa importante, algunos comentarios importantes sobre la metrica blusa es que en general cuando un sistema le da mejor, digamos, con un conjunto de traducciones, le da mejor en metrica blusa, tambi\u00e9n le da mejor con un conjunto de humanos que evaluan el sistema, o sea que tiene una correlaci\u00f3n bastante buena con lo que es la evaluaci\u00f3n subjetiva humana, pero como contra es dif\u00edcil de interpretar estos puntajes, o sea, si yo tengo un puntaje de, como nos ha pasado hoy, tiene un puntaje de 31, en realidad un 31 es un n\u00famero que puede ser muy bueno, muy malo, dependiendo del idioma, pero o sea, si todo saliera bien y yo tradujera exactamente lo mismo que est\u00e1n las referencias, por construcci\u00f3n la media me dar\u00eda uno, pero en realidad es muy dif\u00edcil traducir exactamente lo que est\u00e1n las referencias, porque no es cierto que exista una \u00fanica traducci\u00f3n posible en la traducci\u00f3n digamos humana. Horaciones se pueden traducir de manera distinta y estar igualmente bien, entonces es muy dif\u00edcil tener un conjunto de referencias que contempla todas las posibilidades, as\u00ed que en mi traducutor capaz que anda b\u00e1rbaro, pero el puntaje a\u00fan no es uno, no es 100 digamos, porque est\u00e1 eligiendo palabras distintas o eligiendo formas de escribir las oraciones distintas, entonces bueno, por eso es dif\u00edcil interpretar, yo tengo un puntaje de 30 o de 50 o sea, de 0.3 o de 0.5 y puede ser buen\u00edsimo para ese sistema, pero para algo que s\u00ed me sirve much\u00edsimo el puntaje, digamos, el puntaje de blu es para decir, yo tengo mi sistema, luego el lujo, despu\u00e9s hago algunos cambios, el lujo de vuelta y si subi\u00f3 la performance de un puntaje blu, entonces estoy seguro de que mejoro, porque hay una correlaci\u00f3n con la evaluaci\u00f3n subjetiva. Para pasar el espa\u00f1ol ingl\u00e9s, en realidad lo que pasa es que entren\u00e1s otro traducutor. No, ac\u00e1 estoy volando solo, ac\u00e1 estoy volando solamente en un sentido, yo ten\u00eda un sistema espa\u00f1ol, por ejemplo, digo una oraci\u00f3n espa\u00f1ol, el gato se sent\u00f3, y alguien me dijo bueno, la traducci\u00f3n de referencia a eso es de CatSat y mi sistema me dijo bueno, pero mis traducciones posibles son de Cat y Sad Cat D, entonces yo ten\u00eda un sistema en espa\u00f1ol pero que traduce al ingl\u00e9s, digamos, un sistema de traducci\u00f3n de espa\u00f1ol de ingl\u00e9s, pero no, no estoy traduciendo en el otro sentido, no, no es como las canciones, ac\u00e1 part\u00ed del espa\u00f1ol y llegu\u00e9 al ingl\u00e9s y estoy tratando de evaluar comparando las frases en ingl\u00e9s esperadas con las frases en ingl\u00e9s generadas, claro, probablemente, claro, est\u00e1 en el mismo idioma, o sea, lo que no mostramos ac\u00e1 era cual era la oraci\u00f3n origen, porque para evaluar no nos importa, para evaluar nos importa que comparar solamente la oraci\u00f3n candidato con la referencia y la origen nos olvidamos, sabemos que los dos intentaron traducir de la misma oraci\u00f3n y bueno, y alguno le fue mejor que a otro, bien, esos son comentarios de blue, esto era evaluaci\u00f3n de los sistemas, lo siguiente que vamos a ver es el problema de los corpos paralelos, antes de pasar a lo que son modelos de traducci\u00f3n, vamos a hablar un poco de lo que son los corpos paralelos, que son necesarios para construir un modelo de traducci\u00f3n, un corpos paralelo consiste en pares de textos en dos idiomas, por ejemplo, tener textos en espa\u00f1ol y en ingl\u00e9s, pero adem\u00e1s yo tengo que tener alg\u00fan nivel, tengo que tener una correspondencia entre esos textos, de alguna forma, yo tengo que saber c\u00f3mo se corresponde un texto con el otro, entonces bueno, tiene que estar con juntos, digamos, ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen en el mundo, existen corpos paralelos para algunos idiomas, o sea, hay muchos idiomas en el mundo, pero no todos los pares de idiomas tienen corpos paralelos construidos, entonces existen para el lado de ingl\u00e9s, el chino ingl\u00e9s, para la mayor\u00eda de los lenguajes europeos, debido a su uso en la uni\u00f3n europea, digamos, existen tambi\u00e9n corpos paralelos para ellos, pero para la gran mayor\u00eda de pares de lenguas, no hay, digamos, no tengo un par que traduzca entre el chino y el guaranismo, por ejemplo, o sea, es poco probable que se construye un par de estilos, bien, que es un corpos paralelos, ya que no se ve nada, de vuelta, ac\u00e1 hay un ejemplo que no s\u00e9 si lo conocen, es un ejemplo famoso de corpos paralelos, tiene ni idea de lo que es, lo han visto alguna vez, la piedra de roseta, la piedra de roseta, una piedra que la construyeron, o por lo menos la tallaron el a\u00f1o 1996, antes de Cristo, y hablaba sobre la coronaci\u00f3n de Tolomeo Quinto, y tal, y su adoraci\u00f3n como semi-dios, etc\u00e9tera, etc\u00e9tera, y bueno, hasta estuvo perdida, tomo un mont\u00f3n de a\u00f1os, hasta que durante las campa\u00f1as Napole\u00f3nicas, 1799, la encontraron en Egipto, en el lugar roseta, casualmente, y se lanzaron para Francia, ah\u00ed le empezaron a analizar ling\u00fcistas, empezaron a tratar de entender que era lo que dec\u00eda, y bueno, descubrieron que tiene tres textos, vieron que tienen como tres regiones, tres textos, y despu\u00e9s de estudiarla un rato, seguiron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas distintos, y los idiomas eran, el de arriba era en jerogl\u00edficos egipcios del estilo de lo que uno encuentra dentro de las pir\u00e1mides, el del medio era egipcio dem\u00f3tico, que era el egipcio vulgar que se usaba, digamos, en el d\u00eda a d\u00eda, y el de abajo el todo era griego antiguo. Entonces, si bien, ninguno de los tres idiomas se hablaba en el momento que se encontr\u00f3, la piedra, los tres idiomas antiguos, el griego antiguo por lo menos s\u00ed se sab\u00eda, digamos, se conoc\u00eda como idiomas, se sab\u00eda qu\u00e9 significaba, y digamos, hab\u00eda gente que lo estudiaba, los otros dos no, los otros dos eran lenguas completamente perdidas, que nadie sab\u00eda identificarlas. Pero gracias al hecho de que en realidad se descubri\u00f3 que los tres textos hablan de lo mismo, son el mismo texto entre los idiomas. Entonces ah\u00ed se empez\u00f3 a hacer un trabajo de alineaci\u00f3n, digamos, los arque\u00f3logos, empezaron a decir, bueno, esta porci\u00f3n de texto ac\u00e1 se corresponde con esta de ac\u00e1, se corresponde con esta de ac\u00e1, etc\u00e9tera, y a tratar de encontrar correspondencias en los idiomas, y c\u00f3mo sab\u00edan qu\u00e9 quer\u00eda decir en griego antiguo, empezaron a poder descubrir qu\u00e9 quer\u00edan decir en los otros idiomas. Entonces, a ra\u00edz de eso es que empez\u00f3, digamos, el Egipto Elog\u00eda Moderno se pudo empezar a desifrar, qu\u00e9 dicen, por ejemplo, los geogr\u00e1ficos est\u00e1n en las pir\u00e1mides, y bueno, un mont\u00f3n de cultura, egipcio antiguas, se conoce gracias a que se pudo desifrar lo que dec\u00eda esta piedra. Y en definitiva, esto es un ejemplo de corpus paralelo, o sea, tengo el mismo texto entre los idiomas, y con un poco de esfuerzo logro al alinear, cual son cada uno de los elementos de mis lenguajes, y logro saber la traducci\u00f3n de los tres. Bueno, entonces, esto nos lleva el concepto de alineaci\u00f3n. Los corpus paralelos tienen distintos niveles de alineaci\u00f3n. Lo m\u00e1s f\u00e1cil de encontrar son corpus que est\u00e1n alineados al nivel de documentos. Yo tengo una colecci\u00f3n de documentos en espa\u00f1ol y una colecci\u00f3n de documentos en chino, y yo s\u00e9 qu\u00e9 documentos se corresponde con qu\u00e9 otro, pero no s\u00e9 nada m\u00e1s. Ser\u00eda mejor, incluso que estuvieran alineados a nivel de elaboraci\u00f3n, adem\u00e1s de conocer los documentos, yo s\u00e9 cu\u00e1l elaboraci\u00f3n espa\u00f1ol va con cu\u00e1l elaboraci\u00f3n en chino, digamos. Tengo una correspondencia entre esas dos. Pero ser\u00eda a\u00fan mejor, y esto es lo que m\u00e1s nos servir\u00eda, si estuvieran alineados a nivel de palabra. Cada uno de los caracteres que est\u00e1n en chino se corresponde con qu\u00e9 palabra en espa\u00f1ol, lo que grupo de palabra, si cada uno de las palabras de espa\u00f1ol con qu\u00e9 grupo de caracteres se corresponde en chino. Esto es el ideal, pero claro, o sea, si ya es dif\u00edcil conseguir cosas que est\u00e9n alineadas a nivel de documentos, si imaginan que nadie va a ir a mano al linear a nivel de palabra cada uno de las palabras de los idiomas. Entonces, en la pr\u00e1ctica nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que, como resultado de la construcci\u00f3n de los modelos de lenguaje, se produce tambi\u00e9n como un producto secundario, se produce la alineaci\u00f3n de los corpus. Entonces, obtenes las dos cosas a la vez. Bueno, yo otra cosa es que, a diferencia de el texto monol\u00edngue que yo usaba para los modelos de lenguaje, es muy raro que naturalmente se produzcan textos en dos idiomas a la vez. O sea, hay que buscarlos bastante, digamos, bastante cuidadosamente. Existen algunos contextos en donde eso se produce. Por ejemplo, en algunos portales de noticias, puede pasar que tengan versiones en distintos idiomas y lo que hagan sea traducir las noticias en distintos idiomas. Entonces, si yo puedo encontrar uno de esos, es una buena fuente para construirme un corpus paralelo anineado a nivel de documentos. O sea, esta noticia se corresponde con esta otra en el otro idioma. Pero un lugar en donde se producen naturalmente este tipo de textos es en los pa\u00edses que son bil\u00edng\u00fces, o multil\u00edng\u00fces. Por ejemplo, en Canad\u00e1, que hablan ingl\u00e9s y franc\u00e9s, las discusiones del Parlamento Canad\u00edense siempre, por ley, tienen que transcribirse en los dos idiomas, tienen que traducirse si est\u00e1 en ingl\u00e9s, se daus en franc\u00e9s, se daus en ingl\u00e9s. Y guardan una correspondencia entre eso. Guardan el documento de todas las discusiones del Parlamento en los dos idiomas. Entonces, ah\u00ed, naturalmente se produce un corpus paralelo anineado de documentos para el ingl\u00e9s y el franc\u00e9s, que se se conoce como el corpus Hansard. Eso tambi\u00e9n ocurre en concon, en conconciable ingl\u00e9s y chinos, son los dos idiomas oficiales. Entonces, el corpus m\u00e1s grande que se tiene para ingl\u00e9s y chinos, est\u00e1 hecho como una compilaci\u00f3n de lo que son las discusiones del Parlamento de Hong Kong. Y tambi\u00e9n pasa en la N\u00faneo Europea, en el Parlamento Europeo, tambi\u00e9n tienen la costumbre de traducir todas las discusiones a todos los idiomas o a muchos de los idiomas que se usan en la Uni\u00f3n Europea. Entonces, hay corpus paralelo para casi todos los idiomas de la Uni\u00f3n Europea. Pero claro, todos estos est\u00e1n alineados a nivel de documento. Yo s\u00e9 qu\u00e9 documento se corresponde con cual otro en el otro idioma, pero no anivel de oraciones y mucho menos anivel de palabras. Pero bueno, partiendo de un corpus alineado a nivel de documentos, yo puedo llegar a construir me, por lo menos, una alineaci\u00f3n a nivel de oraciones, siendo un proceso relativamente sencillo. Esto se conoce como el algoritmo de que \u00e9l y Church, que es un algoritmo relativamente f\u00e1cil para alinear corpus, o sea, para pasar corpus que est\u00e1n alineados a nivel de documento, pasarlos a que est\u00e9n alineados a nivel de oraci\u00f3n. Y bueno, esto es un algoritmo que funciona, est\u00e1 un poco basado en lo que era el algoritmo de distancia de edici\u00f3n del EventTime, que vimos hace bastante tiempo en el curso. Bueno, es como muy parecido, tambi\u00e9n es un algoritmo de pronomaci\u00f3n din\u00e1mica, similar a ese. Funciona de la siguiente manera, o sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de c\u00f3mo que funcione. En el algoritmo de Gayley Church dice, yo voy a tener un conjunto de oraciones en un idioma y otro conjunto de oraciones en el otro idioma. Entonces, considero que un traductor para cada oraci\u00f3n pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma. Un traductor, suponga un traductor humano, agarr\u00f3 oraciones que estaban en espa\u00f1ol y oraciones que estaban en franc\u00e9s. O sea, no ponerles EIF porque lo que puede confundir con las otras cosas, as\u00ed que vamos a decir el lenguaje de origen era F, franc\u00e9s y el lenguaje de estino era espa\u00f1ol. Bien, entonces, un traductor humano cada vez que se enfrentaba una oraci\u00f3n ten\u00eda tres posibilidades. O bien, traduc\u00eda una oraci\u00f3n por otra oraci\u00f3n, o bien parte de esta oraci\u00f3n en dos y traduce una oraci\u00f3n por dos, o bien borra esta oraci\u00f3n, decide que no es tan importante y abarra y borra la oraci\u00f3n. Entonces, las tres operaciones que se hacen a nivel de oraci\u00f3n son la de transformarla en cero, una o dos oraciones del otro lado. Eso es una cosa. Lo otro es, el costo relativo de alinear estas dos oraciones depende del largo relativo de las oraciones. Entonces, si yo tengo dos oraciones que tienen un largo muy parecido, le voy a dar un costo menor para alinearlos, era menor o mayor. S\u00ed, menor. Si tiene un largo muy parecido, le voy a dar un valor menor para alinear. Si tiene un largo muy distinto, una es muy corta y la otra muy larga, entonces le voy a dar un valor mayor para alinear. Entonces, lo que ellos hacen es pensando en todo este tipo de operaciones que hay, todas las combinaciones de operaciones posibles, o sea, partir esta oraci\u00f3n en dos o no partirla o eliminarla o dejarla como est\u00e1. Entonces, con programaci\u00f3n din\u00e1mica, ven todas las posibilidades de operar distinto para llegar al otro lado y calculan las que le da un costo menor. O sea, para cada una de las posibilidades calculan cu\u00e1l es el costo de cada par de oraciones suman todos los costos del documento. Y se quedan con el caso que les d\u00e9 un costo menor en alineaci\u00f3n. Eso se puede hacer eficientemente, usando programaci\u00f3n din\u00e1mica lo mismo que hac\u00edamos con la distancia de edici\u00f3n de Leberstein. Bueno, y este algoritmo que es relativamente sencillo, digamos, es una soluci\u00f3n bastante simple, logra una tasa de error muy buena, que es de un 4%, digamos, que, sobre todo, parede m\u00e1s relacionado, parede m\u00e1s que se parecen como el ingl\u00e9s y el espa\u00f1ol, etc\u00e9tera, logra una tasa bastante baja de error de un 4%, hay algunas mejoras que se pueden hacer, pero en realidad hay un 4% de algo que est\u00e1 bastante bien. Hay un catch que es que para sistemas de traducci\u00f3n distintos, traducciones no literales, esto se rompe un poco, por ejemplo, para traducir entre ingl\u00e9s y chino, que en chino ni siquiera est\u00e1 claro que les son los l\u00edmites de las palabras, eso es m\u00e1s dif\u00edcil de ver. Entonces, bueno, este tipo de algoritmos no funcionan tambi\u00e9n, y bueno, hay variantes que funcionan un poco mejor. As\u00ed que bueno, hoy vamos a dejar por ac\u00e1 y vamos a continuar en la pr\u00f3xima con modelos de traducci\u00f3n.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 20.76, "text": " La clase de hoy y la clase que viene, vamos a dar el tema de traducci\u00f3n autom\u00e1tica.", "tokens": [50364, 2369, 44578, 368, 13775, 288, 635, 44578, 631, 19561, 11, 5295, 257, 4072, 806, 15854, 368, 2479, 1311, 5687, 3553, 23432, 13, 51402], "temperature": 0.0, "avg_logprob": -0.3387978993929349, "compression_ratio": 1.0240963855421688, "no_speech_prob": 0.08455567806959152}, {"id": 1, "seek": 2076, "start": 20.76, "end": 28.880000000000003, "text": " Y bueno, vamos a arrancar. Por esto que se conoce como la nota de Weber,", "tokens": [50364, 398, 11974, 11, 5295, 257, 50235, 6166, 13, 5269, 7433, 631, 369, 33029, 384, 2617, 635, 36192, 368, 42690, 11, 50770], "temperature": 0.0, "avg_logprob": -0.3389318400415881, "compression_ratio": 1.5772058823529411, "no_speech_prob": 0.521994948387146}, {"id": 2, "seek": 2076, "start": 28.880000000000003, "end": 34.480000000000004, "text": " o el memorando de Weber, Warren Weber era un matem\u00e1tico norteamericano de primera", "tokens": [50770, 277, 806, 10560, 1806, 368, 42690, 11, 20538, 42690, 4249, 517, 3803, 443, 28234, 41966, 13530, 38028, 368, 17382, 51050], "temperature": 0.0, "avg_logprob": -0.3389318400415881, "compression_ratio": 1.5772058823529411, "no_speech_prob": 0.521994948387146}, {"id": 3, "seek": 2076, "start": 34.480000000000004, "end": 38.56, "text": " mitad de siglo XX. Y el tipo trabaj\u00f3 durante la guerra, especialmente en cosas de", "tokens": [51050, 46895, 368, 48578, 27050, 13, 398, 806, 9746, 9618, 812, 14427, 635, 27542, 11, 41546, 465, 12218, 368, 51254], "temperature": 0.0, "avg_logprob": -0.3389318400415881, "compression_ratio": 1.5772058823529411, "no_speech_prob": 0.521994948387146}, {"id": 4, "seek": 2076, "start": 38.56, "end": 42.760000000000005, "text": " criptograf\u00eda, en an\u00e1lisis estad\u00edstico, de c\u00f3digos, etc\u00e9tera. Entonces en un momento", "tokens": [51254, 12815, 662, 19815, 2686, 11, 465, 44113, 28436, 39160, 19512, 2789, 11, 368, 40210, 13348, 11, 5183, 526, 23833, 13, 15097, 465, 517, 9333, 51464], "temperature": 0.0, "avg_logprob": -0.3389318400415881, "compression_ratio": 1.5772058823529411, "no_speech_prob": 0.521994948387146}, {"id": 5, "seek": 2076, "start": 42.760000000000005, "end": 47.92, "text": " dijo lo siguiente, dijo, es muy tentador decir que un libro escrito en chino, es simplemente un libro", "tokens": [51464, 27024, 450, 25666, 11, 27024, 11, 785, 5323, 7054, 5409, 10235, 631, 517, 29354, 49451, 465, 417, 2982, 11, 785, 33190, 517, 29354, 51722], "temperature": 0.0, "avg_logprob": -0.3389318400415881, "compression_ratio": 1.5772058823529411, "no_speech_prob": 0.521994948387146}, {"id": 6, "seek": 4792, "start": 47.92, "end": 52.56, "text": " escrito en ingl\u00e9s que ha sido codificado en el c\u00f3digo chino. Si tenemos m\u00e9todos \u00fatiles para", "tokens": [50364, 49451, 465, 49766, 631, 324, 14444, 17656, 1089, 1573, 465, 806, 44195, 417, 2982, 13, 4909, 9914, 20275, 378, 329, 6991, 83, 4680, 1690, 50596], "temperature": 0.0, "avg_logprob": -0.16023049318700805, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.006082701962441206}, {"id": 7, "seek": 4792, "start": 52.56, "end": 56.28, "text": " resolver casi cualquier problema criptogr\u00e1fico, no ser\u00e1 que con la interpretaci\u00f3n apropiada,", "tokens": [50596, 34480, 22567, 21004, 12395, 12815, 662, 47810, 23858, 78, 11, 572, 16502, 631, 416, 635, 7302, 3482, 1882, 1513, 39018, 11, 50782], "temperature": 0.0, "avg_logprob": -0.16023049318700805, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.006082701962441206}, {"id": 8, "seek": 4792, "start": 56.28, "end": 63.68, "text": " ya tendr\u00edamos m\u00e9todos \u00fatiles para la traducci\u00f3n. El opinado, digamos, en este memor\u00e1ndum,", "tokens": [50782, 2478, 3928, 81, 16275, 20275, 378, 329, 6991, 83, 4680, 1690, 635, 2479, 1311, 5687, 13, 2699, 3980, 1573, 11, 36430, 11, 465, 4065, 10560, 18606, 449, 11, 51152], "temperature": 0.0, "avg_logprob": -0.16023049318700805, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.006082701962441206}, {"id": 9, "seek": 4792, "start": 63.68, "end": 70.32000000000001, "text": " que los m\u00e9todos que se utilizan para romper c\u00f3digo criptogr\u00e1fico, que son m\u00e9todos estad\u00edsticos,", "tokens": [51152, 631, 1750, 20275, 378, 329, 631, 369, 19906, 282, 1690, 7438, 610, 44195, 12815, 662, 47810, 23858, 78, 11, 631, 1872, 20275, 378, 329, 39160, 19512, 9940, 11, 51484], "temperature": 0.0, "avg_logprob": -0.16023049318700805, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.006082701962441206}, {"id": 10, "seek": 4792, "start": 70.32000000000001, "end": 74.96000000000001, "text": " se pod\u00edan aplicar al problema de la traducci\u00f3n autom\u00e1tica. Y bueno, esto introduce", "tokens": [51484, 369, 2497, 11084, 18221, 289, 419, 12395, 368, 635, 2479, 1311, 5687, 3553, 23432, 13, 398, 11974, 11, 7433, 5366, 51716], "temperature": 0.0, "avg_logprob": -0.16023049318700805, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.006082701962441206}, {"id": 11, "seek": 7496, "start": 74.96, "end": 79.52, "text": " algunas ideas clave como que puede existir un mapeo autom\u00e1tico entre un lenguaje y otro,", "tokens": [50364, 27316, 3487, 596, 946, 2617, 631, 8919, 2514, 347, 517, 463, 494, 78, 3553, 28234, 3962, 517, 35044, 84, 11153, 288, 11921, 11, 50592], "temperature": 0.0, "avg_logprob": -0.2621336331332687, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.03551602363586426}, {"id": 12, "seek": 7496, "start": 79.52, "end": 85.44, "text": " y que codificar, de codificar en un lenguaje de san\u00e1logo, a codificar, de codificar en", "tokens": [50592, 288, 631, 17656, 25625, 11, 368, 17656, 25625, 465, 517, 35044, 84, 11153, 368, 6645, 842, 38212, 11, 257, 17656, 25625, 11, 368, 17656, 25625, 465, 50888], "temperature": 0.0, "avg_logprob": -0.2621336331332687, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.03551602363586426}, {"id": 13, "seek": 7496, "start": 85.44, "end": 93.39999999999999, "text": " una ecorismo criptogr\u00e1fico. Y bueno, el tiro, esa idea es 1949, tom\u00f3 como 50 a\u00f1os para que", "tokens": [50888, 2002, 11437, 284, 6882, 12815, 662, 47810, 23858, 78, 13, 398, 11974, 11, 806, 44188, 11, 11342, 1558, 785, 46476, 11, 2916, 812, 2617, 2625, 11424, 1690, 631, 51286], "temperature": 0.0, "avg_logprob": -0.2621336331332687, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.03551602363586426}, {"id": 14, "seek": 7496, "start": 93.39999999999999, "end": 99.67999999999999, "text": " esa idea madurar, digamos, y despu\u00e9s de 50 a\u00f1os los m\u00e9todos m\u00e1s utilizados, hoy en d\u00eda son", "tokens": [51286, 11342, 1558, 5244, 28586, 11, 36430, 11, 288, 15283, 368, 2625, 11424, 1750, 20275, 378, 329, 3573, 19906, 4181, 11, 13775, 465, 12271, 1872, 51600], "temperature": 0.0, "avg_logprob": -0.2621336331332687, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.03551602363586426}, {"id": 15, "seek": 7496, "start": 99.67999999999999, "end": 104.8, "text": " m\u00e9todos estad\u00edsticos que se basan un poco en estos principios. Pero claro, en esa \u00e9poca era", "tokens": [51600, 20275, 378, 329, 39160, 19512, 9940, 631, 369, 987, 282, 517, 10639, 465, 12585, 6959, 2717, 13, 9377, 16742, 11, 465, 11342, 25024, 4249, 51856], "temperature": 0.0, "avg_logprob": -0.2621336331332687, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.03551602363586426}, {"id": 16, "seek": 10480, "start": 104.8, "end": 111.36, "text": " como muy dif\u00edcil lugar que era lo que iba a ocurrir. Entonces, bueno, vamos a ver un poco esta", "tokens": [50364, 2617, 5323, 17258, 11467, 631, 4249, 450, 631, 33423, 257, 26430, 10949, 13, 15097, 11, 11974, 11, 5295, 257, 1306, 517, 10639, 5283, 50692], "temperature": 0.0, "avg_logprob": -0.2259102459101714, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0011987340403720737}, {"id": 17, "seek": 10480, "start": 111.36, "end": 115.52, "text": " la agenda de lo que vamos a mirar. Vamos a llegarnos a menos hasta la mitad hoy y despu\u00e9s la clase", "tokens": [50692, 635, 9829, 368, 450, 631, 5295, 257, 3149, 289, 13, 10894, 257, 11234, 24979, 257, 8902, 10764, 635, 46895, 13775, 288, 15283, 635, 44578, 50900], "temperature": 0.0, "avg_logprob": -0.2259102459101714, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0011987340403720737}, {"id": 18, "seek": 10480, "start": 115.52, "end": 121.12, "text": " siguiente. Y empecemos con un poco de historia de lo que es la traducci\u00f3n autom\u00e1tica. Esto empez\u00f3", "tokens": [50900, 25666, 13, 398, 846, 494, 38173, 416, 517, 10639, 368, 18385, 368, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 13, 20880, 18730, 812, 51180], "temperature": 0.0, "avg_logprob": -0.2259102459101714, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0011987340403720737}, {"id": 19, "seek": 10480, "start": 121.12, "end": 126.12, "text": " como muchas otras tecnolog\u00edas, como una tecnolog\u00eda militar, con fines militares. Inicialmente era", "tokens": [51180, 2617, 16072, 20244, 20105, 1132, 10025, 11, 2617, 2002, 48055, 30653, 11, 416, 37989, 1962, 2786, 495, 13, 682, 14730, 4082, 4249, 51430], "temperature": 0.0, "avg_logprob": -0.2259102459101714, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0011987340403720737}, {"id": 20, "seek": 10480, "start": 126.12, "end": 132.2, "text": " durante la Guerra Fr\u00eda, era resultado de inter\u00e9s traducir r\u00e1pidamente y abajo costa traducir", "tokens": [51430, 14427, 635, 45725, 1526, 2686, 11, 4249, 28047, 368, 728, 2191, 2479, 1311, 347, 18213, 49663, 288, 30613, 2063, 64, 2479, 1311, 347, 51734], "temperature": 0.0, "avg_logprob": -0.2259102459101714, "compression_ratio": 1.6849315068493151, "no_speech_prob": 0.0011987340403720737}, {"id": 21, "seek": 13220, "start": 132.2, "end": 136.83999999999997, "text": " entre el ruso y el ingl\u00e9s, digamos, los norteamericanos les conven\u00eda poder traducir entre el", "tokens": [50364, 3962, 806, 367, 24431, 288, 806, 49766, 11, 36430, 11, 1750, 41966, 13530, 8914, 329, 1512, 7158, 2686, 8152, 2479, 1311, 347, 3962, 806, 50596], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 22, "seek": 13220, "start": 136.83999999999997, "end": 141.16, "text": " ingl\u00e9s y el ruso. Y bueno, en aquella \u00e9poca se imaginan lo que era los inicios de la computaci\u00f3n,", "tokens": [50596, 49766, 288, 806, 367, 24431, 13, 398, 11974, 11, 465, 2373, 9885, 25024, 369, 23427, 282, 450, 631, 4249, 1750, 294, 26817, 368, 635, 2807, 3482, 11, 50812], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 23, "seek": 13220, "start": 141.16, "end": 145.48, "text": " las computadoras ser\u00e1n caras, en las lentas, no ten\u00eda mucho poderos de computos, pero igual hab\u00eda", "tokens": [50812, 2439, 2807, 5409, 296, 816, 7200, 1032, 296, 11, 465, 2439, 23556, 296, 11, 572, 23718, 9824, 8152, 329, 368, 2807, 329, 11, 4768, 10953, 16395, 51028], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 24, "seek": 13220, "start": 145.48, "end": 148.83999999999997, "text": " como mucho optimismo, de que en poco tiempo se iba a poder resolver los problemas y vamos a tener", "tokens": [51028, 2617, 9824, 5028, 6882, 11, 368, 631, 465, 10639, 11772, 369, 33423, 257, 8152, 34480, 1750, 20720, 288, 5295, 257, 11640, 51196], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 25, "seek": 13220, "start": 148.83999999999997, "end": 155.04, "text": " sistemas que iban a traducir barbaros. Y bueno, era m\u00e1s o menos la \u00e9poca de desarrollo de la", "tokens": [51196, 48720, 631, 741, 5144, 257, 2479, 1311, 347, 2159, 5356, 329, 13, 398, 11974, 11, 4249, 3573, 277, 8902, 635, 25024, 368, 38295, 368, 635, 51506], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 26, "seek": 13220, "start": 155.04, "end": 159.64, "text": " ling\u00fc\u00edstica computacional, inspirado un poco en las teor\u00edas de Chomsky, estaba la idea que se", "tokens": [51506, 22949, 774, 19512, 2262, 2807, 13608, 11, 17432, 1573, 517, 10639, 465, 2439, 40238, 10025, 368, 761, 4785, 4133, 11, 17544, 635, 1558, 631, 369, 51736], "temperature": 0.0, "avg_logprob": -0.2546433813777971, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.02782500348985195}, {"id": 27, "seek": 15964, "start": 159.64, "end": 164.48, "text": " pod\u00eda escribir reglas para todo y que a partir de eso se podr\u00eda llegar a hacer cosas muy muy buenas,", "tokens": [50364, 45588, 30598, 10119, 1121, 7743, 1690, 5149, 288, 631, 257, 13906, 368, 7287, 369, 27246, 24892, 257, 6720, 12218, 5323, 5323, 43852, 11, 50606], "temperature": 0.0, "avg_logprob": -0.2666228413581848, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0013906719395890832}, {"id": 28, "seek": 15964, "start": 164.48, "end": 171.05999999999997, "text": " es particular para la traducci\u00f3n. Hasta que en 1964 pareci\u00f3 el reporte Alpac,", "tokens": [50606, 785, 1729, 1690, 635, 2479, 1311, 5687, 13, 45027, 631, 465, 34314, 7448, 19609, 806, 2275, 68, 967, 79, 326, 11, 50935], "temperature": 0.0, "avg_logprob": -0.2666228413581848, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0013906719395890832}, {"id": 29, "seek": 15964, "start": 171.05999999999997, "end": 176.23999999999998, "text": " Alpac era un comit\u00e9 que estaba estudiando, cu\u00e1les eran los avances en ing\u00fc\u00edstica computacional,", "tokens": [50935, 967, 79, 326, 4249, 517, 395, 5066, 631, 17544, 13542, 72, 1806, 11, 2702, 842, 904, 32762, 1750, 1305, 2676, 465, 3957, 774, 19512, 2262, 2807, 13608, 11, 51194], "temperature": 0.0, "avg_logprob": -0.2666228413581848, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0013906719395890832}, {"id": 30, "seek": 15964, "start": 176.23999999999998, "end": 181.72, "text": " porque se estaba poniendo mucha plata en muchas esas cosas. Y ellos demostraron escepticos acerca de", "tokens": [51194, 4021, 369, 17544, 9224, 7304, 25248, 30780, 465, 16072, 23388, 12218, 13, 398, 16353, 41556, 5352, 266, 785, 1336, 9940, 46321, 368, 51468], "temperature": 0.0, "avg_logprob": -0.2666228413581848, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0013906719395890832}, {"id": 31, "seek": 15964, "start": 181.72, "end": 185.72, "text": " la traducci\u00f3n autom\u00e1tica, acerca de los logros que se hab\u00edan logrado despu\u00e9s de todos esos a\u00f1os", "tokens": [51468, 635, 2479, 1311, 5687, 3553, 23432, 11, 46321, 368, 1750, 31013, 329, 631, 369, 44466, 31013, 1573, 15283, 368, 6321, 22411, 11424, 51668], "temperature": 0.0, "avg_logprob": -0.2666228413581848, "compression_ratio": 1.6406779661016948, "no_speech_prob": 0.0013906719395890832}, {"id": 32, "seek": 18572, "start": 185.72, "end": 191.2, "text": " de meter plata. Y dec\u00eda bueno, pero se puso mucho dinero, pas\u00f3 en muchos a\u00f1os, pero todav\u00eda", "tokens": [50364, 368, 9255, 30780, 13, 398, 37599, 11974, 11, 4768, 369, 280, 24431, 9824, 27923, 11, 41382, 465, 17061, 11424, 11, 4768, 28388, 50638], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 33, "seek": 18572, "start": 191.2, "end": 196.0, "text": " los humanos lo hacen m\u00e1s barato, con mayor precisi\u00f3n, m\u00e1s r\u00e1pido, entonces como que para que estamos", "tokens": [50638, 1750, 34555, 450, 27434, 3573, 2159, 2513, 11, 416, 10120, 7974, 2560, 11, 3573, 24893, 11, 13003, 2617, 631, 1690, 631, 10382, 50878], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 34, "seek": 18572, "start": 196.0, "end": 200.96, "text": " gastando en esto. Como resultado de eso, un reporte de fondos, especialmente en Estados Unidos,", "tokens": [50878, 17898, 1806, 465, 7433, 13, 11913, 28047, 368, 7287, 11, 517, 2275, 68, 368, 9557, 329, 11, 41546, 465, 22362, 23087, 11, 51126], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 35, "seek": 18572, "start": 200.96, "end": 204.56, "text": " para todo lo que la traducci\u00f3n autom\u00e1tica y esto fue parte de lo que se conoci\u00f3 como el", "tokens": [51126, 1690, 5149, 450, 631, 635, 2479, 1311, 5687, 3553, 23432, 288, 7433, 9248, 6975, 368, 450, 631, 369, 33029, 19609, 2617, 806, 51306], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 36, "seek": 18572, "start": 204.56, "end": 209.4, "text": " invierno de la inteligencia artificial, que un mont\u00f3n de proyectos de inteligencia artificial tambi\u00e9n", "tokens": [51306, 1048, 19689, 368, 635, 24777, 3213, 2755, 11677, 11, 631, 517, 45259, 368, 23832, 329, 368, 24777, 3213, 2755, 11677, 6407, 51548], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 37, "seek": 18572, "start": 209.4, "end": 214.4, "text": " no ten\u00edamos el resultado, entonces se par\u00f3 la financiaci\u00f3n que hab\u00eda para todo eso durante unos", "tokens": [51548, 572, 2064, 16275, 806, 28047, 11, 13003, 369, 971, 812, 635, 24323, 3482, 631, 16395, 1690, 5149, 7287, 14427, 17780, 51798], "temperature": 0.0, "avg_logprob": -0.22791589056695258, "compression_ratio": 1.7641791044776118, "no_speech_prob": 0.04408583790063858}, {"id": 38, "seek": 21440, "start": 214.44, "end": 219.24, "text": " cuantos a\u00f1os, entonces se tuvo desarrollado unas cuantas cosas durante unos cuantos a\u00f1os. Y bueno,", "tokens": [50366, 2702, 394, 329, 11424, 11, 13003, 369, 43718, 32501, 1573, 25405, 2702, 49153, 12218, 14427, 17780, 2702, 394, 329, 11424, 13, 398, 11974, 11, 50606], "temperature": 0.0, "avg_logprob": -0.27083308661161964, "compression_ratio": 1.6483870967741936, "no_speech_prob": 0.002505890093743801}, {"id": 39, "seek": 21440, "start": 219.24, "end": 226.88, "text": " despu\u00e9s empezaron a resurgir de apoco, pero despu\u00e9s de esto, digamos, en los 70 y hasta los 90 m\u00e1s o menos,", "tokens": [50606, 15283, 18730, 6372, 257, 725, 5476, 347, 368, 1882, 11198, 11, 4768, 15283, 368, 7433, 11, 36430, 11, 465, 1750, 5285, 288, 10764, 1750, 4289, 3573, 277, 8902, 11, 50988], "temperature": 0.0, "avg_logprob": -0.27083308661161964, "compression_ratio": 1.6483870967741936, "no_speech_prob": 0.002505890093743801}, {"id": 40, "seek": 21440, "start": 226.88, "end": 231.24, "text": " eso le hubo que la investigaci\u00f3n se frenar un poco en Estados Unidos, pero empezar a aparecer en", "tokens": [50988, 7287, 476, 11838, 78, 631, 635, 48919, 369, 33596, 289, 517, 10639, 465, 22362, 23087, 11, 4768, 31168, 257, 43336, 465, 51206], "temperature": 0.0, "avg_logprob": -0.27083308661161964, "compression_ratio": 1.6483870967741936, "no_speech_prob": 0.002505890093743801}, {"id": 41, "seek": 21440, "start": 231.24, "end": 236.6, "text": " otros lados del mundo, como por ejemplo en Europa o en Jap\u00f3n. Y ah\u00ed empez\u00f3 ya con filas b\u00e9licos,", "tokens": [51206, 16422, 40301, 1103, 7968, 11, 2617, 1515, 13358, 465, 16642, 277, 465, 35642, 1801, 13, 398, 12571, 18730, 812, 2478, 416, 1387, 296, 15807, 1050, 329, 11, 51474], "temperature": 0.0, "avg_logprob": -0.27083308661161964, "compression_ratio": 1.6483870967741936, "no_speech_prob": 0.002505890093743801}, {"id": 42, "seek": 21440, "start": 236.6, "end": 242.48000000000002, "text": " sino m\u00e1s bien con fines comerciales, entonces hab\u00eda necesidad de tener traducciones o por lo menos", "tokens": [51474, 18108, 3573, 3610, 416, 37989, 43163, 279, 11, 13003, 16395, 11909, 4580, 368, 11640, 2479, 1311, 23469, 277, 1515, 450, 8902, 51768], "temperature": 0.0, "avg_logprob": -0.27083308661161964, "compression_ratio": 1.6483870967741936, "no_speech_prob": 0.002505890093743801}, {"id": 43, "seek": 24248, "start": 242.48, "end": 246.51999999999998, "text": " dar soporte a los traductores humanos con algunas traducciones, aunque no estuvieran de todo bien,", "tokens": [50364, 4072, 370, 44614, 257, 1750, 2479, 11130, 2706, 34555, 416, 27316, 2479, 1311, 23469, 11, 21962, 572, 49777, 38516, 368, 5149, 3610, 11, 50566], "temperature": 0.0, "avg_logprob": -0.310840246245617, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.007368562277406454}, {"id": 44, "seek": 24248, "start": 247.79999999999998, "end": 251.83999999999997, "text": " pero bueno, dar algunas traducciones de inicio para que los traductores puedan, los traductores humanos", "tokens": [50630, 4768, 11974, 11, 4072, 27316, 2479, 1311, 23469, 368, 294, 18322, 1690, 631, 1750, 2479, 11130, 2706, 41241, 11, 1750, 2479, 11130, 2706, 34555, 50832], "temperature": 0.0, "avg_logprob": -0.310840246245617, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.007368562277406454}, {"id": 45, "seek": 24248, "start": 251.83999999999997, "end": 256.03999999999996, "text": " puedan continuar, adem\u00e1s las computadoras empezaron a bajar de precio, tener mayor hogar de computo,", "tokens": [50832, 41241, 29980, 11, 21251, 2439, 2807, 5409, 296, 18730, 6372, 257, 23589, 289, 368, 46916, 11, 11640, 10120, 24855, 289, 368, 715, 8262, 11, 51042], "temperature": 0.0, "avg_logprob": -0.310840246245617, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.007368562277406454}, {"id": 46, "seek": 24248, "start": 256.03999999999996, "end": 260.0, "text": " y esta fue como la era de oro de los sistemas de traducci\u00f3n basados en reglas,", "tokens": [51042, 288, 5283, 9248, 2617, 635, 4249, 368, 45150, 368, 1750, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 1121, 7743, 11, 51240], "temperature": 0.0, "avg_logprob": -0.310840246245617, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.007368562277406454}, {"id": 47, "seek": 24248, "start": 261.71999999999997, "end": 265.92, "text": " digamos ac\u00e1 hay unos ejemplos, sistemas distranques, todav\u00eda se desarrolla aunque ya no est\u00e1 completamente", "tokens": [51326, 36430, 23496, 4842, 17780, 10012, 5895, 329, 11, 48720, 1483, 4257, 7519, 11, 28388, 369, 21464, 340, 3505, 21962, 2478, 572, 3192, 28381, 51536], "temperature": 0.0, "avg_logprob": -0.310840246245617, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.007368562277406454}, {"id": 48, "seek": 26592, "start": 265.92, "end": 273.08000000000004, "text": " basado en reglas, y bueno, hay sistemas que se realizaron en Jap\u00f3n y en Europa, y bueno,", "tokens": [50364, 987, 1573, 465, 1121, 7743, 11, 288, 11974, 11, 4842, 48720, 631, 369, 22828, 6372, 465, 35642, 1801, 288, 465, 16642, 11, 288, 11974, 11, 50722], "temperature": 0.0, "avg_logprob": -0.21757214612299852, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00417219428345561}, {"id": 49, "seek": 26592, "start": 273.08000000000004, "end": 279.56, "text": " o sea, estos sistemas ten\u00edan fines comerciales y no tanto fines militares, pero bueno,", "tokens": [50722, 277, 4158, 11, 12585, 48720, 47596, 37989, 43163, 279, 288, 572, 10331, 37989, 1962, 2786, 495, 11, 4768, 11974, 11, 51046], "temperature": 0.0, "avg_logprob": -0.21757214612299852, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00417219428345561}, {"id": 50, "seek": 26592, "start": 279.56, "end": 284.8, "text": " fines de los 90 y despu\u00e9s de 2000, en adelante empezaron a dejarse de usar un poco los sistemas", "tokens": [51046, 37989, 368, 1750, 4289, 288, 15283, 368, 8132, 11, 465, 40214, 18730, 6372, 257, 24391, 405, 368, 14745, 517, 10639, 1750, 48720, 51308], "temperature": 0.0, "avg_logprob": -0.21757214612299852, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00417219428345561}, {"id": 51, "seek": 26592, "start": 284.8, "end": 289.8, "text": " basados en reglas, porque empez\u00f3 a haber mayor poder de computo y mayor cantidad de datos disponibles,", "tokens": [51308, 987, 4181, 465, 1121, 7743, 11, 4021, 18730, 812, 257, 15811, 10120, 8152, 368, 715, 8262, 288, 10120, 33757, 368, 27721, 23311, 14428, 11, 51558], "temperature": 0.0, "avg_logprob": -0.21757214612299852, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00417219428345561}, {"id": 52, "seek": 28980, "start": 290.36, "end": 296.0, "text": " especialmente con la aparici\u00f3n de internet, empezaron a haber much\u00edsimos datos de texto disponibles,", "tokens": [50392, 41546, 416, 635, 34115, 15534, 368, 4705, 11, 18730, 6372, 257, 15811, 29353, 8372, 27721, 368, 35503, 23311, 14428, 11, 50674], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 53, "seek": 28980, "start": 296.0, "end": 301.40000000000003, "text": " y eso permit\u00eda construir buenos modelos estad\u00edsticos que podr\u00edan explotar las regularidades", "tokens": [50674, 288, 7287, 13423, 2686, 38445, 49617, 2316, 329, 39160, 19512, 9940, 631, 15305, 11084, 1490, 310, 289, 2439, 3890, 10284, 50944], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 54, "seek": 28980, "start": 301.40000000000003, "end": 305.36, "text": " de los idiomas, entonces aparecieron distintos tipos de modelos estad\u00edsticos, los primeros,", "tokens": [50944, 368, 1750, 18014, 7092, 11, 13003, 15004, 537, 16308, 49337, 37105, 368, 2316, 329, 39160, 19512, 9940, 11, 1750, 12595, 329, 11, 51142], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 55, "seek": 28980, "start": 305.36, "end": 308.8, "text": " los que se llamaron traducciones autom\u00e1ticas estad\u00edsticas, que es la otra traducci\u00f3n basada en", "tokens": [51142, 1750, 631, 369, 16848, 6372, 2479, 1311, 23469, 3553, 44997, 39160, 19512, 9150, 11, 631, 785, 635, 13623, 2479, 1311, 5687, 987, 1538, 465, 51314], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 56, "seek": 28980, "start": 308.8, "end": 314.12, "text": " ejemplos, y aparecieron las primeras aplicaciones comerciales que funcionaban bien, que utilizaban", "tokens": [51314, 10012, 5895, 329, 11, 288, 15004, 537, 16308, 2439, 2886, 6985, 18221, 9188, 43163, 279, 631, 14186, 18165, 3610, 11, 631, 19906, 18165, 51580], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 57, "seek": 28980, "start": 314.12, "end": 317.88, "text": " modelos estad\u00edsticos, la primera fue el English Weber, y despu\u00e9s los traductores que m\u00e1s conocemos", "tokens": [51580, 2316, 329, 39160, 19512, 9940, 11, 635, 17382, 9248, 806, 3669, 42690, 11, 288, 15283, 1750, 2479, 11130, 2706, 631, 3573, 33029, 38173, 51768], "temperature": 0.0, "avg_logprob": -0.24884427736883294, "compression_ratio": 1.829192546583851, "no_speech_prob": 0.012941494584083557}, {"id": 58, "seek": 31788, "start": 317.88, "end": 322.68, "text": " hoy en d\u00eda el Bing, translate de Microsoft, y bueno, el Google translate, que probablemente los", "tokens": [50364, 13775, 465, 12271, 806, 30755, 11, 13799, 368, 8116, 11, 288, 11974, 11, 806, 3329, 13799, 11, 631, 21759, 4082, 1750, 50604], "temperature": 0.0, "avg_logprob": -0.2294880449771881, "compression_ratio": 1.6868686868686869, "no_speech_prob": 0.006152328569442034}, {"id": 59, "seek": 31788, "start": 322.68, "end": 327.44, "text": " lo conozcan y lo hayan usado en alg\u00fan momento, y son traductores que la verdad que hoy en d\u00eda se", "tokens": [50604, 450, 416, 15151, 7035, 288, 450, 4842, 282, 505, 1573, 465, 26300, 9333, 11, 288, 1872, 2479, 11130, 2706, 631, 635, 13692, 631, 13775, 465, 12271, 369, 50842], "temperature": 0.0, "avg_logprob": -0.2294880449771881, "compression_ratio": 1.6868686868686869, "no_speech_prob": 0.006152328569442034}, {"id": 60, "seek": 31788, "start": 327.44, "end": 333.56, "text": " puede decir que funcionan bastante bien, entonces bueno, los m\u00e9todos estad\u00edsticos empezaron subhum al", "tokens": [50842, 8919, 10235, 631, 14186, 282, 14651, 3610, 11, 13003, 11974, 11, 1750, 20275, 378, 329, 39160, 19512, 9940, 18730, 6372, 1422, 14645, 419, 51148], "temperature": 0.0, "avg_logprob": -0.2294880449771881, "compression_ratio": 1.6868686868686869, "no_speech_prob": 0.006152328569442034}, {"id": 61, "seek": 31788, "start": 333.56, "end": 340.36, "text": " alrededor del a\u00f1o 2000 y siguen siendo el estado del arte, pero bueno, primero vamos a ver un poco de", "tokens": [51148, 43663, 1103, 15984, 8132, 288, 4556, 7801, 31423, 806, 18372, 1103, 29159, 11, 4768, 11974, 11, 21289, 5295, 257, 1306, 517, 10639, 368, 51488], "temperature": 0.0, "avg_logprob": -0.2294880449771881, "compression_ratio": 1.6868686868686869, "no_speech_prob": 0.006152328569442034}, {"id": 62, "seek": 31788, "start": 340.36, "end": 344.84, "text": " lo que son los sistemas basados en reglas, que eran estos primeros sistemas que mencionamos antes,", "tokens": [51488, 450, 631, 1872, 1750, 48720, 987, 4181, 465, 1121, 7743, 11, 631, 32762, 12585, 12595, 329, 48720, 631, 37030, 2151, 11014, 11, 51712], "temperature": 0.0, "avg_logprob": -0.2294880449771881, "compression_ratio": 1.6868686868686869, "no_speech_prob": 0.006152328569442034}, {"id": 63, "seek": 34484, "start": 345.56, "end": 353.84, "text": " en 1968 un investigador de traducci\u00f3n autom\u00e1tica, se llamaba Bernard Boquah, y son relevamiento de todos", "tokens": [50400, 465, 29930, 517, 4557, 5409, 368, 2479, 1311, 5687, 3553, 23432, 11, 369, 16848, 5509, 30116, 3286, 358, 545, 11, 288, 1872, 2951, 85, 16971, 368, 6321, 50814], "temperature": 0.0, "avg_logprob": -0.20329741018789785, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.0016342058079317212}, {"id": 64, "seek": 34484, "start": 353.84, "end": 359.84, "text": " los sistemas que se hab\u00edan construido, m\u00e1s o menos por la \u00e9poca, y los clasific\u00f3 todos dentro", "tokens": [50814, 1750, 48720, 631, 369, 44466, 12946, 2925, 11, 3573, 277, 8902, 1515, 635, 25024, 11, 288, 1750, 596, 296, 1089, 812, 6321, 10856, 51114], "temperature": 0.0, "avg_logprob": -0.20329741018789785, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.0016342058079317212}, {"id": 65, "seek": 34484, "start": 359.84, "end": 364.15999999999997, "text": " de este diagrama, el dibujo un tri\u00e1ngulo que ahora se llama el tri\u00e1ngulo de Boquah, y bueno,", "tokens": [51114, 368, 4065, 10686, 64, 11, 806, 46621, 78, 517, 1376, 30344, 13455, 631, 9923, 369, 23272, 806, 1376, 30344, 13455, 368, 3286, 358, 545, 11, 288, 11974, 11, 51330], "temperature": 0.0, "avg_logprob": -0.20329741018789785, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.0016342058079317212}, {"id": 66, "seek": 34484, "start": 364.15999999999997, "end": 367.91999999999996, "text": " en este tri\u00e1ngulo se ubican los distintos tipos de sistemas de traducci\u00f3n basados en reglas,", "tokens": [51330, 465, 4065, 1376, 30344, 13455, 369, 26709, 8914, 1750, 49337, 37105, 368, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 1121, 7743, 11, 51518], "temperature": 0.0, "avg_logprob": -0.20329741018789785, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.0016342058079317212}, {"id": 67, "seek": 34484, "start": 367.91999999999996, "end": 373.91999999999996, "text": " se ponen como escalones dentro de este tri\u00e1ngulo, y los lados del tri\u00e1ngulo tienen como", "tokens": [51518, 369, 9224, 268, 2617, 17871, 2213, 10856, 368, 4065, 1376, 30344, 13455, 11, 288, 1750, 40301, 1103, 1376, 30344, 13455, 12536, 2617, 51818], "temperature": 0.0, "avg_logprob": -0.20329741018789785, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.0016342058079317212}, {"id": 68, "seek": 37392, "start": 373.92, "end": 377.92, "text": " distintas interpretaciones, el lado izquierdo, si yo voy subiendo por este lado, en realidad lo que", "tokens": [50364, 31489, 296, 7302, 9188, 11, 806, 11631, 46428, 2595, 11, 1511, 5290, 7552, 1422, 7304, 1515, 4065, 11631, 11, 465, 25635, 450, 631, 50564], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 69, "seek": 37392, "start": 377.92, "end": 383.32, "text": " aumenta es la cantidad o el esfuerzo de an\u00e1lisis que tengo que hacer de lenguaje origen, yo siempre quiero", "tokens": [50564, 17128, 64, 785, 635, 33757, 277, 806, 49213, 4765, 368, 44113, 28436, 631, 13989, 631, 6720, 368, 35044, 84, 11153, 2349, 268, 11, 5290, 12758, 16811, 50834], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 70, "seek": 37392, "start": 383.32, "end": 387.8, "text": " traducir de lenguaje origen en el lenguaje destino, bueno, entonces de este lado aumenta el esfuerzo", "tokens": [50834, 2479, 1311, 347, 368, 35044, 84, 11153, 2349, 268, 465, 806, 35044, 84, 11153, 2677, 2982, 11, 11974, 11, 13003, 368, 4065, 11631, 17128, 64, 806, 49213, 4765, 51058], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 71, "seek": 37392, "start": 387.8, "end": 392.04, "text": " de traducci\u00f3n en el lenguaje origen, y si voy bajando del lado derecho aumenta, bueno,", "tokens": [51058, 368, 2479, 1311, 5687, 465, 806, 35044, 84, 11153, 2349, 268, 11, 288, 1511, 7552, 23589, 1806, 1103, 11631, 39055, 17128, 64, 11, 11974, 11, 51270], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 72, "seek": 37392, "start": 392.04, "end": 395.8, "text": " si voy subiendo del lado derecho quiero decir, aumenta el esfuerzo de generaci\u00f3n en el lenguaje", "tokens": [51270, 1511, 7552, 1422, 7304, 1103, 11631, 39055, 16811, 10235, 11, 17128, 64, 806, 49213, 4765, 368, 1337, 3482, 465, 806, 35044, 84, 11153, 51458], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 73, "seek": 37392, "start": 395.8, "end": 403.56, "text": " destino, entonces \u00bfqu\u00e9 quiere decir esto? Yo ubico distintos sistemas de traducci\u00f3n, la", "tokens": [51458, 2677, 2982, 11, 13003, 3841, 16412, 23877, 10235, 7433, 30, 7616, 26709, 2789, 49337, 48720, 368, 2479, 1311, 5687, 11, 635, 51846], "temperature": 0.0, "avg_logprob": -0.18415096998214722, "compression_ratio": 2.1236363636363635, "no_speech_prob": 0.030861014500260353}, {"id": 74, "seek": 40356, "start": 403.56, "end": 407.28000000000003, "text": " traducci\u00f3n directa es simplemente buscar en el diccionario de las palabras y traducir", "tokens": [50364, 2479, 1311, 5687, 2047, 64, 785, 33190, 26170, 465, 806, 14285, 10015, 4912, 368, 2439, 35240, 288, 2479, 1311, 347, 50550], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 75, "seek": 40356, "start": 407.28000000000003, "end": 412.8, "text": " palabra palabra con poca informaci\u00f3n m\u00e1s, entonces eso casi no necesitan ning\u00fan tipo de an\u00e1lisis y", "tokens": [50550, 31702, 31702, 416, 714, 496, 21660, 3573, 11, 13003, 7287, 22567, 572, 11909, 9670, 30394, 9746, 368, 44113, 28436, 288, 50826], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 76, "seek": 40356, "start": 412.8, "end": 418.52, "text": " casi no necesitas generaci\u00f3n, pero para que son deb\u00edan, yo necesito ponerle muchas ganas a las", "tokens": [50826, 22567, 572, 11909, 14182, 1337, 3482, 11, 4768, 1690, 631, 1872, 3001, 11084, 11, 5290, 11909, 3528, 19149, 306, 16072, 7574, 296, 257, 2439, 51112], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 77, "seek": 40356, "start": 418.52, "end": 422.48, "text": " reglas, o sea, las reglas de traducci\u00f3n deben ser muy buenas y tienen que tomar en cuenta", "tokens": [51112, 1121, 7743, 11, 277, 4158, 11, 2439, 1121, 7743, 368, 2479, 1311, 5687, 49187, 816, 5323, 43852, 288, 12536, 631, 22048, 465, 17868, 51310], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 78, "seek": 40356, "start": 422.48, "end": 427.04, "text": " muchos casos para que esa traducci\u00f3n llegue a ser buena, entonces es como que la flecha de la", "tokens": [51310, 17061, 25135, 1690, 631, 11342, 2479, 1311, 5687, 11234, 622, 257, 816, 25710, 11, 13003, 785, 2617, 631, 635, 7025, 4413, 368, 635, 51538], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 79, "seek": 40356, "start": 427.04, "end": 431.04, "text": " transferencia, la flecha de la traducci\u00f3n es mucho m\u00e1s larga, en cambio, si yo hago un poco de", "tokens": [51538, 5003, 10974, 11, 635, 7025, 4413, 368, 635, 2479, 1311, 5687, 785, 9824, 3573, 1613, 3680, 11, 465, 28731, 11, 1511, 5290, 38721, 517, 10639, 368, 51738], "temperature": 0.0, "avg_logprob": -0.1700380833943685, "compression_ratio": 1.935374149659864, "no_speech_prob": 0.001192689873278141}, {"id": 80, "seek": 43104, "start": 431.12, "end": 436.08000000000004, "text": " an\u00e1lisis, por ejemplo, llevo hasta al nivel de an\u00e1lisis intactico, tengo un parcer, puedo escribir", "tokens": [50368, 44113, 28436, 11, 1515, 13358, 11, 12038, 3080, 10764, 419, 24423, 368, 44113, 28436, 23493, 2789, 11, 13989, 517, 971, 1776, 11, 21612, 30598, 10119, 50616], "temperature": 0.0, "avg_logprob": -0.21850956269424326, "compression_ratio": 1.811387900355872, "no_speech_prob": 0.005349789280444384}, {"id": 81, "seek": 43104, "start": 436.08000000000004, "end": 440.44, "text": " otro tipo de reglas que pueden ser un poco m\u00e1s expresivos, me resulta un poco m\u00e1s f\u00e1cil y despu\u00e9s,", "tokens": [50616, 11921, 9746, 368, 1121, 7743, 631, 14714, 816, 517, 10639, 3573, 33397, 16501, 11, 385, 1874, 64, 517, 10639, 3573, 17474, 288, 15283, 11, 50834], "temperature": 0.0, "avg_logprob": -0.21850956269424326, "compression_ratio": 1.811387900355872, "no_speech_prob": 0.005349789280444384}, {"id": 82, "seek": 43104, "start": 440.44, "end": 446.04, "text": " si tengo un generador, puedo llegar a traducir, entonces si sigo subiendo de vuelta, voy a necesitar", "tokens": [50834, 1511, 13989, 517, 1337, 5409, 11, 21612, 24892, 257, 2479, 1311, 347, 11, 13003, 1511, 4556, 78, 1422, 7304, 368, 41542, 11, 7552, 257, 11909, 3981, 51114], "temperature": 0.0, "avg_logprob": -0.21850956269424326, "compression_ratio": 1.811387900355872, "no_speech_prob": 0.005349789280444384}, {"id": 83, "seek": 43104, "start": 446.04, "end": 449.88, "text": " mayor esfuerzo de an\u00e1lisis de generaci\u00f3n, pero las reglas pueden ser m\u00e1s expresivas y m\u00e1s f\u00e1ciles", "tokens": [51114, 10120, 49213, 4765, 368, 44113, 28436, 368, 1337, 3482, 11, 4768, 2439, 1121, 7743, 14714, 816, 3573, 33397, 24759, 288, 3573, 17474, 279, 51306], "temperature": 0.0, "avg_logprob": -0.21850956269424326, "compression_ratio": 1.811387900355872, "no_speech_prob": 0.005349789280444384}, {"id": 84, "seek": 43104, "start": 449.88, "end": 455.84000000000003, "text": " de escribir y probablemente la traducci\u00f3n sea mejor, hasta que si llegamos al lo articel tri\u00e1ngulo,", "tokens": [51306, 368, 30598, 10119, 288, 21759, 4082, 635, 2479, 1311, 5687, 4158, 11479, 11, 10764, 631, 1511, 11234, 2151, 419, 450, 1523, 299, 338, 1376, 30344, 13455, 11, 51604], "temperature": 0.0, "avg_logprob": -0.21850956269424326, "compression_ratio": 1.811387900355872, "no_speech_prob": 0.005349789280444384}, {"id": 85, "seek": 45584, "start": 455.84, "end": 461.08, "text": " llegamos a la interlingua, que es una especie de noci\u00f3n en la cual no necesito ning\u00fan tipo", "tokens": [50364, 11234, 2151, 257, 635, 728, 1688, 4398, 11, 631, 785, 2002, 49368, 368, 572, 5687, 465, 635, 10911, 572, 11909, 3528, 30394, 9746, 50626], "temperature": 0.0, "avg_logprob": -0.22729165818956162, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.06238113343715668}, {"id": 86, "seek": 45584, "start": 461.08, "end": 466.52, "text": " de transferencia, vamos a dar un poco dentro de un rato de que se trata eso, pero bueno,", "tokens": [50626, 368, 5003, 10974, 11, 5295, 257, 4072, 517, 10639, 10856, 368, 517, 367, 2513, 368, 631, 369, 31920, 7287, 11, 4768, 11974, 11, 50898], "temperature": 0.0, "avg_logprob": -0.22729165818956162, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.06238113343715668}, {"id": 87, "seek": 45584, "start": 466.52, "end": 471.32, "text": " empecemos a ver los distintos niveles de este tri\u00e1ngulo de bocua, el dem\u00e1s abajo era la traducci\u00f3n", "tokens": [50898, 846, 494, 38173, 257, 1306, 1750, 49337, 11461, 904, 368, 4065, 1376, 30344, 13455, 368, 748, 66, 4398, 11, 806, 34682, 30613, 4249, 635, 2479, 1311, 5687, 51138], "temperature": 0.0, "avg_logprob": -0.22729165818956162, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.06238113343715668}, {"id": 88, "seek": 45584, "start": 471.32, "end": 476.76, "text": " directa, es el enfoque m\u00e1s simple, lo \u00fanico necesito para este enfoque es un diccionario de", "tokens": [51138, 2047, 64, 11, 785, 806, 10667, 29743, 3573, 2199, 11, 450, 26113, 11909, 3528, 1690, 4065, 10667, 29743, 785, 517, 14285, 10015, 4912, 368, 51410], "temperature": 0.0, "avg_logprob": -0.22729165818956162, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.06238113343715668}, {"id": 89, "seek": 45584, "start": 476.76, "end": 481.71999999999997, "text": " ling\u00fce, yo quiero traducir entre dos idiomas, si necesito un diccionario que tenga la correspondencia", "tokens": [51410, 22949, 774, 68, 11, 5290, 16811, 2479, 1311, 347, 3962, 4491, 18014, 7092, 11, 1511, 11909, 3528, 517, 14285, 10015, 4912, 631, 36031, 635, 6805, 10974, 51658], "temperature": 0.0, "avg_logprob": -0.22729165818956162, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.06238113343715668}, {"id": 90, "seek": 48172, "start": 481.72, "end": 485.76000000000005, "text": " entre palabras de un idioma y palabras del otro, y lo que voy a hacer es traducir palabra", "tokens": [50364, 3962, 35240, 368, 517, 18014, 6440, 288, 35240, 1103, 11921, 11, 288, 450, 631, 7552, 257, 6720, 785, 2479, 1311, 347, 31702, 50566], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 91, "seek": 48172, "start": 485.76000000000005, "end": 491.20000000000005, "text": " palabra, o sea, puedo agregarle alguna cosa extra, como por ejemplo, alg\u00fan reordenamiento local,", "tokens": [50566, 31702, 11, 277, 4158, 11, 21612, 4554, 2976, 306, 20651, 10163, 2857, 11, 2617, 1515, 13358, 11, 26300, 319, 19058, 16971, 2654, 11, 50838], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 92, "seek": 48172, "start": 491.20000000000005, "end": 495.76000000000005, "text": " yo que es para traducir entre espa\u00f1ol ingl\u00e9s, yo dir\u00eda que en espa\u00f1ol el nombre se siga el", "tokens": [50838, 5290, 631, 785, 1690, 2479, 1311, 347, 3962, 31177, 49766, 11, 5290, 4746, 2686, 631, 465, 31177, 806, 13000, 369, 4556, 64, 806, 51066], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 93, "seek": 48172, "start": 495.76000000000005, "end": 498.96000000000004, "text": " adjetivo y en ingl\u00e9s se en realidad los han arreves, pone el adjetivo seguido el nombre,", "tokens": [51066, 614, 7108, 6340, 288, 465, 49766, 369, 465, 25635, 1750, 7276, 594, 265, 977, 11, 40192, 806, 614, 7108, 6340, 8878, 2925, 806, 13000, 11, 51226], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 94, "seek": 48172, "start": 498.96000000000004, "end": 505.08000000000004, "text": " entonces ese tipo de reglas simples se las puedo agregar al sistema, y bueno, el sistema", "tokens": [51226, 13003, 10167, 9746, 368, 1121, 7743, 21730, 369, 2439, 21612, 4554, 2976, 419, 13245, 11, 288, 11974, 11, 806, 13245, 51532], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 95, "seek": 48172, "start": 505.08000000000004, "end": 509.22, "text": " funcionar\u00eda un poco as\u00ed, yo tengo una operaci\u00f3n de entrada en el idioma origen, Mary", "tokens": [51532, 14186, 21178, 517, 10639, 8582, 11, 5290, 13989, 2002, 2208, 3482, 368, 37119, 465, 806, 18014, 6440, 2349, 268, 11, 6059, 51739], "temperature": 0.0, "avg_logprob": -0.24790457132700328, "compression_ratio": 1.7941176470588236, "no_speech_prob": 0.027219509705901146}, {"id": 96, "seek": 50922, "start": 509.22, "end": 515.5, "text": " Tiden Slap de Green Witch, le paso un analisador morfol\u00f3gico bastante de superficie, que no hace", "tokens": [50364, 314, 4380, 6187, 569, 368, 6969, 23522, 11, 476, 29212, 517, 2624, 271, 5409, 1896, 69, 27629, 2789, 14651, 368, 23881, 414, 11, 631, 572, 10032, 50678], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 97, "seek": 50922, "start": 515.5, "end": 519.74, "text": " mucho en realidad, simplemente me dice que esto era el barbo du, en pasado y seguido por un", "tokens": [50678, 9824, 465, 25635, 11, 33190, 385, 10313, 631, 7433, 4249, 806, 2159, 1763, 1581, 11, 465, 24794, 288, 8878, 2925, 1515, 517, 50890], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 98, "seek": 50922, "start": 519.74, "end": 525.0600000000001, "text": " not, y bueno, el resto de los tokens sigue en igual, y ac\u00e1 viene la parte de diccionario,", "tokens": [50890, 406, 11, 288, 11974, 11, 806, 28247, 368, 1750, 22667, 34532, 465, 10953, 11, 288, 23496, 19561, 635, 6975, 368, 14285, 10015, 4912, 11, 51156], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 99, "seek": 50922, "start": 525.0600000000001, "end": 528.6600000000001, "text": " digamos, lo siguiente que tengo que hacer es buscar en mi diccionario cada una de las palabras", "tokens": [51156, 36430, 11, 450, 25666, 631, 13989, 631, 6720, 785, 26170, 465, 2752, 14285, 10015, 4912, 8411, 2002, 368, 2439, 35240, 51336], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 100, "seek": 50922, "start": 528.6600000000001, "end": 533.1, "text": " y poner la palabra correspondiente del otro lado, entonces Mary queda Mar\u00eda, duve en pasado", "tokens": [51336, 288, 19149, 635, 31702, 6805, 8413, 1103, 11921, 11631, 11, 13003, 6059, 23314, 48472, 11, 1581, 303, 465, 24794, 51558], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 101, "seek": 50922, "start": 533.1, "end": 538.14, "text": " como en espa\u00f1ol no se usa el du, usamos simplemente el marcador de pasado, not es no, Slap es", "tokens": [51558, 2617, 465, 31177, 572, 369, 29909, 806, 1581, 11, 505, 2151, 33190, 806, 42365, 5409, 368, 24794, 11, 406, 785, 572, 11, 6187, 569, 785, 51810], "temperature": 0.0, "avg_logprob": -0.2827244567871094, "compression_ratio": 1.7217125382262997, "no_speech_prob": 0.16507548093795776}, {"id": 102, "seek": 53814, "start": 538.14, "end": 545.42, "text": " dar una ofetada de Slap Green, es verde, Witch es Bruja, con el diccionario hoy poniendo", "tokens": [50364, 4072, 2002, 295, 302, 1538, 368, 6187, 569, 6969, 11, 785, 29653, 11, 23522, 785, 12792, 2938, 11, 416, 806, 14285, 10015, 4912, 13775, 9224, 7304, 50728], "temperature": 0.0, "avg_logprob": -0.2712027179308174, "compression_ratio": 1.673992673992674, "no_speech_prob": 0.006789166945964098}, {"id": 103, "seek": 53814, "start": 545.42, "end": 551.38, "text": " todas las traducciones, y despu\u00e9s puedo usar mis reglas de ordenamiento local, de ordenamiento", "tokens": [50728, 10906, 2439, 2479, 1311, 23469, 11, 288, 15283, 21612, 14745, 3346, 1121, 7743, 368, 28615, 16971, 2654, 11, 368, 28615, 16971, 51026], "temperature": 0.0, "avg_logprob": -0.2712027179308174, "compression_ratio": 1.673992673992674, "no_speech_prob": 0.006789166945964098}, {"id": 104, "seek": 53814, "start": 551.38, "end": 556.46, "text": " simple como por ejemplo que el adjetivo seguido en nombre en ingl\u00e9s, en realidad en espa\u00f1ol", "tokens": [51026, 2199, 2617, 1515, 13358, 631, 806, 614, 7108, 6340, 8878, 2925, 465, 13000, 465, 49766, 11, 465, 25635, 465, 31177, 51280], "temperature": 0.0, "avg_logprob": -0.2712027179308174, "compression_ratio": 1.673992673992674, "no_speech_prob": 0.006789166945964098}, {"id": 105, "seek": 53814, "start": 556.46, "end": 559.9, "text": " se corresponde con nombres seguido adjetivo, entonces verdad de Bruja lo cambio por Bruja", "tokens": [51280, 369, 6805, 68, 416, 297, 29947, 8878, 2925, 614, 7108, 6340, 11, 13003, 13692, 368, 12792, 2938, 450, 28731, 1515, 12792, 2938, 51452], "temperature": 0.0, "avg_logprob": -0.2712027179308174, "compression_ratio": 1.673992673992674, "no_speech_prob": 0.006789166945964098}, {"id": 106, "seek": 53814, "start": 559.9, "end": 563.7, "text": " verde, ac\u00e1 hay otro ordenamiento, digamos, donde tengo una marca de pasado y se lo paso", "tokens": [51452, 29653, 11, 23496, 4842, 11921, 28615, 16971, 11, 36430, 11, 10488, 13989, 2002, 30582, 368, 24794, 288, 369, 450, 29212, 51642], "temperature": 0.0, "avg_logprob": -0.2712027179308174, "compression_ratio": 1.673992673992674, "no_speech_prob": 0.006789166945964098}, {"id": 107, "seek": 56370, "start": 563.7, "end": 569.22, "text": " para adelante a lo largo, y finalmente lo que hago es una peque\u00f1a generaci\u00f3n morfol\u00f3gica", "tokens": [50364, 1690, 40214, 257, 450, 31245, 11, 288, 35577, 450, 631, 38721, 785, 2002, 47177, 1337, 3482, 1896, 69, 27629, 2262, 50640], "temperature": 0.0, "avg_logprob": -0.2822127107714043, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.03355928510427475}, {"id": 108, "seek": 56370, "start": 569.22, "end": 575.1800000000001, "text": " con estas marcas y digo bueno, este dar en pasado se transforma en dio, entonces me queda", "tokens": [50640, 416, 13897, 1849, 16369, 288, 22990, 11974, 11, 4065, 4072, 465, 24794, 369, 4088, 64, 465, 31965, 11, 13003, 385, 23314, 50938], "temperature": 0.0, "avg_logprob": -0.2822127107714043, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.03355928510427475}, {"id": 109, "seek": 56370, "start": 575.1800000000001, "end": 581.34, "text": " Mar\u00eda no dio una ofetada a la Bruja verde, as\u00ed que part\u00ed de el texto en el idioma", "tokens": [50938, 48472, 572, 31965, 2002, 295, 302, 1538, 257, 635, 12792, 2938, 29653, 11, 8582, 631, 644, 870, 368, 806, 35503, 465, 806, 18014, 6440, 51246], "temperature": 0.0, "avg_logprob": -0.2822127107714043, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.03355928510427475}, {"id": 110, "seek": 56370, "start": 581.34, "end": 586.3000000000001, "text": " Rige, Mary did and Slap de Green Witch y llegue a una oraci\u00f3n en el idioma destino Mar\u00eda", "tokens": [51246, 497, 3969, 11, 6059, 630, 293, 6187, 569, 368, 6969, 23522, 288, 11234, 622, 257, 2002, 420, 3482, 465, 806, 18014, 6440, 2677, 2982, 48472, 51494], "temperature": 0.0, "avg_logprob": -0.2822127107714043, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.03355928510427475}, {"id": 111, "seek": 56370, "start": 586.3000000000001, "end": 589.9000000000001, "text": " no dio una ofetada a la Bruja verde, que parece estar bastante bien digamos, bastante", "tokens": [51494, 572, 31965, 2002, 295, 302, 1538, 257, 635, 12792, 2938, 29653, 11, 631, 14120, 8755, 14651, 3610, 36430, 11, 14651, 51674], "temperature": 0.0, "avg_logprob": -0.2822127107714043, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.03355928510427475}, {"id": 112, "seek": 58990, "start": 589.9, "end": 594.38, "text": " bien la traducci\u00f3n, entonces as\u00ed es como funcionar\u00eda un poco un sistema de traducci\u00f3n", "tokens": [50364, 3610, 635, 2479, 1311, 5687, 11, 13003, 8582, 785, 2617, 14186, 21178, 517, 10639, 517, 13245, 368, 2479, 1311, 5687, 50588], "temperature": 0.0, "avg_logprob": -0.28043018687855115, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.11668801307678223}, {"id": 113, "seek": 58990, "start": 594.38, "end": 599.26, "text": " directa, como les parece que funcionan estos sistemas en la pr\u00e1ctica, digamos que tambi\u00e9n", "tokens": [50588, 2047, 64, 11, 2617, 1512, 14120, 631, 14186, 282, 12585, 48720, 465, 635, 27300, 29041, 11, 36430, 631, 6407, 50832], "temperature": 0.0, "avg_logprob": -0.28043018687855115, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.11668801307678223}, {"id": 114, "seek": 58990, "start": 599.26, "end": 603.9, "text": " se comportan en la pr\u00e1ctica este tipo de sistemas, pues ac\u00e1 vimos un ejemplo que", "tokens": [50832, 369, 25883, 282, 465, 635, 27300, 29041, 4065, 9746, 368, 48720, 11, 11059, 23496, 49266, 517, 13358, 631, 51064], "temperature": 0.0, "avg_logprob": -0.28043018687855115, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.11668801307678223}, {"id": 115, "seek": 58990, "start": 603.9, "end": 616.3, "text": " quedan bastante bien digamos, pero no s\u00e9 qu\u00e9, claro, y hay otro problema m\u00e1s, y es", "tokens": [51064, 13617, 282, 14651, 3610, 36430, 11, 4768, 572, 7910, 8057, 11, 16742, 11, 288, 4842, 11921, 12395, 3573, 11, 288, 785, 51684], "temperature": 0.0, "avg_logprob": -0.28043018687855115, "compression_ratio": 1.650943396226415, "no_speech_prob": 0.11668801307678223}, {"id": 116, "seek": 61630, "start": 617.3, "end": 621.54, "text": " lo que, que no tenga todas las palabras, pero adem\u00e1s que palabras que se pueden traducir", "tokens": [50414, 450, 631, 11, 631, 572, 36031, 10906, 2439, 35240, 11, 4768, 21251, 631, 35240, 631, 369, 14714, 2479, 1311, 347, 50626], "temperature": 0.0, "avg_logprob": -0.2347686675287062, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.06244721636176109}, {"id": 117, "seek": 61630, "start": 621.54, "end": 627.0999999999999, "text": " de m\u00e1s de una manera, entonces necesitas saber qu\u00e9 palabras ten\u00e9s que usar, entonces bueno,", "tokens": [50626, 368, 3573, 368, 2002, 13913, 11, 13003, 11909, 14182, 12489, 8057, 35240, 2064, 2191, 631, 14745, 11, 13003, 11974, 11, 50904], "temperature": 0.0, "avg_logprob": -0.2347686675287062, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.06244721636176109}, {"id": 118, "seek": 61630, "start": 628.3, "end": 633.14, "text": " la web est\u00e1 llena de ejemplos de lo que puede salir m\u00e1s y yo utilizo un sistema de traducci\u00f3n", "tokens": [50964, 635, 3670, 3192, 4849, 4118, 368, 10012, 5895, 329, 368, 450, 631, 8919, 31514, 3573, 288, 5290, 4976, 19055, 517, 13245, 368, 2479, 1311, 5687, 51206], "temperature": 0.0, "avg_logprob": -0.2347686675287062, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.06244721636176109}, {"id": 119, "seek": 61630, "start": 633.14, "end": 638.78, "text": " directa como este, entonces lo que est\u00e1bamos viendo reci\u00e9n era los sistemas de traducci\u00f3n directa,", "tokens": [51206, 2047, 64, 2617, 4065, 11, 13003, 450, 631, 3192, 65, 2151, 34506, 4214, 3516, 4249, 1750, 48720, 368, 2479, 1311, 5687, 2047, 64, 11, 51488], "temperature": 0.0, "avg_logprob": -0.2347686675287062, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.06244721636176109}, {"id": 120, "seek": 61630, "start": 638.78, "end": 644.5799999999999, "text": " vamos a subir un poco en la complejidad de los sistemas y llegar a la transferencia sint\u00e1ctica,", "tokens": [51488, 5295, 257, 34785, 517, 10639, 465, 635, 44424, 73, 4580, 368, 1750, 48720, 288, 24892, 257, 635, 5003, 10974, 41259, 842, 29041, 11, 51778], "temperature": 0.0, "avg_logprob": -0.2347686675287062, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.06244721636176109}, {"id": 121, "seek": 64458, "start": 645.14, "end": 649.62, "text": " entonces para la transferencia sint\u00e1ctica, yo lo que voy a necesitar primero es tener un", "tokens": [50392, 13003, 1690, 635, 5003, 10974, 41259, 842, 29041, 11, 5290, 450, 631, 7552, 257, 11909, 3981, 21289, 785, 11640, 517, 50616], "temperature": 0.0, "avg_logprob": -0.2285873783168508, "compression_ratio": 1.86328125, "no_speech_prob": 0.0014155505923554301}, {"id": 122, "seek": 64458, "start": 649.62, "end": 655.22, "text": " parcer de lenguaje origen que me lleva a un an\u00e1lisis sint\u00e1ctico y adem\u00e1s voy a necesitar un", "tokens": [50616, 971, 1776, 368, 35044, 84, 11153, 2349, 268, 631, 385, 37681, 257, 517, 44113, 28436, 41259, 842, 349, 2789, 288, 21251, 7552, 257, 11909, 3981, 517, 50896], "temperature": 0.0, "avg_logprob": -0.2285873783168508, "compression_ratio": 1.86328125, "no_speech_prob": 0.0014155505923554301}, {"id": 123, "seek": 64458, "start": 655.22, "end": 660.38, "text": " generador, lenguaje destino que agarra, un algo sint\u00e1ctico de lenguaje destino y genera una", "tokens": [50896, 1337, 5409, 11, 35044, 84, 11153, 2677, 2982, 631, 623, 289, 424, 11, 517, 8655, 41259, 842, 349, 2789, 368, 35044, 84, 11153, 2677, 2982, 288, 1337, 64, 2002, 51154], "temperature": 0.0, "avg_logprob": -0.2285873783168508, "compression_ratio": 1.86328125, "no_speech_prob": 0.0014155505923554301}, {"id": 124, "seek": 64458, "start": 660.38, "end": 666.34, "text": " oraci\u00f3n, entonces yo lo que puedo hacer es escribir reglas que transformar un \u00e1rbol en el otro", "tokens": [51154, 420, 3482, 11, 13003, 5290, 450, 631, 21612, 6720, 785, 30598, 10119, 1121, 7743, 631, 4088, 289, 517, 35349, 17460, 465, 806, 11921, 51452], "temperature": 0.0, "avg_logprob": -0.2285873783168508, "compression_ratio": 1.86328125, "no_speech_prob": 0.0014155505923554301}, {"id": 125, "seek": 64458, "start": 666.34, "end": 670.9000000000001, "text": " y esas reglas son un poco m\u00e1s f\u00e1ciles digamos que lo que necesitar\u00eda para un sistema de traducci\u00f3n", "tokens": [51452, 288, 23388, 1121, 7743, 1872, 517, 10639, 3573, 17474, 279, 36430, 631, 450, 631, 11909, 3981, 2686, 1690, 517, 13245, 368, 2479, 1311, 5687, 51680], "temperature": 0.0, "avg_logprob": -0.2285873783168508, "compression_ratio": 1.86328125, "no_speech_prob": 0.0014155505923554301}, {"id": 126, "seek": 67090, "start": 670.9, "end": 674.26, "text": " directa, entonces para el ingl\u00e9s, por ejemplo para todo el siguiente del ingl\u00e9s y el espa\u00f1ol,", "tokens": [50364, 2047, 64, 11, 13003, 1690, 806, 49766, 11, 1515, 13358, 1690, 5149, 806, 25666, 1103, 49766, 288, 806, 31177, 11, 50532], "temperature": 0.0, "avg_logprob": -0.3013381012215102, "compression_ratio": 1.95, "no_speech_prob": 0.0129964305087924}, {"id": 127, "seek": 67090, "start": 674.26, "end": 678.8199999999999, "text": " yo dir\u00eda que si tengo un nominal que es un adjetivo nombre, un adjetivo en un nombre en ingl\u00e9s,", "tokens": [50532, 5290, 4746, 2686, 631, 1511, 13989, 517, 41641, 631, 785, 517, 614, 7108, 6340, 13000, 11, 517, 614, 7108, 6340, 465, 517, 13000, 465, 49766, 11, 50760], "temperature": 0.0, "avg_logprob": -0.3013381012215102, "compression_ratio": 1.95, "no_speech_prob": 0.0129964305087924}, {"id": 128, "seek": 67090, "start": 678.8199999999999, "end": 685.26, "text": " lo transformar\u00eda en un nombre, segu\u00ed un adjetivo en espa\u00f1ol y la reglas escribir\u00eda algo as\u00ed", "tokens": [50760, 450, 4088, 21178, 465, 517, 13000, 11, 8878, 870, 517, 614, 7108, 6340, 465, 31177, 288, 635, 1121, 7743, 30598, 10119, 2686, 8655, 8582, 51082], "temperature": 0.0, "avg_logprob": -0.3013381012215102, "compression_ratio": 1.95, "no_speech_prob": 0.0129964305087924}, {"id": 129, "seek": 67090, "start": 685.26, "end": 689.26, "text": " dir\u00eda, tengo nominal adjetivo nombre, entonces lo cambio por nominal nombre adjetivo,", "tokens": [51082, 4746, 2686, 11, 13989, 41641, 614, 7108, 6340, 13000, 11, 13003, 450, 28731, 1515, 41641, 13000, 614, 7108, 6340, 11, 51282], "temperature": 0.0, "avg_logprob": -0.3013381012215102, "compression_ratio": 1.95, "no_speech_prob": 0.0129964305087924}, {"id": 130, "seek": 67090, "start": 691.66, "end": 697.46, "text": " entonces ahora que sabemos c\u00f3mo funciona esto, tratemos de hacer el ejemplo en japon\u00e9s,", "tokens": [51402, 13003, 9923, 631, 27200, 12826, 26210, 7433, 11, 21507, 4485, 368, 6720, 806, 13358, 465, 361, 21319, 2191, 11, 51692], "temperature": 0.0, "avg_logprob": -0.3013381012215102, "compression_ratio": 1.95, "no_speech_prob": 0.0129964305087924}, {"id": 131, "seek": 69746, "start": 697.46, "end": 701.86, "text": " digamos c\u00f3mo ser\u00edan las reglas para transformar el \u00e1rbol en ingl\u00e9s de Geador, se le dicen en", "tokens": [50364, 36430, 12826, 816, 11084, 2439, 1121, 7743, 1690, 4088, 289, 806, 35349, 17460, 465, 49766, 368, 2876, 5409, 11, 369, 476, 33816, 465, 50584], "temperature": 0.0, "avg_logprob": -0.32898818745332603, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.021869797259569168}, {"id": 132, "seek": 69746, "start": 701.86, "end": 708.46, "text": " tu music, a japon\u00e9s, careja, ongaku, wokiku, no gada y suki de su, donde est\u00e1, tenemos la", "tokens": [50584, 2604, 1318, 11, 257, 361, 21319, 2191, 11, 1127, 2938, 11, 322, 70, 15803, 11, 261, 453, 24320, 11, 572, 290, 1538, 288, 459, 2984, 368, 459, 11, 10488, 3192, 11, 9914, 635, 50914], "temperature": 0.0, "avg_logprob": -0.32898818745332603, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.021869797259569168}, {"id": 133, "seek": 69746, "start": 708.46, "end": 712.94, "text": " correspondencia de cada una de las palabras, pero claro los \u00e1rboles son un poco distintos,", "tokens": [50914, 6805, 10974, 368, 8411, 2002, 368, 2439, 35240, 11, 4768, 16742, 1750, 35349, 65, 7456, 1872, 517, 10639, 49337, 11, 51138], "temperature": 0.0, "avg_logprob": -0.32898818745332603, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.021869797259569168}, {"id": 134, "seek": 69746, "start": 712.94, "end": 720.5, "text": " el ingl\u00e9s y el espa\u00f1ol se caracterizan por ser lenguajes de tipo, no s\u00e9 si esto lo hemos visto", "tokens": [51138, 806, 49766, 288, 806, 31177, 369, 28760, 590, 282, 1515, 816, 35044, 84, 29362, 368, 9746, 11, 572, 7910, 1511, 7433, 450, 15396, 17558, 51516], "temperature": 0.0, "avg_logprob": -0.32898818745332603, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.021869797259569168}, {"id": 135, "seek": 69746, "start": 720.5, "end": 725.5400000000001, "text": " ya en el curso, pero son lenguajes de tipo SBO, que significa que habitualmente yo solo escribir", "tokens": [51516, 2478, 465, 806, 31085, 11, 4768, 1872, 35044, 84, 29362, 368, 9746, 318, 15893, 11, 631, 19957, 631, 46883, 4082, 5290, 6944, 30598, 10119, 51768], "temperature": 0.0, "avg_logprob": -0.32898818745332603, "compression_ratio": 1.6101694915254237, "no_speech_prob": 0.021869797259569168}, {"id": 136, "seek": 72554, "start": 725.54, "end": 730.42, "text": " un sujeto se dio un verbo seguido de un objeto, el japon\u00e9s en cambio es un lenguaje de tipo SBOB", "tokens": [50364, 517, 23634, 78, 369, 31965, 517, 1306, 1763, 8878, 2925, 368, 517, 40438, 11, 806, 361, 21319, 2191, 465, 28731, 785, 517, 35044, 84, 11153, 368, 9746, 318, 15893, 33, 50608], "temperature": 0.0, "avg_logprob": -0.24422834847719616, "compression_ratio": 1.8093385214007782, "no_speech_prob": 0.00443364167585969}, {"id": 137, "seek": 72554, "start": 730.42, "end": 735.54, "text": " porque habitualmente se escribi\u00f3 el sujeto, seguido del objeto, seguido del barbol, hay muchos lenguajes", "tokens": [50608, 4021, 46883, 4082, 369, 30598, 5614, 812, 806, 23634, 78, 11, 8878, 2925, 1103, 40438, 11, 8878, 2925, 1103, 2159, 17460, 11, 4842, 17061, 35044, 84, 29362, 50864], "temperature": 0.0, "avg_logprob": -0.24422834847719616, "compression_ratio": 1.8093385214007782, "no_speech_prob": 0.00443364167585969}, {"id": 138, "seek": 72554, "start": 735.54, "end": 741.98, "text": " que pertenecen a esta otra categor\u00eda, entonces bueno, queremos escribir reglas de transferencia", "tokens": [50864, 631, 680, 1147, 3045, 268, 257, 5283, 13623, 19250, 2686, 11, 13003, 11974, 11, 26813, 30598, 10119, 1121, 7743, 368, 5003, 10974, 51186], "temperature": 0.0, "avg_logprob": -0.24422834847719616, "compression_ratio": 1.8093385214007782, "no_speech_prob": 0.00443364167585969}, {"id": 139, "seek": 72554, "start": 741.98, "end": 746.6999999999999, "text": " para transformar este \u00e1rbol en aquel otro \u00e1rbol, como escribir\u00edamos esas reglas, que les parece,", "tokens": [51186, 1690, 4088, 289, 4065, 35349, 17460, 465, 2373, 338, 11921, 35349, 17460, 11, 2617, 30598, 10119, 16275, 23388, 1121, 7743, 11, 631, 1512, 14120, 11, 51422], "temperature": 0.0, "avg_logprob": -0.24422834847719616, "compression_ratio": 1.8093385214007782, "no_speech_prob": 0.00443364167585969}, {"id": 140, "seek": 72554, "start": 749.4599999999999, "end": 752.2199999999999, "text": " que reglas utilizar\u00eda yo para transformar un \u00e1rbol en el otro,", "tokens": [51560, 631, 1121, 7743, 24060, 2686, 5290, 1690, 4088, 289, 517, 35349, 17460, 465, 806, 11921, 11, 51698], "temperature": 0.0, "avg_logprob": -0.24422834847719616, "compression_ratio": 1.8093385214007782, "no_speech_prob": 0.00443364167585969}, {"id": 141, "seek": 75554, "start": 755.54, "end": 775.3, "text": " ah\u00ed est\u00e1, una de esas, en ingl\u00e9s yo escribo, una fraser\u00f3balo, un grupo verbal como un verbo seguido de un grupo", "tokens": [50364, 12571, 3192, 11, 2002, 368, 23388, 11, 465, 49766, 5290, 30598, 1763, 11, 2002, 431, 17756, 812, 2645, 78, 11, 517, 20190, 24781, 2617, 517, 1306, 1763, 8878, 2925, 368, 517, 20190, 51352], "temperature": 0.0, "avg_logprob": -0.3985496891869439, "compression_ratio": 1.1855670103092784, "no_speech_prob": 0.019077666103839874}, {"id": 142, "seek": 77530, "start": 775.3, "end": 787.5, "text": " proporcional, esta es la que dec\u00edas, y la cambio por que otra cosa, la cambio por un grupo", "tokens": [50364, 2365, 36003, 1966, 11, 5283, 785, 635, 631, 979, 10025, 11, 288, 635, 28731, 1515, 631, 13623, 10163, 11, 635, 28731, 1515, 517, 20190, 50974], "temperature": 0.0, "avg_logprob": -0.3092742871634568, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.12531787157058716}, {"id": 143, "seek": 77530, "start": 787.5, "end": 796.54, "text": " proporcional que sigue un verbo, esa es una, que otra regla tendr\u00eda que agregar, cu\u00e1l,", "tokens": [50974, 2365, 36003, 1966, 631, 34532, 517, 1306, 1763, 11, 11342, 785, 2002, 11, 631, 13623, 1121, 875, 3928, 37183, 631, 4554, 2976, 11, 44318, 11, 51426], "temperature": 0.0, "avg_logprob": -0.3092742871634568, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.12531787157058716}, {"id": 144, "seek": 77530, "start": 796.54, "end": 802.02, "text": " la elaboraci\u00f3n, que tiene la elaboraci\u00f3n, la elaboraci\u00f3n seg\u00fan esto en ingl\u00e9s es un pronombre", "tokens": [51426, 635, 16298, 3482, 11, 631, 7066, 635, 16298, 3482, 11, 635, 16298, 3482, 36570, 7433, 465, 49766, 785, 517, 7569, 298, 2672, 51700], "temperature": 0.0, "avg_logprob": -0.3092742871634568, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.12531787157058716}, {"id": 145, "seek": 80202, "start": 802.74, "end": 811.6999999999999, "text": " seguido de un verbo, seguido de un grupo verbal, por qu\u00e9 tendr\u00eda a cambiarlo, ahora en", "tokens": [50400, 8878, 2925, 368, 517, 1306, 1763, 11, 8878, 2925, 368, 517, 20190, 24781, 11, 1515, 8057, 3928, 37183, 257, 19569, 19457, 11, 9923, 465, 50848], "temperature": 0.0, "avg_logprob": -0.24332271303449357, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.020868895575404167}, {"id": 146, "seek": 80202, "start": 811.6999999999999, "end": 819.14, "text": " japon\u00e9s la elaboraci\u00f3n va a ser el pronombre seguido del verphrase, seguido del verbo, bien,", "tokens": [50848, 361, 21319, 2191, 635, 16298, 3482, 2773, 257, 816, 806, 7569, 298, 2672, 8878, 2925, 1103, 1306, 44598, 651, 11, 8878, 2925, 1103, 1306, 1763, 11, 3610, 11, 51220], "temperature": 0.0, "avg_logprob": -0.24332271303449357, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.020868895575404167}, {"id": 147, "seek": 80202, "start": 819.14, "end": 827.86, "text": " alguna otra, ah\u00ed est\u00e1, el grupo preposicional que est\u00e1 formado por un t\u00fa, seguido un nombre,", "tokens": [51220, 20651, 13623, 11, 12571, 3192, 11, 806, 20190, 2666, 329, 33010, 631, 3192, 1254, 1573, 1515, 517, 15056, 11, 8878, 2925, 517, 13000, 11, 51656], "temperature": 0.0, "avg_logprob": -0.24332271303449357, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.020868895575404167}, {"id": 148, "seek": 82786, "start": 827.86, "end": 835.14, "text": " eso es en ingl\u00e9s y en japon\u00e9s que va a pasar, voy a tener un grupo proporcional que es un nombre", "tokens": [50364, 7287, 785, 465, 49766, 288, 465, 361, 21319, 2191, 631, 2773, 257, 25344, 11, 7552, 257, 11640, 517, 20190, 2365, 36003, 1966, 631, 785, 517, 13000, 50728], "temperature": 0.0, "avg_logprob": -0.1798399112842701, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.004000943154096603}, {"id": 149, "seek": 82786, "start": 835.14, "end": 841.7, "text": " seguido de t\u00fa, bien, entonces con eso m\u00e1s o menos creo que tendr\u00eda las reglas suficientes para", "tokens": [50728, 8878, 2925, 368, 15056, 11, 3610, 11, 13003, 416, 7287, 3573, 277, 8902, 14336, 631, 3928, 37183, 2439, 1121, 7743, 459, 1786, 20135, 1690, 51056], "temperature": 0.0, "avg_logprob": -0.1798399112842701, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.004000943154096603}, {"id": 150, "seek": 82786, "start": 841.7, "end": 845.74, "text": " transformar un \u00e1rbol en el otro, los sistemas de traducci\u00f3n, vamos a ver si est\u00e1 bien,", "tokens": [51056, 4088, 289, 517, 35349, 17460, 465, 806, 11921, 11, 1750, 48720, 368, 2479, 1311, 5687, 11, 5295, 257, 1306, 1511, 3192, 3610, 11, 51258], "temperature": 0.0, "avg_logprob": -0.1798399112842701, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.004000943154096603}, {"id": 151, "seek": 82786, "start": 847.74, "end": 855.22, "text": " son los que escribimos, esta es la soluci\u00f3n del ejercicio, los sistemas de traducci\u00f3n basados en", "tokens": [51358, 1872, 1750, 631, 30598, 65, 8372, 11, 5283, 785, 635, 24807, 5687, 1103, 39151, 18322, 11, 1750, 48720, 368, 2479, 1311, 5687, 987, 4181, 465, 51732], "temperature": 0.0, "avg_logprob": -0.1798399112842701, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.004000943154096603}, {"id": 152, "seek": 85522, "start": 855.22, "end": 860.38, "text": " s\u00edntaxis, en realidad los sistemas de traducciones de reglas, en s\u00edntaxis hacen esto a alto", "tokens": [50364, 8600, 580, 24633, 11, 465, 25635, 1750, 48720, 368, 2479, 1311, 23469, 368, 1121, 7743, 11, 465, 8600, 580, 24633, 27434, 7433, 257, 21275, 50622], "temperature": 0.0, "avg_logprob": -0.25527641468478324, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.0008090037736110389}, {"id": 153, "seek": 85522, "start": 860.38, "end": 864.86, "text": " nivel, digamos, tienen montones de pared de \u00e1rboles, hay gente que los analiza y escriba reglas", "tokens": [50622, 24423, 11, 36430, 11, 12536, 8143, 2213, 368, 280, 1642, 368, 35349, 65, 7456, 11, 4842, 3788, 631, 1750, 2624, 13427, 288, 30598, 4231, 1121, 7743, 50846], "temperature": 0.0, "avg_logprob": -0.25527641468478324, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.0008090037736110389}, {"id": 154, "seek": 85522, "start": 864.86, "end": 870.6600000000001, "text": " como se transforma uno en el otro, a veces las reglas son complicadas porque se pueden superponer,", "tokens": [50846, 2617, 369, 4088, 64, 8526, 465, 806, 11921, 11, 257, 17054, 2439, 1121, 7743, 1872, 16060, 6872, 4021, 369, 14714, 1687, 79, 32949, 11, 51136], "temperature": 0.0, "avg_logprob": -0.25527641468478324, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.0008090037736110389}, {"id": 155, "seek": 85522, "start": 870.6600000000001, "end": 875.9, "text": " entonces hay que definir prioridades y ese tipo de cosas, bueno, esas transferencias", "tokens": [51136, 13003, 4842, 631, 1561, 347, 4059, 10284, 288, 10167, 9746, 368, 12218, 11, 11974, 11, 23388, 5003, 37246, 51398], "temperature": 0.0, "avg_logprob": -0.25527641468478324, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.0008090037736110389}, {"id": 156, "seek": 85522, "start": 875.9, "end": 881.4200000000001, "text": " sint\u00e1cticas, si seguimos subiendo en el tri\u00e1ngulo de bocua, llegamos a lo que es la transferencia", "tokens": [51398, 41259, 842, 349, 9150, 11, 1511, 8878, 8372, 1422, 7304, 465, 806, 1376, 30344, 13455, 368, 748, 66, 4398, 11, 11234, 2151, 257, 450, 631, 785, 635, 5003, 10974, 51674], "temperature": 0.0, "avg_logprob": -0.25527641468478324, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.0008090037736110389}, {"id": 157, "seek": 88142, "start": 881.42, "end": 886.0999999999999, "text": " sem\u00e1ntica, tal vez es sem\u00e1ntica uno puede pensarla un poco como lo que hab\u00edamos en la clase", "tokens": [50364, 4361, 27525, 2262, 11, 4023, 5715, 785, 4361, 27525, 2262, 8526, 8919, 18321, 875, 517, 10639, 2617, 450, 631, 3025, 16275, 465, 635, 44578, 50598], "temperature": 0.0, "avg_logprob": -0.2516431599637888, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008617333136498928}, {"id": 158, "seek": 88142, "start": 886.0999999999999, "end": 891.18, "text": " pasada, utilizando roles sem\u00e1nticos, yo tengo un etiquetador de roles sem\u00e1nticos, que agarra", "tokens": [50598, 1736, 1538, 11, 19906, 1806, 9604, 4361, 27525, 9940, 11, 5290, 13989, 517, 42177, 302, 5409, 368, 9604, 4361, 27525, 9940, 11, 631, 623, 289, 424, 50852], "temperature": 0.0, "avg_logprob": -0.2516431599637888, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008617333136498928}, {"id": 159, "seek": 88142, "start": 891.18, "end": 896.2199999999999, "text": " la relaci\u00f3n Juan fue a la tienda y me devuelve los roles de los constituyentes, me dice que Juan", "tokens": [50852, 635, 37247, 17064, 9248, 257, 635, 256, 30498, 288, 385, 1905, 3483, 303, 1750, 9604, 368, 1750, 16085, 88, 9240, 11, 385, 10313, 631, 17064, 51104], "temperature": 0.0, "avg_logprob": -0.2516431599637888, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008617333136498928}, {"id": 160, "seek": 88142, "start": 896.2199999999999, "end": 902.8199999999999, "text": " es el agente y a la tienda es el objetivo o goal, digamos, es el nombre del rol, entonces yo,", "tokens": [51104, 785, 806, 623, 1576, 288, 257, 635, 256, 30498, 785, 806, 29809, 277, 3387, 11, 36430, 11, 785, 806, 13000, 1103, 34109, 11, 13003, 5290, 11, 51434], "temperature": 0.0, "avg_logprob": -0.2516431599637888, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008617333136498928}, {"id": 161, "seek": 88142, "start": 902.8199999999999, "end": 908.3, "text": " para ciertos idiomas podr\u00edas escribir reglas m\u00e1s espec\u00edficas, por ejemplo, en chino ocurre que", "tokens": [51434, 1690, 49252, 329, 18014, 7092, 15305, 10025, 30598, 10119, 1121, 7743, 3573, 32741, 296, 11, 1515, 13358, 11, 465, 417, 2982, 26430, 265, 631, 51708], "temperature": 0.0, "avg_logprob": -0.2516431599637888, "compression_ratio": 1.704626334519573, "no_speech_prob": 0.008617333136498928}, {"id": 162, "seek": 90830, "start": 908.3, "end": 912.74, "text": " los sint\u00e1mas propulsionales, que son de tipo objetivo, se escriben antes del largo, pero los", "tokens": [50364, 1750, 41259, 842, 3799, 2365, 9468, 1966, 279, 11, 631, 1872, 368, 9746, 14964, 6340, 11, 369, 30598, 1799, 11014, 1103, 31245, 11, 4768, 1750, 50586], "temperature": 0.0, "avg_logprob": -0.21651869446691804, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.007834288291633129}, {"id": 163, "seek": 90830, "start": 912.74, "end": 917.4599999999999, "text": " dem\u00e1s sint\u00e1mas propulsionales escriben despu\u00e9s, o sea, el chino es un lenguaje de tipo SBO igual que", "tokens": [50586, 34682, 41259, 842, 3799, 2365, 9468, 1966, 279, 30598, 1799, 15283, 11, 277, 4158, 11, 806, 417, 2982, 785, 517, 35044, 84, 11153, 368, 9746, 318, 15893, 10953, 631, 50822], "temperature": 0.0, "avg_logprob": -0.21651869446691804, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.007834288291633129}, {"id": 164, "seek": 90830, "start": 917.4599999999999, "end": 924.38, "text": " el ingl\u00e9s o el espa\u00f1ol, pero cuando el objeto es de tipo goal lo que hacen es ponerlo antes del", "tokens": [50822, 806, 49766, 277, 806, 31177, 11, 4768, 7767, 806, 40438, 785, 368, 9746, 3387, 450, 631, 27434, 785, 19149, 752, 11014, 1103, 51168], "temperature": 0.0, "avg_logprob": -0.21651869446691804, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.007834288291633129}, {"id": 165, "seek": 90830, "start": 924.38, "end": 930.5799999999999, "text": " largo, entonces yo podr\u00eda escribir una regla un poco m\u00e1s expresiva, para este caso del chino,", "tokens": [51168, 31245, 11, 13003, 5290, 27246, 30598, 10119, 2002, 1121, 875, 517, 10639, 3573, 33397, 5931, 11, 1690, 4065, 9666, 1103, 417, 2982, 11, 51478], "temperature": 0.0, "avg_logprob": -0.21651869446691804, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.007834288291633129}, {"id": 166, "seek": 90830, "start": 930.5799999999999, "end": 937.02, "text": " si yo tuviera los roles sem\u00e1nticos, yo dir\u00eda que un grupo verbal es un verbo seguido de esto,", "tokens": [51478, 1511, 5290, 38177, 10609, 1750, 9604, 4361, 27525, 9940, 11, 5290, 4746, 2686, 631, 517, 20190, 24781, 785, 517, 1306, 1763, 8878, 2925, 368, 7433, 11, 51800], "temperature": 0.0, "avg_logprob": -0.21651869446691804, "compression_ratio": 1.770909090909091, "no_speech_prob": 0.007834288291633129}, {"id": 167, "seek": 93702, "start": 937.02, "end": 942.6999999999999, "text": " esto no est\u00e1 tachado, sino que era la barrita que qued\u00f3 arriba, es un verbo seguido de un grupo", "tokens": [50364, 7433, 572, 3192, 256, 608, 1573, 11, 18108, 631, 4249, 635, 38236, 2786, 631, 13617, 812, 28469, 11, 785, 517, 1306, 1763, 8878, 2925, 368, 517, 20190, 50648], "temperature": 0.0, "avg_logprob": -0.24932730288905952, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.005846530199050903}, {"id": 168, "seek": 93702, "start": 942.6999999999999, "end": 948.46, "text": " proporcional de tipo goal, en chino lo cambiar\u00eda por un verbo seguido de un verbo, por un grupo", "tokens": [50648, 2365, 36003, 1966, 368, 9746, 3387, 11, 465, 417, 2982, 450, 19569, 21178, 1515, 517, 1306, 1763, 8878, 2925, 368, 517, 1306, 1763, 11, 1515, 517, 20190, 50936], "temperature": 0.0, "avg_logprob": -0.24932730288905952, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.005846530199050903}, {"id": 169, "seek": 93702, "start": 948.46, "end": 954.6999999999999, "text": " proporcional de tipo goal seguido de un verbo, es m\u00e1s costoso para generar y para parcear,", "tokens": [50936, 2365, 36003, 1966, 368, 9746, 3387, 8878, 2925, 368, 517, 1306, 1763, 11, 785, 3573, 2063, 9869, 1690, 1337, 289, 288, 1690, 971, 384, 289, 11, 51248], "temperature": 0.0, "avg_logprob": -0.24932730288905952, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.005846530199050903}, {"id": 170, "seek": 93702, "start": 954.6999999999999, "end": 958.34, "text": " digamos, necesito tener m\u00e1s esfuerzo de parcin y m\u00e1s esfuerzo de generaci\u00f3n, pero puedes", "tokens": [51248, 36430, 11, 11909, 3528, 11640, 3573, 49213, 4765, 368, 971, 20021, 288, 3573, 49213, 4765, 368, 1337, 3482, 11, 4768, 19010, 51430], "temperature": 0.0, "avg_logprob": -0.24932730288905952, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.005846530199050903}, {"id": 171, "seek": 93702, "start": 958.34, "end": 962.1, "text": " escribir mejores reglas que capturan ciertas particularidades de los lenguajes,", "tokens": [51430, 30598, 10119, 42284, 1121, 7743, 631, 3770, 12125, 49252, 296, 1729, 10284, 368, 1750, 35044, 84, 29362, 11, 51618], "temperature": 0.0, "avg_logprob": -0.24932730288905952, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.005846530199050903}, {"id": 172, "seek": 96210, "start": 962.1, "end": 967.74, "text": " y si yo sigo subiendo en el tri\u00e1ngulo llego a lo que se conoce como interlingua,", "tokens": [50364, 288, 1511, 5290, 4556, 78, 1422, 7304, 465, 806, 1376, 30344, 13455, 4849, 6308, 257, 450, 631, 369, 33029, 384, 2617, 728, 1688, 4398, 11, 50646], "temperature": 0.0, "avg_logprob": -0.223365966796875, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.08446035534143448}, {"id": 173, "seek": 96210, "start": 967.74, "end": 971.98, "text": " cu\u00e1l es la gracia de interlingua, cu\u00e1l es la idea, esto sirve si nosotros estamos en un", "tokens": [50646, 44318, 785, 635, 11625, 654, 368, 728, 1688, 4398, 11, 44318, 785, 635, 1558, 11, 7433, 4735, 303, 1511, 13863, 10382, 465, 517, 50858], "temperature": 0.0, "avg_logprob": -0.223365966796875, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.08446035534143448}, {"id": 174, "seek": 96210, "start": 971.98, "end": 976.82, "text": " contexto multicultural, estamos trabajando, por ejemplo, en la ONU o en el Palamento Europeo,", "tokens": [50858, 47685, 47684, 11, 10382, 40473, 11, 1515, 13358, 11, 465, 635, 9299, 52, 277, 465, 806, 6116, 8824, 3315, 78, 11, 51100], "temperature": 0.0, "avg_logprob": -0.223365966796875, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.08446035534143448}, {"id": 175, "seek": 96210, "start": 976.82, "end": 981.9, "text": " o algo de eso donde se hablan muchos idiomas, si yo quiero mantener un mont\u00f3n de documentos", "tokens": [51100, 277, 8655, 368, 7287, 10488, 369, 3025, 8658, 17061, 18014, 7092, 11, 1511, 5290, 16811, 42759, 517, 45259, 368, 4166, 329, 51354], "temperature": 0.0, "avg_logprob": -0.223365966796875, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.08446035534143448}, {"id": 176, "seek": 96210, "start": 981.9, "end": 986.3000000000001, "text": " que est\u00e9n en todos los idiomas a la vez, voy a necesitar para los sistemas que estuve en", "tokens": [51354, 631, 871, 3516, 465, 6321, 1750, 18014, 7092, 257, 635, 5715, 11, 7552, 257, 11909, 3981, 1690, 1750, 48720, 631, 871, 31564, 465, 51574], "temperature": 0.0, "avg_logprob": -0.223365966796875, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.08446035534143448}, {"id": 177, "seek": 98630, "start": 986.3, "end": 991.4599999999999, "text": " nuestro momento, voy a necesitar tener N parsers, uno para cada idioma, N generadores,", "tokens": [50364, 14726, 9333, 11, 7552, 257, 11909, 3981, 11640, 426, 21156, 433, 11, 8526, 1690, 8411, 18014, 6440, 11, 426, 1337, 11856, 11, 50622], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 178, "seek": 98630, "start": 991.4599999999999, "end": 995.54, "text": " tambi\u00e9n uno para cada idioma, y despu\u00e9s para cada par de idiomas, voy a necesitar reglas", "tokens": [50622, 6407, 8526, 1690, 8411, 18014, 6440, 11, 288, 15283, 1690, 8411, 971, 368, 18014, 7092, 11, 7552, 257, 11909, 3981, 1121, 7743, 50826], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 179, "seek": 98630, "start": 995.54, "end": 1000.14, "text": " de transferencia, entonces voy a necesitar tener en total N por N menos 1, 7 de transferencia,", "tokens": [50826, 368, 5003, 10974, 11, 13003, 7552, 257, 11909, 3981, 11640, 465, 3217, 426, 1515, 426, 8902, 502, 11, 1614, 368, 5003, 10974, 11, 51056], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 180, "seek": 98630, "start": 1000.14, "end": 1005.78, "text": " yo tengo 20 idiomas, voy a necesitar 380 conjuntos de reglas de transferencia, y esos", "tokens": [51056, 5290, 13989, 945, 18014, 7092, 11, 7552, 257, 11909, 3981, 805, 4702, 20295, 2760, 329, 368, 1121, 7743, 368, 5003, 10974, 11, 288, 22411, 51338], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 181, "seek": 98630, "start": 1005.78, "end": 1009.38, "text": " conjuntos de reglas de transferencia son largos, son grandes, son complejos, hay que mantener", "tokens": [51338, 20295, 2760, 329, 368, 1121, 7743, 368, 5003, 10974, 1872, 11034, 329, 11, 1872, 16640, 11, 1872, 44424, 19136, 11, 4842, 631, 42759, 51518], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 182, "seek": 98630, "start": 1009.38, "end": 1015.06, "text": " los, pueden tener errores, entonces esto claramente no es cala, es como muy dif\u00edcil poder mantener", "tokens": [51518, 1750, 11, 14714, 11640, 45935, 495, 11, 13003, 7433, 6093, 3439, 572, 785, 2104, 64, 11, 785, 2617, 5323, 17258, 8152, 42759, 51802], "temperature": 0.0, "avg_logprob": -0.22880844116210938, "compression_ratio": 2.1312741312741315, "no_speech_prob": 0.08101534098386765}, {"id": 183, "seek": 101506, "start": 1015.06, "end": 1018.9399999999999, "text": " un entorno de todos esos idiomas y poder mandar la traducci\u00f3n en base a reglas, entonces", "tokens": [50364, 517, 948, 21998, 368, 6321, 22411, 18014, 7092, 288, 8152, 48689, 635, 2479, 1311, 5687, 465, 3096, 257, 1121, 7743, 11, 13003, 50558], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 184, "seek": 101506, "start": 1018.9399999999999, "end": 1025.74, "text": " la idea del interlingua es decir, \u00bfqu\u00e9 tal si pudi\u00e9ramos parcear lo suficiente o analizar", "tokens": [50558, 635, 1558, 1103, 728, 1688, 4398, 785, 10235, 11, 3841, 16412, 4023, 1511, 14166, 72, 4198, 2151, 971, 384, 289, 450, 33958, 277, 2624, 9736, 50898], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 185, "seek": 101506, "start": 1025.74, "end": 1030.54, "text": " lo suficiente como para llevar a una representaci\u00f3n com\u00fan, una representaci\u00f3n que captur\u00e9 el significado", "tokens": [50898, 450, 33958, 2617, 1690, 30374, 257, 2002, 2906, 3482, 45448, 11, 2002, 2906, 3482, 631, 3770, 374, 526, 806, 3350, 1573, 51138], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 186, "seek": 101506, "start": 1030.54, "end": 1036.54, "text": " de todos los idiomas a la vez, y adem\u00e1s tuvieramos un generador para cada uno de los idiomas.", "tokens": [51138, 368, 6321, 1750, 18014, 7092, 257, 635, 5715, 11, 288, 21251, 38177, 811, 2151, 517, 1337, 5409, 1690, 8411, 8526, 368, 1750, 18014, 7092, 13, 51438], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 187, "seek": 101506, "start": 1036.54, "end": 1040.74, "text": " Si eso pasara, si nosotros pudi\u00e9ramos capturar con una representaci\u00f3n el significado de todos", "tokens": [51438, 4909, 7287, 1736, 2419, 11, 1511, 13863, 14166, 72, 4198, 2151, 3770, 28586, 416, 2002, 2906, 3482, 806, 3350, 1573, 368, 6321, 51648], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 188, "seek": 101506, "start": 1040.74, "end": 1044.3799999999999, "text": " los idiomas a la vez, no necesitar\u00edamos transferencias, simplemente parceamos y llevamos", "tokens": [51648, 1750, 18014, 7092, 257, 635, 5715, 11, 572, 11909, 3981, 16275, 5003, 37246, 11, 33190, 971, 384, 2151, 288, 27124, 2151, 51830], "temperature": 0.0, "avg_logprob": -0.1891899617513021, "compression_ratio": 1.9522184300341296, "no_speech_prob": 0.010246430523693562}, {"id": 189, "seek": 104438, "start": 1044.38, "end": 1050.18, "text": " a esa interlingua y despu\u00e9s generamos en el otro idioma. Esto est\u00e1 muy bien, digamos,", "tokens": [50364, 257, 11342, 728, 1688, 4398, 288, 15283, 1337, 2151, 465, 806, 11921, 18014, 6440, 13, 20880, 3192, 5323, 3610, 11, 36430, 11, 50654], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 190, "seek": 104438, "start": 1050.18, "end": 1056.46, "text": " del punto de vista ideal, pero es muy dif\u00edcil obtener la pr\u00e1ctica. \u00bfQu\u00e9 se podr\u00eda usar", "tokens": [50654, 1103, 14326, 368, 22553, 7157, 11, 4768, 785, 5323, 17258, 28326, 260, 635, 27300, 29041, 13, 3841, 15137, 369, 27246, 14745, 50968], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 191, "seek": 104438, "start": 1056.46, "end": 1060.38, "text": " como representaci\u00f3n de interlingua? \u00bfQu\u00e9 podr\u00eda hacer un candidato? Bueno, podr\u00edamos", "tokens": [50968, 2617, 2906, 3482, 368, 728, 1688, 4398, 30, 3841, 15137, 27246, 6720, 517, 6268, 2513, 30, 16046, 11, 15305, 16275, 51164], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 192, "seek": 104438, "start": 1060.38, "end": 1064.8600000000001, "text": " usar la l\u00f3gica de primer orden, que era lo que ve\u00edamos en las primeras clases de sem\u00e1ntica,", "tokens": [51164, 14745, 635, 48475, 2262, 368, 12595, 28615, 11, 631, 4249, 450, 631, 1241, 16275, 465, 2439, 2886, 6985, 596, 1957, 368, 4361, 27525, 2262, 11, 51388], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 193, "seek": 104438, "start": 1064.8600000000001, "end": 1068.3400000000001, "text": " como representar variaciones en la l\u00f3gica de primer orden, o alguna de sus variantes", "tokens": [51388, 2617, 2906, 289, 3034, 9188, 465, 635, 48475, 2262, 368, 12595, 28615, 11, 277, 20651, 368, 3291, 3034, 9327, 51562], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 194, "seek": 104438, "start": 1068.3400000000001, "end": 1072.3000000000002, "text": " que da un cuenta mejor de lo que es la l\u00f3gica de la lengua genatural, como las m\u00ednimos", "tokens": [51562, 631, 1120, 517, 17868, 11479, 368, 450, 631, 785, 635, 48475, 2262, 368, 635, 35044, 4398, 1049, 267, 1807, 11, 2617, 2439, 33656, 8372, 51760], "temperature": 0.0, "avg_logprob": -0.22523527474238955, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0012263880344107747}, {"id": 195, "seek": 107230, "start": 1072.3, "end": 1076.4199999999998, "text": " con recursos sem\u00e1nticos o las whole sem\u00e1nticos. O si no, hay como parecido lo que ve\u00edamos", "tokens": [50364, 416, 30409, 4361, 27525, 9940, 277, 2439, 1379, 4361, 27525, 9940, 13, 422, 1511, 572, 11, 4842, 2617, 7448, 17994, 450, 631, 1241, 16275, 50570], "temperature": 0.0, "avg_logprob": -0.34641754150390625, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.17003987729549408}, {"id": 196, "seek": 107230, "start": 1076.4199999999998, "end": 1081.54, "text": " en la clase anterior de frames, construirme frames con el estado de las cosas, como por ejemplo", "tokens": [50570, 465, 635, 44578, 22272, 368, 12083, 11, 38445, 1398, 12083, 416, 806, 18372, 368, 2439, 12218, 11, 2617, 1515, 13358, 50826], "temperature": 0.0, "avg_logprob": -0.34641754150390625, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.17003987729549408}, {"id": 197, "seek": 107230, "start": 1081.54, "end": 1085.02, "text": " est\u00e1 la misma operaci\u00f3n de hoy, Mary didn't slap the green witch, pero es crita como", "tokens": [50826, 3192, 635, 24946, 2208, 3482, 368, 13775, 11, 6059, 994, 380, 21075, 264, 3092, 14867, 11, 4768, 785, 941, 2786, 2617, 51000], "temperature": 0.0, "avg_logprob": -0.34641754150390625, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.17003987729549408}, {"id": 198, "seek": 107230, "start": 1085.02, "end": 1089.94, "text": " un frame, es hay un evento de slapping, la gente es Mary, ocurre en pasado, la polaridad", "tokens": [51000, 517, 3920, 11, 785, 4842, 517, 40655, 368, 8039, 3759, 11, 635, 3788, 785, 6059, 11, 26430, 265, 465, 24794, 11, 635, 12367, 4580, 51246], "temperature": 0.0, "avg_logprob": -0.34641754150390625, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.17003987729549408}, {"id": 199, "seek": 107230, "start": 1089.94, "end": 1095.18, "text": " negativa, el tema de ese evento es la bruja y la bruja de m\u00e1s es verde. Yo podr\u00eda construir", "tokens": [51246, 2485, 18740, 11, 806, 15854, 368, 10167, 40655, 785, 635, 25267, 2938, 288, 635, 25267, 2938, 368, 3573, 785, 29653, 13, 7616, 27246, 38445, 51508], "temperature": 0.0, "avg_logprob": -0.34641754150390625, "compression_ratio": 1.6715328467153285, "no_speech_prob": 0.17003987729549408}, {"id": 200, "seek": 109518, "start": 1095.18, "end": 1104.74, "text": " este tipo de frames y usarlos como representaciones. Pero bueno, hay problema que tiene crear o", "tokens": [50364, 4065, 9746, 368, 12083, 288, 14745, 9389, 2617, 2906, 9188, 13, 9377, 11974, 11, 4842, 12395, 631, 7066, 31984, 277, 50842], "temperature": 0.0, "avg_logprob": -0.25243687373335644, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.04471305385231972}, {"id": 201, "seek": 109518, "start": 1104.74, "end": 1109.18, "text": " pensar en crear una interlingua, es que esa interlingua seguro que va a ser muy compleja", "tokens": [50842, 18321, 465, 31984, 2002, 728, 1688, 4398, 11, 785, 631, 11342, 728, 1688, 4398, 31424, 631, 2773, 257, 816, 5323, 44424, 2938, 51064], "temperature": 0.0, "avg_logprob": -0.25243687373335644, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.04471305385231972}, {"id": 202, "seek": 109518, "start": 1109.18, "end": 1114.38, "text": " y seguro que va a tener que modelar las caracter\u00edsticas de todos los idiomas al mismo tiempo. Y hay", "tokens": [51064, 288, 31424, 631, 2773, 257, 11640, 631, 2316, 289, 2439, 47990, 368, 6321, 1750, 18014, 7092, 419, 12461, 11772, 13, 398, 4842, 51324], "temperature": 0.0, "avg_logprob": -0.25243687373335644, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.04471305385231972}, {"id": 203, "seek": 109518, "start": 1114.38, "end": 1121.1000000000001, "text": " caracter\u00edsticas que son complicadas en los distintos idiomas, y algunas que ni nos imaginamos,", "tokens": [51324, 47990, 631, 1872, 16060, 6872, 465, 1750, 49337, 18014, 7092, 11, 288, 27316, 631, 3867, 3269, 23427, 2151, 11, 51660], "temperature": 0.0, "avg_logprob": -0.25243687373335644, "compression_ratio": 1.731818181818182, "no_speech_prob": 0.04471305385231972}, {"id": 204, "seek": 112110, "start": 1121.1, "end": 1126.02, "text": " o sea, por ejemplo, en chino existen palabras distintas para decir hermano mayor y hermano", "tokens": [50364, 277, 4158, 11, 1515, 13358, 11, 465, 417, 2982, 2514, 268, 35240, 31489, 296, 1690, 10235, 39458, 78, 10120, 288, 39458, 78, 50610], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 205, "seek": 112110, "start": 1126.02, "end": 1129.4199999999998, "text": " menor, y no hay una palabra para decir hermano. O sea, no hay una palabra que quiera decir", "tokens": [50610, 26343, 11, 288, 572, 4842, 2002, 31702, 1690, 10235, 39458, 78, 13, 422, 4158, 11, 572, 4842, 2002, 31702, 631, 421, 10609, 10235, 50780], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 206, "seek": 112110, "start": 1129.4199999999998, "end": 1134.74, "text": " solamente hermano. En espa\u00f1ol s\u00ed, y en ingl\u00e9s tambi\u00e9n, en ingl\u00e9s puede decir brado, pero", "tokens": [50780, 27814, 39458, 78, 13, 2193, 31177, 8600, 11, 288, 465, 49766, 6407, 11, 465, 49766, 8919, 10235, 738, 1573, 11, 4768, 51046], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 207, "seek": 112110, "start": 1134.74, "end": 1137.5, "text": " en chino no, en chino tienes que elegir cuando vas a decir hermano, si es hermano mayor", "tokens": [51046, 465, 417, 2982, 572, 11, 465, 417, 2982, 20716, 631, 14459, 347, 7767, 11481, 257, 10235, 39458, 78, 11, 1511, 785, 39458, 78, 10120, 51184], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 208, "seek": 112110, "start": 1137.5, "end": 1142.74, "text": " o hermano menor. Entonces, imag\u00ednense que si yo estoy traduciendo del espa\u00f1ol al ingl\u00e9s", "tokens": [51184, 277, 39458, 78, 26343, 13, 15097, 11, 2576, 10973, 1288, 631, 1511, 5290, 15796, 2479, 1311, 7304, 1103, 31177, 419, 49766, 51446], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 209, "seek": 112110, "start": 1142.74, "end": 1147.82, "text": " y estoy utilizando una interlingua, la interlingua en su parcer necesita poder distinguir en", "tokens": [51446, 288, 15796, 19906, 1806, 2002, 728, 1688, 4398, 11, 635, 728, 1688, 4398, 465, 459, 971, 1776, 45485, 8152, 11365, 347, 465, 51700], "temperature": 0.0, "avg_logprob": -0.22971305068658324, "compression_ratio": 1.9818840579710144, "no_speech_prob": 0.07496241480112076}, {"id": 210, "seek": 114782, "start": 1147.8999999999999, "end": 1151.34, "text": " alg\u00fan momento, si estoy hablando de un hermano mayor o un hermano menor, porque tiene que", "tokens": [50368, 26300, 9333, 11, 1511, 15796, 29369, 368, 517, 39458, 78, 10120, 277, 517, 39458, 78, 26343, 11, 4021, 7066, 631, 50540], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 211, "seek": 114782, "start": 1151.34, "end": 1155.6599999999999, "text": " lograr la representaci\u00f3n suficiente como para poder traducir al chino. Entonces, necesita", "tokens": [50540, 31013, 289, 635, 2906, 3482, 33958, 2617, 1690, 8152, 2479, 1311, 347, 419, 417, 2982, 13, 15097, 11, 11909, 2786, 50756], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 212, "seek": 114782, "start": 1155.6599999999999, "end": 1158.9399999999998, "text": " esa informaci\u00f3n y no s\u00e9 d\u00f3nde la va a sacar, la puedes sacar de contexto, lo puedes sacar", "tokens": [50756, 11342, 21660, 288, 572, 7910, 34264, 635, 2773, 257, 43823, 11, 635, 19010, 43823, 368, 47685, 11, 450, 19010, 43823, 50920], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 213, "seek": 114782, "start": 1158.9399999999998, "end": 1163.54, "text": " inventar de alg\u00fan lado, pero en alg\u00fan momento va a tener que averiguar el hermano que se", "tokens": [50920, 7962, 289, 368, 26300, 11631, 11, 4768, 465, 26300, 9333, 2773, 257, 11640, 631, 18247, 16397, 289, 806, 39458, 78, 631, 369, 51150], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 214, "seek": 114782, "start": 1163.54, "end": 1167.78, "text": " est\u00e1 hablando en espa\u00f1ol, si es un hermano mayor o menor, como para poder tener la representaci\u00f3n,", "tokens": [51150, 3192, 29369, 465, 31177, 11, 1511, 785, 517, 39458, 78, 10120, 277, 26343, 11, 2617, 1690, 8152, 11640, 635, 2906, 3482, 11, 51362], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 215, "seek": 114782, "start": 1167.78, "end": 1171.7, "text": " y despu\u00e9s esa informaci\u00f3n se va a perder, porque cuando baja de vuelta, al lado del ingl\u00e9s,", "tokens": [51362, 288, 15283, 11342, 21660, 369, 2773, 257, 26971, 11, 4021, 7767, 49427, 368, 41542, 11, 419, 11631, 1103, 49766, 11, 51558], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 216, "seek": 114782, "start": 1171.7, "end": 1176.3, "text": " de vuelta vuelve a ser brada y no importa si es mayor o menor. Y esto es solamente un caso", "tokens": [51558, 368, 41542, 20126, 303, 257, 816, 738, 1538, 288, 572, 33218, 1511, 785, 10120, 277, 26343, 13, 398, 7433, 785, 27814, 517, 9666, 51788], "temperature": 0.0, "avg_logprob": -0.19007218249736388, "compression_ratio": 1.960960960960961, "no_speech_prob": 0.021882764995098114}, {"id": 217, "seek": 117630, "start": 1176.3, "end": 1180.6599999999999, "text": " de un fen\u00f3meno que ocurre en chino, pero, imag\u00ednense, los fen\u00f3menos que ocurren en el idioma", "tokens": [50364, 368, 517, 26830, 812, 43232, 631, 26430, 265, 465, 417, 2982, 11, 4768, 11, 2576, 10973, 1288, 11, 1750, 26830, 812, 2558, 329, 631, 26430, 1095, 465, 806, 18014, 6440, 50582], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 218, "seek": 117630, "start": 1180.6599999999999, "end": 1186.74, "text": " en todo el tiempo, digamos, y todas las peque\u00f1as variantes que hay. Y como en realidad,", "tokens": [50582, 465, 5149, 806, 11772, 11, 36430, 11, 288, 10906, 2439, 19132, 32448, 3034, 9327, 631, 4842, 13, 398, 2617, 465, 25635, 11, 50886], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 219, "seek": 117630, "start": 1186.74, "end": 1191.1, "text": " no es cierto que podamos traducir exactamente lo mismo conceptos, como que es muy dif\u00edcil", "tokens": [50886, 572, 785, 28558, 631, 2497, 2151, 2479, 1311, 347, 48686, 450, 12461, 3410, 329, 11, 2617, 631, 785, 5323, 17258, 51104], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 220, "seek": 117630, "start": 1191.1, "end": 1195.1, "text": " encontrar conceptos que se correspondan 100% en idioma y otro. Hay una cosa que se llama", "tokens": [51104, 17525, 3410, 329, 631, 369, 6805, 282, 2319, 4, 465, 18014, 6440, 288, 11921, 13, 8721, 2002, 10163, 631, 369, 23272, 51304], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 221, "seek": 117630, "start": 1195.1, "end": 1198.62, "text": " el principio de incertidumbre de la traducci\u00f3n y dice eso, que en realidad, cuando yo tengo", "tokens": [51304, 806, 34308, 368, 834, 911, 327, 449, 2672, 368, 635, 2479, 1311, 5687, 288, 10313, 7287, 11, 631, 465, 25635, 11, 7767, 5290, 13989, 51480], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 222, "seek": 117630, "start": 1198.62, "end": 1202.7, "text": " un idioma y otro, los conceptos no siempre se van a traducir 100% bien, o sea, no siempre", "tokens": [51480, 517, 18014, 6440, 288, 11921, 11, 1750, 3410, 329, 572, 12758, 369, 3161, 257, 2479, 1311, 347, 2319, 4, 3610, 11, 277, 4158, 11, 572, 12758, 51684], "temperature": 0.0, "avg_logprob": -0.2112006655164585, "compression_ratio": 1.775974025974026, "no_speech_prob": 0.08635727316141129}, {"id": 223, "seek": 120270, "start": 1203.7, "end": 1207.5, "text": " la traducci\u00f3n es exacta, sino que hay cierto suelopamiento y a veces se va a funcionar y a veces no.", "tokens": [50414, 635, 2479, 1311, 5687, 785, 1900, 64, 11, 18108, 631, 4842, 28558, 459, 338, 404, 16971, 288, 257, 17054, 369, 2773, 257, 14186, 289, 288, 257, 17054, 572, 13, 50604], "temperature": 0.0, "avg_logprob": -0.26927193999290466, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.04223523661494255}, {"id": 224, "seek": 120270, "start": 1210.7, "end": 1216.66, "text": " Bien, pero a pesar de que es una utop\u00eda, tener un interlingo que funcione para todos los", "tokens": [50764, 16956, 11, 4768, 257, 41951, 368, 631, 785, 2002, 2839, 404, 2686, 11, 11640, 517, 728, 1688, 78, 631, 1019, 66, 5328, 1690, 6321, 1750, 51062], "temperature": 0.0, "avg_logprob": -0.26927193999290466, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.04223523661494255}, {"id": 225, "seek": 120270, "start": 1216.66, "end": 1220.9, "text": " lenguajes bien, este tipo de tecnolog\u00eda s\u00ed se utilizan para dominios m\u00e1s acotados, para", "tokens": [51062, 35044, 84, 29362, 3610, 11, 4065, 9746, 368, 48055, 8600, 369, 19906, 282, 1690, 8859, 2717, 3573, 696, 310, 4181, 11, 1690, 51274], "temperature": 0.0, "avg_logprob": -0.26927193999290466, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.04223523661494255}, {"id": 226, "seek": 120270, "start": 1220.9, "end": 1225.54, "text": " dominios peque\u00f1os, como por ejemplo, el de meteorolog\u00eda, yo puedo escribir perfectamente,", "tokens": [51274, 8859, 2717, 19132, 8242, 11, 2617, 1515, 13358, 11, 806, 368, 25313, 29987, 11, 5290, 21612, 30598, 10119, 2176, 3439, 11, 51506], "temperature": 0.0, "avg_logprob": -0.26927193999290466, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.04223523661494255}, {"id": 227, "seek": 120270, "start": 1225.54, "end": 1229.22, "text": " puedo construir una representaci\u00f3n de todos los estados meteorol\u00f3gicos que hay, y si hay", "tokens": [51506, 21612, 38445, 2002, 2906, 3482, 368, 6321, 1750, 871, 4181, 25313, 27629, 9940, 631, 4842, 11, 288, 1511, 4842, 51690], "temperature": 0.0, "avg_logprob": -0.26927193999290466, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.04223523661494255}, {"id": 228, "seek": 122922, "start": 1229.74, "end": 1235.74, "text": " lluvias y nievas, y hay granizo, la temperatura, la presi\u00f3n, etc. y traducirlo a las distintas", "tokens": [50390, 4849, 9350, 4609, 288, 2838, 7967, 11, 288, 4842, 9370, 19055, 11, 635, 36903, 11, 635, 1183, 2560, 11, 5183, 13, 288, 2479, 1311, 347, 752, 257, 2439, 31489, 296, 50690], "temperature": 0.0, "avg_logprob": -0.2882268726825714, "compression_ratio": 1.6350877192982456, "no_speech_prob": 0.019607920199632645}, {"id": 229, "seek": 122922, "start": 1235.74, "end": 1239.8600000000001, "text": " palabras, que son los distintos idiomas para dar cuenta de estos conceptos. Entonces, ese", "tokens": [50690, 35240, 11, 631, 1872, 1750, 49337, 18014, 7092, 1690, 4072, 17868, 368, 12585, 3410, 329, 13, 15097, 11, 10167, 50896], "temperature": 0.0, "avg_logprob": -0.2882268726825714, "compression_ratio": 1.6350877192982456, "no_speech_prob": 0.019607920199632645}, {"id": 230, "seek": 122922, "start": 1239.8600000000001, "end": 1244.94, "text": " dominio acotado es bastante bien manejable con una interlingua. Y otro ejemplo son los manuales", "tokens": [50896, 8859, 1004, 696, 310, 1573, 785, 14651, 3610, 12743, 73, 712, 416, 2002, 728, 1688, 4398, 13, 398, 11921, 13358, 1872, 1750, 9688, 279, 51150], "temperature": 0.0, "avg_logprob": -0.2882268726825714, "compression_ratio": 1.6350877192982456, "no_speech_prob": 0.019607920199632645}, {"id": 231, "seek": 122922, "start": 1244.94, "end": 1250.34, "text": " t\u00e9cnicos, hay empresas que, de un mont\u00f3n de documentaci\u00f3n t\u00e9cnica, o describen las", "tokens": [51150, 25564, 48674, 11, 4842, 26433, 631, 11, 368, 517, 45259, 368, 4166, 3482, 45411, 11, 277, 2189, 1799, 2439, 51420], "temperature": 0.0, "avg_logprob": -0.2882268726825714, "compression_ratio": 1.6350877192982456, "no_speech_prob": 0.019607920199632645}, {"id": 232, "seek": 122922, "start": 1250.34, "end": 1255.66, "text": " apis de sus productos, etc. Y uno suele dar, cuando mira la p\u00e1gina web, digamos que aparece como", "tokens": [51420, 1882, 271, 368, 3291, 46363, 11, 5183, 13, 398, 8526, 459, 16884, 4072, 11, 7767, 30286, 635, 36960, 3670, 11, 36430, 631, 37863, 2617, 51686], "temperature": 0.0, "avg_logprob": -0.2882268726825714, "compression_ratio": 1.6350877192982456, "no_speech_prob": 0.019607920199632645}, {"id": 233, "seek": 125566, "start": 1256.38, "end": 1260.3400000000001, "text": " con su fijo es, porque est\u00e1 en espa\u00f1ol, pero si se lo cambias por en, autom\u00e1ticamente", "tokens": [50400, 416, 459, 283, 24510, 785, 11, 4021, 3192, 465, 31177, 11, 4768, 1511, 369, 450, 18751, 4609, 1515, 465, 11, 3553, 7656, 23653, 50598], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 234, "seek": 125566, "start": 1260.3400000000001, "end": 1263.78, "text": " te genera otras p\u00e1ginas, exactamente igual, pero en ingl\u00e9s, y en realidad lo que hacen es", "tokens": [50598, 535, 1337, 64, 20244, 40639, 1494, 296, 11, 48686, 10953, 11, 4768, 465, 49766, 11, 288, 465, 25635, 450, 631, 27434, 785, 50770], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 235, "seek": 125566, "start": 1263.78, "end": 1267.52, "text": " como mantener una representaci\u00f3n abstracta de lo que est\u00e1n escribiendo y generarla en los", "tokens": [50770, 2617, 42759, 2002, 2906, 3482, 12649, 64, 368, 450, 631, 10368, 30598, 65, 7304, 288, 1337, 34148, 465, 1750, 50957], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 236, "seek": 125566, "start": 1267.52, "end": 1274.8200000000002, "text": " distintos idiomas. Bien, entonces, hasta ah\u00ed lo que vimos era como un paneo de lo que son", "tokens": [50957, 49337, 18014, 7092, 13, 16956, 11, 13003, 11, 10764, 12571, 450, 631, 49266, 4249, 2617, 517, 32605, 78, 368, 450, 631, 1872, 51322], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 237, "seek": 125566, "start": 1274.8200000000002, "end": 1279.46, "text": " los distintos sistemas basados en reglas, ahora vamos a pasar a hablar de lo que es la traducci\u00f3n", "tokens": [51322, 1750, 49337, 48720, 987, 4181, 465, 1121, 7743, 11, 9923, 5295, 257, 25344, 257, 21014, 368, 450, 631, 785, 635, 2479, 1311, 5687, 51554], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 238, "seek": 125566, "start": 1279.46, "end": 1285.38, "text": " estad\u00edstica que es el estado del arte hoy en d\u00eda, y vamos a empezar con un ejemplo, un ejemplo", "tokens": [51554, 39160, 19512, 2262, 631, 785, 806, 18372, 1103, 29159, 13775, 465, 12271, 11, 288, 5295, 257, 31168, 416, 517, 13358, 11, 517, 13358, 51850], "temperature": 0.0, "avg_logprob": -0.21228585177904938, "compression_ratio": 1.797427652733119, "no_speech_prob": 0.007346578873693943}, {"id": 239, "seek": 128538, "start": 1285.38, "end": 1291.46, "text": " de una frase en hebreo, que es Adonai Roy, que la traducci\u00f3n ser\u00eda el se\u00f1or a mi pastor", "tokens": [50364, 368, 2002, 38406, 465, 415, 2672, 78, 11, 631, 785, 1999, 266, 1301, 8751, 11, 631, 635, 2479, 1311, 5687, 23679, 806, 22188, 257, 2752, 21193, 50668], "temperature": 0.0, "avg_logprob": -0.30611085158128004, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.014331217855215073}, {"id": 240, "seek": 128538, "start": 1291.46, "end": 1298.5, "text": " o del Lord Ismail Shepper, y esta frase, en realidad, funciona bien, porque nosotros conocemos", "tokens": [50668, 277, 1103, 3257, 1119, 11799, 1240, 3717, 11, 288, 5283, 38406, 11, 465, 25635, 11, 26210, 3610, 11, 4021, 13863, 33029, 38173, 51020], "temperature": 0.0, "avg_logprob": -0.30611085158128004, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.014331217855215073}, {"id": 241, "seek": 128538, "start": 1298.5, "end": 1302.6200000000001, "text": " que son las ovejas, digamos, la cultura en la que surgi\u00f3 esta frase, conoc\u00eda que eran", "tokens": [51020, 631, 1872, 2439, 277, 303, 19221, 11, 36430, 11, 635, 30576, 465, 635, 631, 19560, 7138, 5283, 38406, 11, 15871, 2686, 631, 32762, 51226], "temperature": 0.0, "avg_logprob": -0.30611085158128004, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.014331217855215073}, {"id": 242, "seek": 128538, "start": 1302.6200000000001, "end": 1306.7800000000002, "text": " las ovejas, ten\u00edan pastores, los pastores cuidaban las ovejas, la llevaban a donde hab\u00eda", "tokens": [51226, 2439, 277, 303, 19221, 11, 47596, 1791, 2706, 11, 1750, 1791, 2706, 20770, 18165, 2439, 277, 303, 19221, 11, 635, 27124, 18165, 257, 10488, 16395, 51434], "temperature": 0.0, "avg_logprob": -0.30611085158128004, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.014331217855215073}, {"id": 243, "seek": 128538, "start": 1306.7800000000002, "end": 1313.18, "text": " estado los mejores pastos, etc. Entonces, esta met\u00e1fora funcionaba bien, digamos, la", "tokens": [51434, 18372, 1750, 42284, 1791, 329, 11, 5183, 13, 15097, 11, 5283, 1131, 842, 2994, 64, 14186, 5509, 3610, 11, 36430, 11, 635, 51754], "temperature": 0.0, "avg_logprob": -0.30611085158128004, "compression_ratio": 1.717557251908397, "no_speech_prob": 0.014331217855215073}, {"id": 244, "seek": 131318, "start": 1313.18, "end": 1317.7, "text": " gente describ\u00eda como se sent\u00eda en respecto a Dios utilizando esta met\u00e1fora. Pero", "tokens": [50364, 3788, 2189, 65, 2686, 2617, 369, 2279, 2686, 465, 35694, 257, 21838, 19906, 1806, 5283, 1131, 842, 2994, 64, 13, 9377, 50590], "temperature": 0.0, "avg_logprob": -0.2073725014925003, "compression_ratio": 1.6173285198555956, "no_speech_prob": 0.06822125613689423}, {"id": 245, "seek": 131318, "start": 1317.7, "end": 1323.74, "text": " \u00bfqu\u00e9 tal si quisieramos expresar esta misma frase a una cultura que no conoce a las ovejas?", "tokens": [50590, 3841, 16412, 4023, 1511, 37945, 811, 2151, 33397, 289, 5283, 24946, 38406, 257, 2002, 30576, 631, 572, 33029, 384, 257, 2439, 277, 303, 19221, 30, 50892], "temperature": 0.0, "avg_logprob": -0.2073725014925003, "compression_ratio": 1.6173285198555956, "no_speech_prob": 0.06822125613689423}, {"id": 246, "seek": 131318, "start": 1323.74, "end": 1329.02, "text": " Por ejemplo, los primeros misioneros que vendr\u00edan de Europa y tendr\u00edan contacto con los", "tokens": [50892, 5269, 13358, 11, 1750, 12595, 329, 275, 1991, 16771, 631, 10169, 81, 11084, 368, 16642, 288, 3928, 81, 11084, 3385, 78, 416, 1750, 51156], "temperature": 0.0, "avg_logprob": -0.2073725014925003, "compression_ratio": 1.6173285198555956, "no_speech_prob": 0.06822125613689423}, {"id": 247, "seek": 131318, "start": 1329.02, "end": 1333.42, "text": " ind\u00edgenas americanos, los ind\u00edgenas americanos no conoc\u00edan ovejas, entonces, \u00bfc\u00f3mo hacemos", "tokens": [51156, 1016, 36492, 296, 31229, 329, 11, 1750, 1016, 36492, 296, 31229, 329, 572, 15871, 11084, 277, 303, 19221, 11, 13003, 11, 3841, 46614, 33839, 51376], "temperature": 0.0, "avg_logprob": -0.2073725014925003, "compression_ratio": 1.6173285198555956, "no_speech_prob": 0.06822125613689423}, {"id": 248, "seek": 131318, "start": 1333.42, "end": 1340.9, "text": " para expresarles el concepto de Adonai Roy? Una forma de expresarlo es decir, bueno,", "tokens": [51376, 1690, 33397, 289, 904, 806, 3410, 78, 368, 1999, 266, 1301, 8751, 30, 15491, 8366, 368, 33397, 19457, 785, 10235, 11, 11974, 11, 51750], "temperature": 0.0, "avg_logprob": -0.2073725014925003, "compression_ratio": 1.6173285198555956, "no_speech_prob": 0.06822125613689423}, {"id": 249, "seek": 134090, "start": 1340.9, "end": 1346.14, "text": " adusco la met\u00e1fora, el significador de la met\u00e1fora, digo, significa el se\u00f1or me cuidar\u00e1,", "tokens": [50364, 614, 301, 1291, 635, 1131, 842, 2994, 64, 11, 806, 3350, 5409, 368, 635, 1131, 842, 2994, 64, 11, 22990, 11, 19957, 806, 22188, 385, 20770, 21534, 11, 50626], "temperature": 0.0, "avg_logprob": -0.21739105049890417, "compression_ratio": 1.852, "no_speech_prob": 0.226533442735672}, {"id": 250, "seek": 134090, "start": 1346.14, "end": 1349.3400000000001, "text": " que en definitiva es un poco la met\u00e1fora que quiere decir eso, aunque pierda un poco", "tokens": [50626, 631, 465, 28781, 5931, 785, 517, 10639, 635, 1131, 842, 2994, 64, 631, 23877, 10235, 7287, 11, 21962, 9766, 2675, 517, 10639, 50786], "temperature": 0.0, "avg_logprob": -0.21739105049890417, "compression_ratio": 1.852, "no_speech_prob": 0.226533442735672}, {"id": 251, "seek": 134090, "start": 1349.3400000000001, "end": 1355.66, "text": " de contenido, o si no, lo que lo otro que puedo hacer es tratar de ser m\u00e1s fiel al significado", "tokens": [50786, 368, 47117, 11, 277, 1511, 572, 11, 450, 631, 450, 11921, 631, 21612, 6720, 785, 42549, 368, 816, 3573, 283, 1187, 419, 3350, 1573, 51102], "temperature": 0.0, "avg_logprob": -0.21739105049890417, "compression_ratio": 1.852, "no_speech_prob": 0.226533442735672}, {"id": 252, "seek": 134090, "start": 1355.66, "end": 1359.98, "text": " original y tratar de traducirlo m\u00e1s literalmente, es decir, bueno, el se\u00f1or ser\u00e1 para m\u00ed como", "tokens": [51102, 3380, 288, 42549, 368, 2479, 1311, 347, 752, 3573, 20411, 4082, 11, 785, 10235, 11, 11974, 11, 806, 22188, 16502, 1690, 14692, 2617, 51318], "temperature": 0.0, "avg_logprob": -0.21739105049890417, "compression_ratio": 1.852, "no_speech_prob": 0.226533442735672}, {"id": 253, "seek": 134090, "start": 1359.98, "end": 1367.02, "text": " un hombre que cuida de animales que tiene el pelo como algod\u00f3n, que es bastante m\u00e1s fiel", "tokens": [51318, 517, 26102, 631, 2702, 2887, 368, 45102, 631, 7066, 806, 12167, 2617, 3501, 378, 1801, 11, 631, 785, 14651, 3573, 283, 1187, 51670], "temperature": 0.0, "avg_logprob": -0.21739105049890417, "compression_ratio": 1.852, "no_speech_prob": 0.226533442735672}, {"id": 254, "seek": 136702, "start": 1367.02, "end": 1371.3, "text": " al original, pero sin embargo, se entiende mucho menos, es como que te van a mirar y decir", "tokens": [50364, 419, 3380, 11, 4768, 3343, 23955, 11, 369, 948, 45816, 9824, 8902, 11, 785, 2617, 631, 535, 3161, 257, 3149, 289, 288, 10235, 50578], "temperature": 0.0, "avg_logprob": -0.20259615270102896, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.01073959656059742}, {"id": 255, "seek": 136702, "start": 1371.3, "end": 1376.86, "text": " lo de qu\u00e9 me est\u00e1s hablando. Y bueno, un poco, este es el problema que hay que", "tokens": [50578, 450, 368, 8057, 385, 24389, 29369, 13, 398, 11974, 11, 517, 10639, 11, 4065, 785, 806, 12395, 631, 4842, 631, 50856], "temperature": 0.0, "avg_logprob": -0.20259615270102896, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.01073959656059742}, {"id": 256, "seek": 136702, "start": 1376.86, "end": 1382.94, "text": " se enfrentan los traductores humanos todos los d\u00edas, o sea, es muy dif\u00edcil tener las dos", "tokens": [50856, 369, 33771, 282, 1750, 2479, 11130, 2706, 34555, 6321, 1750, 19527, 11, 277, 4158, 11, 785, 5323, 17258, 11640, 2439, 4491, 51160], "temperature": 0.0, "avg_logprob": -0.20259615270102896, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.01073959656059742}, {"id": 257, "seek": 136702, "start": 1382.94, "end": 1389.34, "text": " cosas, ser fiel al original y sonar natural que suene bien en el lenguaje destino. Una traducci\u00f3n", "tokens": [51160, 12218, 11, 816, 283, 1187, 419, 3380, 288, 1872, 289, 3303, 631, 459, 1450, 3610, 465, 806, 35044, 84, 11153, 2677, 2982, 13, 15491, 2479, 1311, 5687, 51480], "temperature": 0.0, "avg_logprob": -0.20259615270102896, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.01073959656059742}, {"id": 258, "seek": 136702, "start": 1389.34, "end": 1393.9, "text": " queremos que tenga esas dos propiedades, pero es muy dif\u00edcil lograrlo a la vez, entonces", "tokens": [51480, 26813, 631, 36031, 23388, 4491, 2365, 1091, 2977, 11, 4768, 785, 5323, 17258, 31013, 19457, 257, 635, 5715, 11, 13003, 51708], "temperature": 0.0, "avg_logprob": -0.20259615270102896, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.01073959656059742}, {"id": 259, "seek": 139390, "start": 1393.9, "end": 1397.46, "text": " los traductores humanos saben que esto es imposible en la pr\u00e1ctica y lo que hacen es tratar", "tokens": [50364, 1750, 2479, 11130, 2706, 34555, 36670, 631, 7433, 785, 38396, 964, 465, 635, 27300, 29041, 288, 450, 631, 27434, 785, 42549, 50542], "temperature": 0.0, "avg_logprob": -0.1616244115749327, "compression_ratio": 1.7890625, "no_speech_prob": 0.011632977053523064}, {"id": 260, "seek": 139390, "start": 1397.46, "end": 1402.66, "text": " de traducir de manera de encontrar un punto intermedio en el cual, bueno, suene bastante", "tokens": [50542, 368, 2479, 1311, 347, 368, 13913, 368, 17525, 517, 14326, 728, 1912, 1004, 465, 806, 10911, 11, 11974, 11, 459, 1450, 14651, 50802], "temperature": 0.0, "avg_logprob": -0.1616244115749327, "compression_ratio": 1.7890625, "no_speech_prob": 0.011632977053523064}, {"id": 261, "seek": 139390, "start": 1402.66, "end": 1410.22, "text": " bien, pero adem\u00e1s sea fiel al significado original. Entonces, esto significa que lo que estamos", "tokens": [50802, 3610, 11, 4768, 21251, 4158, 283, 1187, 419, 3350, 1573, 3380, 13, 15097, 11, 7433, 19957, 631, 450, 631, 10382, 51180], "temperature": 0.0, "avg_logprob": -0.1616244115749327, "compression_ratio": 1.7890625, "no_speech_prob": 0.011632977053523064}, {"id": 262, "seek": 139390, "start": 1410.22, "end": 1415.0600000000002, "text": " tratando de hacer al traducir es que estamos tratando de maximizar dos cosas a la vez,", "tokens": [51180, 21507, 1806, 368, 6720, 419, 2479, 1311, 347, 785, 631, 10382, 21507, 1806, 368, 5138, 9736, 4491, 12218, 257, 635, 5715, 11, 51422], "temperature": 0.0, "avg_logprob": -0.1616244115749327, "compression_ratio": 1.7890625, "no_speech_prob": 0.011632977053523064}, {"id": 263, "seek": 139390, "start": 1415.0600000000002, "end": 1420.94, "text": " como dos medidas que queremos maximizar. Una medida es que tan fiel es mi oraci\u00f3n traducida", "tokens": [51422, 2617, 4491, 37295, 631, 26813, 5138, 9736, 13, 15491, 32984, 785, 631, 7603, 283, 1187, 785, 2752, 420, 3482, 2479, 1311, 2887, 51716], "temperature": 0.0, "avg_logprob": -0.1616244115749327, "compression_ratio": 1.7890625, "no_speech_prob": 0.011632977053523064}, {"id": 264, "seek": 142094, "start": 1420.94, "end": 1425.26, "text": " a la oraci\u00f3n original, a esa medida le vamos a llamar adecuaci\u00f3n o fidelidad y en ingl\u00e9s", "tokens": [50364, 257, 635, 420, 3482, 3380, 11, 257, 11342, 32984, 476, 5295, 257, 16848, 289, 614, 3045, 84, 3482, 277, 283, 16189, 4580, 288, 465, 49766, 50580], "temperature": 0.0, "avg_logprob": -0.19121447343092698, "compression_ratio": 1.8830645161290323, "no_speech_prob": 0.018389033153653145}, {"id": 265, "seek": 142094, "start": 1425.26, "end": 1431.46, "text": " es adecuaci\u00f3n fidelity of faithfulness y la otra medida es que tan natural suena la oraci\u00f3n", "tokens": [50580, 785, 614, 3045, 84, 3482, 283, 16189, 507, 295, 17808, 1287, 288, 635, 13623, 32984, 785, 631, 7603, 3303, 459, 4118, 635, 420, 3482, 50890], "temperature": 0.0, "avg_logprob": -0.19121447343092698, "compression_ratio": 1.8830645161290323, "no_speech_prob": 0.018389033153653145}, {"id": 266, "seek": 142094, "start": 1431.46, "end": 1436.06, "text": " que yo traduje en el lenguaje destino y a esa medida le voy a llamar fluidez o en ingl\u00e9s fluency.", "tokens": [50890, 631, 5290, 2479, 4579, 68, 465, 806, 35044, 84, 11153, 2677, 2982, 288, 257, 11342, 32984, 476, 7552, 257, 16848, 289, 5029, 45170, 277, 465, 49766, 5029, 3020, 13, 51120], "temperature": 0.0, "avg_logprob": -0.19121447343092698, "compression_ratio": 1.8830645161290323, "no_speech_prob": 0.018389033153653145}, {"id": 267, "seek": 142094, "start": 1436.06, "end": 1443.26, "text": " Entonces, esta idea de que estoy tratando de maximizar dos medidas a la vez, despu\u00e9s", "tokens": [51120, 15097, 11, 5283, 1558, 368, 631, 15796, 21507, 1806, 368, 5138, 9736, 4491, 37295, 257, 635, 5715, 11, 15283, 51480], "temperature": 0.0, "avg_logprob": -0.19121447343092698, "compression_ratio": 1.8830645161290323, "no_speech_prob": 0.018389033153653145}, {"id": 268, "seek": 142094, "start": 1443.26, "end": 1446.38, "text": " vamos a ver que en realidad lo que vamos a tratar de maximizar es el producto de las dos medidas", "tokens": [51480, 5295, 257, 1306, 631, 465, 25635, 450, 631, 5295, 257, 42549, 368, 5138, 9736, 785, 806, 47583, 368, 2439, 4491, 37295, 51636], "temperature": 0.0, "avg_logprob": -0.19121447343092698, "compression_ratio": 1.8830645161290323, "no_speech_prob": 0.018389033153653145}, {"id": 269, "seek": 144638, "start": 1446.38, "end": 1452.5800000000002, "text": " porque eso significa maximizar ambas al mismo tiempo, es una idea que sirve para poder", "tokens": [50364, 4021, 7287, 19957, 5138, 9736, 3913, 296, 419, 12461, 11772, 11, 785, 2002, 1558, 631, 4735, 303, 1690, 8152, 50674], "temperature": 0.0, "avg_logprob": -0.23261776617017843, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0591357983648777}, {"id": 270, "seek": 144638, "start": 1452.5800000000002, "end": 1456.74, "text": " inferir o para poder construir mecanismos para crear los traductores autom\u00e1ticos y tambi\u00e9n", "tokens": [50674, 13596, 347, 277, 1690, 8152, 38445, 385, 7035, 1434, 329, 1690, 31984, 1750, 2479, 11130, 2706, 3553, 7656, 9940, 288, 6407, 50882], "temperature": 0.0, "avg_logprob": -0.23261776617017843, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0591357983648777}, {"id": 271, "seek": 144638, "start": 1456.74, "end": 1460.98, "text": " mecanismos para testearlos. Y vamos a ver un poco c\u00f3mo que funciona eso.", "tokens": [50882, 385, 7035, 1434, 329, 1690, 1500, 14881, 9389, 13, 398, 5295, 257, 1306, 517, 10639, 12826, 631, 26210, 7287, 13, 51094], "temperature": 0.0, "avg_logprob": -0.23261776617017843, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0591357983648777}, {"id": 272, "seek": 144638, "start": 1460.98, "end": 1466.14, "text": " Yo voy a intentar traducir a partir de ahora el resto de la clase y la clase que", "tokens": [51094, 7616, 7552, 257, 46596, 2479, 1311, 347, 257, 13906, 368, 9923, 806, 28247, 368, 635, 44578, 288, 635, 44578, 631, 51352], "temperature": 0.0, "avg_logprob": -0.23261776617017843, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0591357983648777}, {"id": 273, "seek": 144638, "start": 1466.14, "end": 1470.8200000000002, "text": " viene vamos a hablar siempre de que voy a traducir un lenguaje origen f a un lenguaje destino", "tokens": [51352, 19561, 5295, 257, 21014, 12758, 368, 631, 7552, 257, 2479, 1311, 347, 517, 35044, 84, 11153, 2349, 268, 283, 257, 517, 35044, 84, 11153, 2677, 2982, 51586], "temperature": 0.0, "avg_logprob": -0.23261776617017843, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.0591357983648777}, {"id": 274, "seek": 147082, "start": 1470.82, "end": 1498.3799999999999, "text": " f es el lenguaje origen y es el lenguaje destino. Eso es nombre surgen porque el paper inicial", "tokens": [50364, 283, 785, 806, 35044, 84, 11153, 2349, 268, 288, 785, 806, 35044, 84, 11153, 2677, 2982, 13, 27795, 785, 13000, 1022, 1766, 4021, 806, 3035, 44076, 51742], "temperature": 0.0, "avg_logprob": -0.3924981435139974, "compression_ratio": 1.2533333333333334, "no_speech_prob": 0.12176352739334106}, {"id": 275, "seek": 149838, "start": 1498.38, "end": 1502.42, "text": " donde se empez\u00f3 a hablar de esta cosa de los m\u00e9todos estad\u00edsticos traduc\u00eda del franc\u00e9s", "tokens": [50364, 10488, 369, 18730, 812, 257, 21014, 368, 5283, 10163, 368, 1750, 20275, 378, 329, 39160, 19512, 9940, 2479, 1311, 2686, 1103, 30514, 2191, 50566], "temperature": 0.0, "avg_logprob": -0.316745846088116, "compression_ratio": 1.789272030651341, "no_speech_prob": 0.30268245935440063}, {"id": 276, "seek": 149838, "start": 1502.42, "end": 1507.0200000000002, "text": " al ingl\u00e9s, entonces acolo nombre de ah\u00ed dijo bueno franc\u00e9s f el ingl\u00e9s e entonces traducimos", "tokens": [50566, 419, 49766, 11, 13003, 696, 7902, 13000, 368, 12571, 27024, 11974, 30514, 2191, 283, 806, 49766, 308, 13003, 2479, 1311, 8372, 50796], "temperature": 0.0, "avg_logprob": -0.316745846088116, "compression_ratio": 1.789272030651341, "no_speech_prob": 0.30268245935440063}, {"id": 277, "seek": 149838, "start": 1507.0200000000002, "end": 1513.66, "text": " del origen al destino. Bueno, yo quiero traducir una frase del idioma f a otra frase del idioma", "tokens": [50796, 1103, 2349, 268, 419, 2677, 2982, 13, 16046, 11, 5290, 16811, 2479, 1311, 347, 2002, 38406, 1103, 18014, 6440, 283, 257, 13623, 38406, 1103, 18014, 6440, 51128], "temperature": 0.0, "avg_logprob": -0.316745846088116, "compression_ratio": 1.789272030651341, "no_speech_prob": 0.30268245935440063}, {"id": 278, "seek": 149838, "start": 1513.66, "end": 1520.42, "text": " e lo que quiero tratar de encontrar es el mejor etecho que maximice a la vez la de ecuaci\u00f3n", "tokens": [51128, 308, 450, 631, 16811, 42549, 368, 17525, 785, 806, 11479, 1030, 5023, 78, 631, 5138, 573, 257, 635, 5715, 635, 368, 11437, 84, 3482, 51466], "temperature": 0.0, "avg_logprob": -0.316745846088116, "compression_ratio": 1.789272030651341, "no_speech_prob": 0.30268245935440063}, {"id": 279, "seek": 149838, "start": 1520.42, "end": 1524.8200000000002, "text": " y la fluidez, o sea de todos los e posibles del lenguaje destino, quiero encontrar el que", "tokens": [51466, 288, 635, 5029, 45170, 11, 277, 4158, 368, 6321, 1750, 308, 1366, 14428, 1103, 35044, 84, 11153, 2677, 2982, 11, 16811, 17525, 806, 631, 51686], "temperature": 0.0, "avg_logprob": -0.316745846088116, "compression_ratio": 1.789272030651341, "no_speech_prob": 0.30268245935440063}, {"id": 280, "seek": 152482, "start": 1524.82, "end": 1529.62, "text": " maximice la fluidez de es, o sea que suene natural y adem\u00e1s la de ecuaci\u00f3n entre la", "tokens": [50364, 5138, 573, 635, 5029, 45170, 368, 785, 11, 277, 4158, 631, 459, 1450, 3303, 288, 21251, 635, 368, 11437, 84, 3482, 3962, 635, 50604], "temperature": 0.0, "avg_logprob": -0.3899505091648476, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.11996769160032272}, {"id": 281, "seek": 152482, "start": 1529.62, "end": 1537.98, "text": " oraci\u00f3n origen f y s e que estoy buscando. Esta f\u00f3rmula as\u00ed escrita de esa manera de", "tokens": [50604, 420, 3482, 2349, 268, 283, 288, 262, 308, 631, 15796, 46804, 13, 20547, 283, 15614, 76, 3780, 8582, 49865, 2786, 368, 11342, 13913, 368, 51022], "temperature": 0.0, "avg_logprob": -0.3899505091648476, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.11996769160032272}, {"id": 282, "seek": 152482, "start": 1537.98, "end": 1541.4199999999998, "text": " est\u00e1s acordado a algo que hayamos visto ya en el curso en alg\u00fan momento, les suena", "tokens": [51022, 24389, 38077, 1573, 257, 8655, 631, 4842, 2151, 17558, 2478, 465, 806, 31085, 465, 26300, 9333, 11, 1512, 459, 4118, 51194], "temperature": 0.0, "avg_logprob": -0.3899505091648476, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.11996769160032272}, {"id": 283, "seek": 152482, "start": 1541.4199999999998, "end": 1551.1, "text": " alg\u00fan lado. Entrop\u00eda, s\u00ed. Valles, s\u00ed, o sea viene por ese lado, se parece al modelo", "tokens": [51194, 26300, 11631, 13, 3951, 1513, 2686, 11, 8600, 13, 691, 37927, 11, 8600, 11, 277, 4158, 19561, 1515, 10167, 11631, 11, 369, 14120, 419, 27825, 51678], "temperature": 0.0, "avg_logprob": -0.3899505091648476, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.11996769160032272}, {"id": 284, "seek": 155110, "start": 1551.1, "end": 1554.1399999999999, "text": " de valles porque esto es otra aplicaci\u00f3n del modelo de canal ruidoso. El modelo de", "tokens": [50364, 368, 371, 37927, 4021, 7433, 785, 13623, 18221, 3482, 1103, 27825, 368, 9911, 5420, 7895, 78, 13, 2699, 27825, 368, 50516], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 285, "seek": 155110, "start": 1554.1399999999999, "end": 1558.1, "text": " canal ruidoso lo hayamos visto en el curso cuando vimos correcciones de errores, hace", "tokens": [50516, 9911, 5420, 7895, 78, 450, 4842, 2151, 17558, 465, 806, 31085, 7767, 49266, 1181, 13867, 23469, 368, 45935, 495, 11, 10032, 50714], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 286, "seek": 155110, "start": 1558.1, "end": 1562.1, "text": " ya bastante tiempo y tambi\u00e9n es una aplicaci\u00f3n de lo que es la regla de valles.", "tokens": [50714, 2478, 14651, 11772, 288, 6407, 785, 2002, 18221, 3482, 368, 450, 631, 785, 635, 1121, 875, 368, 371, 37927, 13, 50914], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 287, "seek": 155110, "start": 1562.1, "end": 1567.26, "text": " Entonces, el modelo de canal ruidoso ha aplicado ac\u00e1 funciona de la siguiente manera. Yo", "tokens": [50914, 15097, 11, 806, 27825, 368, 9911, 5420, 7895, 78, 324, 18221, 1573, 23496, 26210, 368, 635, 25666, 13913, 13, 7616, 51172], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 288, "seek": 155110, "start": 1567.26, "end": 1573.1799999999998, "text": " tengo una oraci\u00f3n origen en el lenguaje f que es f chica que tiene m palabras y es bueno", "tokens": [51172, 13989, 2002, 420, 3482, 2349, 268, 465, 806, 35044, 84, 11153, 283, 631, 785, 283, 417, 2262, 631, 7066, 275, 35240, 288, 785, 11974, 51468], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 289, "seek": 155110, "start": 1573.1799999999998, "end": 1578.58, "text": " f sub 1, f sub 2 hasta f sub m y quiero encontrar la mejor oraci\u00f3n en el lenguaje destino", "tokens": [51468, 283, 1422, 502, 11, 283, 1422, 568, 10764, 283, 1422, 275, 288, 16811, 17525, 635, 11479, 420, 3482, 465, 806, 35044, 84, 11153, 2677, 2982, 51738], "temperature": 0.0, "avg_logprob": -0.23446602291531032, "compression_ratio": 1.8576512455516014, "no_speech_prob": 0.15591907501220703}, {"id": 290, "seek": 157858, "start": 1578.58, "end": 1585.9399999999998, "text": " e techo que es sub 1 hasta f sub n, hasta f sub n, que maximiza y en realidad lo que quiero", "tokens": [50364, 308, 535, 5738, 631, 785, 1422, 502, 10764, 283, 1422, 297, 11, 10764, 283, 1422, 297, 11, 631, 5138, 13427, 288, 465, 25635, 450, 631, 16811, 50732], "temperature": 0.0, "avg_logprob": -0.260002520657325, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.008871996775269508}, {"id": 291, "seek": 157858, "start": 1585.9399999999998, "end": 1591.34, "text": " maximizar originalmente como todos esperar\u00edamos es decir, bueno, yo quiero encontrar la oraci\u00f3n", "tokens": [50732, 5138, 9736, 3380, 4082, 2617, 6321, 37577, 16275, 785, 10235, 11, 11974, 11, 5290, 16811, 17525, 635, 420, 3482, 51002], "temperature": 0.0, "avg_logprob": -0.260002520657325, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.008871996775269508}, {"id": 292, "seek": 157858, "start": 1591.34, "end": 1595.6999999999998, "text": " e que maximiza la probabilidad de edad o f, digamos eso es lo que uno se lo ocurrir\u00eda", "tokens": [51002, 308, 631, 5138, 13427, 635, 31959, 4580, 368, 1257, 345, 277, 283, 11, 36430, 7287, 785, 450, 631, 8526, 369, 450, 26430, 10949, 2686, 51220], "temperature": 0.0, "avg_logprob": -0.260002520657325, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.008871996775269508}, {"id": 293, "seek": 157858, "start": 1595.6999999999998, "end": 1599.6799999999998, "text": " primero, dir\u00eda bueno, yo quiero estoy traduciendo la oraci\u00f3n f, quiero encontrar la e que", "tokens": [51220, 21289, 11, 4746, 2686, 11974, 11, 5290, 16811, 15796, 2479, 1311, 7304, 635, 420, 3482, 283, 11, 16811, 17525, 635, 308, 631, 51419], "temperature": 0.0, "avg_logprob": -0.260002520657325, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.008871996775269508}, {"id": 294, "seek": 157858, "start": 1599.6799999999998, "end": 1605.3799999999999, "text": " me dem\u00e1ximo la probabilidad de edad o f. Bien, pero en realidad yo esto lo puedo descomponer", "tokens": [51419, 385, 1371, 842, 3081, 78, 635, 31959, 4580, 368, 1257, 345, 277, 283, 13, 16956, 11, 4768, 465, 25635, 5290, 7433, 450, 21612, 730, 21541, 32949, 51704], "temperature": 0.0, "avg_logprob": -0.260002520657325, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.008871996775269508}, {"id": 295, "seek": 160538, "start": 1605.38, "end": 1609.18, "text": " por valles, digamos, y por definici\u00f3n de probabilidad condicional, pues decir que la probabilidad", "tokens": [50364, 1515, 371, 37927, 11, 36430, 11, 288, 1515, 1561, 15534, 368, 31959, 4580, 2224, 33010, 11, 11059, 10235, 631, 635, 31959, 4580, 50554], "temperature": 0.0, "avg_logprob": -0.2970245541550043, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.04517949000000954}, {"id": 296, "seek": 160538, "start": 1609.18, "end": 1614.3000000000002, "text": " de edad o f es igual a la probabilidad de f de edad o f por la probabilidad de edad o f.", "tokens": [50554, 368, 1257, 345, 277, 283, 785, 10953, 257, 635, 31959, 4580, 368, 283, 368, 1257, 345, 277, 283, 1515, 635, 31959, 4580, 368, 1257, 345, 277, 283, 13, 50810], "temperature": 0.0, "avg_logprob": -0.2970245541550043, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.04517949000000954}, {"id": 297, "seek": 160538, "start": 1614.3000000000002, "end": 1621.3400000000001, "text": " Y vamos a esa equivalencia directa por definici\u00f3n de probabilidad condicional y adem\u00e1s como estoy", "tokens": [50810, 398, 5295, 257, 11342, 9052, 10974, 2047, 64, 1515, 1561, 15534, 368, 31959, 4580, 2224, 33010, 288, 21251, 2617, 15796, 51162], "temperature": 0.0, "avg_logprob": -0.2970245541550043, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.04517949000000954}, {"id": 298, "seek": 160538, "start": 1621.3400000000001, "end": 1626.7, "text": " maximizando en e, esta f se mantiene constante, porque lo que voy variando es la e, entonces", "tokens": [51162, 5138, 590, 1806, 465, 308, 11, 5283, 283, 369, 10845, 10174, 47343, 11, 4021, 450, 631, 7552, 3034, 1806, 785, 635, 308, 11, 13003, 51430], "temperature": 0.0, "avg_logprob": -0.2970245541550043, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.04517949000000954}, {"id": 299, "seek": 160538, "start": 1626.7, "end": 1633.7, "text": " la etacho, o sea maximizar sobre una constante no hace ning\u00fan cambio, entonces lo que me queda", "tokens": [51430, 635, 1030, 46574, 11, 277, 4158, 5138, 9736, 5473, 2002, 47343, 572, 10032, 30394, 28731, 11, 13003, 450, 631, 385, 23314, 51780], "temperature": 0.0, "avg_logprob": -0.2970245541550043, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.04517949000000954}, {"id": 300, "seek": 163370, "start": 1633.7, "end": 1639.5800000000002, "text": " el final es que yo busco un etacho que es el e que hace m\u00e1ximo la probabilidad de", "tokens": [50364, 806, 2572, 785, 631, 5290, 1255, 1291, 517, 1030, 46574, 631, 785, 806, 308, 631, 10032, 38876, 635, 31959, 4580, 368, 50658], "temperature": 0.0, "avg_logprob": -0.2464730556194599, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.009480227716267109}, {"id": 301, "seek": 163370, "start": 1639.5800000000002, "end": 1646.18, "text": " f de edad o f por la probabilidad de. Y eso que tenemos escrito ah\u00ed, se parece mucho a la", "tokens": [50658, 283, 368, 1257, 345, 277, 283, 1515, 635, 31959, 4580, 368, 13, 398, 7287, 631, 9914, 49451, 12571, 11, 369, 14120, 9824, 257, 635, 50988], "temperature": 0.0, "avg_logprob": -0.2464730556194599, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.009480227716267109}, {"id": 302, "seek": 163370, "start": 1646.18, "end": 1653.1000000000001, "text": " otra ecuaci\u00f3n que ten\u00edamos antes, digamos, se parece mucho a esta ecuaci\u00f3n de f y fluidez", "tokens": [50988, 13623, 11437, 84, 3482, 631, 2064, 16275, 11014, 11, 36430, 11, 369, 14120, 9824, 257, 5283, 11437, 84, 3482, 368, 283, 288, 5029, 45170, 51334], "temperature": 0.0, "avg_logprob": -0.2464730556194599, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.009480227716267109}, {"id": 303, "seek": 163370, "start": 1653.1000000000001, "end": 1663.18, "text": " de e. Entonces, se conoce como la ecuaci\u00f3n fundamental de la traducion autom\u00e1tica estad\u00edstica,", "tokens": [51334, 368, 308, 13, 15097, 11, 369, 33029, 384, 2617, 635, 11437, 84, 3482, 8088, 368, 635, 2479, 1311, 313, 3553, 23432, 39160, 19512, 2262, 11, 51838], "temperature": 0.0, "avg_logprob": -0.2464730556194599, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.009480227716267109}, {"id": 304, "seek": 166318, "start": 1663.18, "end": 1669.74, "text": " vamos a ver unas cuantas veces en estas dos clases, la vamos a estar refrescando y funcional", "tokens": [50364, 5295, 257, 1306, 25405, 2702, 49153, 17054, 465, 13897, 4491, 596, 1957, 11, 635, 5295, 257, 8755, 17368, 29585, 288, 1019, 42395, 50692], "temperature": 0.0, "avg_logprob": -0.21115011157411517, "compression_ratio": 1.8408163265306123, "no_speech_prob": 0.023017652332782745}, {"id": 305, "seek": 166318, "start": 1669.74, "end": 1675.0600000000002, "text": " as\u00ed de manera. Yo quiero encontrar el e techo que es el e que maximiza el producto de", "tokens": [50692, 8582, 368, 13913, 13, 7616, 16811, 17525, 806, 308, 535, 5738, 631, 785, 806, 308, 631, 5138, 13427, 806, 47583, 368, 50958], "temperature": 0.0, "avg_logprob": -0.21115011157411517, "compression_ratio": 1.8408163265306123, "no_speech_prob": 0.023017652332782745}, {"id": 306, "seek": 166318, "start": 1675.0600000000002, "end": 1679.6200000000001, "text": " estas dos probabilidades. La primera probabilidad pdf de edad o e es la que se encarga de medir", "tokens": [50958, 13897, 4491, 31959, 10284, 13, 2369, 17382, 31959, 4580, 280, 45953, 368, 1257, 345, 277, 308, 785, 635, 631, 369, 2058, 289, 3680, 368, 1205, 347, 51186], "temperature": 0.0, "avg_logprob": -0.21115011157411517, "compression_ratio": 1.8408163265306123, "no_speech_prob": 0.023017652332782745}, {"id": 307, "seek": 166318, "start": 1679.6200000000001, "end": 1683.7, "text": " que tal la ecuaci\u00f3n, digamos, de la frase, que tal adecuada es la frase f para la frase", "tokens": [51186, 631, 4023, 635, 11437, 84, 3482, 11, 36430, 11, 368, 635, 38406, 11, 631, 4023, 614, 3045, 84, 1538, 785, 635, 38406, 283, 1690, 635, 38406, 51390], "temperature": 0.0, "avg_logprob": -0.21115011157411517, "compression_ratio": 1.8408163265306123, "no_speech_prob": 0.023017652332782745}, {"id": 308, "seek": 166318, "start": 1683.7, "end": 1690.46, "text": " e. La segunda probabilidad, la pdf es la que se encarga de la fluidez, que tal natural", "tokens": [51390, 308, 13, 2369, 21978, 31959, 4580, 11, 635, 280, 45953, 785, 635, 631, 369, 2058, 289, 3680, 368, 635, 5029, 45170, 11, 631, 4023, 3303, 51728], "temperature": 0.0, "avg_logprob": -0.21115011157411517, "compression_ratio": 1.8408163265306123, "no_speech_prob": 0.023017652332782745}, {"id": 309, "seek": 169046, "start": 1690.46, "end": 1696.06, "text": " suena esa frase en el lenguaje destino. Y se calculan con modelo distintos. La primera", "tokens": [50364, 459, 4118, 11342, 38406, 465, 806, 35044, 84, 11153, 2677, 2982, 13, 398, 369, 4322, 282, 416, 27825, 49337, 13, 2369, 17382, 50644], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 310, "seek": 169046, "start": 1696.06, "end": 1699.42, "text": " se calcula con lo que se conoce como modelo de traducci\u00f3n y la segunda con lo que se conoce", "tokens": [50644, 369, 4322, 64, 416, 450, 631, 369, 33029, 384, 2617, 27825, 368, 2479, 1311, 5687, 288, 635, 21978, 416, 450, 631, 369, 33029, 384, 50812], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 311, "seek": 169046, "start": 1699.42, "end": 1703.8600000000001, "text": " como modelo de lenguaje. De hecho, los modelos del lenguaje ya lo hemos visto en el curso.", "tokens": [50812, 2617, 27825, 368, 35044, 84, 11153, 13, 1346, 13064, 11, 1750, 2316, 329, 1103, 35044, 84, 11153, 2478, 450, 15396, 17558, 465, 806, 31085, 13, 51034], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 312, "seek": 169046, "start": 1703.8600000000001, "end": 1709.54, "text": " Vamos a dar un breve repaso de que se trataba. Bueno, \u00bfpor qu\u00e9 esto es una aplicaci\u00f3n", "tokens": [51034, 10894, 257, 4072, 517, 48517, 1085, 35281, 368, 631, 369, 21507, 5509, 13, 16046, 11, 3841, 2816, 8057, 7433, 785, 2002, 18221, 3482, 51318], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 313, "seek": 169046, "start": 1709.54, "end": 1714.5, "text": " de canal ruidoso? Es una aplicaci\u00f3n de canal ruidoso por lo siguiente. Nosotros estamos", "tokens": [51318, 368, 9911, 5420, 7895, 78, 30, 2313, 2002, 18221, 3482, 368, 9911, 5420, 7895, 78, 1515, 450, 25666, 13, 18749, 11792, 10382, 51566], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 314, "seek": 169046, "start": 1714.5, "end": 1719.18, "text": " tratando de traducir del lenguaje f, f, el lenguaje origen, al lenguaje e que es el lenguaje", "tokens": [51566, 21507, 1806, 368, 2479, 1311, 347, 1103, 35044, 84, 11153, 283, 11, 283, 11, 806, 35044, 84, 11153, 2349, 268, 11, 419, 35044, 84, 11153, 308, 631, 785, 806, 35044, 84, 11153, 51800], "temperature": 0.0, "avg_logprob": -0.20488675435384116, "compression_ratio": 1.9889705882352942, "no_speech_prob": 0.21911115944385529}, {"id": 315, "seek": 171918, "start": 1719.18, "end": 1724.02, "text": " destino. Y lo estamos pensando al rev\u00e9s. Estamos pensando como que alguien emiti\u00f3 los", "tokens": [50364, 2677, 2982, 13, 398, 450, 10382, 34525, 419, 3698, 2191, 13, 34563, 34525, 2617, 631, 25814, 32084, 7138, 1750, 50606], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 316, "seek": 171918, "start": 1724.02, "end": 1728.1000000000001, "text": " sonidos de la elaboraci\u00f3n e, la elaboraci\u00f3n del lenguaje destino. Eso pas\u00f3 a trav\u00e9s de", "tokens": [50606, 1872, 7895, 368, 635, 16298, 3482, 308, 11, 635, 16298, 3482, 1103, 35044, 84, 11153, 2677, 2982, 13, 27795, 41382, 257, 24463, 368, 50810], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 317, "seek": 171918, "start": 1728.1000000000001, "end": 1731.94, "text": " un canal ruidoso. Y cuando lleg\u00f3 hasta m\u00ed, yo escuch\u00e9 los sonidos de la elaboraci\u00f3n", "tokens": [50810, 517, 9911, 5420, 7895, 78, 13, 398, 7767, 46182, 10764, 14692, 11, 5290, 22483, 526, 1750, 1872, 7895, 368, 635, 16298, 3482, 51002], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 318, "seek": 171918, "start": 1731.94, "end": 1736.6200000000001, "text": " f. Estoy pensando como esa especie de met\u00e1fora. Alguien emiti\u00f3 e pas\u00f3 por un canal ruidoso", "tokens": [51002, 283, 13, 49651, 34525, 2617, 11342, 49368, 368, 1131, 842, 2994, 64, 13, 967, 2794, 1053, 846, 270, 7138, 308, 41382, 1515, 517, 9911, 5420, 7895, 78, 51236], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 319, "seek": 171918, "start": 1736.6200000000001, "end": 1741.1000000000001, "text": " y llegaron los ruidos de f. Entonces, lo que yo trat\u00f3 de hacer como proceso de traducci\u00f3n", "tokens": [51236, 288, 11234, 6372, 1750, 5420, 7895, 368, 283, 13, 15097, 11, 450, 631, 5290, 21507, 812, 368, 6720, 2617, 29314, 368, 2479, 1311, 5687, 51460], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 320, "seek": 171918, "start": 1741.1000000000001, "end": 1746.14, "text": " es encontrar cu\u00e1l tiene que haber sido esa e original para que yo haya escuchado la", "tokens": [51460, 785, 17525, 44318, 7066, 631, 15811, 14444, 11342, 308, 3380, 1690, 631, 5290, 24693, 22483, 1573, 635, 51712], "temperature": 0.0, "avg_logprob": -0.21340730745498449, "compression_ratio": 1.917857142857143, "no_speech_prob": 0.09056311100721359}, {"id": 321, "seek": 174614, "start": 1746.14, "end": 1754.0200000000002, "text": " f, cu\u00e1l es la e original que me da probabilidad m\u00e1xima de que yo haya escuchado esta f. Y bueno,", "tokens": [50364, 283, 11, 44318, 785, 635, 308, 3380, 631, 385, 1120, 31959, 4580, 31031, 64, 368, 631, 5290, 24693, 22483, 1573, 5283, 283, 13, 398, 11974, 11, 50758], "temperature": 0.0, "avg_logprob": -0.2415087761417512, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.019855113700032234}, {"id": 322, "seek": 174614, "start": 1754.0200000000002, "end": 1758.66, "text": " por eso es una aplicaci\u00f3n de canal ruidoso. Y bueno, la realidad es que en realidad damos", "tokens": [50758, 1515, 7287, 785, 2002, 18221, 3482, 368, 9911, 5420, 7895, 78, 13, 398, 11974, 11, 635, 25635, 785, 631, 465, 25635, 274, 2151, 50990], "temperature": 0.0, "avg_logprob": -0.2415087761417512, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.019855113700032234}, {"id": 323, "seek": 174614, "start": 1758.66, "end": 1762.94, "text": " vuelta esta probabilidad porque nos da toda otra forma de calcularlo que no podr\u00edamos hacerlos", "tokens": [50990, 41542, 5283, 31959, 4580, 4021, 3269, 1120, 11687, 13623, 8366, 368, 2104, 17792, 752, 631, 572, 15305, 16275, 6720, 9389, 51204], "temperature": 0.0, "avg_logprob": -0.2415087761417512, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.019855113700032234}, {"id": 324, "seek": 174614, "start": 1762.94, "end": 1768.14, "text": " y calculamos la probabilidad directa. Es como que hay mejores herramientas para hacer eso.", "tokens": [51204, 288, 4322, 2151, 635, 31959, 4580, 2047, 64, 13, 2313, 2617, 631, 4842, 42284, 38271, 296, 1690, 6720, 7287, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2415087761417512, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.019855113700032234}, {"id": 325, "seek": 174614, "start": 1768.14, "end": 1772.26, "text": " Bueno, de vuelta, esto es la ecuaci\u00f3n fundamental de la traducci\u00f3n autom\u00e1tica estad\u00edstica.", "tokens": [51464, 16046, 11, 368, 41542, 11, 7433, 785, 635, 11437, 84, 3482, 8088, 368, 635, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 13, 51670], "temperature": 0.0, "avg_logprob": -0.2415087761417512, "compression_ratio": 1.7444444444444445, "no_speech_prob": 0.019855113700032234}, {"id": 326, "seek": 177226, "start": 1772.26, "end": 1777.58, "text": " Y techo es el argumento que hace m\u00e1ximo la probabilidad de fedadoe por la probabilidad", "tokens": [50364, 398, 535, 5738, 785, 806, 6770, 78, 631, 10032, 38876, 635, 31959, 4580, 368, 4636, 1573, 68, 1515, 635, 31959, 4580, 50630], "temperature": 0.0, "avg_logprob": -0.2814663325514749, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.6343809366226196}, {"id": 327, "seek": 177226, "start": 1777.58, "end": 1782.78, "text": " de. Y para poder resolver esta ecuaci\u00f3n necesitamos tres cosas. Necesitamos un modelo de", "tokens": [50630, 368, 13, 398, 1690, 8152, 34480, 5283, 11437, 84, 3482, 38661, 2151, 15890, 12218, 13, 1734, 887, 270, 2151, 517, 27825, 368, 50890], "temperature": 0.0, "avg_logprob": -0.2814663325514749, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.6343809366226196}, {"id": 328, "seek": 177226, "start": 1782.78, "end": 1790.94, "text": " lenguaje p.d.e. que es el que se va a encargar de la fluidez. Esto se calcula mediante la t\u00e9cnica", "tokens": [50890, 35044, 84, 11153, 280, 13, 67, 13, 68, 13, 631, 785, 806, 631, 369, 2773, 257, 2058, 289, 2976, 368, 635, 5029, 45170, 13, 20880, 369, 4322, 64, 17269, 2879, 635, 45411, 51298], "temperature": 0.0, "avg_logprob": -0.2814663325514749, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.6343809366226196}, {"id": 329, "seek": 177226, "start": 1790.94, "end": 1796.62, "text": " de negramas en general. Los negramas son bastante f\u00e1ciles de construir, digamos, porque yo", "tokens": [51298, 368, 408, 861, 19473, 465, 2674, 13, 7632, 408, 861, 19473, 1872, 14651, 17474, 279, 368, 38445, 11, 36430, 11, 4021, 5290, 51582], "temperature": 0.0, "avg_logprob": -0.2814663325514749, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.6343809366226196}, {"id": 330, "seek": 179662, "start": 1796.62, "end": 1804.3799999999999, "text": " necesito texto en un solo idioma, solo en el idioma destino. p.d.e. es la componente", "tokens": [50364, 11909, 3528, 35503, 465, 517, 6944, 18014, 6440, 11, 6944, 465, 806, 18014, 6440, 2677, 2982, 13, 280, 13, 67, 13, 68, 13, 785, 635, 4026, 1576, 50752], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 331, "seek": 179662, "start": 1804.3799999999999, "end": 1808.4599999999998, "text": " que se encarga de la adecuaci\u00f3n y se resuelve mediante el modelo de traducci\u00f3n. El modelo", "tokens": [50752, 631, 369, 2058, 289, 3680, 368, 635, 614, 3045, 84, 3482, 288, 369, 725, 3483, 303, 17269, 2879, 806, 27825, 368, 2479, 1311, 5687, 13, 2699, 27825, 50956], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 332, "seek": 179662, "start": 1808.4599999999998, "end": 1812.1, "text": " de traducci\u00f3n no es tan f\u00e1cil de construir como el modelo de lenguaje, porque el modelo", "tokens": [50956, 368, 2479, 1311, 5687, 572, 785, 7603, 17474, 368, 38445, 2617, 806, 27825, 368, 35044, 84, 11153, 11, 4021, 806, 27825, 51138], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 333, "seek": 179662, "start": 1812.1, "end": 1815.1399999999999, "text": " de traducci\u00f3n voy a necesitar texto de bil\u00edngue. De hecho, voy a necesitar un corpus", "tokens": [51138, 368, 2479, 1311, 5687, 7552, 257, 11909, 3981, 35503, 368, 8588, 870, 872, 622, 13, 1346, 13064, 11, 7552, 257, 11909, 3981, 517, 1181, 31624, 51290], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 334, "seek": 179662, "start": 1815.1399999999999, "end": 1819.9399999999998, "text": " para el hilo que sea texto en dos idiomas que adem\u00e1s tengan su correspondencia. Y adem\u00e1s", "tokens": [51290, 1690, 806, 276, 10720, 631, 4158, 35503, 465, 4491, 18014, 7092, 631, 21251, 46874, 459, 6805, 10974, 13, 398, 21251, 51530], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 335, "seek": 179662, "start": 1819.9399999999998, "end": 1825.02, "text": " necesito una tercer componente. Esta tercer componente se llama de codificador. Y se trata", "tokens": [51530, 11909, 3528, 2002, 38103, 4026, 1576, 13, 20547, 38103, 4026, 1576, 369, 23272, 368, 17656, 1089, 5409, 13, 398, 369, 31920, 51784], "temperature": 0.0, "avg_logprob": -0.19666404724121095, "compression_ratio": 1.917562724014337, "no_speech_prob": 0.45812565088272095}, {"id": 336, "seek": 182502, "start": 1825.02, "end": 1829.74, "text": " de lo siguiente. Yo cuando estoy buscando, cuando estoy resolvido esta ecuaci\u00f3n, yo veo", "tokens": [50364, 368, 450, 25666, 13, 7616, 7767, 15796, 46804, 11, 7767, 15796, 7923, 85, 2925, 5283, 11437, 84, 3482, 11, 5290, 41319, 50600], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 337, "seek": 182502, "start": 1829.74, "end": 1834.26, "text": " la oraci\u00f3n F y quiero buscar la mejor E que maximizes esta ecuaci\u00f3n. Pero en realidad", "tokens": [50600, 635, 420, 3482, 479, 288, 16811, 26170, 635, 11479, 462, 631, 5138, 5660, 5283, 11437, 84, 3482, 13, 9377, 465, 25635, 50826], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 338, "seek": 182502, "start": 1834.26, "end": 1838.34, "text": " lo que tendr\u00eda que hacer es probar con todas las oraciones E del idioma destino, todas", "tokens": [50826, 450, 631, 3928, 37183, 631, 6720, 785, 1239, 289, 416, 10906, 2439, 420, 9188, 462, 1103, 18014, 6440, 2677, 2982, 11, 10906, 51030], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 339, "seek": 182502, "start": 1838.34, "end": 1844.0, "text": " las oraciones posibles que cuantas son las oraciones del idioma destino. Son infinitas", "tokens": [51030, 2439, 420, 9188, 1366, 14428, 631, 2702, 49153, 1872, 2439, 420, 9188, 1103, 18014, 6440, 2677, 2982, 13, 5185, 7193, 14182, 51313], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 340, "seek": 182502, "start": 1844.0, "end": 1847.3, "text": " oraciones posibles en el idioma destino. Entonces yo estar\u00eda probando con infinitas", "tokens": [51313, 420, 9188, 1366, 14428, 465, 806, 18014, 6440, 2677, 2982, 13, 15097, 5290, 8755, 2686, 1239, 1806, 416, 7193, 14182, 51478], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 341, "seek": 182502, "start": 1847.3, "end": 1850.84, "text": " oraciones hasta que una de ellas me d\u00e9 el m\u00e1ximo. Obviamente esto no es un problema", "tokens": [51478, 420, 9188, 10764, 631, 2002, 368, 38397, 385, 2795, 806, 38876, 13, 4075, 23347, 7433, 572, 785, 517, 12395, 51655], "temperature": 0.0, "avg_logprob": -0.2149281709090523, "compression_ratio": 1.9772727272727273, "no_speech_prob": 0.03375542163848877}, {"id": 342, "seek": 185084, "start": 1850.84, "end": 1854.9199999999998, "text": " atratable, yo no puedo probar con infinitas oraciones. Lo que necesito es un proceso", "tokens": [50364, 412, 4481, 712, 11, 5290, 572, 21612, 1239, 289, 416, 7193, 14182, 420, 9188, 13, 6130, 631, 11909, 3528, 785, 517, 29314, 50568], "temperature": 0.0, "avg_logprob": -0.24989066446634164, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.008136470802128315}, {"id": 343, "seek": 185084, "start": 1854.9199999999998, "end": 1859.86, "text": " que me limites a cantidad de b\u00fasqueda de infinitas oraciones a algo atratable. Entonces", "tokens": [50568, 631, 385, 2364, 3324, 257, 33757, 368, 272, 10227, 358, 8801, 368, 7193, 14182, 420, 9188, 257, 8655, 412, 4481, 712, 13, 15097, 50815], "temperature": 0.0, "avg_logprob": -0.24989066446634164, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.008136470802128315}, {"id": 344, "seek": 185084, "start": 1859.86, "end": 1865.8799999999999, "text": " el codificador va a ser un algoritmo de b\u00fasqueda que va a agarrar la oraci\u00f3n origen y", "tokens": [50815, 806, 17656, 1089, 5409, 2773, 257, 816, 517, 3501, 50017, 3280, 368, 272, 10227, 358, 8801, 631, 2773, 257, 623, 2284, 289, 635, 420, 3482, 2349, 268, 288, 51116], "temperature": 0.0, "avg_logprob": -0.24989066446634164, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.008136470802128315}, {"id": 345, "seek": 185084, "start": 1865.8799999999999, "end": 1871.04, "text": " me va a devolver la cien, doscientas, mil oraciones destino, candidatas m\u00e1s probables que", "tokens": [51116, 385, 2773, 257, 1905, 401, 331, 635, 269, 1053, 11, 4491, 5412, 296, 11, 1962, 420, 9188, 2677, 2982, 11, 6268, 37892, 3573, 1239, 2965, 631, 51374], "temperature": 0.0, "avg_logprob": -0.24989066446634164, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.008136470802128315}, {"id": 346, "seek": 185084, "start": 1871.04, "end": 1876.6799999999998, "text": " alzelo curra para que yo pueda resolver y calcular esa ecuaci\u00f3n para esas oraciones en", "tokens": [51374, 419, 89, 10590, 1262, 424, 1690, 631, 5290, 31907, 34480, 288, 2104, 17792, 11342, 11437, 84, 3482, 1690, 23388, 420, 9188, 465, 51656], "temperature": 0.0, "avg_logprob": -0.24989066446634164, "compression_ratio": 1.752988047808765, "no_speech_prob": 0.008136470802128315}, {"id": 347, "seek": 187668, "start": 1876.68, "end": 1881.16, "text": " vez de para todas las posibles. Entonces lo que hace es volver este problema atratable.", "tokens": [50364, 5715, 368, 1690, 10906, 2439, 1366, 14428, 13, 15097, 450, 631, 10032, 785, 33998, 4065, 12395, 412, 4481, 712, 13, 50588], "temperature": 0.0, "avg_logprob": -0.26172557798754265, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0719945877790451}, {"id": 348, "seek": 187668, "start": 1881.16, "end": 1889.96, "text": " Vamos a ver tambi\u00e9n una ecuaci\u00f3n de codificaci\u00f3n que se llama Binsarch. Bueno, entonces un", "tokens": [50588, 10894, 257, 1306, 6407, 2002, 11437, 84, 3482, 368, 17656, 40802, 631, 369, 23272, 363, 1292, 1178, 13, 16046, 11, 13003, 517, 51028], "temperature": 0.0, "avg_logprob": -0.26172557798754265, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0719945877790451}, {"id": 349, "seek": 187668, "start": 1889.96, "end": 1893.8, "text": " poco m\u00e1s sobre modelos del lenguaje. La componente pd de la ecuaci\u00f3n era la que", "tokens": [51028, 10639, 3573, 5473, 2316, 329, 1103, 35044, 84, 11153, 13, 2369, 4026, 1576, 280, 67, 368, 635, 11437, 84, 3482, 4249, 635, 631, 51220], "temperature": 0.0, "avg_logprob": -0.26172557798754265, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0719945877790451}, {"id": 350, "seek": 187668, "start": 1893.8, "end": 1897.76, "text": " med\u00eda las fluidez y se calculaba mediante un modelo del lenguaje. Los modelos del lenguaje", "tokens": [51220, 1205, 2686, 2439, 5029, 45170, 288, 369, 4322, 5509, 17269, 2879, 517, 27825, 1103, 35044, 84, 11153, 13, 7632, 2316, 329, 1103, 35044, 84, 11153, 51418], "temperature": 0.0, "avg_logprob": -0.26172557798754265, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0719945877790451}, {"id": 351, "seek": 187668, "start": 1897.76, "end": 1902.2, "text": " son relativamente f\u00e1ciles de construir porque necesitamos informaci\u00f3n mono-lingue, informaci\u00f3n", "tokens": [51418, 1872, 21960, 3439, 17474, 279, 368, 38445, 4021, 38661, 2151, 21660, 35624, 12, 1688, 622, 11, 21660, 51640], "temperature": 0.0, "avg_logprob": -0.26172557798754265, "compression_ratio": 1.6777777777777778, "no_speech_prob": 0.0719945877790451}, {"id": 352, "seek": 190220, "start": 1902.2, "end": 1907.92, "text": " solamente del lenguaje destino. Entonces en la web tenemos monton, toneladas de informaci\u00f3n,", "tokens": [50364, 27814, 1103, 35044, 84, 11153, 2677, 2982, 13, 15097, 465, 635, 3670, 9914, 8143, 266, 11, 2952, 338, 6872, 368, 21660, 11, 50650], "temperature": 0.0, "avg_logprob": -0.29076551853265975, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.051963165402412415}, {"id": 353, "seek": 190220, "start": 1907.92, "end": 1912.96, "text": " bueno, de muchos idiomas. Entonces como sonetamos informaci\u00f3n idiomas, sacamos texto, web, noticias,", "tokens": [50650, 11974, 11, 368, 17061, 18014, 7092, 13, 15097, 2617, 1872, 302, 2151, 21660, 18014, 7092, 11, 4899, 2151, 35503, 11, 3670, 11, 406, 48042, 11, 50902], "temperature": 0.0, "avg_logprob": -0.29076551853265975, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.051963165402412415}, {"id": 354, "seek": 190220, "start": 1912.96, "end": 1920.3600000000001, "text": " blogs, etc\u00e9tera y compilamos un gran corpus del lenguaje destino. Los modelos que se utilizan", "tokens": [50902, 31038, 11, 5183, 526, 23833, 288, 715, 388, 2151, 517, 9370, 1181, 31624, 1103, 35044, 84, 11153, 2677, 2982, 13, 7632, 2316, 329, 631, 369, 19906, 282, 51272], "temperature": 0.0, "avg_logprob": -0.29076551853265975, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.051963165402412415}, {"id": 355, "seek": 190220, "start": 1920.3600000000001, "end": 1923.32, "text": " para traducci\u00f3n autom\u00e1tica en general son modelos basados en enegramas que ya hemos", "tokens": [51272, 1690, 2479, 1311, 5687, 3553, 23432, 465, 2674, 1872, 2316, 329, 987, 4181, 465, 465, 1146, 2356, 296, 631, 2478, 15396, 51420], "temperature": 0.0, "avg_logprob": -0.29076551853265975, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.051963165402412415}, {"id": 356, "seek": 190220, "start": 1923.32, "end": 1929.8400000000001, "text": " visto en el curso como funcionaban, se suele usar orden de 4 o 5, en otras tareas de pdn", "tokens": [51420, 17558, 465, 806, 31085, 2617, 14186, 18165, 11, 369, 459, 16884, 14745, 28615, 368, 1017, 277, 1025, 11, 465, 20244, 49423, 296, 368, 280, 67, 77, 51746], "temperature": 0.0, "avg_logprob": -0.29076551853265975, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.051963165402412415}, {"id": 357, "seek": 192984, "start": 1929.84, "end": 1935.24, "text": " suele usar ordenes m\u00e1s chicos, pero para ac\u00e1 da buenos resultados con 4 o 5. Y bueno,", "tokens": [50364, 459, 16884, 14745, 28615, 279, 3573, 46070, 11, 4768, 1690, 23496, 1120, 49617, 36796, 416, 1017, 277, 1025, 13, 398, 11974, 11, 50634], "temperature": 0.0, "avg_logprob": -0.24371121610913957, "compression_ratio": 1.5884476534296028, "no_speech_prob": 0.0069295191206038}, {"id": 358, "seek": 192984, "start": 1935.24, "end": 1938.9199999999998, "text": " el importante es tener una gran cantidad de material de entrenamiento. O sea, los mejores", "tokens": [50634, 806, 9416, 785, 11640, 2002, 9370, 33757, 368, 2527, 368, 45069, 16971, 13, 422, 4158, 11, 1750, 42284, 50818], "temperature": 0.0, "avg_logprob": -0.24371121610913957, "compression_ratio": 1.5884476534296028, "no_speech_prob": 0.0069295191206038}, {"id": 359, "seek": 192984, "start": 1938.9199999999998, "end": 1944.36, "text": " modelos que usan Google Translate y otras empresas usan trisiones de palabras y bueno,", "tokens": [50818, 2316, 329, 631, 505, 282, 3329, 6531, 17593, 288, 20244, 26433, 505, 282, 504, 1991, 279, 368, 35240, 288, 11974, 11, 51090], "temperature": 0.0, "avg_logprob": -0.24371121610913957, "compression_ratio": 1.5884476534296028, "no_speech_prob": 0.0069295191206038}, {"id": 360, "seek": 192984, "start": 1944.36, "end": 1949.6799999999998, "text": " son necesitan hardware especial, especialmente dise\u00f1ado para poder ir r\u00e1pido y recuperar", "tokens": [51090, 1872, 11909, 9670, 8837, 15342, 11, 41546, 3814, 2791, 1573, 1690, 8152, 3418, 24893, 288, 25692, 289, 51356], "temperature": 0.0, "avg_logprob": -0.24371121610913957, "compression_ratio": 1.5884476534296028, "no_speech_prob": 0.0069295191206038}, {"id": 361, "seek": 192984, "start": 1949.6799999999998, "end": 1954.4399999999998, "text": " la informaci\u00f3n. O si no, bueno, si estoy hablando de un dominio acotado, usar datos", "tokens": [51356, 635, 21660, 13, 422, 1511, 572, 11, 11974, 11, 1511, 15796, 29369, 368, 517, 8859, 1004, 696, 310, 1573, 11, 14745, 27721, 51594], "temperature": 0.0, "avg_logprob": -0.24371121610913957, "compression_ratio": 1.5884476534296028, "no_speech_prob": 0.0069295191206038}, {"id": 362, "seek": 195444, "start": 1954.44, "end": 1958.2, "text": " de dominio para entrenar que tambi\u00e9n va a ser buenos resultados.", "tokens": [50364, 368, 8859, 1004, 1690, 45069, 289, 631, 6407, 2773, 257, 816, 49617, 36796, 13, 50552], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 363, "seek": 195444, "start": 1958.2, "end": 1960.56, "text": " \u00bfQu\u00e9 es la de la t\u00e9cnica?", "tokens": [50552, 3841, 15137, 785, 635, 368, 635, 45411, 30, 50670], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 364, "seek": 195444, "start": 1960.56, "end": 1964.48, "text": " Las t\u00e9cnicas de Moodin es cuando hay alguna enegrama que no viste lo que te va a pasar", "tokens": [50670, 10663, 25564, 40672, 368, 376, 1816, 259, 785, 7767, 4842, 20651, 465, 1146, 29762, 631, 572, 371, 8375, 450, 631, 535, 2773, 257, 25344, 50866], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 365, "seek": 195444, "start": 1964.48, "end": 1968.24, "text": " es que la probabilidad es cero. Y ah\u00ed te va a dar todo cero. En realidad, las mejores", "tokens": [50866, 785, 631, 635, 31959, 4580, 785, 269, 2032, 13, 398, 12571, 535, 2773, 257, 4072, 5149, 269, 2032, 13, 2193, 25635, 11, 2439, 42284, 51054], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 366, "seek": 195444, "start": 1968.24, "end": 1971.56, "text": " t\u00e9cnicas es muy significado, darle una buena probabilidad a eso a pesar de que nunca", "tokens": [51054, 25564, 40672, 785, 5323, 3350, 1573, 11, 37666, 2002, 25710, 31959, 4580, 257, 7287, 257, 41951, 368, 631, 13768, 51220], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 367, "seek": 195444, "start": 1971.56, "end": 1977.0, "text": " lo yo ha visto. Se dice que las mejores mejoras, digamos, las m\u00e1s grandes mejoras en los", "tokens": [51220, 450, 5290, 324, 17558, 13, 1100, 10313, 631, 2439, 42284, 11479, 296, 11, 36430, 11, 2439, 3573, 16640, 11479, 296, 465, 1750, 51492], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 368, "seek": 195444, "start": 1977.0, "end": 1980.48, "text": " modelos en la traducci\u00f3n autom\u00e1tica de los \u00faltimos a\u00f1os se han dado porque hay", "tokens": [51492, 2316, 329, 465, 635, 2479, 1311, 5687, 3553, 23432, 368, 1750, 33013, 11424, 369, 7276, 29568, 4021, 4842, 51666], "temperature": 0.0, "avg_logprob": -0.3578362037395609, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.21678699553012848}, {"id": 369, "seek": 198048, "start": 1980.48, "end": 1986.16, "text": " mejores modelos de lenguaje que me dan traducciones que son m\u00e1s fluidas. Y bueno,", "tokens": [50364, 42284, 2316, 329, 368, 35044, 84, 11153, 631, 385, 3277, 2479, 1311, 23469, 631, 1872, 3573, 5029, 11382, 13, 398, 11974, 11, 50648], "temperature": 0.0, "avg_logprob": -0.2621124027011631, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.04961413890123367}, {"id": 370, "seek": 198048, "start": 1986.16, "end": 1991.24, "text": " usualmente hay como cierta correlaci\u00f3n o cierta inclinaci\u00f3n hacia las fluidas.", "tokens": [50648, 7713, 4082, 4842, 2617, 39769, 1328, 13983, 3482, 277, 39769, 1328, 834, 5045, 3482, 21365, 2439, 5029, 11382, 13, 50902], "temperature": 0.0, "avg_logprob": -0.2621124027011631, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.04961413890123367}, {"id": 371, "seek": 198048, "start": 1991.24, "end": 1995.84, "text": " La gente prefiere cuando las oraciones son zonas m\u00e1s naturales.", "tokens": [50902, 2369, 3788, 18417, 14412, 7767, 2439, 420, 9188, 1872, 710, 38027, 3573, 3303, 279, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2621124027011631, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.04961413890123367}, {"id": 372, "seek": 198048, "start": 1995.84, "end": 2000.56, "text": " Ac\u00e1 en ejemplo, esto era sacado un sistema de traducci\u00f3n del chino al ingl\u00e9s, un sistema", "tokens": [51132, 5097, 842, 465, 13358, 11, 7433, 4249, 4899, 1573, 517, 13245, 368, 2479, 1311, 5687, 1103, 417, 2982, 419, 49766, 11, 517, 13245, 51368], "temperature": 0.0, "avg_logprob": -0.2621124027011631, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.04961413890123367}, {"id": 373, "seek": 198048, "start": 2000.56, "end": 2005.6, "text": " estad\u00edstico de San Staxis, que cuando no utilizaba modelo de lenguaje ten\u00eda un", "tokens": [51368, 39160, 19512, 2789, 368, 5271, 745, 24633, 11, 631, 7767, 572, 19906, 5509, 27825, 368, 35044, 84, 11153, 23718, 517, 51620], "temperature": 0.0, "avg_logprob": -0.2621124027011631, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.04961413890123367}, {"id": 374, "seek": 200560, "start": 2005.6, "end": 2012.28, "text": " puntaje de 25x2 al incorporar modelo de lenguaje subi\u00f3 como un 20% su performance y lleg\u00f3", "tokens": [50364, 4468, 1328, 2884, 368, 3552, 87, 17, 419, 8788, 289, 27825, 368, 35044, 84, 11153, 1422, 7138, 2617, 517, 945, 4, 459, 3389, 288, 46182, 50698], "temperature": 0.0, "avg_logprob": -0.2637866260559578, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0971093401312828}, {"id": 375, "seek": 200560, "start": 2012.28, "end": 2017.1999999999998, "text": " a 31x2 como 6 puntos. Esos puntos corresponden a una medida que vamos a ver dentro de un", "tokens": [50698, 257, 10353, 87, 17, 2617, 1386, 34375, 13, 2313, 329, 34375, 6805, 268, 257, 2002, 32984, 631, 5295, 257, 1306, 10856, 368, 517, 50944], "temperature": 0.0, "avg_logprob": -0.2637866260559578, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0971093401312828}, {"id": 376, "seek": 200560, "start": 2017.1999999999998, "end": 2021.08, "text": " rato que le llama medida blue, que es una medida muy utilizada en lo que es traducci\u00f3n", "tokens": [50944, 367, 2513, 631, 476, 23272, 32984, 3344, 11, 631, 785, 2002, 32984, 5323, 19906, 1538, 465, 450, 631, 785, 2479, 1311, 5687, 51138], "temperature": 0.0, "avg_logprob": -0.2637866260559578, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0971093401312828}, {"id": 377, "seek": 200560, "start": 2021.08, "end": 2028.12, "text": " estad\u00edstica. La traducci\u00f3n autom\u00e1tica en general, pero bueno, ahora solamente saber", "tokens": [51138, 39160, 19512, 2262, 13, 2369, 2479, 1311, 5687, 3553, 23432, 465, 2674, 11, 4768, 11974, 11, 9923, 27814, 12489, 51490], "temperature": 0.0, "avg_logprob": -0.2637866260559578, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0971093401312828}, {"id": 378, "seek": 200560, "start": 2028.12, "end": 2034.6, "text": " que 6 puntos es una mejora que es much\u00edsimo. Y como es que mejora esto, mejora haciendo", "tokens": [51490, 631, 1386, 34375, 785, 2002, 11479, 64, 631, 785, 44722, 13, 398, 2617, 785, 631, 11479, 64, 7433, 11, 11479, 64, 20509, 51814], "temperature": 0.0, "avg_logprob": -0.2637866260559578, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0971093401312828}, {"id": 379, "seek": 203460, "start": 2034.6, "end": 2039.0, "text": " que las traducciones que devuelven en general sean m\u00e1s fluidas, son m\u00e1s naturales en el", "tokens": [50364, 631, 2439, 2479, 1311, 23469, 631, 1905, 3483, 553, 465, 2674, 37670, 3573, 5029, 11382, 11, 1872, 3573, 3303, 279, 465, 806, 50584], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 380, "seek": 203460, "start": 2039.0, "end": 2043.3999999999999, "text": " lenguaje de estino. Y ac\u00e1 hay un ejemplo de traducciones de ese mismo sistema. Yo ten\u00eda", "tokens": [50584, 35044, 84, 11153, 368, 871, 2982, 13, 398, 23496, 4842, 517, 13358, 368, 2479, 1311, 23469, 368, 10167, 12461, 13245, 13, 7616, 23718, 50804], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 381, "seek": 203460, "start": 2043.3999999999999, "end": 2047.04, "text": " una traducci\u00f3n de referencia que era, I don't have enough money with me to buy a new", "tokens": [50804, 2002, 2479, 1311, 5687, 368, 2864, 10974, 631, 4249, 11, 286, 500, 380, 362, 1547, 1460, 365, 385, 281, 2256, 257, 777, 50986], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 382, "seek": 203460, "start": 2047.04, "end": 2052.1, "text": " airplane ticket. El sistema sin el modelo de lenguaje devolv\u00eda esta traducci\u00f3n, de", "tokens": [50986, 17130, 10550, 13, 2699, 13245, 3343, 806, 27825, 368, 35044, 84, 11153, 1905, 401, 85, 2686, 5283, 2479, 1311, 5687, 11, 368, 51239], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 383, "seek": 203460, "start": 2052.1, "end": 2057.16, "text": " decir, I don't have enough bag on me change please go a new by plane. Que no, no se entiende", "tokens": [51239, 10235, 11, 286, 500, 380, 362, 1547, 3411, 322, 385, 1319, 1767, 352, 257, 777, 538, 5720, 13, 4493, 572, 11, 572, 369, 948, 45816, 51492], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 384, "seek": 203460, "start": 2057.16, "end": 2061.6, "text": " mucho que lo que dice, no es gramatical. Pero al agregar el modelo de traducci\u00f3n, su", "tokens": [51492, 9824, 631, 450, 631, 10313, 11, 572, 785, 21353, 267, 804, 13, 9377, 419, 4554, 2976, 806, 27825, 368, 2479, 1311, 5687, 11, 459, 51714], "temperature": 0.0, "avg_logprob": -0.24217999608893143, "compression_ratio": 1.7633333333333334, "no_speech_prob": 0.1000356674194336}, {"id": 385, "seek": 206160, "start": 2061.6, "end": 2066.2799999999997, "text": " traducci\u00f3n es la siguiente, I have enough money to buy a new one by air, que suena mucho", "tokens": [50364, 2479, 1311, 5687, 785, 635, 25666, 11, 286, 362, 1547, 1460, 281, 2256, 257, 777, 472, 538, 1988, 11, 631, 459, 4118, 9824, 50598], "temperature": 0.0, "avg_logprob": -0.21570170858631962, "compression_ratio": 1.6642066420664208, "no_speech_prob": 0.02433190681040287}, {"id": 386, "seek": 206160, "start": 2066.2799999999997, "end": 2076.52, "text": " mejor \u00bfverdad? Que les parece acerca del significado. El significado es el opuesto, digamos, ac\u00e1", "tokens": [50598, 11479, 3841, 331, 20034, 30, 4493, 1512, 14120, 46321, 1103, 3350, 1573, 13, 2699, 3350, 1573, 785, 806, 999, 22057, 11, 36430, 11, 23496, 51110], "temperature": 0.0, "avg_logprob": -0.21570170858631962, "compression_ratio": 1.6642066420664208, "no_speech_prob": 0.02433190681040287}, {"id": 387, "seek": 206160, "start": 2076.52, "end": 2079.72, "text": " est\u00e1 diciendo que tiene suficiente plata para comprar uno por aire y ac\u00e1 dice que", "tokens": [51110, 3192, 42797, 631, 7066, 33958, 30780, 1690, 22077, 8526, 1515, 42885, 288, 23496, 10313, 631, 51270], "temperature": 0.0, "avg_logprob": -0.21570170858631962, "compression_ratio": 1.6642066420664208, "no_speech_prob": 0.02433190681040287}, {"id": 388, "seek": 206160, "start": 2079.72, "end": 2084.72, "text": " no tiene suficiente plata para comprar un pasaje de avi\u00f3n. O sea, este suena much\u00edsimo", "tokens": [51270, 572, 7066, 33958, 30780, 1690, 22077, 517, 1736, 11153, 368, 1305, 2560, 13, 422, 4158, 11, 4065, 459, 4118, 44722, 51520], "temperature": 0.0, "avg_logprob": -0.21570170858631962, "compression_ratio": 1.6642066420664208, "no_speech_prob": 0.02433190681040287}, {"id": 389, "seek": 206160, "start": 2084.72, "end": 2088.3199999999997, "text": " mejor porque est\u00e1 ni siquiera gramatical, pero esta por lo menos manten\u00eda la negaci\u00f3n,", "tokens": [51520, 11479, 4021, 3192, 3867, 1511, 35134, 21353, 267, 804, 11, 4768, 5283, 1515, 450, 8902, 38417, 2686, 635, 2485, 3482, 11, 51700], "temperature": 0.0, "avg_logprob": -0.21570170858631962, "compression_ratio": 1.6642066420664208, "no_speech_prob": 0.02433190681040287}, {"id": 390, "seek": 208832, "start": 2088.32, "end": 2093.0, "text": " digamos, manten\u00eda que era una oraci\u00f3n negativa. Entonces hay que tener cuidado con esto.", "tokens": [50364, 36430, 11, 38417, 2686, 631, 4249, 2002, 420, 3482, 2485, 18740, 13, 15097, 4842, 631, 11640, 31891, 416, 7433, 13, 50598], "temperature": 0.0, "avg_logprob": -0.22796317821240608, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.017819346860051155}, {"id": 391, "seek": 208832, "start": 2093.0, "end": 2097.4, "text": " La traducci\u00f3n suena mucho mejor, pero a veces podemos estar sacrificando fidelidad,", "tokens": [50598, 2369, 2479, 1311, 5687, 459, 4118, 9824, 11479, 11, 4768, 257, 17054, 12234, 8755, 14108, 1806, 283, 16189, 4580, 11, 50818], "temperature": 0.0, "avg_logprob": -0.22796317821240608, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.017819346860051155}, {"id": 392, "seek": 208832, "start": 2097.4, "end": 2104.76, "text": " sacrificando adecuaci\u00f3n de la traducci\u00f3n. Bien, eso es sobre modelos de lenguaje. Ahora", "tokens": [50818, 14108, 1806, 614, 3045, 84, 3482, 368, 635, 2479, 1311, 5687, 13, 16956, 11, 7287, 785, 5473, 2316, 329, 368, 35044, 84, 11153, 13, 18840, 51186], "temperature": 0.0, "avg_logprob": -0.22796317821240608, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.017819346860051155}, {"id": 393, "seek": 208832, "start": 2104.76, "end": 2112.48, "text": " pasemos a la otra, los modelos de traducci\u00f3n. La componente pdf de la ecuaci\u00f3n mide lo que", "tokens": [51186, 1736, 4485, 257, 635, 13623, 11, 1750, 2316, 329, 368, 2479, 1311, 5687, 13, 2369, 4026, 1576, 280, 45953, 368, 635, 11437, 84, 3482, 275, 482, 450, 631, 51572], "temperature": 0.0, "avg_logprob": -0.22796317821240608, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.017819346860051155}, {"id": 394, "seek": 208832, "start": 2112.48, "end": 2116.96, "text": " es la adecuaci\u00f3n o fidelidad de una traducci\u00f3n y la otra y para esto necesito corpos para", "tokens": [51572, 785, 635, 614, 3045, 84, 3482, 277, 283, 16189, 4580, 368, 2002, 2479, 1311, 5687, 288, 635, 13623, 288, 1690, 7433, 11909, 3528, 1181, 30010, 1690, 51796], "temperature": 0.0, "avg_logprob": -0.22796317821240608, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.017819346860051155}, {"id": 395, "seek": 211696, "start": 2116.96, "end": 2122.16, "text": " leylos o corpos bil\u00edng\u00fces que para poder entrenar estos modelos. Los corpos bil\u00edng\u00fces", "tokens": [50364, 27786, 9389, 277, 1181, 30010, 8588, 870, 872, 774, 279, 631, 1690, 8152, 45069, 289, 12585, 2316, 329, 13, 7632, 1181, 30010, 8588, 870, 872, 774, 279, 50624], "temperature": 0.0, "avg_logprob": -0.25831601046776587, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.028429966419935226}, {"id": 396, "seek": 211696, "start": 2122.16, "end": 2125.96, "text": " son bastante m\u00e1s dif\u00edciles de construir que los corpos monol\u00edng\u00fces, digamos, no alcanza", "tokens": [50624, 1872, 14651, 3573, 17258, 279, 368, 38445, 631, 1750, 1181, 30010, 1108, 401, 870, 872, 774, 279, 11, 36430, 11, 572, 419, 7035, 2394, 50814], "temperature": 0.0, "avg_logprob": -0.25831601046776587, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.028429966419935226}, {"id": 397, "seek": 211696, "start": 2125.96, "end": 2130.42, "text": " con hacer una pasada por la web y obtener texto de un idioma. Y bueno, los modelos que", "tokens": [50814, 416, 6720, 2002, 1736, 1538, 1515, 635, 3670, 288, 28326, 260, 35503, 368, 517, 18014, 6440, 13, 398, 11974, 11, 1750, 2316, 329, 631, 51037], "temperature": 0.0, "avg_logprob": -0.25831601046776587, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.028429966419935226}, {"id": 398, "seek": 211696, "start": 2130.42, "end": 2137.68, "text": " vamos a ver son los propuestos por Brown y si equipo en 1993 que trabajan en IBM, ellos", "tokens": [51037, 5295, 257, 1306, 1872, 1750, 2365, 42738, 1515, 8030, 288, 1511, 30048, 465, 25137, 631, 9618, 282, 465, 23487, 11, 16353, 51400], "temperature": 0.0, "avg_logprob": -0.25831601046776587, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.028429966419935226}, {"id": 399, "seek": 211696, "start": 2137.68, "end": 2142.0, "text": " construyeron cinco modelos de c\u00f3mo construir cinco modelos, digamos, en creciente complejidad", "tokens": [51400, 12946, 7224, 266, 21350, 2316, 329, 368, 12826, 38445, 21350, 2316, 329, 11, 36430, 11, 465, 31668, 8413, 44424, 73, 4580, 51616], "temperature": 0.0, "avg_logprob": -0.25831601046776587, "compression_ratio": 1.6765799256505576, "no_speech_prob": 0.028429966419935226}, {"id": 400, "seek": 214200, "start": 2142.0, "end": 2148.28, "text": " de c\u00f3mo construir un modelo de traducci\u00f3n para traducci\u00f3n estad\u00edstica. Y bueno, los", "tokens": [50364, 368, 12826, 38445, 517, 27825, 368, 2479, 1311, 5687, 1690, 2479, 1311, 5687, 39160, 19512, 2262, 13, 398, 11974, 11, 1750, 50678], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 401, "seek": 214200, "start": 2148.28, "end": 2152.4, "text": " modelos, las diferencias de cada modelo se es en la historia de generaci\u00f3n de las", "tokens": [50678, 2316, 329, 11, 2439, 18959, 12046, 368, 8411, 27825, 369, 785, 465, 635, 18385, 368, 1337, 3482, 368, 2439, 50884], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 402, "seek": 214200, "start": 2152.4, "end": 2156.12, "text": " soldaciones candidatas. Y bueno, despu\u00e9s vamos a ver tambi\u00e9n otro modelo un poco m\u00e1s", "tokens": [50884, 3718, 9188, 6268, 37892, 13, 398, 11974, 11, 15283, 5295, 257, 1306, 6407, 11921, 27825, 517, 10639, 3573, 51070], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 403, "seek": 214200, "start": 2156.12, "end": 2161.96, "text": " moderno, pero bueno, vamos a empezar viendo m\u00e1s bien los modelos de Brown. Aqu\u00ed me refiero", "tokens": [51070, 4363, 78, 11, 4768, 11974, 11, 5295, 257, 31168, 34506, 3573, 3610, 1750, 2316, 329, 368, 8030, 13, 24386, 385, 1895, 12030, 51362], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 404, "seek": 214200, "start": 2161.96, "end": 2167.04, "text": " con historia de generaci\u00f3n de las soldaciones candidatas. Una historia de generaci\u00f3n, esto", "tokens": [51362, 416, 18385, 368, 1337, 3482, 368, 2439, 3718, 9188, 6268, 37892, 13, 15491, 18385, 368, 1337, 3482, 11, 7433, 51616], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 405, "seek": 214200, "start": 2167.04, "end": 2170.56, "text": " lo digo ahora, pero en realidad lo vamos a profundizar despu\u00e9s. Una historia de generaci\u00f3n", "tokens": [51616, 450, 22990, 9923, 11, 4768, 465, 25635, 450, 5295, 257, 40958, 9736, 15283, 13, 15491, 18385, 368, 1337, 3482, 51792], "temperature": 0.0, "avg_logprob": -0.20640097242413144, "compression_ratio": 2.034090909090909, "no_speech_prob": 0.018265919759869576}, {"id": 406, "seek": 217056, "start": 2170.56, "end": 2173.96, "text": " en realidad es como una especie de proceso mental que seguir\u00eda un traductor cuando", "tokens": [50364, 465, 25635, 785, 2617, 2002, 49368, 368, 29314, 4973, 631, 18584, 2686, 517, 2479, 84, 1672, 7767, 50534], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 407, "seek": 217056, "start": 2173.96, "end": 2179.44, "text": " quiere pasar de una oraci\u00f3n a la otra. Entonces, estas historias se basan en decir, bueno,", "tokens": [50534, 23877, 25344, 368, 2002, 420, 3482, 257, 635, 13623, 13, 15097, 11, 13897, 4058, 4609, 369, 987, 282, 465, 10235, 11, 11974, 11, 50808], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 408, "seek": 217056, "start": 2179.44, "end": 2184.44, "text": " un traductor agarr\u00f3 una oraci\u00f3n en el idioma origen y despu\u00e9s elige la cantidad de palabras", "tokens": [50808, 517, 2479, 84, 1672, 623, 2284, 812, 2002, 420, 3482, 465, 806, 18014, 6440, 2349, 268, 288, 15283, 806, 3969, 635, 33757, 368, 35240, 51058], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 409, "seek": 217056, "start": 2184.44, "end": 2188.2, "text": " que voy a tener el idioma de estino, reordena palabras, despu\u00e9s va traduciendo una a una", "tokens": [51058, 631, 7552, 257, 11640, 806, 18014, 6440, 368, 871, 2982, 11, 319, 19058, 64, 35240, 11, 15283, 2773, 2479, 1311, 7304, 2002, 257, 2002, 51246], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 410, "seek": 217056, "start": 2188.2, "end": 2192.24, "text": " seg\u00fan un diccionario, despu\u00e9s agrega palabras nuevas que no estaban en la oraci\u00f3n.", "tokens": [51246, 36570, 517, 14285, 10015, 4912, 11, 15283, 623, 3375, 64, 35240, 42817, 631, 572, 36713, 465, 635, 420, 3482, 13, 51448], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 411, "seek": 217056, "start": 2192.24, "end": 2197.48, "text": " Ese tipo de cosas, digamos, ese tipo de pasos, me lo voy a escribir en la historia de generaci\u00f3n", "tokens": [51448, 462, 405, 9746, 368, 12218, 11, 36430, 11, 10167, 9746, 368, 1736, 329, 11, 385, 450, 7552, 257, 30598, 10119, 465, 635, 18385, 368, 1337, 3482, 51710], "temperature": 0.0, "avg_logprob": -0.23567777066617399, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.02127658762037754}, {"id": 412, "seek": 219748, "start": 2197.48, "end": 2201.32, "text": " y para que sirve eso, sirve para que a cada uno de esos pasos yo le pudo dar un valor", "tokens": [50364, 288, 1690, 631, 4735, 303, 7287, 11, 4735, 303, 1690, 631, 257, 8411, 8526, 368, 22411, 1736, 329, 5290, 476, 280, 6207, 4072, 517, 15367, 50556], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 413, "seek": 219748, "start": 2201.32, "end": 2205.68, "text": " num\u00e9rico, un valor en cuanto a probabilidades y despu\u00e9s lo que voy a hacer cuando entreno", "tokens": [50556, 1031, 526, 23776, 11, 517, 15367, 465, 36685, 257, 31959, 10284, 288, 15283, 450, 631, 7552, 257, 6720, 7767, 45069, 78, 50774], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 414, "seek": 219748, "start": 2205.68, "end": 2209.96, "text": " mi sistema es tu\u00f1ar esos valores num\u00e9ricos, tu\u00f1ar todas esas probabilidades para darme", "tokens": [50774, 2752, 13245, 785, 2604, 2791, 289, 22411, 38790, 1031, 27578, 329, 11, 2604, 2791, 289, 10906, 23388, 31959, 10284, 1690, 4072, 1398, 50988], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 415, "seek": 219748, "start": 2209.96, "end": 2217.48, "text": " el c\u00e1lculo de probabilidad total. Vamos a profundizar m\u00e1s de en esto despu\u00e9s, pero antes", "tokens": [50988, 806, 6476, 75, 25436, 368, 31959, 4580, 3217, 13, 10894, 257, 40958, 9736, 3573, 368, 465, 7433, 15283, 11, 4768, 11014, 51364], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 416, "seek": 219748, "start": 2217.48, "end": 2220.8, "text": " de pasar a lo que son las modelos de traducci\u00f3n, vamos a hablar un poco de c\u00f3mo se evaluan", "tokens": [51364, 368, 25344, 257, 450, 631, 1872, 2439, 2316, 329, 368, 2479, 1311, 5687, 11, 5295, 257, 21014, 517, 10639, 368, 12826, 369, 6133, 282, 51530], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 417, "seek": 219748, "start": 2220.8, "end": 2225.52, "text": " estos sistemas. En general, siempre es importante evaluar todo en el PLN, digamos, porque no", "tokens": [51530, 12585, 48720, 13, 2193, 2674, 11, 12758, 785, 9416, 6133, 289, 5149, 465, 806, 6999, 45, 11, 36430, 11, 4021, 572, 51766], "temperature": 0.0, "avg_logprob": -0.19869020822885874, "compression_ratio": 1.775244299674267, "no_speech_prob": 0.0010640107793733478}, {"id": 418, "seek": 222552, "start": 2225.52, "end": 2230.08, "text": " hay soluciones perfectas, entonces voy a tener sistemas que andan mejor o peor que otros.", "tokens": [50364, 4842, 1404, 46649, 2176, 296, 11, 13003, 7552, 257, 11640, 48720, 631, 293, 282, 11479, 277, 520, 284, 631, 16422, 13, 50592], "temperature": 0.0, "avg_logprob": -0.23590996686150045, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.013890092261135578}, {"id": 419, "seek": 222552, "start": 2230.08, "end": 2235.68, "text": " Y bueno, la traducci\u00f3n autom\u00e1tica obviamente no es la excepci\u00f3n. Entonces, me sirve", "tokens": [50592, 398, 11974, 11, 635, 2479, 1311, 5687, 3553, 23432, 36325, 572, 785, 635, 454, 27493, 5687, 13, 15097, 11, 385, 4735, 303, 50872], "temperature": 0.0, "avg_logprob": -0.23590996686150045, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.013890092261135578}, {"id": 420, "seek": 222552, "start": 2235.68, "end": 2238.92, "text": " poder evaluar los sistemas para poder saber qu\u00e9 sistema es mejor que el otro y adem\u00e1s,", "tokens": [50872, 8152, 6133, 289, 1750, 48720, 1690, 8152, 12489, 8057, 13245, 785, 11479, 631, 806, 11921, 288, 21251, 11, 51034], "temperature": 0.0, "avg_logprob": -0.23590996686150045, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.013890092261135578}, {"id": 421, "seek": 222552, "start": 2238.92, "end": 2243.68, "text": " si yo hago cambios en mi sistema, poder evaluar de vuelta a ver si mejor\u00e9 o no. Entonces,", "tokens": [51034, 1511, 5290, 38721, 18751, 2717, 465, 2752, 13245, 11, 8152, 6133, 289, 368, 41542, 257, 1306, 1511, 11479, 526, 277, 572, 13, 15097, 11, 51272], "temperature": 0.0, "avg_logprob": -0.23590996686150045, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.013890092261135578}, {"id": 422, "seek": 222552, "start": 2243.68, "end": 2247.96, "text": " \u00bfqu\u00e9 puedo considerar una buena traducci\u00f3n? Para empezar, eso es una pregunta que es abierto", "tokens": [51272, 3841, 16412, 21612, 1949, 289, 2002, 25710, 2479, 1311, 5687, 30, 11107, 31168, 11, 7287, 785, 2002, 24252, 631, 785, 410, 20747, 51486], "temperature": 0.0, "avg_logprob": -0.23590996686150045, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.013890092261135578}, {"id": 423, "seek": 224796, "start": 2247.96, "end": 2255.7200000000003, "text": " en su, digamos, esa abierta en su respuesta. O sea, yo ten\u00eda en un sistema de traducci\u00f3n", "tokens": [50364, 465, 459, 11, 36430, 11, 11342, 410, 811, 1328, 465, 459, 40585, 13, 422, 4158, 11, 5290, 23718, 465, 517, 13245, 368, 2479, 1311, 5687, 50752], "temperature": 0.0, "avg_logprob": -0.23571066819984493, "compression_ratio": 1.9652173913043478, "no_speech_prob": 0.17896391451358795}, {"id": 424, "seek": 224796, "start": 2255.7200000000003, "end": 2259.8, "text": " ten\u00eda una referencia, un candidato de referencia que era de CatSat on Demat, digamos,", "tokens": [50752, 23718, 2002, 2864, 10974, 11, 517, 6268, 2513, 368, 2864, 10974, 631, 4249, 368, 9565, 50, 267, 322, 4686, 267, 11, 36430, 11, 50956], "temperature": 0.0, "avg_logprob": -0.23571066819984493, "compression_ratio": 1.9652173913043478, "no_speech_prob": 0.17896391451358795}, {"id": 425, "seek": 224796, "start": 2259.8, "end": 2264.92, "text": " esa era una traducci\u00f3n de referencia y un sistema medio seis posibles candidatos para", "tokens": [50956, 11342, 4249, 2002, 2479, 1311, 5687, 368, 2864, 10974, 288, 517, 13245, 22123, 28233, 1366, 14428, 6268, 26818, 1690, 51212], "temperature": 0.0, "avg_logprob": -0.23571066819984493, "compression_ratio": 1.9652173913043478, "no_speech_prob": 0.17896391451358795}, {"id": 426, "seek": 224796, "start": 2264.92, "end": 2270.84, "text": " esa traducci\u00f3n. O sea, originalmente hab\u00eda una frase, por ejemplo, en China, la traducci\u00f3n", "tokens": [51212, 11342, 2479, 1311, 5687, 13, 422, 4158, 11, 3380, 4082, 16395, 2002, 38406, 11, 1515, 13358, 11, 465, 3533, 11, 635, 2479, 1311, 5687, 51508], "temperature": 0.0, "avg_logprob": -0.23571066819984493, "compression_ratio": 1.9652173913043478, "no_speech_prob": 0.17896391451358795}, {"id": 427, "seek": 224796, "start": 2270.84, "end": 2276.08, "text": " de referencia, la de CatSat on Demat y mi sistema a traducirme el chino medio estas opciones.", "tokens": [51508, 368, 2864, 10974, 11, 635, 368, 9565, 50, 267, 322, 4686, 267, 288, 2752, 13245, 257, 2479, 1311, 347, 1398, 806, 417, 2982, 22123, 13897, 999, 23469, 13, 51770], "temperature": 0.0, "avg_logprob": -0.23571066819984493, "compression_ratio": 1.9652173913043478, "no_speech_prob": 0.17896391451358795}, {"id": 428, "seek": 227608, "start": 2276.08, "end": 2281.7999999999997, "text": " Tengo de CatSat on Demat Sat de Cat, de Cat on the floor, a CatSat on Demat, de CatSat", "tokens": [50364, 314, 30362, 368, 9565, 50, 267, 322, 4686, 267, 318, 267, 368, 9565, 11, 368, 9565, 322, 264, 4123, 11, 257, 9565, 50, 267, 322, 4686, 267, 11, 368, 9565, 50, 267, 50650], "temperature": 0.0, "avg_logprob": -0.3337438599137235, "compression_ratio": 1.7864583333333333, "no_speech_prob": 0.1641012728214264}, {"id": 429, "seek": 227608, "start": 2281.7999999999997, "end": 2288.92, "text": " on Demat, con min\u00fascula o de CatSat on the Stromat. \u00bfCu\u00e1les les parecen que son buenas", "tokens": [50650, 322, 4686, 267, 11, 416, 923, 10227, 2444, 64, 277, 368, 9565, 50, 267, 322, 264, 39126, 267, 13, 3841, 35222, 842, 904, 1512, 7448, 13037, 631, 1872, 43852, 51006], "temperature": 0.0, "avg_logprob": -0.3337438599137235, "compression_ratio": 1.7864583333333333, "no_speech_prob": 0.1641012728214264}, {"id": 430, "seek": 227608, "start": 2288.92, "end": 2293.44, "text": " traducciones de estos candidatos que me dio el sistema? \u00bfCu\u00e1les les gusta m\u00e1s?", "tokens": [51006, 2479, 1311, 23469, 368, 12585, 6268, 26818, 631, 385, 31965, 806, 13245, 30, 3841, 35222, 842, 904, 1512, 20576, 3573, 30, 51232], "temperature": 0.0, "avg_logprob": -0.3337438599137235, "compression_ratio": 1.7864583333333333, "no_speech_prob": 0.1641012728214264}, {"id": 431, "seek": 227608, "start": 2293.44, "end": 2301.84, "text": " La E, que es de CatSat on Demat, pero con min\u00fascula me d\u00e9 como yo, \u00bfqu\u00e9 otra? La", "tokens": [51232, 2369, 462, 11, 631, 785, 368, 9565, 50, 267, 322, 4686, 267, 11, 4768, 416, 923, 10227, 2444, 64, 385, 2795, 2617, 5290, 11, 3841, 16412, 13623, 30, 2369, 51652], "temperature": 0.0, "avg_logprob": -0.3337438599137235, "compression_ratio": 1.7864583333333333, "no_speech_prob": 0.1641012728214264}, {"id": 432, "seek": 230184, "start": 2301.84, "end": 2314.84, "text": " B, on Demat Sat de Cat, \u00bfqu\u00e9 otra? La D les gusta tambi\u00e9n a CatSat on Demat. \u00bfCapaz que", "tokens": [50364, 363, 11, 322, 4686, 267, 318, 267, 368, 9565, 11, 3841, 16412, 13623, 30, 2369, 413, 1512, 20576, 6407, 257, 9565, 50, 267, 322, 4686, 267, 13, 3841, 34, 569, 921, 631, 51014], "temperature": 0.0, "avg_logprob": -0.31214349311694767, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0254217516630888}, {"id": 433, "seek": 230184, "start": 2314.84, "end": 2318.6800000000003, "text": " no calienta tanto, dependiendo del uso que le vas a dar esa frase en contexto, capaz que", "tokens": [51014, 572, 2104, 1196, 64, 10331, 11, 5672, 7304, 1103, 22728, 631, 476, 11481, 257, 4072, 11342, 38406, 465, 47685, 11, 1410, 921, 631, 51206], "temperature": 0.0, "avg_logprob": -0.31214349311694767, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0254217516630888}, {"id": 434, "seek": 230184, "start": 2318.6800000000003, "end": 2323.2000000000003, "text": " no calienta tanto? Y bueno, s\u00ed, la verdad no se ve nada cuando est\u00e1n las cosas marcadas", "tokens": [51206, 572, 2104, 1196, 64, 10331, 30, 398, 11974, 11, 8600, 11, 635, 13692, 572, 369, 1241, 8096, 7767, 10368, 2439, 12218, 42365, 6872, 51432], "temperature": 0.0, "avg_logprob": -0.31214349311694767, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0254217516630888}, {"id": 435, "seek": 230184, "start": 2323.2000000000003, "end": 2326.56, "text": " en rojo, pero bueno, en fin. Crea que ac\u00e1 las cosas marcadas en rojo son las que acaban", "tokens": [51432, 465, 744, 5134, 11, 4768, 11974, 11, 465, 962, 13, 9549, 64, 631, 23496, 2439, 12218, 42365, 6872, 465, 744, 5134, 1872, 2439, 631, 13281, 282, 51600], "temperature": 0.0, "avg_logprob": -0.31214349311694767, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.0254217516630888}, {"id": 436, "seek": 232656, "start": 2326.56, "end": 2332.32, "text": " de decir. Una buena traducci\u00f3n, podemos decir que es una traducci\u00f3n que le gusta la gente,", "tokens": [50364, 368, 10235, 13, 15491, 25710, 2479, 1311, 5687, 11, 12234, 10235, 631, 785, 2002, 2479, 1311, 5687, 631, 476, 20576, 635, 3788, 11, 50652], "temperature": 0.0, "avg_logprob": -0.19514821099896804, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.17629502713680267}, {"id": 437, "seek": 232656, "start": 2332.32, "end": 2337.72, "text": " que la gente dice si es una buena traducci\u00f3n. Entonces ac\u00e1 se elige on Demat Sat de Cat,", "tokens": [50652, 631, 635, 3788, 10313, 1511, 785, 2002, 25710, 2479, 1311, 5687, 13, 15097, 23496, 369, 806, 3969, 322, 4686, 267, 318, 267, 368, 9565, 11, 50922], "temperature": 0.0, "avg_logprob": -0.19514821099896804, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.17629502713680267}, {"id": 438, "seek": 232656, "start": 2337.72, "end": 2344.12, "text": " a CatSat on Demat, y de CatSat on Demat en min\u00fascula. Y bueno, como decimos, le preguntamos", "tokens": [50922, 257, 9565, 50, 267, 322, 4686, 267, 11, 288, 368, 9565, 50, 267, 322, 4686, 267, 465, 923, 10227, 2444, 64, 13, 398, 11974, 11, 2617, 979, 8372, 11, 476, 19860, 2151, 51242], "temperature": 0.0, "avg_logprob": -0.19514821099896804, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.17629502713680267}, {"id": 439, "seek": 232656, "start": 2344.12, "end": 2347.92, "text": " a la gente a ver que traducciones le gustan, y bueno, ya ah\u00ed ponemos cuales son las mejores", "tokens": [51242, 257, 635, 3788, 257, 1306, 631, 2479, 1311, 23469, 476, 9679, 282, 11, 288, 11974, 11, 2478, 12571, 9224, 4485, 46932, 1872, 2439, 42284, 51432], "temperature": 0.0, "avg_logprob": -0.19514821099896804, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.17629502713680267}, {"id": 440, "seek": 232656, "start": 2347.92, "end": 2353.12, "text": " traducciones. O si no, le damos a un conjunto de jurados las traducciones y le decimos", "tokens": [51432, 2479, 1311, 23469, 13, 422, 1511, 572, 11, 476, 274, 2151, 257, 517, 37776, 368, 12721, 4181, 2439, 2479, 1311, 23469, 288, 476, 979, 8372, 51692], "temperature": 0.0, "avg_logprob": -0.19514821099896804, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.17629502713680267}, {"id": 441, "seek": 235312, "start": 2353.12, "end": 2357.4, "text": " que hagan un an\u00e1lisis un poco m\u00e1s preciso, y nos digan, bueno, cu\u00e1nto le dan en uno", "tokens": [50364, 631, 324, 1275, 517, 44113, 28436, 517, 10639, 3573, 30109, 11, 288, 3269, 2528, 282, 11, 11974, 11, 44256, 78, 476, 3277, 465, 8526, 50578], "temperature": 0.0, "avg_logprob": -0.2568634513794906, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.08263678848743439}, {"id": 442, "seek": 235312, "start": 2357.4, "end": 2364.16, "text": " al diez de adecuaci\u00f3n, y cu\u00e1nto le dan en uno al diez de fluidez.", "tokens": [50578, 419, 48165, 368, 614, 3045, 84, 3482, 11, 288, 44256, 78, 476, 3277, 465, 8526, 419, 48165, 368, 5029, 45170, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2568634513794906, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.08263678848743439}, {"id": 443, "seek": 235312, "start": 2364.16, "end": 2369.64, "text": " Esas otra forma de evaluar, digamos, y ah\u00ed ya nos est\u00e1n dando las dos medidas. En general,", "tokens": [50916, 2313, 296, 13623, 8366, 368, 6133, 289, 11, 36430, 11, 288, 12571, 2478, 3269, 10368, 29854, 2439, 4491, 37295, 13, 2193, 2674, 11, 51190], "temperature": 0.0, "avg_logprob": -0.2568634513794906, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.08263678848743439}, {"id": 444, "seek": 235312, "start": 2369.64, "end": 2374.3599999999997, "text": " los humanos nos cuesta realizar esta evaluaci\u00f3n. En general, tenemos una preferencia de la fluidez,", "tokens": [51190, 1750, 34555, 3269, 2702, 7841, 36461, 5283, 6133, 3482, 13, 2193, 2674, 11, 9914, 2002, 4382, 10974, 368, 635, 5029, 45170, 11, 51426], "temperature": 0.0, "avg_logprob": -0.2568634513794906, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.08263678848743439}, {"id": 445, "seek": 235312, "start": 2374.3599999999997, "end": 2381.68, "text": " como pasaba hoy con el caso de traducci\u00f3n del chino al ingl\u00e9s, por los pasajes de avi\u00f3n.", "tokens": [51426, 2617, 1736, 5509, 13775, 416, 806, 9666, 368, 2479, 1311, 5687, 1103, 417, 2982, 419, 49766, 11, 1515, 1750, 1736, 29362, 368, 1305, 2560, 13, 51792], "temperature": 0.0, "avg_logprob": -0.2568634513794906, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.08263678848743439}, {"id": 446, "seek": 238168, "start": 2381.68, "end": 2385.7999999999997, "text": " Adem\u00e1s, la gente no se pone a acuerdo. Adem\u00e1s, hay un problema que es que hacer este tipo", "tokens": [50364, 34621, 11, 635, 3788, 572, 369, 40192, 257, 28113, 13, 34621, 11, 4842, 517, 12395, 631, 785, 631, 6720, 4065, 9746, 50570], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 447, "seek": 238168, "start": 2385.7999999999997, "end": 2389.8799999999997, "text": " de evaluaciones con usuarios humanos, lleva tiempo, digamos, hay que pagarles a los usuarios", "tokens": [50570, 368, 6133, 9188, 416, 32247, 9720, 34555, 11, 37681, 11772, 11, 36430, 11, 4842, 631, 28024, 904, 257, 1750, 32247, 9720, 50774], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 448, "seek": 238168, "start": 2389.8799999999997, "end": 2395.52, "text": " por hora para que est\u00e9n evaluando sistemas. Y despu\u00e9s, yo le d\u00ed un conjunto de traducciones,", "tokens": [50774, 1515, 15098, 1690, 631, 871, 3516, 6133, 1806, 48720, 13, 398, 15283, 11, 5290, 476, 274, 870, 517, 37776, 368, 2479, 1311, 23469, 11, 51056], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 449, "seek": 238168, "start": 2395.52, "end": 2399.56, "text": " ellos me la se evaluaron, hice alg\u00fan cambio en mi sistema para mejorarlo, y devuelta", "tokens": [51056, 16353, 385, 635, 369, 6133, 6372, 11, 50026, 26300, 28731, 465, 2752, 13245, 1690, 11479, 19457, 11, 288, 1905, 3483, 1328, 51258], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 450, "seek": 238168, "start": 2399.56, "end": 2403.0, "text": " hacerle, de teo que dale conjunto de traducciones a los humanos, y devuelta lo tienen que evaluar,", "tokens": [51258, 6720, 306, 11, 368, 535, 78, 631, 27326, 37776, 368, 2479, 1311, 23469, 257, 1750, 34555, 11, 288, 1905, 3483, 1328, 450, 12536, 631, 6133, 289, 11, 51430], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 451, "seek": 238168, "start": 2403.0, "end": 2408.08, "text": " y devuelta, tengo que pagar obras de usuarios humanos para que lo val\u00faen.", "tokens": [51430, 288, 1905, 3483, 1328, 11, 13989, 631, 28024, 47618, 368, 32247, 9720, 34555, 1690, 631, 450, 1323, 2481, 268, 13, 51684], "temperature": 0.0, "avg_logprob": -0.3061455907048406, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.22207731008529663}, {"id": 452, "seek": 240808, "start": 2408.6, "end": 2412.4, "text": " Entonces, es dif\u00edcil de reutilizar. Yo voy a estar haciendo cambios constantemente en mi sistema,", "tokens": [50390, 15097, 11, 785, 17258, 368, 319, 20835, 9736, 13, 7616, 7552, 257, 8755, 20509, 18751, 2717, 5754, 16288, 465, 2752, 13245, 11, 50580], "temperature": 0.0, "avg_logprob": -0.21543411981491817, "compression_ratio": 1.6902985074626866, "no_speech_prob": 0.0014210790395736694}, {"id": 453, "seek": 240808, "start": 2412.4, "end": 2417.24, "text": " y bueno, y necesito tener una forma m\u00e1s r\u00e1pida de evaluar a ver si estoy haciendo las cosas mejor.", "tokens": [50580, 288, 11974, 11, 288, 11909, 3528, 11640, 2002, 8366, 3573, 18213, 2887, 368, 6133, 289, 257, 1306, 1511, 15796, 20509, 2439, 12218, 11479, 13, 50822], "temperature": 0.0, "avg_logprob": -0.21543411981491817, "compression_ratio": 1.6902985074626866, "no_speech_prob": 0.0014210790395736694}, {"id": 454, "seek": 240808, "start": 2417.24, "end": 2421.16, "text": " Entonces, como este proceso de evaluaci\u00f3n es largo, es engorroso, es caro,", "tokens": [50822, 15097, 11, 2617, 4065, 29314, 368, 6133, 3482, 785, 31245, 11, 785, 1741, 284, 2635, 78, 11, 785, 1032, 78, 11, 51018], "temperature": 0.0, "avg_logprob": -0.21543411981491817, "compression_ratio": 1.6902985074626866, "no_speech_prob": 0.0014210790395736694}, {"id": 455, "seek": 240808, "start": 2421.16, "end": 2424.7999999999997, "text": " lo que se ha vuelto m\u00e1s popular son los m\u00e9todos autom\u00e1ticos de evaluaci\u00f3n. Y,", "tokens": [51018, 450, 631, 369, 324, 20126, 1353, 3573, 3743, 1872, 1750, 20275, 378, 329, 3553, 7656, 9940, 368, 6133, 3482, 13, 398, 11, 51200], "temperature": 0.0, "avg_logprob": -0.21543411981491817, "compression_ratio": 1.6902985074626866, "no_speech_prob": 0.0014210790395736694}, {"id": 456, "seek": 240808, "start": 2424.7999999999997, "end": 2431.08, "text": " a continuaci\u00f3n, vamos a ver uno, que es muy utilizado en lo que es la traducci\u00f3n autom\u00e1tica.", "tokens": [51200, 257, 2993, 3482, 11, 5295, 257, 1306, 8526, 11, 631, 785, 5323, 19906, 1573, 465, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21543411981491817, "compression_ratio": 1.6902985074626866, "no_speech_prob": 0.0014210790395736694}, {"id": 457, "seek": 243108, "start": 2431.08, "end": 2439.2, "text": " Bueno, \u00bfc\u00f3mo funciona un m\u00e9todo de evaluaci\u00f3n? En realidad, lo que hace alguien,", "tokens": [50364, 16046, 11, 3841, 46614, 26210, 517, 20275, 17423, 368, 6133, 3482, 30, 2193, 25635, 11, 450, 631, 10032, 25814, 11, 50770], "temperature": 0.0, "avg_logprob": -0.2211790997049083, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.011544992215931416}, {"id": 458, "seek": 243108, "start": 2439.2, "end": 2447.2, "text": " alguien que est\u00e1 dise\u00f1ando un sistema, es crearse un conjunto de oraciones con cada una", "tokens": [50770, 25814, 631, 3192, 3814, 2791, 1806, 517, 13245, 11, 785, 1197, 11668, 517, 37776, 368, 420, 9188, 416, 8411, 2002, 51170], "temperature": 0.0, "avg_logprob": -0.2211790997049083, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.011544992215931416}, {"id": 459, "seek": 243108, "start": 2447.2, "end": 2450.36, "text": " con una traducci\u00f3n de referencia que est\u00e1 bien, digamos, una traducci\u00f3n hecha mano.", "tokens": [51170, 416, 2002, 2479, 1311, 5687, 368, 2864, 10974, 631, 3192, 3610, 11, 36430, 11, 2002, 2479, 1311, 5687, 415, 4413, 18384, 13, 51328], "temperature": 0.0, "avg_logprob": -0.2211790997049083, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.011544992215931416}, {"id": 460, "seek": 243108, "start": 2450.36, "end": 2454.3199999999997, "text": " Entonces, yo quiero evaluar un sistema que va del espa\u00f1ol al ingl\u00e9s, lo que tengo es un", "tokens": [51328, 15097, 11, 5290, 16811, 6133, 289, 517, 13245, 631, 2773, 1103, 31177, 419, 49766, 11, 450, 631, 13989, 785, 517, 51526], "temperature": 0.0, "avg_logprob": -0.2211790997049083, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.011544992215931416}, {"id": 461, "seek": 243108, "start": 2454.3199999999997, "end": 2459.3199999999997, "text": " conjunto de oraciones en espa\u00f1ol, y alguien, alg\u00fan traductor humano me tradujo todas esas", "tokens": [51526, 37776, 368, 420, 9188, 465, 31177, 11, 288, 25814, 11, 26300, 2479, 84, 1672, 30985, 385, 2479, 4579, 78, 10906, 23388, 51776], "temperature": 0.0, "avg_logprob": -0.2211790997049083, "compression_ratio": 1.757936507936508, "no_speech_prob": 0.011544992215931416}, {"id": 462, "seek": 245932, "start": 2459.32, "end": 2463.0800000000004, "text": " oraciones en espa\u00f1ol, y medio un candidato, o m\u00e1s candidato est\u00e1 lo es para cada una,", "tokens": [50364, 420, 9188, 465, 31177, 11, 288, 22123, 517, 6268, 2513, 11, 277, 3573, 6268, 2513, 3192, 450, 785, 1690, 8411, 2002, 11, 50552], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 463, "seek": 245932, "start": 2463.0800000000004, "end": 2466.36, "text": " digamos, a eso le voy a llamar referencias, traducciones de referencia.", "tokens": [50552, 36430, 11, 257, 7287, 476, 7552, 257, 16848, 289, 2864, 37246, 11, 2479, 1311, 23469, 368, 2864, 10974, 13, 50716], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 464, "seek": 245932, "start": 2466.36, "end": 2471.32, "text": " Lo siguiente que tengo que hacer es poder dise\u00f1ar una m\u00e9trica de similitud para que,", "tokens": [50716, 6130, 25666, 631, 13989, 631, 6720, 785, 8152, 3814, 2791, 289, 2002, 20275, 15192, 368, 1034, 388, 21875, 1690, 631, 11, 50964], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 465, "seek": 245932, "start": 2471.32, "end": 2475.8, "text": " cuando mi sistema me da un candidato de traducci\u00f3n, yo puedo establecer una similitud entre ese", "tokens": [50964, 7767, 2752, 13245, 385, 1120, 517, 6268, 2513, 368, 2479, 1311, 5687, 11, 5290, 21612, 37444, 1776, 2002, 1034, 388, 21875, 3962, 10167, 51188], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 466, "seek": 245932, "start": 2475.8, "end": 2479.76, "text": " candidato y alguna de las referencias. Y bueno, despu\u00e9s lo que voy a hacer es aplicar esa", "tokens": [51188, 6268, 2513, 288, 20651, 368, 2439, 2864, 37246, 13, 398, 11974, 11, 15283, 450, 631, 7552, 257, 6720, 785, 18221, 289, 11342, 51386], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 467, "seek": 245932, "start": 2479.76, "end": 2486.1600000000003, "text": " m\u00e9trica para los pares, candidatos y referencias, y bueno, y sacar como un promedio de todos", "tokens": [51386, 20275, 15192, 1690, 1750, 2502, 495, 11, 6268, 26818, 288, 2864, 37246, 11, 288, 11974, 11, 288, 43823, 2617, 517, 2234, 292, 1004, 368, 6321, 51706], "temperature": 0.0, "avg_logprob": -0.225600490831349, "compression_ratio": 1.856140350877193, "no_speech_prob": 0.018788645043969154}, {"id": 468, "seek": 248616, "start": 2486.24, "end": 2492.2799999999997, "text": " los valores de similitud que tengo. Entonces, se han inmetado muchos m\u00e9todos de este estilo,", "tokens": [50368, 1750, 38790, 368, 1034, 388, 21875, 631, 13989, 13, 15097, 11, 369, 7276, 294, 5537, 1573, 17061, 20275, 378, 329, 368, 4065, 37470, 11, 50670], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 469, "seek": 248616, "start": 2492.2799999999997, "end": 2497.56, "text": " muchos m\u00e9todos autom\u00e1ticos, que vamos a ver en particular se llama Blue, que es una", "tokens": [50670, 17061, 20275, 378, 329, 3553, 7656, 9940, 11, 631, 5295, 257, 1306, 465, 1729, 369, 23272, 8510, 11, 631, 785, 2002, 50934], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 470, "seek": 248616, "start": 2497.56, "end": 2502.56, "text": " m\u00e9trica muy difundida en lo que es la traducci\u00f3n autom\u00e1tica estad\u00edstica. Y bueno,", "tokens": [50934, 20275, 15192, 5323, 679, 997, 2887, 465, 450, 631, 785, 635, 2479, 1311, 5687, 3553, 23432, 39160, 19512, 2262, 13, 398, 11974, 11, 51184], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 471, "seek": 248616, "start": 2502.56, "end": 2507.12, "text": " primero hay algunas definiciones, le vamos a llamar referencia a una traducci\u00f3n que", "tokens": [51184, 21289, 4842, 27316, 1561, 29719, 11, 476, 5295, 257, 16848, 289, 2864, 10974, 257, 2002, 2479, 1311, 5687, 631, 51412], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 472, "seek": 248616, "start": 2507.12, "end": 2511.44, "text": " est\u00e1 traducida manualmente, o sea, consideramos que es una oraci\u00f3n correcta, eso es una referencia,", "tokens": [51412, 3192, 2479, 1311, 2887, 9688, 4082, 11, 277, 4158, 11, 1949, 2151, 631, 785, 2002, 420, 3482, 3006, 64, 11, 7287, 785, 2002, 2864, 10974, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 473, "seek": 248616, "start": 2511.44, "end": 2515.0, "text": " y le vamos a llamar candidato a una traducci\u00f3n que no tiene por qu\u00e9 estar correcta porque", "tokens": [51628, 288, 476, 5295, 257, 16848, 289, 6268, 2513, 257, 2002, 2479, 1311, 5687, 631, 572, 7066, 1515, 8057, 8755, 3006, 64, 4021, 51806], "temperature": 0.0, "avg_logprob": -0.1905331579630807, "compression_ratio": 1.8954703832752613, "no_speech_prob": 0.00417654262855649}, {"id": 474, "seek": 251500, "start": 2515.0, "end": 2520.32, "text": " la tradujo del sistema autom\u00e1tico. Y le vamos a llamar documento al conjunto de todas", "tokens": [50364, 635, 2479, 4579, 78, 1103, 13245, 3553, 28234, 13, 398, 476, 5295, 257, 16848, 289, 4166, 78, 419, 37776, 368, 10906, 50630], "temperature": 0.0, "avg_logprob": -0.14857285598228717, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.031249549239873886}, {"id": 475, "seek": 251500, "start": 2520.32, "end": 2525.0, "text": " las oraciones candidatas, al conjunto de todas las oraciones traducidas por el sistema,", "tokens": [50630, 2439, 420, 9188, 6268, 37892, 11, 419, 37776, 368, 10906, 2439, 420, 9188, 2479, 1311, 11382, 1515, 806, 13245, 11, 50864], "temperature": 0.0, "avg_logprob": -0.14857285598228717, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.031249549239873886}, {"id": 476, "seek": 251500, "start": 2525.0, "end": 2529.24, "text": " que es lo que vamos a estar evaluando. As\u00ed que recuerden, tenemos referencia, candidato", "tokens": [50864, 631, 785, 450, 631, 5295, 257, 8755, 6133, 1806, 13, 17419, 631, 39092, 1556, 11, 9914, 2864, 10974, 11, 6268, 2513, 51076], "temperature": 0.0, "avg_logprob": -0.14857285598228717, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.031249549239873886}, {"id": 477, "seek": 251500, "start": 2529.24, "end": 2535.08, "text": " y documento. Y bueno, \u00bfqu\u00e9 es lo primero que se nos puede ocurrir hacer cuando queremos", "tokens": [51076, 288, 4166, 78, 13, 398, 11974, 11, 3841, 16412, 785, 450, 21289, 631, 369, 3269, 8919, 26430, 10949, 6720, 7767, 26813, 51368], "temperature": 0.0, "avg_logprob": -0.14857285598228717, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.031249549239873886}, {"id": 478, "seek": 251500, "start": 2535.08, "end": 2541.36, "text": " saber si un candidato es bueno para la referencia o no? Lo primero que podemos hacer es tratar", "tokens": [51368, 12489, 1511, 517, 6268, 2513, 785, 11974, 1690, 635, 2864, 10974, 277, 572, 30, 6130, 21289, 631, 12234, 6720, 785, 42549, 51682], "temperature": 0.0, "avg_logprob": -0.14857285598228717, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.031249549239873886}, {"id": 479, "seek": 254136, "start": 2541.36, "end": 2549.08, "text": " de contar las palabras que ocurren en ambos. Entonces, yo puedo tratar de contar palabras", "tokens": [50364, 368, 27045, 2439, 35240, 631, 26430, 1095, 465, 41425, 13, 15097, 11, 5290, 21612, 42549, 368, 27045, 35240, 50750], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 480, "seek": 254136, "start": 2549.08, "end": 2552.96, "text": " que ocurren en el candidato y palabras que ocurren en la referencia, y ah\u00ed dir\u00eda que", "tokens": [50750, 631, 26430, 1095, 465, 806, 6268, 2513, 288, 35240, 631, 26430, 1095, 465, 635, 2864, 10974, 11, 288, 12571, 4746, 2686, 631, 50944], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 481, "seek": 254136, "start": 2552.96, "end": 2556.6400000000003, "text": " la elecci\u00f3n de las palabras de candidato, si est\u00e1n, la palabra candidato, si est\u00e1n,", "tokens": [50944, 635, 1118, 14735, 368, 2439, 35240, 368, 6268, 2513, 11, 1511, 10368, 11, 635, 31702, 6268, 2513, 11, 1511, 10368, 11, 51128], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 482, "seek": 254136, "start": 2556.6400000000003, "end": 2560.4, "text": " tambi\u00e9n en la referencia, yo dir\u00eda que eso se acerca un poco a la adecuaci\u00f3n, se acerca", "tokens": [51128, 6407, 465, 635, 2864, 10974, 11, 5290, 4746, 2686, 631, 7287, 369, 46321, 517, 10639, 257, 635, 614, 3045, 84, 3482, 11, 369, 46321, 51316], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 483, "seek": 254136, "start": 2560.4, "end": 2565.48, "text": " que, bueno, por lo menos, us\u00f3 palabras que son fieles a la traducci\u00f3n de referencia.", "tokens": [51316, 631, 11, 11974, 11, 1515, 450, 8902, 11, 505, 812, 35240, 631, 1872, 283, 1187, 279, 257, 635, 2479, 1311, 5687, 368, 2864, 10974, 13, 51570], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 484, "seek": 254136, "start": 2565.48, "end": 2569.52, "text": " Pero si adem\u00e1s esas palabras est\u00e1n usadas en el mismo orden, ah\u00ed se acerca un poco m\u00e1s", "tokens": [51570, 9377, 1511, 21251, 23388, 35240, 10368, 505, 6872, 465, 806, 12461, 28615, 11, 12571, 369, 46321, 517, 10639, 3573, 51772], "temperature": 0.0, "avg_logprob": -0.15913811263504563, "compression_ratio": 2.1538461538461537, "no_speech_prob": 0.016126954928040504}, {"id": 485, "seek": 256952, "start": 2569.52, "end": 2573.36, "text": " a la fluidez, o sea, si est\u00e1n usadas en el mismo orden, puede sonar tan natural como", "tokens": [50364, 257, 635, 5029, 45170, 11, 277, 4158, 11, 1511, 10368, 505, 6872, 465, 806, 12461, 28615, 11, 8919, 1872, 289, 7603, 3303, 2617, 50556], "temperature": 0.0, "avg_logprob": -0.27983856201171875, "compression_ratio": 1.78, "no_speech_prob": 0.0827246829867363}, {"id": 486, "seek": 256952, "start": 2573.36, "end": 2581.92, "text": " la referencia. Y esto se puede hacer autom\u00e1ticamente haciendo conteos de enegramas.", "tokens": [50556, 635, 2864, 10974, 13, 398, 7433, 369, 8919, 6720, 3553, 7656, 23653, 20509, 34444, 329, 368, 465, 1146, 2356, 296, 13, 50984], "temperature": 0.0, "avg_logprob": -0.27983856201171875, "compression_ratio": 1.78, "no_speech_prob": 0.0827246829867363}, {"id": 487, "seek": 256952, "start": 2581.92, "end": 2586.52, "text": " Ac\u00e1 yo tengo una referencia que es de CatSat, mi sistema me ten\u00eda que haber devuelto", "tokens": [50984, 5097, 842, 5290, 13989, 2002, 2864, 10974, 631, 785, 368, 9565, 50, 267, 11, 2752, 13245, 385, 23718, 631, 15811, 1905, 3483, 1353, 51214], "temperature": 0.0, "avg_logprob": -0.27983856201171875, "compression_ratio": 1.78, "no_speech_prob": 0.0827246829867363}, {"id": 488, "seek": 256952, "start": 2586.52, "end": 2593.28, "text": " de CatSat y ten\u00eda dos candidatos, candidato era de Cat y el candidato era SadCatD. Entonces,", "tokens": [51214, 368, 9565, 50, 267, 288, 23718, 4491, 6268, 26818, 11, 6268, 2513, 4249, 368, 9565, 288, 806, 6268, 2513, 4249, 12269, 34, 267, 35, 13, 15097, 11, 51552], "temperature": 0.0, "avg_logprob": -0.27983856201171875, "compression_ratio": 1.78, "no_speech_prob": 0.0827246829867363}, {"id": 489, "seek": 256952, "start": 2593.28, "end": 2597.6, "text": " lo que puedo hacer es conteo de enegramas, cu\u00e1les son enegramas de los candidatos pertenecen", "tokens": [51552, 450, 631, 21612, 6720, 785, 34444, 78, 368, 465, 1146, 2356, 296, 11, 2702, 842, 904, 1872, 465, 1146, 2356, 296, 368, 1750, 6268, 26818, 680, 1147, 3045, 268, 51768], "temperature": 0.0, "avg_logprob": -0.27983856201171875, "compression_ratio": 1.78, "no_speech_prob": 0.0827246829867363}, {"id": 490, "seek": 259760, "start": 2597.6, "end": 2603.54, "text": " a la referencia. Y entonces, para el caso de Cat, el enegrama D pertenece la referencia,", "tokens": [50364, 257, 635, 2864, 10974, 13, 398, 13003, 11, 1690, 806, 9666, 368, 9565, 11, 806, 465, 1146, 29762, 413, 680, 1147, 68, 384, 635, 2864, 10974, 11, 50661], "temperature": 0.4, "avg_logprob": -0.24544314334267064, "compression_ratio": 2.306878306878307, "no_speech_prob": 0.07240874320268631}, {"id": 491, "seek": 259760, "start": 2603.54, "end": 2607.8199999999997, "text": " el enegrama Cat pertenece a la referencia y el enegrama D Cat, o sea, el Vigra Madecat", "tokens": [50661, 806, 465, 1146, 29762, 9565, 680, 1147, 68, 384, 257, 635, 2864, 10974, 288, 806, 465, 1146, 29762, 413, 9565, 11, 277, 4158, 11, 806, 691, 328, 424, 376, 762, 18035, 50875], "temperature": 0.4, "avg_logprob": -0.24544314334267064, "compression_ratio": 2.306878306878307, "no_speech_prob": 0.07240874320268631}, {"id": 492, "seek": 259760, "start": 2607.8199999999997, "end": 2613.3199999999997, "text": " tambi\u00e9n pertenece a la referencia. Para el caso del candidato B, el unigrama Sad", "tokens": [50875, 6407, 680, 1147, 68, 384, 257, 635, 2864, 10974, 13, 11107, 806, 9666, 1103, 6268, 2513, 363, 11, 806, 517, 328, 29762, 12269, 51150], "temperature": 0.4, "avg_logprob": -0.24544314334267064, "compression_ratio": 2.306878306878307, "no_speech_prob": 0.07240874320268631}, {"id": 493, "seek": 259760, "start": 2613.3199999999997, "end": 2619.52, "text": " pertenece el unigrama Cat pertenece el unigrama D pertenece. Pero SadCatD este Vigrama no", "tokens": [51150, 680, 1147, 68, 384, 806, 517, 328, 29762, 9565, 680, 1147, 68, 384, 806, 517, 328, 29762, 413, 680, 1147, 68, 384, 13, 9377, 12269, 34, 267, 35, 4065, 691, 328, 29762, 572, 51460], "temperature": 0.4, "avg_logprob": -0.24544314334267064, "compression_ratio": 2.306878306878307, "no_speech_prob": 0.07240874320268631}, {"id": 494, "seek": 259760, "start": 2619.52, "end": 2623.96, "text": " pertenece a la referencia y CatD tampoco pertenece a la referencia. Y adem\u00e1s, el \u00fanico", "tokens": [51460, 680, 1147, 68, 384, 257, 635, 2864, 10974, 288, 9565, 35, 36838, 680, 1147, 68, 384, 257, 635, 2864, 10974, 13, 398, 21251, 11, 806, 26113, 51682], "temperature": 0.4, "avg_logprob": -0.24544314334267064, "compression_ratio": 2.306878306878307, "no_speech_prob": 0.07240874320268631}, {"id": 495, "seek": 262396, "start": 2623.96, "end": 2627.92, "text": " trigrama que hay, SadCatD tampoco est\u00e1 en la referencia. Entonces, lo que aparece", "tokens": [50364, 1376, 1342, 64, 631, 4842, 11, 12269, 34, 267, 35, 36838, 3192, 465, 635, 2864, 10974, 13, 15097, 11, 450, 631, 37863, 50562], "temperature": 0.0, "avg_logprob": -0.22945275105221172, "compression_ratio": 1.85, "no_speech_prob": 0.011166533455252647}, {"id": 496, "seek": 262396, "start": 2627.92, "end": 2633.32, "text": " a la derecha son los enegramas que s\u00ed pertenecen tanto el candidato como a la referencia.", "tokens": [50562, 257, 635, 15969, 4413, 1872, 1750, 465, 1146, 2356, 296, 631, 8600, 680, 1147, 3045, 268, 10331, 806, 6268, 2513, 2617, 257, 635, 2864, 10974, 13, 50832], "temperature": 0.0, "avg_logprob": -0.22945275105221172, "compression_ratio": 1.85, "no_speech_prob": 0.011166533455252647}, {"id": 497, "seek": 262396, "start": 2633.32, "end": 2640.52, "text": " As\u00ed que, bueno, resumiendo, yo puedo contar la cantidad de hits de unigramas, de Vigramas,", "tokens": [50832, 17419, 631, 11, 11974, 11, 725, 449, 7304, 11, 5290, 21612, 27045, 635, 33757, 368, 8664, 368, 517, 328, 2356, 296, 11, 368, 691, 328, 2356, 296, 11, 51192], "temperature": 0.0, "avg_logprob": -0.22945275105221172, "compression_ratio": 1.85, "no_speech_prob": 0.011166533455252647}, {"id": 498, "seek": 262396, "start": 2640.52, "end": 2644.96, "text": " de trigramas. Y para el candidato B se cumple que todos los unigramas que hay pertenece", "tokens": [51192, 368, 1376, 1342, 296, 13, 398, 1690, 806, 6268, 2513, 363, 369, 12713, 781, 631, 6321, 1750, 517, 328, 2356, 296, 631, 4842, 680, 1147, 68, 384, 51414], "temperature": 0.0, "avg_logprob": -0.22945275105221172, "compression_ratio": 1.85, "no_speech_prob": 0.011166533455252647}, {"id": 499, "seek": 262396, "start": 2644.96, "end": 2649.28, "text": " a la referencia. As\u00ed que, voy a tener dos de dos hits. Para los Vigramas, voy a tener uno", "tokens": [51414, 257, 635, 2864, 10974, 13, 17419, 631, 11, 7552, 257, 11640, 4491, 368, 4491, 8664, 13, 11107, 1750, 691, 328, 2356, 296, 11, 7552, 257, 11640, 8526, 51630], "temperature": 0.0, "avg_logprob": -0.22945275105221172, "compression_ratio": 1.85, "no_speech_prob": 0.011166533455252647}, {"id": 500, "seek": 264928, "start": 2649.28, "end": 2655.92, "text": " de uno. Pero para el candidato B, los unigramas me dan 3 de 3, digamos, 3 hits. Los Vigramas", "tokens": [50364, 368, 8526, 13, 9377, 1690, 806, 6268, 2513, 363, 11, 1750, 517, 328, 2356, 296, 385, 3277, 805, 368, 805, 11, 36430, 11, 805, 8664, 13, 7632, 691, 328, 2356, 296, 50696], "temperature": 0.0, "avg_logprob": -0.24621515016298037, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.18836438655853271}, {"id": 501, "seek": 264928, "start": 2655.92, "end": 2660.0800000000004, "text": " no. O sea, tengo dos Vigramas posibles y ninguno estaba bien. Y los trigramas tampoco.", "tokens": [50696, 572, 13, 422, 4158, 11, 13989, 4491, 691, 328, 2356, 296, 1366, 14428, 288, 17210, 12638, 17544, 3610, 13, 398, 1750, 1376, 1342, 296, 36838, 13, 50904], "temperature": 0.0, "avg_logprob": -0.24621515016298037, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.18836438655853271}, {"id": 502, "seek": 264928, "start": 2660.0800000000004, "end": 2665.0400000000004, "text": " Tengo un trigrama posible y no estaba bien. Entonces, por ahora, parece que le va ganando", "tokens": [50904, 314, 30362, 517, 1376, 1342, 64, 26644, 288, 572, 17544, 3610, 13, 15097, 11, 1515, 9923, 11, 14120, 631, 476, 2773, 7574, 1806, 51152], "temperature": 0.0, "avg_logprob": -0.24621515016298037, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.18836438655853271}, {"id": 503, "seek": 264928, "start": 2665.0400000000004, "end": 2672.2000000000003, "text": " de Cat, la el candidato B de Cat le va ganando a SadCatD como traducci\u00f3n. Bien, \u00bfqu\u00e9", "tokens": [51152, 368, 9565, 11, 635, 806, 6268, 2513, 363, 368, 9565, 476, 2773, 7574, 1806, 257, 12269, 34, 267, 35, 2617, 2479, 1311, 5687, 13, 16956, 11, 3841, 16412, 51510], "temperature": 0.0, "avg_logprob": -0.24621515016298037, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.18836438655853271}, {"id": 504, "seek": 264928, "start": 2672.2000000000003, "end": 2678.5600000000004, "text": " puedo hacer con los contegos de enegramas? Lo que hago habitualmente, o sea, contar enegramas,", "tokens": [51510, 21612, 6720, 416, 1750, 660, 1146, 329, 368, 465, 1146, 2356, 296, 30, 6130, 631, 38721, 46883, 4082, 11, 277, 4158, 11, 27045, 465, 1146, 2356, 296, 11, 51828], "temperature": 0.0, "avg_logprob": -0.24621515016298037, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.18836438655853271}, {"id": 505, "seek": 267856, "start": 2678.56, "end": 2682.88, "text": " para unigramas, vigramas, tiramas, se acerca un poco a lo que es la noci\u00f3n de una precisi\u00f3n", "tokens": [50364, 1690, 517, 328, 2356, 296, 11, 371, 328, 2356, 296, 11, 13807, 335, 296, 11, 369, 46321, 517, 10639, 257, 450, 631, 785, 635, 572, 5687, 368, 2002, 7974, 2560, 50580], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 506, "seek": 267856, "start": 2682.88, "end": 2686.12, "text": " de algo. Entonces, lo que voy a hacer es contarlos", "tokens": [50580, 368, 8655, 13, 15097, 11, 450, 631, 7552, 257, 6720, 785, 27045, 9389, 50742], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 507, "seek": 267856, "start": 2686.12, "end": 2689.96, "text": " por separado. Voy a decir, voy a contar todos los unigramas por un lado, todos los Vigramas", "tokens": [50742, 1515, 3128, 1573, 13, 25563, 257, 10235, 11, 7552, 257, 27045, 6321, 1750, 517, 328, 2356, 296, 1515, 517, 11631, 11, 6321, 1750, 691, 328, 2356, 296, 50934], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 508, "seek": 267856, "start": 2689.96, "end": 2694.08, "text": " por otro, todos los trigramas por otro. Y para cada uno de esos, me voy a armar una", "tokens": [50934, 1515, 11921, 11, 6321, 1750, 1376, 1342, 296, 1515, 11921, 13, 398, 1690, 8411, 8526, 368, 22411, 11, 385, 7552, 257, 3726, 289, 2002, 51140], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 509, "seek": 267856, "start": 2694.08, "end": 2698.12, "text": " precisi\u00f3n. Voy a decir que tengo. El candidato", "tokens": [51140, 7974, 2560, 13, 25563, 257, 10235, 631, 13989, 13, 2699, 6268, 2513, 51342], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 510, "seek": 267856, "start": 2698.12, "end": 2703.52, "text": " se sub\u00ed, digamos, un candidato que voy a considerar. Voy a contar los hits de orden N,", "tokens": [51342, 369, 1422, 870, 11, 36430, 11, 517, 6268, 2513, 631, 7552, 257, 1949, 289, 13, 25563, 257, 27045, 1750, 8664, 368, 28615, 426, 11, 51612], "temperature": 0.0, "avg_logprob": -0.26203272077772355, "compression_ratio": 1.9655172413793103, "no_speech_prob": 0.0024147601798176765}, {"id": 511, "seek": 270352, "start": 2703.52, "end": 2709.64, "text": " se sub\u00ed, digamos, los hits de unigramas, se sub\u00ed. Voy a llamar H, se sub\u00ed. Y voy a contar", "tokens": [50364, 369, 1422, 870, 11, 36430, 11, 1750, 8664, 368, 517, 328, 2356, 296, 11, 369, 1422, 870, 13, 25563, 257, 16848, 289, 389, 11, 369, 1422, 870, 13, 398, 7552, 257, 27045, 50670], "temperature": 0.0, "avg_logprob": -0.2313030515398298, "compression_ratio": 1.7913385826771653, "no_speech_prob": 0.03139817714691162}, {"id": 512, "seek": 270352, "start": 2709.64, "end": 2715.16, "text": " la cantidad de unigramas totales que hay y le voy a llamar T, se sub\u00ed. Pero adem\u00e1s,", "tokens": [50670, 635, 33757, 368, 517, 328, 2356, 296, 3217, 279, 631, 4842, 288, 476, 7552, 257, 16848, 289, 314, 11, 369, 1422, 870, 13, 9377, 21251, 11, 50946], "temperature": 0.0, "avg_logprob": -0.2313030515398298, "compression_ratio": 1.7913385826771653, "no_speech_prob": 0.03139817714691162}, {"id": 513, "seek": 270352, "start": 2715.16, "end": 2720.48, "text": " voy a hacer esto, en vez de hacerlo para una sola oraci\u00f3n, para un candidato y su referencia,", "tokens": [50946, 7552, 257, 6720, 7433, 11, 465, 5715, 368, 32039, 1690, 2002, 34162, 420, 3482, 11, 1690, 517, 6268, 2513, 288, 459, 2864, 10974, 11, 51212], "temperature": 0.0, "avg_logprob": -0.2313030515398298, "compression_ratio": 1.7913385826771653, "no_speech_prob": 0.03139817714691162}, {"id": 514, "seek": 270352, "start": 2720.48, "end": 2724.32, "text": " lo voy a hacer para todo el documento. Voy a contar todos los unigramas que estaban en mis", "tokens": [51212, 450, 7552, 257, 6720, 1690, 5149, 806, 4166, 78, 13, 25563, 257, 27045, 6321, 1750, 517, 328, 2356, 296, 631, 36713, 465, 3346, 51404], "temperature": 0.0, "avg_logprob": -0.2313030515398298, "compression_ratio": 1.7913385826771653, "no_speech_prob": 0.03139817714691162}, {"id": 515, "seek": 270352, "start": 2724.32, "end": 2729.68, "text": " candidatos. Voy a ver cu\u00e1nto eso est\u00e1 bien y voy a hacer esta divisi\u00f3n. Entonces, me va", "tokens": [51404, 6268, 26818, 13, 25563, 257, 1306, 44256, 78, 7287, 3192, 3610, 288, 7552, 257, 6720, 5283, 25974, 2560, 13, 15097, 11, 385, 2773, 51672], "temperature": 0.0, "avg_logprob": -0.2313030515398298, "compression_ratio": 1.7913385826771653, "no_speech_prob": 0.03139817714691162}, {"id": 516, "seek": 272968, "start": 2729.68, "end": 2736.52, "text": " a dar cu\u00e1l es la precisi\u00f3n en unigramas. \u00bfQu\u00e9 va a ser? Bueno, tanta cantidad de unigramas", "tokens": [50364, 257, 4072, 44318, 785, 635, 7974, 2560, 465, 517, 328, 2356, 296, 13, 3841, 15137, 2773, 257, 816, 30, 16046, 11, 40864, 33757, 368, 517, 328, 2356, 296, 50706], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 517, "seek": 272968, "start": 2736.52, "end": 2741.6, "text": " estaban bien dividido, toda la cantidad de unigramas que genero en los candidatos. Despu\u00e9s", "tokens": [50706, 36713, 3610, 4996, 2925, 11, 11687, 635, 33757, 368, 517, 328, 2356, 296, 631, 1337, 78, 465, 1750, 6268, 26818, 13, 40995, 50960], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 518, "seek": 272968, "start": 2741.6, "end": 2745.3999999999996, "text": " voy a hacer eso para Vigramas. Voy a contar toda la cantidad de Vigramas que estaban bien,", "tokens": [50960, 7552, 257, 6720, 7287, 1690, 691, 328, 2356, 296, 13, 25563, 257, 27045, 11687, 635, 33757, 368, 691, 328, 2356, 296, 631, 36713, 3610, 11, 51150], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 519, "seek": 272968, "start": 2745.3999999999996, "end": 2748.7, "text": " porque estaban en el candidato en la referencia, dividido toda la cantidad de Vigramas que", "tokens": [51150, 4021, 36713, 465, 806, 6268, 2513, 465, 635, 2864, 10974, 11, 4996, 2925, 11687, 635, 33757, 368, 691, 328, 2356, 296, 631, 51315], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 520, "seek": 272968, "start": 2748.7, "end": 2752.6, "text": " en el candidato. Voy a hacer lo mismo para trigramas y voy a hacer lo mismo para 4igramas.", "tokens": [51315, 465, 806, 6268, 2513, 13, 25563, 257, 6720, 450, 12461, 1690, 1376, 1342, 296, 288, 7552, 257, 6720, 450, 12461, 1690, 1017, 328, 2356, 296, 13, 51510], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 521, "seek": 272968, "start": 2752.6, "end": 2757.04, "text": " En general, se suele llegar hasta 4, digamos, en traducion autom\u00e1tica estad\u00edstica, la", "tokens": [51510, 2193, 2674, 11, 369, 459, 16884, 24892, 10764, 1017, 11, 36430, 11, 465, 2479, 1311, 313, 3553, 23432, 39160, 19512, 2262, 11, 635, 51732], "temperature": 0.0, "avg_logprob": -0.24001903533935548, "compression_ratio": 2.0036630036630036, "no_speech_prob": 0.00756305456161499}, {"id": 522, "seek": 275704, "start": 2757.04, "end": 2762.48, "text": " medida blu llega a calcular hasta 4. Entonces, bueno, lo que me define ah\u00ed es lo que se llama", "tokens": [50364, 32984, 888, 84, 40423, 257, 2104, 17792, 10764, 1017, 13, 15097, 11, 11974, 11, 450, 631, 385, 6964, 12571, 785, 450, 631, 369, 23272, 50636], "temperature": 0.0, "avg_logprob": -0.2018251197282658, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.003262521466240287}, {"id": 523, "seek": 275704, "start": 2762.48, "end": 2768.44, "text": " probabilidad de orden N, la probabilidad, precisi\u00f3n de orden N, la precisi\u00f3n para unigrama,", "tokens": [50636, 31959, 4580, 368, 28615, 426, 11, 635, 31959, 4580, 11, 7974, 2560, 368, 28615, 426, 11, 635, 7974, 2560, 1690, 517, 328, 29762, 11, 50934], "temperature": 0.0, "avg_logprob": -0.2018251197282658, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.003262521466240287}, {"id": 524, "seek": 275704, "start": 2768.44, "end": 2775.8, "text": " la precisi\u00f3n para Vigramas, la precisi\u00f3n para trigramas, etc. Bien, esta m\u00e9trica que", "tokens": [50934, 635, 7974, 2560, 1690, 691, 328, 2356, 296, 11, 635, 7974, 2560, 1690, 1376, 1342, 296, 11, 5183, 13, 16956, 11, 5283, 20275, 15192, 631, 51302], "temperature": 0.0, "avg_logprob": -0.2018251197282658, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.003262521466240287}, {"id": 525, "seek": 275704, "start": 2775.8, "end": 2781.0, "text": " estamos construyendo es bastante f\u00e1cil enga\u00f1ar. En realidad, yo me defin\u00ed una probabilidad,", "tokens": [51302, 10382, 12946, 88, 3999, 785, 14651, 17474, 1741, 23217, 289, 13, 2193, 25635, 11, 5290, 385, 1561, 870, 2002, 31959, 4580, 11, 51562], "temperature": 0.0, "avg_logprob": -0.2018251197282658, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.003262521466240287}, {"id": 526, "seek": 275704, "start": 2781.0, "end": 2784.6, "text": " por ejemplo, de la probabilidad de orden 1 y la puedo enga\u00f1ar muy f\u00e1cil, porque yo me", "tokens": [51562, 1515, 13358, 11, 368, 635, 31959, 4580, 368, 28615, 502, 288, 635, 21612, 1741, 23217, 289, 5323, 17474, 11, 4021, 5290, 385, 51742], "temperature": 0.0, "avg_logprob": -0.2018251197282658, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.003262521466240287}, {"id": 527, "seek": 278460, "start": 2784.6, "end": 2789.7599999999998, "text": " puedo construir un candidato que tiene siempre la misma palabra. Puedes ir, bueno, un candidato", "tokens": [50364, 21612, 38445, 517, 6268, 2513, 631, 7066, 12758, 635, 24946, 31702, 13, 430, 5827, 279, 3418, 11, 11974, 11, 517, 6268, 2513, 50622], "temperature": 0.0, "avg_logprob": -0.2611277997493744, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.023055503144860268}, {"id": 528, "seek": 278460, "start": 2789.7599999999998, "end": 2797.72, "text": " para la referencia de Catzato Nemat es el candidato DDDDD. Como yo justo le emboque a una palabra", "tokens": [50622, 1690, 635, 2864, 10974, 368, 9565, 89, 2513, 1734, 15677, 785, 806, 6268, 2513, 30778, 20818, 35, 13, 11913, 5290, 40534, 476, 4605, 29743, 257, 2002, 31702, 51020], "temperature": 0.0, "avg_logprob": -0.2611277997493744, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.023055503144860268}, {"id": 529, "seek": 278460, "start": 2797.72, "end": 2802.36, "text": " que est\u00e1 en la referencia, entonces cuento los unigramas y me da que hay 6 hits de 6,", "tokens": [51020, 631, 3192, 465, 635, 2864, 10974, 11, 13003, 2702, 15467, 1750, 517, 328, 2356, 296, 288, 385, 1120, 631, 4842, 1386, 8664, 368, 1386, 11, 51252], "temperature": 0.0, "avg_logprob": -0.2611277997493744, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.023055503144860268}, {"id": 530, "seek": 278460, "start": 2802.36, "end": 2807.04, "text": " a pesar de que la traducci\u00f3n es horrible. Entonces, como hago para evitar esto, lo que se", "tokens": [51252, 257, 41951, 368, 631, 635, 2479, 1311, 5687, 785, 9263, 13, 15097, 11, 2617, 38721, 1690, 31326, 7433, 11, 450, 631, 369, 51486], "temperature": 0.0, "avg_logprob": -0.2611277997493744, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.023055503144860268}, {"id": 531, "seek": 278460, "start": 2807.04, "end": 2811.8399999999997, "text": " suele hacer es clipping, lo que significa que cuento cuanto es la cantidad m\u00e1xima de palabras", "tokens": [51486, 459, 16884, 6720, 785, 49320, 11, 450, 631, 19957, 631, 2702, 15467, 36685, 785, 635, 33757, 31031, 64, 368, 35240, 51726], "temperature": 0.0, "avg_logprob": -0.2611277997493744, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.023055503144860268}, {"id": 532, "seek": 281184, "start": 2811.84, "end": 2815.76, "text": " en la referencia y no permite que haya m\u00e1s de eso. Entonces, yo ac\u00e1 tengo hasta dos palabras", "tokens": [50364, 465, 635, 2864, 10974, 288, 572, 31105, 631, 24693, 3573, 368, 7287, 13, 15097, 11, 5290, 23496, 13989, 10764, 4491, 35240, 50560], "temperature": 0.0, "avg_logprob": -0.2471498628941978, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.004061968065798283}, {"id": 533, "seek": 281184, "start": 2815.76, "end": 2822.52, "text": " D, entonces no puedo contar 6 de 6, tendr\u00eda que contar m\u00e1ximo 126. Entonces ah\u00ed evitamos ese", "tokens": [50560, 413, 11, 13003, 572, 21612, 27045, 1386, 368, 1386, 11, 3928, 37183, 631, 27045, 38876, 2272, 21, 13, 15097, 12571, 1073, 270, 2151, 10167, 50898], "temperature": 0.0, "avg_logprob": -0.2471498628941978, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.004061968065798283}, {"id": 534, "seek": 281184, "start": 2822.52, "end": 2830.4, "text": " problema de que, bueno, alguien se haga el vivo y genera simplemente una sola palabra. Bien,", "tokens": [50898, 12395, 368, 631, 11, 11974, 11, 25814, 369, 46726, 806, 30689, 288, 1337, 64, 33190, 2002, 34162, 31702, 13, 16956, 11, 51292], "temperature": 0.0, "avg_logprob": -0.2471498628941978, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.004061968065798283}, {"id": 535, "seek": 281184, "start": 2830.4, "end": 2836.0, "text": " entonces, hasta ahora vimos dos cosas, calculamos la precisi\u00f3n de orden N, la precisi\u00f3n de cada uno", "tokens": [51292, 13003, 11, 10764, 9923, 49266, 4491, 12218, 11, 4322, 2151, 635, 7974, 2560, 368, 28615, 426, 11, 635, 7974, 2560, 368, 8411, 8526, 51572], "temperature": 0.0, "avg_logprob": -0.2471498628941978, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.004061968065798283}, {"id": 536, "seek": 281184, "start": 2836.0, "end": 2840.88, "text": " de los unigramas o diagramas, los segundos que vimos es que vamos a hacer clipping para evitar", "tokens": [51572, 368, 1750, 517, 328, 2356, 296, 277, 10686, 296, 11, 1750, 40108, 631, 49266, 785, 631, 5295, 257, 6720, 49320, 1690, 31326, 51816], "temperature": 0.0, "avg_logprob": -0.2471498628941978, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.004061968065798283}, {"id": 537, "seek": 284088, "start": 2840.88, "end": 2843.96, "text": " pasarnos de conteo en las palabras que aparecen m\u00e1s de una vez.", "tokens": [50364, 1736, 24979, 368, 34444, 78, 465, 2439, 35240, 631, 15004, 13037, 3573, 368, 2002, 5715, 13, 50518], "temperature": 0.0, "avg_logprob": -0.31163196240441277, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.011973985470831394}, {"id": 538, "seek": 284088, "start": 2845.96, "end": 2853.7200000000003, "text": " Lo tercero que pasa es ve\u00edamos en este ejemplo de ac\u00e1, ac\u00e1 tenemos dos candidatos de Catz", "tokens": [50618, 6130, 38103, 78, 631, 20260, 785, 1241, 16275, 465, 4065, 13358, 368, 23496, 11, 23496, 9914, 4491, 6268, 26818, 368, 9565, 89, 51006], "temperature": 0.0, "avg_logprob": -0.31163196240441277, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.011973985470831394}, {"id": 539, "seek": 284088, "start": 2853.7200000000003, "end": 2859.0, "text": " y Sad CatzD, y lo que pasaba ac\u00e1 era que le estaba haciendo mejor a la traducci\u00f3n de", "tokens": [51006, 288, 12269, 9565, 89, 35, 11, 288, 450, 631, 1736, 5509, 23496, 4249, 631, 476, 17544, 20509, 11479, 257, 635, 2479, 1311, 5687, 368, 51270], "temperature": 0.0, "avg_logprob": -0.31163196240441277, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.011973985470831394}, {"id": 540, "seek": 284088, "start": 2859.0, "end": 2865.0, "text": " Catz porque ten\u00eda todos los unigramas que est\u00e1n en la traducci\u00f3n, est\u00e1n tambi\u00e9n en la", "tokens": [51270, 9565, 89, 4021, 23718, 6321, 1750, 517, 328, 2356, 296, 631, 10368, 465, 635, 2479, 1311, 5687, 11, 10368, 6407, 465, 635, 51570], "temperature": 0.0, "avg_logprob": -0.31163196240441277, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.011973985470831394}, {"id": 541, "seek": 284088, "start": 2865.0, "end": 2869.36, "text": " referencia y todos los diagramas tambi\u00e9n, en cambio el candidato V no, el candidato V tiene", "tokens": [51570, 2864, 10974, 288, 6321, 1750, 10686, 296, 6407, 11, 465, 28731, 806, 6268, 2513, 691, 572, 11, 806, 6268, 2513, 691, 7066, 51788], "temperature": 0.0, "avg_logprob": -0.31163196240441277, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.011973985470831394}, {"id": 542, "seek": 286936, "start": 2869.36, "end": 2873.2400000000002, "text": " unigramas que est\u00e1n, pero diagramas y trilamas que no est\u00e1n. Entonces en cuanto a precisi\u00f3n", "tokens": [50364, 517, 328, 2356, 296, 631, 10368, 11, 4768, 10686, 296, 288, 26120, 19473, 631, 572, 10368, 13, 15097, 465, 36685, 257, 7974, 2560, 50558], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 543, "seek": 286936, "start": 2873.2400000000002, "end": 2878.6, "text": " el candidato V va bastante mejor. \u00bfPor qu\u00e9 va bastante mejor el candidato V? Porque es", "tokens": [50558, 806, 6268, 2513, 691, 2773, 14651, 11479, 13, 3841, 24907, 8057, 2773, 14651, 11479, 806, 6268, 2513, 691, 30, 11287, 785, 50826], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 544, "seek": 286936, "start": 2878.6, "end": 2886.04, "text": " un candidato que es m\u00e1s corto que la referencia, o sea, es un candidato que tiene menos palabras.", "tokens": [50826, 517, 6268, 2513, 631, 785, 3573, 11278, 78, 631, 635, 2864, 10974, 11, 277, 4158, 11, 785, 517, 6268, 2513, 631, 7066, 8902, 35240, 13, 51198], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 545, "seek": 286936, "start": 2886.04, "end": 2890.04, "text": " Como venimos definiendo la m\u00e9trica, si yo tengo una referencia y despu\u00e9s tengo un candidato", "tokens": [51198, 11913, 6138, 8372, 1561, 7304, 635, 20275, 15192, 11, 1511, 5290, 13989, 2002, 2864, 10974, 288, 15283, 13989, 517, 6268, 2513, 51398], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 546, "seek": 286936, "start": 2890.04, "end": 2894.6800000000003, "text": " que es justo un prefijo de la referencia, entonces va a cumplir que ese prefijo andaba", "tokens": [51398, 631, 785, 40534, 517, 18417, 24510, 368, 635, 2864, 10974, 11, 13003, 2773, 257, 37483, 347, 631, 10167, 18417, 24510, 293, 5509, 51630], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 547, "seek": 286936, "start": 2894.6800000000003, "end": 2898.0, "text": " bien en todas las medidas de precisi\u00f3n, porque todos los enigramas que tiene van a", "tokens": [51630, 3610, 465, 10906, 2439, 37295, 368, 7974, 2560, 11, 4021, 6321, 1750, 465, 328, 2356, 296, 631, 7066, 3161, 257, 51796], "temperature": 0.0, "avg_logprob": -0.18155047011702027, "compression_ratio": 1.9535714285714285, "no_speech_prob": 0.0018989481031894684}, {"id": 548, "seek": 289800, "start": 2898.0, "end": 2903.08, "text": " pertenecer a la referencia. As\u00ed que lo que hace la medida blue es penalizar ese tipo", "tokens": [50364, 680, 1147, 68, 1776, 257, 635, 2864, 10974, 13, 17419, 631, 450, 631, 10032, 635, 32984, 3344, 785, 13661, 9736, 10167, 9746, 50618], "temperature": 0.0, "avg_logprob": -0.2699515914916992, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.001419800566509366}, {"id": 549, "seek": 289800, "start": 2903.08, "end": 2911.92, "text": " de comportamientos. Penaliza los candidatos que son muy cortos para que digamos le de", "tokens": [50618, 368, 25883, 43466, 13, 10571, 304, 13427, 1750, 6268, 26818, 631, 1872, 5323, 11278, 329, 1690, 631, 36430, 476, 368, 51060], "temperature": 0.0, "avg_logprob": -0.2699515914916992, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.001419800566509366}, {"id": 550, "seek": 289800, "start": 2911.92, "end": 2919.28, "text": " menos puntaje. Entonces, \u00bfpor qu\u00e9 se penaliza los candidatos cortos y no los candidatos largos?", "tokens": [51060, 8902, 4468, 1328, 2884, 13, 15097, 11, 3841, 2816, 8057, 369, 13661, 13427, 1750, 6268, 26818, 11278, 329, 288, 572, 1750, 6268, 26818, 11034, 329, 30, 51428], "temperature": 0.0, "avg_logprob": -0.2699515914916992, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.001419800566509366}, {"id": 551, "seek": 289800, "start": 2919.28, "end": 2925.36, "text": " \u00bfPor qu\u00e9 les parece? Candidatos que son demasiado cortos se penalizan, pero les hemos", "tokens": [51428, 3841, 24907, 8057, 1512, 14120, 30, 20466, 327, 26818, 631, 1872, 39820, 11278, 329, 369, 13661, 590, 282, 11, 4768, 1512, 15396, 51732], "temperature": 0.0, "avg_logprob": -0.2699515914916992, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.001419800566509366}, {"id": 552, "seek": 292536, "start": 2925.36, "end": 2931.56, "text": " dado largos, \u00bfno? La respuesta est\u00e1 en las slides, pero bueno, se que se penaliza los", "tokens": [50364, 29568, 11034, 329, 11, 3841, 1771, 30, 2369, 40585, 3192, 465, 2439, 9788, 11, 4768, 11974, 11, 369, 631, 369, 13661, 13427, 1750, 50674], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 553, "seek": 292536, "start": 2931.56, "end": 2935.6400000000003, "text": " candidatos cortos porque los candidatos largos, si yo genero un candidato que es mucho m\u00e1s", "tokens": [50674, 6268, 26818, 11278, 329, 4021, 1750, 6268, 26818, 11034, 329, 11, 1511, 5290, 1337, 78, 517, 6268, 2513, 631, 785, 9824, 3573, 50878], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 554, "seek": 292536, "start": 2935.6400000000003, "end": 2939.96, "text": " largo que la referencia, lo que va a pasar es que ese candidato tiene enigramas, seguramente", "tokens": [50878, 31245, 631, 635, 2864, 10974, 11, 450, 631, 2773, 257, 25344, 785, 631, 10167, 6268, 2513, 7066, 465, 328, 2356, 296, 11, 22179, 3439, 51094], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 555, "seek": 292536, "start": 2939.96, "end": 2944.7200000000003, "text": " tiene enigramas que no pertenece de la referencia. Entonces, en el contenido de precisi\u00f3n me", "tokens": [51094, 7066, 465, 328, 2356, 296, 631, 572, 680, 1147, 68, 384, 368, 635, 2864, 10974, 13, 15097, 11, 465, 806, 47117, 368, 7974, 2560, 385, 51332], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 556, "seek": 292536, "start": 2944.7200000000003, "end": 2949.08, "text": " va a dar un puntaje m\u00e1s bajo. Candidatos largos ya est\u00e1n penalizados por la precisi\u00f3n,", "tokens": [51332, 2773, 257, 4072, 517, 4468, 1328, 2884, 3573, 30139, 13, 20466, 327, 26818, 11034, 329, 2478, 10368, 13661, 590, 4181, 1515, 635, 7974, 2560, 11, 51550], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 557, "seek": 292536, "start": 2949.08, "end": 2953.6, "text": " candidatos cortos no est\u00e1n penalizados por la precisi\u00f3n. Entonces, necesito otro tipo", "tokens": [51550, 6268, 26818, 11278, 329, 572, 10368, 13661, 590, 4181, 1515, 635, 7974, 2560, 13, 15097, 11, 11909, 3528, 11921, 9746, 51776], "temperature": 0.0, "avg_logprob": -0.1935238308376736, "compression_ratio": 2.029850746268657, "no_speech_prob": 0.00241949874907732}, {"id": 558, "seek": 295360, "start": 2953.6, "end": 2959.48, "text": " de penalizaci\u00f3n para evitar eso. Bien, entonces lo que vamos a dar es una cosa de", "tokens": [50364, 368, 13661, 27603, 1690, 31326, 7287, 13, 16956, 11, 13003, 450, 631, 5295, 257, 4072, 785, 2002, 10163, 368, 50658], "temperature": 0.0, "avg_logprob": -0.2696293195088704, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.04758560657501221}, {"id": 559, "seek": 295360, "start": 2959.48, "end": 2965.08, "text": " llama penalizaci\u00f3n propiedad o brevitipenal, que es un puntaje que se le da en referencia", "tokens": [50658, 23272, 13661, 27603, 2365, 1091, 345, 277, 1403, 10398, 647, 268, 304, 11, 631, 785, 517, 4468, 1328, 2884, 631, 369, 476, 1120, 465, 2864, 10974, 50938], "temperature": 0.0, "avg_logprob": -0.2696293195088704, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.04758560657501221}, {"id": 560, "seek": 295360, "start": 2965.08, "end": 2970.8399999999997, "text": " que tan corto es un candidato respecto a la referencia y bueno, se calcula teniendo en", "tokens": [50938, 631, 7603, 11278, 78, 785, 517, 6268, 2513, 35694, 257, 635, 2864, 10974, 288, 11974, 11, 369, 4322, 64, 2064, 7304, 465, 51226], "temperature": 0.0, "avg_logprob": -0.2696293195088704, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.04758560657501221}, {"id": 561, "seek": 295360, "start": 2970.8399999999997, "end": 2974.3199999999997, "text": " cuenta todo el largo del documento, todo el largo del documento traducido, entonces", "tokens": [51226, 17868, 5149, 806, 31245, 1103, 4166, 78, 11, 5149, 806, 31245, 1103, 4166, 78, 2479, 1311, 2925, 11, 13003, 51400], "temperature": 0.0, "avg_logprob": -0.2696293195088704, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.04758560657501221}, {"id": 562, "seek": 295360, "start": 2974.3199999999997, "end": 2979.7999999999997, "text": " ac\u00e1 yo defino que el reprima es el largo total de todas las referencias, se prima es", "tokens": [51400, 23496, 5290, 1561, 78, 631, 806, 1085, 81, 4775, 785, 806, 31245, 3217, 368, 10906, 2439, 2864, 37246, 11, 369, 19507, 785, 51674], "temperature": 0.0, "avg_logprob": -0.2696293195088704, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.04758560657501221}, {"id": 563, "seek": 297980, "start": 2979.8, "end": 2987.0800000000004, "text": " el largo total de todos los candidatos. Y entonces, si el largo de los candidatos es mayor", "tokens": [50364, 806, 31245, 3217, 368, 6321, 1750, 6268, 26818, 13, 398, 13003, 11, 1511, 806, 31245, 368, 1750, 6268, 26818, 785, 10120, 50728], "temperature": 0.0, "avg_logprob": -0.17567008169073808, "compression_ratio": 1.9184782608695652, "no_speech_prob": 0.004489804618060589}, {"id": 564, "seek": 297980, "start": 2987.0800000000004, "end": 2991.88, "text": " a largo de las referencias no hay penalizaci\u00f3n, le pongo uno, si el largo total de los candidatos", "tokens": [50728, 257, 31245, 368, 2439, 2864, 37246, 572, 4842, 13661, 27603, 11, 476, 280, 25729, 8526, 11, 1511, 806, 31245, 3217, 368, 1750, 6268, 26818, 50968], "temperature": 0.0, "avg_logprob": -0.17567008169073808, "compression_ratio": 1.9184782608695652, "no_speech_prob": 0.004489804618060589}, {"id": 565, "seek": 297980, "start": 2991.88, "end": 2997.88, "text": " es menor a largo de las referencias, entonces lo calculo como e a la menos, e a la uno menos", "tokens": [50968, 785, 26343, 257, 31245, 368, 2439, 2864, 37246, 11, 13003, 450, 4322, 78, 2617, 308, 257, 635, 8902, 11, 308, 257, 635, 8526, 8902, 51268], "temperature": 0.0, "avg_logprob": -0.17567008169073808, "compression_ratio": 1.9184782608695652, "no_speech_prob": 0.004489804618060589}, {"id": 566, "seek": 297980, "start": 2997.88, "end": 3003.88, "text": " la divisi\u00f3n entre los largos. Esto es una definici\u00f3n de probabilidad", "tokens": [51268, 635, 25974, 2560, 3962, 1750, 11034, 329, 13, 20880, 785, 2002, 1561, 15534, 368, 31959, 4580, 51568], "temperature": 0.0, "avg_logprob": -0.17567008169073808, "compression_ratio": 1.9184782608695652, "no_speech_prob": 0.004489804618060589}, {"id": 567, "seek": 300388, "start": 3003.88, "end": 3009.8, "text": " exponencial, digamos, no es m\u00e1s que eso. Y en realidad lo que trata de hacer es penalizar", "tokens": [50364, 12680, 26567, 11, 36430, 11, 572, 785, 3573, 631, 7287, 13, 398, 465, 25635, 450, 631, 31920, 368, 6720, 785, 13661, 9736, 50660], "temperature": 0.0, "avg_logprob": -0.21181095533134522, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.05097878351807594}, {"id": 568, "seek": 300388, "start": 3009.8, "end": 3015.32, "text": " traducciones que son muy cortas, entonces si yo ten\u00eda un candidato que ten\u00eda cinco palabras", "tokens": [50660, 2479, 1311, 23469, 631, 1872, 5323, 11278, 296, 11, 13003, 1511, 5290, 23718, 517, 6268, 2513, 631, 23718, 21350, 35240, 50936], "temperature": 0.0, "avg_logprob": -0.21181095533134522, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.05097878351807594}, {"id": 569, "seek": 300388, "start": 3015.32, "end": 3020.1600000000003, "text": " mientras la referencia ten\u00eda diez, lo voy a penalizar fuertemente, le voy a dar un 0.37", "tokens": [50936, 26010, 635, 2864, 10974, 23718, 48165, 11, 450, 7552, 257, 13661, 9736, 8536, 911, 16288, 11, 476, 7552, 257, 4072, 517, 1958, 13, 12851, 51178], "temperature": 0.0, "avg_logprob": -0.21181095533134522, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.05097878351807594}, {"id": 570, "seek": 300388, "start": 3020.1600000000003, "end": 3025.08, "text": " de penalizaci\u00f3n, si yo ten\u00eda un candidato que estaba que era menor pero era m\u00e1s cercano,", "tokens": [51178, 368, 13661, 27603, 11, 1511, 5290, 23718, 517, 6268, 2513, 631, 17544, 631, 4249, 26343, 4768, 4249, 3573, 36099, 3730, 11, 51424], "temperature": 0.0, "avg_logprob": -0.21181095533134522, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.05097878351807594}, {"id": 571, "seek": 300388, "start": 3025.08, "end": 3030.6, "text": " entonces la penalizaci\u00f3n no es tanta de 0.78 y despu\u00e9s si los largos son iguales o si", "tokens": [51424, 13003, 635, 13661, 27603, 572, 785, 40864, 368, 1958, 13, 30693, 288, 15283, 1511, 1750, 11034, 329, 1872, 10953, 279, 277, 1511, 51700], "temperature": 0.0, "avg_logprob": -0.21181095533134522, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.05097878351807594}, {"id": 572, "seek": 303060, "start": 3030.6, "end": 3034.04, "text": " el candidato es m\u00e1s largo, no penaliz\u00f3 nada, le doy uno de puntas.", "tokens": [50364, 806, 6268, 2513, 785, 3573, 31245, 11, 572, 13661, 590, 812, 8096, 11, 476, 360, 88, 8526, 368, 18212, 296, 13, 50536], "temperature": 0.0, "avg_logprob": -0.2881486047174513, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.004958858247846365}, {"id": 573, "seek": 303060, "start": 3034.04, "end": 3041.8399999999997, "text": " Bueno, entonces la metrica blue, que es una metrica muy usada en traducci\u00f3n autom\u00e1tica,", "tokens": [50536, 16046, 11, 13003, 635, 1131, 81, 2262, 3344, 11, 631, 785, 2002, 1131, 81, 2262, 5323, 505, 1538, 465, 2479, 1311, 5687, 3553, 23432, 11, 50926], "temperature": 0.0, "avg_logprob": -0.2881486047174513, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.004958858247846365}, {"id": 574, "seek": 303060, "start": 3041.8399999999997, "end": 3045.48, "text": " pone todo esto juntos, digamos, todos estos pedacitos que estuvimos viendo, los pone juntos", "tokens": [50926, 40192, 5149, 7433, 33868, 11, 36430, 11, 6321, 12585, 5670, 326, 11343, 631, 49777, 8372, 34506, 11, 1750, 40192, 33868, 51108], "temperature": 0.0, "avg_logprob": -0.2881486047174513, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.004958858247846365}, {"id": 575, "seek": 303060, "start": 3045.48, "end": 3050.2799999999997, "text": " en un solo c\u00e1lculo. Blue se calcula como la penalizaci\u00f3n por probabilidad, el breve", "tokens": [51108, 465, 517, 6944, 6476, 75, 25436, 13, 8510, 369, 4322, 64, 2617, 635, 13661, 27603, 1515, 31959, 4580, 11, 806, 48517, 51348], "temperature": 0.0, "avg_logprob": -0.2881486047174513, "compression_ratio": 1.5627906976744186, "no_speech_prob": 0.004958858247846365}, {"id": 576, "seek": 305028, "start": 3050.28, "end": 3062.36, "text": " penal D, por E a la suma de las precisiones de orden N. \u00bfQu\u00e9 palabras ruido?", "tokens": [50364, 13661, 413, 11, 1515, 462, 257, 635, 2408, 64, 368, 2439, 7974, 5411, 368, 28615, 426, 13, 3841, 15137, 35240, 5420, 2925, 30, 50968], "temperature": 0.0, "avg_logprob": -0.6247094352290316, "compression_ratio": 1.2481203007518797, "no_speech_prob": 0.23145635426044464}, {"id": 577, "seek": 305028, "start": 3062.36, "end": 3074.84, "text": " Por ejemplo, esto es un unigrama que le va a dar 0 de precisi\u00f3n, digamos, por ejemplo,", "tokens": [50968, 5269, 13358, 11, 7433, 785, 517, 517, 328, 29762, 631, 476, 2773, 257, 4072, 1958, 368, 7974, 2560, 11, 36430, 11, 1515, 13358, 11, 51592], "temperature": 0.0, "avg_logprob": -0.6247094352290316, "compression_ratio": 1.2481203007518797, "no_speech_prob": 0.23145635426044464}, {"id": 578, "seek": 307484, "start": 3075.4, "end": 3080.32, "text": " bueno, esta palabra no va, o sea, es un unigrama que le va a dar 0 de precisi\u00f3n, digamos,", "tokens": [50392, 11974, 11, 5283, 31702, 572, 2773, 11, 277, 4158, 11, 785, 517, 517, 328, 29762, 631, 476, 2773, 257, 4072, 1958, 368, 7974, 2560, 11, 36430, 11, 50638], "temperature": 0.0, "avg_logprob": -0.2861971783993849, "compression_ratio": 1.8553719008264462, "no_speech_prob": 0.17646171152591705}, {"id": 579, "seek": 307484, "start": 3080.32, "end": 3084.0, "text": " porque no est\u00e1, adem\u00e1s participan un diagrama que tambi\u00e9n le va a dar mala precisi\u00f3n porque", "tokens": [50638, 4021, 572, 3192, 11, 21251, 3421, 282, 517, 10686, 64, 631, 6407, 476, 2773, 257, 4072, 2806, 64, 7974, 2560, 4021, 50822], "temperature": 0.0, "avg_logprob": -0.2861971783993849, "compression_ratio": 1.8553719008264462, "no_speech_prob": 0.17646171152591705}, {"id": 580, "seek": 307484, "start": 3084.0, "end": 3089.1600000000003, "text": " tampoco est\u00e1 el diagrama, entonces lo que, reestan realidad porque no est\u00e1 sumando la", "tokens": [50822, 36838, 3192, 806, 10686, 64, 11, 13003, 450, 631, 11, 319, 377, 282, 25635, 4021, 572, 3192, 2408, 1806, 635, 51080], "temperature": 0.0, "avg_logprob": -0.2861971783993849, "compression_ratio": 1.8553719008264462, "no_speech_prob": 0.17646171152591705}, {"id": 581, "seek": 307484, "start": 3089.1600000000003, "end": 3095.1600000000003, "text": " impresi\u00f3n, ac\u00e1 yo tengo 1, 2, 3, 4, 5, 6, 7 unigramas de los cuales 6 es tambi\u00e9n, pero", "tokens": [51080, 35672, 2560, 11, 23496, 5290, 13989, 502, 11, 568, 11, 805, 11, 1017, 11, 1025, 11, 1386, 11, 1614, 517, 328, 2356, 296, 368, 1750, 46932, 1386, 785, 6407, 11, 4768, 51380], "temperature": 0.0, "avg_logprob": -0.2861971783993849, "compression_ratio": 1.8553719008264462, "no_speech_prob": 0.17646171152591705}, {"id": 582, "seek": 307484, "start": 3095.1600000000003, "end": 3099.84, "text": " hay uno que no, en cambio, en este tengo 6 unigrama de los cuales los 6 es tambi\u00e9n,", "tokens": [51380, 4842, 8526, 631, 572, 11, 465, 28731, 11, 465, 4065, 13989, 1386, 517, 328, 29762, 368, 1750, 46932, 1750, 1386, 785, 6407, 11, 51614], "temperature": 0.0, "avg_logprob": -0.2861971783993849, "compression_ratio": 1.8553719008264462, "no_speech_prob": 0.17646171152591705}, {"id": 583, "seek": 309984, "start": 3099.84, "end": 3104.7200000000003, "text": " entonces ac\u00e1 el hecho de agregar palabras que no son, que no est\u00e1n bien, no est\u00e1n en la", "tokens": [50364, 13003, 23496, 806, 13064, 368, 4554, 2976, 35240, 631, 572, 1872, 11, 631, 572, 10368, 3610, 11, 572, 10368, 465, 635, 50608], "temperature": 0.0, "avg_logprob": -0.2196644614724552, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.022773824632167816}, {"id": 584, "seek": 309984, "start": 3104.7200000000003, "end": 3110.92, "text": " referencia, ya te penaliza. La diferencia es cuando yo tengo una traducci\u00f3n que m\u00e1s corta,", "tokens": [50608, 2864, 10974, 11, 2478, 535, 13661, 13427, 13, 2369, 38844, 785, 7767, 5290, 13989, 2002, 2479, 1311, 5687, 631, 3573, 11278, 64, 11, 50918], "temperature": 0.0, "avg_logprob": -0.2196644614724552, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.022773824632167816}, {"id": 585, "seek": 309984, "start": 3110.92, "end": 3115.6800000000003, "text": " si yo dir\u00eda, solo de CatSatOn, entonces ah\u00ed es m\u00e1s corta y no tengo forma de penalizarlo", "tokens": [50918, 1511, 5290, 4746, 2686, 11, 6944, 368, 9565, 50, 267, 11747, 11, 13003, 12571, 785, 3573, 11278, 64, 288, 572, 13989, 8366, 368, 13661, 9736, 752, 51156], "temperature": 0.0, "avg_logprob": -0.2196644614724552, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.022773824632167816}, {"id": 586, "seek": 309984, "start": 3115.6800000000003, "end": 3119.44, "text": " solo con la precisi\u00f3n, entonces tengo el otro penalizador que es porque la traducci\u00f3n es muy", "tokens": [51156, 6944, 416, 635, 7974, 2560, 11, 13003, 13989, 806, 11921, 13661, 590, 5409, 631, 785, 4021, 635, 2479, 1311, 5687, 785, 5323, 51344], "temperature": 0.0, "avg_logprob": -0.2196644614724552, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.022773824632167816}, {"id": 587, "seek": 311944, "start": 3120.44, "end": 3131.44, "text": " corta. Bien, entonces les estaba comentando, la media blusa define como una media geometrica,", "tokens": [50414, 11278, 64, 13, 16956, 11, 13003, 1512, 17544, 14541, 1806, 11, 635, 3021, 888, 20318, 6964, 2617, 2002, 3021, 12956, 15192, 11, 50964], "temperature": 0.0, "avg_logprob": -0.3756011327107747, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.09453940391540527}, {"id": 588, "seek": 311944, "start": 3131.44, "end": 3138.2000000000003, "text": " definici\u00f3n de media geometrica, de las precisiones de orden N, tambi\u00e9n tienes un peso por", "tokens": [50964, 1561, 15534, 368, 3021, 12956, 15192, 11, 368, 2439, 7974, 5411, 368, 28615, 426, 11, 6407, 20716, 517, 28149, 1515, 51302], "temperature": 0.0, "avg_logprob": -0.3756011327107747, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.09453940391540527}, {"id": 589, "seek": 311944, "start": 3138.2000000000003, "end": 3143.8, "text": " precisi\u00f3n que se puede variar, pero en general se utiliza el mismo peso para todos, multiplicado", "tokens": [51302, 7974, 2560, 631, 369, 8919, 3034, 289, 11, 4768, 465, 2674, 369, 4976, 13427, 806, 12461, 28149, 1690, 6321, 11, 17596, 1573, 51582], "temperature": 0.0, "avg_logprob": -0.3756011327107747, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.09453940391540527}, {"id": 590, "seek": 314380, "start": 3143.8, "end": 3156.28, "text": " por la penalizaci\u00f3n pobrevedad. Bien, eso es la definici\u00f3n de la media blusa, que es una", "tokens": [50364, 1515, 635, 13661, 27603, 40819, 937, 345, 13, 16956, 11, 7287, 785, 635, 1561, 15534, 368, 635, 3021, 888, 20318, 11, 631, 785, 2002, 50988], "temperature": 0.0, "avg_logprob": -0.384754783228824, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.0009715001797303557}, {"id": 591, "seek": 314380, "start": 3156.28, "end": 3161.6800000000003, "text": " media que se utiliza much\u00edsimo, esos puntajes que vemos hoy de 25 con 2 y 31 con algo eran", "tokens": [50988, 3021, 631, 369, 4976, 13427, 44722, 11, 22411, 18212, 29362, 631, 20909, 13775, 368, 3552, 416, 568, 288, 10353, 416, 8655, 32762, 51258], "temperature": 0.0, "avg_logprob": -0.384754783228824, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.0009715001797303557}, {"id": 592, "seek": 314380, "start": 3161.6800000000003, "end": 3169.1200000000003, "text": " ejemplos de media blusa aplicados en un sistema. Y bueno, una cosa importante, algunos comentarios", "tokens": [51258, 10012, 5895, 329, 368, 3021, 888, 20318, 18221, 4181, 465, 517, 13245, 13, 398, 11974, 11, 2002, 10163, 9416, 11, 21078, 36842, 51630], "temperature": 0.0, "avg_logprob": -0.384754783228824, "compression_ratio": 1.4484536082474226, "no_speech_prob": 0.0009715001797303557}, {"id": 593, "seek": 316912, "start": 3169.12, "end": 3173.3199999999997, "text": " importantes sobre la metrica blusa es que en general cuando un sistema le da mejor, digamos,", "tokens": [50364, 27963, 5473, 635, 1131, 81, 2262, 888, 20318, 785, 631, 465, 2674, 7767, 517, 13245, 476, 1120, 11479, 11, 36430, 11, 50574], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 594, "seek": 316912, "start": 3173.3199999999997, "end": 3176.64, "text": " con un conjunto de traducciones, le da mejor en metrica blusa, tambi\u00e9n le da mejor con un", "tokens": [50574, 416, 517, 37776, 368, 2479, 1311, 23469, 11, 476, 1120, 11479, 465, 1131, 81, 2262, 888, 20318, 11, 6407, 476, 1120, 11479, 416, 517, 50740], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 595, "seek": 316912, "start": 3176.64, "end": 3181.2799999999997, "text": " conjunto de humanos que evaluan el sistema, o sea que tiene una correlaci\u00f3n bastante buena con lo", "tokens": [50740, 37776, 368, 34555, 631, 6133, 282, 806, 13245, 11, 277, 4158, 631, 7066, 2002, 13983, 3482, 14651, 25710, 416, 450, 50972], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 596, "seek": 316912, "start": 3181.2799999999997, "end": 3186.96, "text": " que es la evaluaci\u00f3n subjetiva humana, pero como contra es dif\u00edcil de interpretar estos", "tokens": [50972, 631, 785, 635, 6133, 3482, 1422, 7108, 5931, 1952, 64, 11, 4768, 2617, 10742, 785, 17258, 368, 7302, 289, 12585, 51256], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 597, "seek": 316912, "start": 3186.96, "end": 3191.3599999999997, "text": " puntajes, o sea, si yo tengo un puntaje de, como nos ha pasado hoy, tiene un puntaje de 31,", "tokens": [51256, 18212, 29362, 11, 277, 4158, 11, 1511, 5290, 13989, 517, 18212, 11153, 368, 11, 2617, 3269, 324, 24794, 13775, 11, 7066, 517, 18212, 11153, 368, 10353, 11, 51476], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 598, "seek": 316912, "start": 3191.3599999999997, "end": 3195.6, "text": " en realidad un 31 es un n\u00famero que puede ser muy bueno, muy malo, dependiendo del idioma,", "tokens": [51476, 465, 25635, 517, 10353, 785, 517, 14959, 631, 8919, 816, 5323, 11974, 11, 5323, 2806, 78, 11, 5672, 7304, 1103, 18014, 6440, 11, 51688], "temperature": 0.0, "avg_logprob": -0.24720285402848416, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.04265308752655983}, {"id": 599, "seek": 319560, "start": 3195.6, "end": 3202.2, "text": " pero o sea, si todo saliera bien y yo tradujera exactamente lo mismo que est\u00e1n las referencias,", "tokens": [50364, 4768, 277, 4158, 11, 1511, 5149, 1845, 10609, 3610, 288, 5290, 2479, 4579, 1663, 48686, 450, 12461, 631, 10368, 2439, 2864, 37246, 11, 50694], "temperature": 0.0, "avg_logprob": -0.1800568229273746, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0013840898172929883}, {"id": 600, "seek": 319560, "start": 3202.2, "end": 3206.64, "text": " por construcci\u00f3n la media me dar\u00eda uno, pero en realidad es muy dif\u00edcil traducir exactamente", "tokens": [50694, 1515, 12946, 14735, 635, 3021, 385, 4072, 2686, 8526, 11, 4768, 465, 25635, 785, 5323, 17258, 2479, 1311, 347, 48686, 50916], "temperature": 0.0, "avg_logprob": -0.1800568229273746, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0013840898172929883}, {"id": 601, "seek": 319560, "start": 3206.64, "end": 3210.8399999999997, "text": " lo que est\u00e1n las referencias, porque no es cierto que exista una \u00fanica traducci\u00f3n posible", "tokens": [50916, 450, 631, 10368, 2439, 2864, 37246, 11, 4021, 572, 785, 28558, 631, 2514, 64, 2002, 30104, 2479, 1311, 5687, 26644, 51126], "temperature": 0.0, "avg_logprob": -0.1800568229273746, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0013840898172929883}, {"id": 602, "seek": 319560, "start": 3210.8399999999997, "end": 3216.96, "text": " en la traducci\u00f3n digamos humana. Horaciones se pueden traducir de manera distinta y estar", "tokens": [51126, 465, 635, 2479, 1311, 5687, 36430, 1952, 64, 13, 10691, 9188, 369, 14714, 2479, 1311, 347, 368, 13913, 1483, 16071, 288, 8755, 51432], "temperature": 0.0, "avg_logprob": -0.1800568229273746, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0013840898172929883}, {"id": 603, "seek": 319560, "start": 3216.96, "end": 3220.88, "text": " igualmente bien, entonces es muy dif\u00edcil tener un conjunto de referencias que contempla", "tokens": [51432, 10953, 4082, 3610, 11, 13003, 785, 5323, 17258, 11640, 517, 37776, 368, 2864, 37246, 631, 19935, 64, 51628], "temperature": 0.0, "avg_logprob": -0.1800568229273746, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.0013840898172929883}, {"id": 604, "seek": 322088, "start": 3220.88, "end": 3225.0, "text": " todas las posibilidades, as\u00ed que en mi traducutor capaz que anda b\u00e1rbaro, pero el puntaje", "tokens": [50364, 10906, 2439, 1366, 11607, 10284, 11, 8582, 631, 465, 2752, 2479, 1311, 22163, 35453, 631, 21851, 272, 20335, 5356, 78, 11, 4768, 806, 4468, 1328, 2884, 50570], "temperature": 0.0, "avg_logprob": -0.27542642865862166, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.08691152930259705}, {"id": 605, "seek": 322088, "start": 3225.0, "end": 3231.56, "text": " a\u00fan no es uno, no es 100 digamos, porque est\u00e1 eligiendo palabras distintas o eligiendo", "tokens": [50570, 31676, 572, 785, 8526, 11, 572, 785, 2319, 36430, 11, 4021, 3192, 31089, 7304, 35240, 31489, 296, 277, 31089, 7304, 50898], "temperature": 0.0, "avg_logprob": -0.27542642865862166, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.08691152930259705}, {"id": 606, "seek": 322088, "start": 3231.56, "end": 3237.0, "text": " formas de escribir las oraciones distintas, entonces bueno, por eso es dif\u00edcil interpretar,", "tokens": [50898, 33463, 368, 30598, 10119, 2439, 420, 9188, 31489, 296, 11, 13003, 11974, 11, 1515, 7287, 785, 17258, 7302, 289, 11, 51170], "temperature": 0.0, "avg_logprob": -0.27542642865862166, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.08691152930259705}, {"id": 607, "seek": 322088, "start": 3237.0, "end": 3244.2400000000002, "text": " yo tengo un puntaje de 30 o de 50 o sea, de 0.3 o de 0.5 y puede ser buen\u00edsimo para", "tokens": [51170, 5290, 13989, 517, 4468, 1328, 2884, 368, 2217, 277, 368, 2625, 277, 4158, 11, 368, 1958, 13, 18, 277, 368, 1958, 13, 20, 288, 8919, 816, 30037, 49889, 1690, 51532], "temperature": 0.0, "avg_logprob": -0.27542642865862166, "compression_ratio": 1.5633187772925765, "no_speech_prob": 0.08691152930259705}, {"id": 608, "seek": 324424, "start": 3244.24, "end": 3253.12, "text": " ese sistema, pero para algo que s\u00ed me sirve much\u00edsimo el puntaje, digamos, el puntaje", "tokens": [50364, 10167, 13245, 11, 4768, 1690, 8655, 631, 8600, 385, 4735, 303, 44722, 806, 4468, 1328, 2884, 11, 36430, 11, 806, 4468, 1328, 2884, 50808], "temperature": 0.0, "avg_logprob": -0.31015762017697707, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.1412392407655716}, {"id": 609, "seek": 324424, "start": 3253.12, "end": 3257.3199999999997, "text": " de blu es para decir, yo tengo mi sistema, luego el lujo, despu\u00e9s hago algunos cambios,", "tokens": [50808, 368, 888, 84, 785, 1690, 10235, 11, 5290, 13989, 2752, 13245, 11, 17222, 806, 287, 4579, 78, 11, 15283, 38721, 21078, 18751, 2717, 11, 51018], "temperature": 0.0, "avg_logprob": -0.31015762017697707, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.1412392407655716}, {"id": 610, "seek": 324424, "start": 3257.3199999999997, "end": 3261.7999999999997, "text": " el lujo de vuelta y si subi\u00f3 la performance de un puntaje blu, entonces estoy seguro", "tokens": [51018, 806, 287, 4579, 78, 368, 41542, 288, 1511, 1422, 7138, 635, 3389, 368, 517, 4468, 1328, 2884, 888, 84, 11, 13003, 15796, 31424, 51242], "temperature": 0.0, "avg_logprob": -0.31015762017697707, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.1412392407655716}, {"id": 611, "seek": 324424, "start": 3261.7999999999997, "end": 3265.0, "text": " de que mejoro, porque hay una correlaci\u00f3n con la evaluaci\u00f3n subjetiva.", "tokens": [51242, 368, 631, 11479, 78, 11, 4021, 4842, 2002, 13983, 3482, 416, 635, 6133, 3482, 1422, 7108, 5931, 13, 51402], "temperature": 0.0, "avg_logprob": -0.31015762017697707, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.1412392407655716}, {"id": 612, "seek": 326500, "start": 3265.0, "end": 3281.44, "text": " Para pasar el espa\u00f1ol ingl\u00e9s, en realidad lo que pasa es que entren\u00e1s otro traducutor.", "tokens": [50364, 11107, 25344, 806, 31177, 49766, 11, 465, 25635, 450, 631, 20260, 785, 631, 45069, 2490, 11921, 2479, 1311, 22163, 13, 51186], "temperature": 0.0, "avg_logprob": -0.45797514408192735, "compression_ratio": 1.4076923076923078, "no_speech_prob": 0.27508559823036194}, {"id": 613, "seek": 326500, "start": 3281.44, "end": 3288.32, "text": " No, ac\u00e1 estoy volando solo, ac\u00e1 estoy volando solamente en un sentido, yo ten\u00eda un sistema", "tokens": [51186, 883, 11, 23496, 15796, 1996, 1806, 6944, 11, 23496, 15796, 1996, 1806, 27814, 465, 517, 19850, 11, 5290, 23718, 517, 13245, 51530], "temperature": 0.0, "avg_logprob": -0.45797514408192735, "compression_ratio": 1.4076923076923078, "no_speech_prob": 0.27508559823036194}, {"id": 614, "seek": 328832, "start": 3288.32, "end": 3298.32, "text": " espa\u00f1ol, por ejemplo, digo una oraci\u00f3n espa\u00f1ol, el gato se sent\u00f3, y alguien me dijo bueno,", "tokens": [50364, 31177, 11, 1515, 13358, 11, 22990, 2002, 420, 3482, 31177, 11, 806, 290, 2513, 369, 2279, 812, 11, 288, 25814, 385, 27024, 11974, 11, 50864], "temperature": 0.0, "avg_logprob": -0.26012891338717553, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.18913720548152924}, {"id": 615, "seek": 328832, "start": 3298.32, "end": 3302.6400000000003, "text": " la traducci\u00f3n de referencia a eso es de CatSat y mi sistema me dijo bueno, pero mis", "tokens": [50864, 635, 2479, 1311, 5687, 368, 2864, 10974, 257, 7287, 785, 368, 9565, 50, 267, 288, 2752, 13245, 385, 27024, 11974, 11, 4768, 3346, 51080], "temperature": 0.0, "avg_logprob": -0.26012891338717553, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.18913720548152924}, {"id": 616, "seek": 328832, "start": 3302.6400000000003, "end": 3307.84, "text": " traducciones posibles son de Cat y Sad Cat D, entonces yo ten\u00eda un sistema en espa\u00f1ol", "tokens": [51080, 2479, 1311, 23469, 1366, 14428, 1872, 368, 9565, 288, 12269, 9565, 413, 11, 13003, 5290, 23718, 517, 13245, 465, 31177, 51340], "temperature": 0.0, "avg_logprob": -0.26012891338717553, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.18913720548152924}, {"id": 617, "seek": 328832, "start": 3307.84, "end": 3311.6400000000003, "text": " pero que traduce al ingl\u00e9s, digamos, un sistema de traducci\u00f3n de espa\u00f1ol de ingl\u00e9s,", "tokens": [51340, 4768, 631, 2479, 4176, 419, 49766, 11, 36430, 11, 517, 13245, 368, 2479, 1311, 5687, 368, 31177, 368, 49766, 11, 51530], "temperature": 0.0, "avg_logprob": -0.26012891338717553, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.18913720548152924}, {"id": 618, "seek": 328832, "start": 3311.6400000000003, "end": 3316.96, "text": " pero no, no estoy traduciendo en el otro sentido, no, no es como las canciones, ac\u00e1 part\u00ed", "tokens": [51530, 4768, 572, 11, 572, 15796, 2479, 1311, 7304, 465, 806, 11921, 19850, 11, 572, 11, 572, 785, 2617, 2439, 393, 23469, 11, 23496, 644, 870, 51796], "temperature": 0.0, "avg_logprob": -0.26012891338717553, "compression_ratio": 1.8244897959183672, "no_speech_prob": 0.18913720548152924}, {"id": 619, "seek": 331696, "start": 3316.96, "end": 3320.44, "text": " del espa\u00f1ol y llegu\u00e9 al ingl\u00e9s y estoy tratando de evaluar comparando las frases en", "tokens": [50364, 1103, 31177, 288, 11234, 42423, 419, 49766, 288, 15796, 21507, 1806, 368, 6133, 289, 6311, 1806, 2439, 431, 1957, 465, 50538], "temperature": 0.0, "avg_logprob": -0.27091137568155926, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.1678757667541504}, {"id": 620, "seek": 331696, "start": 3320.44, "end": 3327.84, "text": " ingl\u00e9s esperadas con las frases en ingl\u00e9s generadas, claro, probablemente, claro, est\u00e1 en", "tokens": [50538, 49766, 10045, 6872, 416, 2439, 431, 1957, 465, 49766, 1337, 6872, 11, 16742, 11, 21759, 4082, 11, 16742, 11, 3192, 465, 50908], "temperature": 0.0, "avg_logprob": -0.27091137568155926, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.1678757667541504}, {"id": 621, "seek": 331696, "start": 3327.84, "end": 3332.84, "text": " el mismo idioma, o sea, lo que no mostramos ac\u00e1 era cual era la oraci\u00f3n origen, porque para", "tokens": [50908, 806, 12461, 18014, 6440, 11, 277, 4158, 11, 450, 631, 572, 881, 30227, 23496, 4249, 10911, 4249, 635, 420, 3482, 2349, 268, 11, 4021, 1690, 51158], "temperature": 0.0, "avg_logprob": -0.27091137568155926, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.1678757667541504}, {"id": 622, "seek": 331696, "start": 3332.84, "end": 3337.7200000000003, "text": " evaluar no nos importa, para evaluar nos importa que comparar solamente la oraci\u00f3n candidato", "tokens": [51158, 6133, 289, 572, 3269, 33218, 11, 1690, 6133, 289, 3269, 33218, 631, 6311, 289, 27814, 635, 420, 3482, 6268, 2513, 51402], "temperature": 0.0, "avg_logprob": -0.27091137568155926, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.1678757667541504}, {"id": 623, "seek": 331696, "start": 3337.7200000000003, "end": 3342.84, "text": " con la referencia y la origen nos olvidamos, sabemos que los dos intentaron traducir de", "tokens": [51402, 416, 635, 2864, 10974, 288, 635, 2349, 268, 3269, 43194, 2151, 11, 27200, 631, 1750, 4491, 8446, 6372, 2479, 1311, 347, 368, 51658], "temperature": 0.0, "avg_logprob": -0.27091137568155926, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.1678757667541504}, {"id": 624, "seek": 334284, "start": 3342.84, "end": 3351.08, "text": " la misma oraci\u00f3n y bueno, y alguno le fue mejor que a otro, bien, esos son comentarios", "tokens": [50364, 635, 24946, 420, 3482, 288, 11974, 11, 288, 9813, 78, 476, 9248, 11479, 631, 257, 11921, 11, 3610, 11, 22411, 1872, 36842, 50776], "temperature": 0.0, "avg_logprob": -0.19213796997070312, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.02638915739953518}, {"id": 625, "seek": 334284, "start": 3351.08, "end": 3356.76, "text": " de blue, esto era evaluaci\u00f3n de los sistemas, lo siguiente que vamos a ver es el problema", "tokens": [50776, 368, 3344, 11, 7433, 4249, 6133, 3482, 368, 1750, 48720, 11, 450, 25666, 631, 5295, 257, 1306, 785, 806, 12395, 51060], "temperature": 0.0, "avg_logprob": -0.19213796997070312, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.02638915739953518}, {"id": 626, "seek": 334284, "start": 3356.76, "end": 3360.6000000000004, "text": " de los corpos paralelos, antes de pasar a lo que son modelos de traducci\u00f3n, vamos a", "tokens": [51060, 368, 1750, 1181, 30010, 26009, 338, 329, 11, 11014, 368, 25344, 257, 450, 631, 1872, 2316, 329, 368, 2479, 1311, 5687, 11, 5295, 257, 51252], "temperature": 0.0, "avg_logprob": -0.19213796997070312, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.02638915739953518}, {"id": 627, "seek": 334284, "start": 3360.6000000000004, "end": 3365.1600000000003, "text": " hablar un poco de lo que son los corpos paralelos, que son necesarios para construir un modelo", "tokens": [51252, 21014, 517, 10639, 368, 450, 631, 1872, 1750, 1181, 30010, 26009, 338, 329, 11, 631, 1872, 11909, 9720, 1690, 38445, 517, 27825, 51480], "temperature": 0.0, "avg_logprob": -0.19213796997070312, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.02638915739953518}, {"id": 628, "seek": 334284, "start": 3365.1600000000003, "end": 3370.92, "text": " de traducci\u00f3n, un corpos paralelo consiste en pares de textos en dos idiomas, por ejemplo,", "tokens": [51480, 368, 2479, 1311, 5687, 11, 517, 1181, 30010, 26009, 10590, 49066, 465, 2502, 495, 368, 2487, 329, 465, 4491, 18014, 7092, 11, 1515, 13358, 11, 51768], "temperature": 0.0, "avg_logprob": -0.19213796997070312, "compression_ratio": 1.9313304721030042, "no_speech_prob": 0.02638915739953518}, {"id": 629, "seek": 337092, "start": 3370.92, "end": 3375.7200000000003, "text": " tener textos en espa\u00f1ol y en ingl\u00e9s, pero adem\u00e1s yo tengo que tener alg\u00fan nivel, tengo", "tokens": [50364, 11640, 2487, 329, 465, 31177, 288, 465, 49766, 11, 4768, 21251, 5290, 13989, 631, 11640, 26300, 24423, 11, 13989, 50604], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 630, "seek": 337092, "start": 3375.7200000000003, "end": 3380.1, "text": " que tener una correspondencia entre esos textos, de alguna forma, yo tengo que saber c\u00f3mo", "tokens": [50604, 631, 11640, 2002, 6805, 10974, 3962, 22411, 2487, 329, 11, 368, 20651, 8366, 11, 5290, 13989, 631, 12489, 12826, 50823], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 631, "seek": 337092, "start": 3380.1, "end": 3386.8, "text": " se corresponde un texto con el otro, entonces bueno, tiene que estar con juntos, digamos,", "tokens": [50823, 369, 6805, 68, 517, 35503, 416, 806, 11921, 11, 13003, 11974, 11, 7066, 631, 8755, 416, 33868, 11, 36430, 11, 51158], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 632, "seek": 337092, "start": 3386.8, "end": 3391.4, "text": " ordenados de textos en el lenguaje origen, en el lenguaje destino, y bueno, existen en", "tokens": [51158, 28615, 4181, 368, 2487, 329, 465, 806, 35044, 84, 11153, 2349, 268, 11, 465, 806, 35044, 84, 11153, 2677, 2982, 11, 288, 11974, 11, 2514, 268, 465, 51388], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 633, "seek": 337092, "start": 3391.4, "end": 3396.4, "text": " el mundo, existen corpos paralelos para algunos idiomas, o sea, hay muchos idiomas en el mundo,", "tokens": [51388, 806, 7968, 11, 2514, 268, 1181, 30010, 26009, 338, 329, 1690, 21078, 18014, 7092, 11, 277, 4158, 11, 4842, 17061, 18014, 7092, 465, 806, 7968, 11, 51638], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 634, "seek": 337092, "start": 3396.4, "end": 3400.12, "text": " pero no todos los pares de idiomas tienen corpos paralelos construidos, entonces existen", "tokens": [51638, 4768, 572, 6321, 1750, 2502, 495, 368, 18014, 7092, 12536, 1181, 30010, 26009, 338, 329, 12946, 7895, 11, 13003, 2514, 268, 51824], "temperature": 0.0, "avg_logprob": -0.16908567245692424, "compression_ratio": 2.011111111111111, "no_speech_prob": 0.08927338570356369}, {"id": 635, "seek": 340012, "start": 3400.12, "end": 3404.64, "text": " para el lado de ingl\u00e9s, el chino ingl\u00e9s, para la mayor\u00eda de los lenguajes europeos,", "tokens": [50364, 1690, 806, 11631, 368, 49766, 11, 806, 417, 2982, 49766, 11, 1690, 635, 35342, 368, 1750, 35044, 84, 29362, 27207, 329, 11, 50590], "temperature": 0.0, "avg_logprob": -0.1649790529934865, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.015892798081040382}, {"id": 636, "seek": 340012, "start": 3404.64, "end": 3410.3599999999997, "text": " debido a su uso en la uni\u00f3n europea, digamos, existen tambi\u00e9n corpos paralelos para ellos,", "tokens": [50590, 50003, 257, 459, 22728, 465, 635, 517, 2560, 27207, 64, 11, 36430, 11, 2514, 268, 6407, 1181, 30010, 26009, 338, 329, 1690, 16353, 11, 50876], "temperature": 0.0, "avg_logprob": -0.1649790529934865, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.015892798081040382}, {"id": 637, "seek": 340012, "start": 3410.3599999999997, "end": 3416.2799999999997, "text": " pero para la gran mayor\u00eda de pares de lenguas, no hay, digamos, no tengo un par que traduzca", "tokens": [50876, 4768, 1690, 635, 9370, 35342, 368, 2502, 495, 368, 35044, 84, 296, 11, 572, 4842, 11, 36430, 11, 572, 13989, 517, 971, 631, 2479, 3334, 496, 51172], "temperature": 0.0, "avg_logprob": -0.1649790529934865, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.015892798081040382}, {"id": 638, "seek": 340012, "start": 3416.2799999999997, "end": 3421.08, "text": " entre el chino y el guaranismo, por ejemplo, o sea, es poco probable que se construye un", "tokens": [51172, 3962, 806, 417, 2982, 288, 806, 7498, 282, 6882, 11, 1515, 13358, 11, 277, 4158, 11, 785, 10639, 21759, 631, 369, 12946, 1200, 517, 51412], "temperature": 0.0, "avg_logprob": -0.1649790529934865, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.015892798081040382}, {"id": 639, "seek": 342108, "start": 3421.08, "end": 3431.3199999999997, "text": " par de estilos, bien, que es un corpos paralelos, ya que no se ve nada, de vuelta, ac\u00e1 hay un ejemplo", "tokens": [50364, 971, 368, 871, 6136, 11, 3610, 11, 631, 785, 517, 1181, 30010, 26009, 338, 329, 11, 2478, 631, 572, 369, 1241, 8096, 11, 368, 41542, 11, 23496, 4842, 517, 13358, 50876], "temperature": 0.0, "avg_logprob": -0.26030002756321685, "compression_ratio": 1.7891566265060241, "no_speech_prob": 0.20191730558872223}, {"id": 640, "seek": 342108, "start": 3431.3199999999997, "end": 3438.7999999999997, "text": " que no s\u00e9 si lo conocen, es un ejemplo famoso de corpos paralelos, tiene ni idea de lo que", "tokens": [50876, 631, 572, 7910, 1511, 450, 15871, 268, 11, 785, 517, 13358, 49526, 368, 1181, 30010, 26009, 338, 329, 11, 7066, 3867, 1558, 368, 450, 631, 51250], "temperature": 0.0, "avg_logprob": -0.26030002756321685, "compression_ratio": 1.7891566265060241, "no_speech_prob": 0.20191730558872223}, {"id": 641, "seek": 342108, "start": 3438.7999999999997, "end": 3449.52, "text": " es, lo han visto alguna vez, la piedra de roseta, la piedra de roseta, una piedra que la construyeron,", "tokens": [51250, 785, 11, 450, 7276, 17558, 20651, 5715, 11, 635, 24186, 424, 368, 18953, 7664, 11, 635, 24186, 424, 368, 18953, 7664, 11, 2002, 24186, 424, 631, 635, 12946, 7224, 266, 11, 51786], "temperature": 0.0, "avg_logprob": -0.26030002756321685, "compression_ratio": 1.7891566265060241, "no_speech_prob": 0.20191730558872223}, {"id": 642, "seek": 344952, "start": 3449.52, "end": 3455.44, "text": " o por lo menos la tallaron el a\u00f1o 1996, antes de Cristo, y hablaba sobre la coronaci\u00f3n de", "tokens": [50364, 277, 1515, 450, 8902, 635, 6764, 6372, 806, 15984, 22690, 11, 11014, 368, 36524, 11, 288, 26280, 5509, 5473, 635, 10451, 3482, 368, 50660], "temperature": 0.0, "avg_logprob": -0.3805686029894599, "compression_ratio": 1.5336134453781514, "no_speech_prob": 0.020128833130002022}, {"id": 643, "seek": 344952, "start": 3455.44, "end": 3462.48, "text": " Tolomeo Quinto, y tal, y su adoraci\u00f3n como semi-dios, etc\u00e9tera, etc\u00e9tera, y bueno,", "tokens": [50660, 21402, 423, 78, 2326, 17246, 11, 288, 4023, 11, 288, 459, 614, 284, 3482, 2617, 12909, 12, 67, 2717, 11, 5183, 526, 23833, 11, 5183, 526, 23833, 11, 288, 11974, 11, 51012], "temperature": 0.0, "avg_logprob": -0.3805686029894599, "compression_ratio": 1.5336134453781514, "no_speech_prob": 0.020128833130002022}, {"id": 644, "seek": 344952, "start": 3462.48, "end": 3467.28, "text": " hasta estuvo perdida, tomo un mont\u00f3n de a\u00f1os, hasta que durante las campa\u00f1as Napole\u00f3nicas,", "tokens": [51012, 10764, 871, 43744, 12611, 2887, 11, 2916, 78, 517, 45259, 368, 11424, 11, 10764, 631, 14427, 2439, 2255, 23217, 296, 28298, 1801, 9150, 11, 51252], "temperature": 0.0, "avg_logprob": -0.3805686029894599, "compression_ratio": 1.5336134453781514, "no_speech_prob": 0.020128833130002022}, {"id": 645, "seek": 344952, "start": 3467.28, "end": 3475.08, "text": " 1799, la encontraron en Egipto, en el lugar roseta, casualmente, y se lanzaron para Francia,", "tokens": [51252, 3282, 8494, 11, 635, 17525, 266, 465, 43515, 647, 1353, 11, 465, 806, 11467, 18953, 7664, 11, 13052, 4082, 11, 288, 369, 38363, 6372, 1690, 17288, 2755, 11, 51642], "temperature": 0.0, "avg_logprob": -0.3805686029894599, "compression_ratio": 1.5336134453781514, "no_speech_prob": 0.020128833130002022}, {"id": 646, "seek": 347508, "start": 3475.08, "end": 3479.7999999999997, "text": " ah\u00ed le empezaron a analizar ling\u00fcistas, empezaron a tratar de entender que era lo que dec\u00eda, y bueno,", "tokens": [50364, 12571, 476, 18730, 6372, 257, 2624, 9736, 22949, 774, 14858, 11, 18730, 6372, 257, 42549, 368, 20054, 631, 4249, 450, 631, 37599, 11, 288, 11974, 11, 50600], "temperature": 0.0, "avg_logprob": -0.2165115274113717, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.02074197679758072}, {"id": 647, "seek": 347508, "start": 3479.7999999999997, "end": 3486.2, "text": " descubrieron que tiene tres textos, vieron que tienen como tres regiones, tres textos, y despu\u00e9s de", "tokens": [50600, 32592, 7326, 266, 631, 7066, 15890, 2487, 329, 11, 371, 14440, 631, 12536, 2617, 15890, 4458, 279, 11, 15890, 2487, 329, 11, 288, 15283, 368, 50920], "temperature": 0.0, "avg_logprob": -0.2165115274113717, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.02074197679758072}, {"id": 648, "seek": 347508, "start": 3486.2, "end": 3490.72, "text": " estudiarla un rato, seguiron cuenta que en realidad lo que tiene es el mismo texto en tres idiomas", "tokens": [50920, 13542, 9448, 875, 517, 367, 2513, 11, 18584, 266, 17868, 631, 465, 25635, 450, 631, 7066, 785, 806, 12461, 35503, 465, 15890, 18014, 7092, 51146], "temperature": 0.0, "avg_logprob": -0.2165115274113717, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.02074197679758072}, {"id": 649, "seek": 347508, "start": 3490.72, "end": 3496.04, "text": " distintos, y los idiomas eran, el de arriba era en jerogl\u00edficos egipcios del estilo de lo que", "tokens": [51146, 49337, 11, 288, 1750, 18014, 7092, 32762, 11, 806, 368, 28469, 4249, 465, 20160, 664, 75, 18869, 329, 24263, 647, 23132, 1103, 37470, 368, 450, 631, 51412], "temperature": 0.0, "avg_logprob": -0.2165115274113717, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.02074197679758072}, {"id": 650, "seek": 347508, "start": 3496.04, "end": 3500.72, "text": " uno encuentra dentro de las pir\u00e1mides, el del medio era egipcio dem\u00f3tico, que era el egipcio", "tokens": [51412, 8526, 43274, 10856, 368, 2439, 13528, 19524, 1875, 11, 806, 1103, 22123, 4249, 24263, 647, 8529, 1371, 34712, 2789, 11, 631, 4249, 806, 24263, 647, 8529, 51646], "temperature": 0.0, "avg_logprob": -0.2165115274113717, "compression_ratio": 1.8364312267657992, "no_speech_prob": 0.02074197679758072}, {"id": 651, "seek": 350072, "start": 3500.7599999999998, "end": 3506.8399999999997, "text": " vulgar que se usaba, digamos, en el d\u00eda a d\u00eda, y el de abajo el todo era griego antiguo. Entonces,", "tokens": [50366, 7452, 2976, 631, 369, 505, 5509, 11, 36430, 11, 465, 806, 12271, 257, 12271, 11, 288, 806, 368, 30613, 806, 5149, 4249, 677, 12200, 2511, 16397, 78, 13, 15097, 11, 50670], "temperature": 0.0, "avg_logprob": -0.23488016728754643, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.03114338032901287}, {"id": 652, "seek": 350072, "start": 3506.8399999999997, "end": 3510.7999999999997, "text": " si bien, ninguno de los tres idiomas se hablaba en el momento que se encontr\u00f3, la piedra,", "tokens": [50670, 1511, 3610, 11, 17210, 12638, 368, 1750, 15890, 18014, 7092, 369, 26280, 5509, 465, 806, 9333, 631, 369, 10176, 11721, 11, 635, 24186, 424, 11, 50868], "temperature": 0.0, "avg_logprob": -0.23488016728754643, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.03114338032901287}, {"id": 653, "seek": 350072, "start": 3510.7999999999997, "end": 3517.4399999999996, "text": " los tres idiomas antiguos, el griego antiguo por lo menos s\u00ed se sab\u00eda, digamos, se conoc\u00eda como", "tokens": [50868, 1750, 15890, 18014, 7092, 2511, 16397, 329, 11, 806, 677, 12200, 2511, 16397, 78, 1515, 450, 8902, 8600, 369, 5560, 2686, 11, 36430, 11, 369, 15871, 2686, 2617, 51200], "temperature": 0.0, "avg_logprob": -0.23488016728754643, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.03114338032901287}, {"id": 654, "seek": 350072, "start": 3517.4399999999996, "end": 3521.7999999999997, "text": " idiomas, se sab\u00eda qu\u00e9 significaba, y digamos, hab\u00eda gente que lo estudiaba, los otros dos no,", "tokens": [51200, 18014, 7092, 11, 369, 5560, 2686, 8057, 3350, 5509, 11, 288, 36430, 11, 16395, 3788, 631, 450, 13542, 72, 5509, 11, 1750, 16422, 4491, 572, 11, 51418], "temperature": 0.0, "avg_logprob": -0.23488016728754643, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.03114338032901287}, {"id": 655, "seek": 350072, "start": 3521.7999999999997, "end": 3527.3599999999997, "text": " los otros dos eran lenguas completamente perdidas, que nadie sab\u00eda identificarlas. Pero gracias al", "tokens": [51418, 1750, 16422, 4491, 32762, 35044, 84, 296, 28381, 12611, 11382, 11, 631, 28060, 5560, 2686, 2473, 25625, 7743, 13, 9377, 16611, 419, 51696], "temperature": 0.0, "avg_logprob": -0.23488016728754643, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.03114338032901287}, {"id": 656, "seek": 352736, "start": 3527.4, "end": 3531.2400000000002, "text": " hecho de que en realidad se descubri\u00f3 que los tres textos hablan de lo mismo, son el mismo", "tokens": [50366, 13064, 368, 631, 465, 25635, 369, 32592, 44802, 631, 1750, 15890, 2487, 329, 3025, 8658, 368, 450, 12461, 11, 1872, 806, 12461, 50558], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 657, "seek": 352736, "start": 3531.2400000000002, "end": 3537.6400000000003, "text": " texto entre los idiomas. Entonces ah\u00ed se empez\u00f3 a hacer un trabajo de alineaci\u00f3n, digamos, los", "tokens": [50558, 35503, 3962, 1750, 18014, 7092, 13, 15097, 12571, 369, 18730, 812, 257, 6720, 517, 18099, 368, 419, 533, 3482, 11, 36430, 11, 1750, 50878], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 658, "seek": 352736, "start": 3537.6400000000003, "end": 3540.48, "text": " arque\u00f3logos, empezaron a decir, bueno, esta porci\u00f3n de texto ac\u00e1 se corresponde con esta", "tokens": [50878, 594, 1077, 812, 4987, 329, 11, 18730, 6372, 257, 10235, 11, 11974, 11, 5283, 1515, 5687, 368, 35503, 23496, 369, 6805, 68, 416, 5283, 51020], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 659, "seek": 352736, "start": 3540.48, "end": 3544.48, "text": " de ac\u00e1, se corresponde con esta de ac\u00e1, etc\u00e9tera, y a tratar de encontrar correspondencias en los", "tokens": [51020, 368, 23496, 11, 369, 6805, 68, 416, 5283, 368, 23496, 11, 5183, 526, 23833, 11, 288, 257, 42549, 368, 17525, 6805, 37246, 465, 1750, 51220], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 660, "seek": 352736, "start": 3544.48, "end": 3549.1200000000003, "text": " idiomas, y c\u00f3mo sab\u00edan qu\u00e9 quer\u00eda decir en griego antiguo, empezaron a poder descubrir qu\u00e9", "tokens": [51220, 18014, 7092, 11, 288, 12826, 5560, 11084, 8057, 37869, 10235, 465, 677, 12200, 2511, 16397, 78, 11, 18730, 6372, 257, 8152, 32592, 10949, 8057, 51452], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 661, "seek": 352736, "start": 3549.1200000000003, "end": 3553.32, "text": " quer\u00edan decir en los otros idiomas. Entonces, a ra\u00edz de eso es que empez\u00f3, digamos, el", "tokens": [51452, 7083, 11084, 10235, 465, 1750, 16422, 18014, 7092, 13, 15097, 11, 257, 3342, 44551, 368, 7287, 785, 631, 18730, 812, 11, 36430, 11, 806, 51662], "temperature": 0.0, "avg_logprob": -0.18673360270838585, "compression_ratio": 1.9319727891156462, "no_speech_prob": 0.005231387447565794}, {"id": 662, "seek": 355332, "start": 3553.32, "end": 3558.48, "text": " Egipto Elog\u00eda Moderno se pudo empezar a desifrar, qu\u00e9 dicen, por ejemplo, los geogr\u00e1ficos", "tokens": [50364, 43515, 647, 1353, 2699, 664, 2686, 19814, 78, 369, 280, 6207, 31168, 257, 730, 351, 5352, 11, 8057, 33816, 11, 1515, 13358, 11, 1750, 1519, 47810, 23858, 329, 50622], "temperature": 0.0, "avg_logprob": -0.2875497991388494, "compression_ratio": 1.597938144329897, "no_speech_prob": 0.017822569236159325}, {"id": 663, "seek": 355332, "start": 3558.48, "end": 3562.56, "text": " est\u00e1n en las pir\u00e1mides, y bueno, un mont\u00f3n de cultura, egipcio antiguas, se conoce gracias", "tokens": [50622, 10368, 465, 2439, 13528, 19524, 1875, 11, 288, 11974, 11, 517, 45259, 368, 30576, 11, 24263, 647, 8529, 2511, 16397, 296, 11, 369, 33029, 384, 16611, 50826], "temperature": 0.0, "avg_logprob": -0.2875497991388494, "compression_ratio": 1.597938144329897, "no_speech_prob": 0.017822569236159325}, {"id": 664, "seek": 355332, "start": 3562.56, "end": 3566.92, "text": " a que se pudo desifrar lo que dec\u00eda esta piedra. Y en definitiva, esto es un ejemplo de corpus", "tokens": [50826, 257, 631, 369, 280, 6207, 730, 351, 5352, 450, 631, 37599, 5283, 24186, 424, 13, 398, 465, 28781, 5931, 11, 7433, 785, 517, 13358, 368, 1181, 31624, 51044], "temperature": 0.0, "avg_logprob": -0.2875497991388494, "compression_ratio": 1.597938144329897, "no_speech_prob": 0.017822569236159325}, {"id": 665, "seek": 355332, "start": 3566.92, "end": 3571.0800000000004, "text": " paralelo, o sea, tengo el mismo texto entre los idiomas, y con un poco de esfuerzo logro al", "tokens": [51044, 26009, 10590, 11, 277, 4158, 11, 13989, 806, 12461, 35503, 3962, 1750, 18014, 7092, 11, 288, 416, 517, 10639, 368, 49213, 4765, 3565, 340, 419, 51252], "temperature": 0.0, "avg_logprob": -0.2875497991388494, "compression_ratio": 1.597938144329897, "no_speech_prob": 0.017822569236159325}, {"id": 666, "seek": 355332, "start": 3571.0800000000004, "end": 3578.7200000000003, "text": " alinear, cual son cada uno de los elementos de mis lenguajes, y logro saber la traducci\u00f3n", "tokens": [51252, 419, 533, 289, 11, 10911, 1872, 8411, 8526, 368, 1750, 35797, 368, 3346, 35044, 84, 29362, 11, 288, 3565, 340, 12489, 635, 2479, 1311, 5687, 51634], "temperature": 0.0, "avg_logprob": -0.2875497991388494, "compression_ratio": 1.597938144329897, "no_speech_prob": 0.017822569236159325}, {"id": 667, "seek": 357872, "start": 3578.72, "end": 3586.24, "text": " de los tres. Bueno, entonces, esto nos lleva el concepto de alineaci\u00f3n. Los corpus paralelos", "tokens": [50364, 368, 1750, 15890, 13, 16046, 11, 13003, 11, 7433, 3269, 37681, 806, 3410, 78, 368, 419, 533, 3482, 13, 7632, 1181, 31624, 26009, 338, 329, 50740], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 668, "seek": 357872, "start": 3586.24, "end": 3590.64, "text": " tienen distintos niveles de alineaci\u00f3n. Lo m\u00e1s f\u00e1cil de encontrar son corpus que est\u00e1n", "tokens": [50740, 12536, 49337, 11461, 904, 368, 419, 533, 3482, 13, 6130, 3573, 17474, 368, 17525, 1872, 1181, 31624, 631, 10368, 50960], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 669, "seek": 357872, "start": 3590.64, "end": 3593.68, "text": " alineados al nivel de documentos. Yo tengo una colecci\u00f3n de documentos en espa\u00f1ol y una", "tokens": [50960, 419, 533, 4181, 419, 24423, 368, 4166, 329, 13, 7616, 13989, 2002, 45139, 14735, 368, 4166, 329, 465, 31177, 288, 2002, 51112], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 670, "seek": 357872, "start": 3593.68, "end": 3598.48, "text": " colecci\u00f3n de documentos en chino, y yo s\u00e9 qu\u00e9 documentos se corresponde con qu\u00e9 otro,", "tokens": [51112, 45139, 14735, 368, 4166, 329, 465, 417, 2982, 11, 288, 5290, 7910, 8057, 4166, 329, 369, 6805, 68, 416, 8057, 11921, 11, 51352], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 671, "seek": 357872, "start": 3598.48, "end": 3602.72, "text": " pero no s\u00e9 nada m\u00e1s. Ser\u00eda mejor, incluso que estuvieran alineados a nivel de", "tokens": [51352, 4768, 572, 7910, 8096, 3573, 13, 4210, 2686, 11479, 11, 24018, 631, 49777, 38516, 419, 533, 4181, 257, 24423, 368, 51564], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 672, "seek": 357872, "start": 3602.72, "end": 3607.3599999999997, "text": " elaboraci\u00f3n, adem\u00e1s de conocer los documentos, yo s\u00e9 cu\u00e1l elaboraci\u00f3n espa\u00f1ol va con", "tokens": [51564, 16298, 3482, 11, 21251, 368, 35241, 1750, 4166, 329, 11, 5290, 7910, 44318, 16298, 3482, 31177, 2773, 416, 51796], "temperature": 0.0, "avg_logprob": -0.21259236507278553, "compression_ratio": 1.9280575539568345, "no_speech_prob": 0.04061415046453476}, {"id": 673, "seek": 360736, "start": 3607.36, "end": 3611.1600000000003, "text": " cu\u00e1l elaboraci\u00f3n en chino, digamos. Tengo una correspondencia entre esas dos. Pero ser\u00eda", "tokens": [50364, 44318, 16298, 3482, 465, 417, 2982, 11, 36430, 13, 314, 30362, 2002, 6805, 10974, 3962, 23388, 4491, 13, 9377, 23679, 50554], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 674, "seek": 360736, "start": 3611.1600000000003, "end": 3615.6, "text": " a\u00fan mejor, y esto es lo que m\u00e1s nos servir\u00eda, si estuvieran alineados a nivel de palabra.", "tokens": [50554, 31676, 11479, 11, 288, 7433, 785, 450, 631, 3573, 3269, 29463, 2686, 11, 1511, 49777, 38516, 419, 533, 4181, 257, 24423, 368, 31702, 13, 50776], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 675, "seek": 360736, "start": 3615.6, "end": 3618.76, "text": " Cada uno de los caracteres que est\u00e1n en chino se corresponde con qu\u00e9 palabra en espa\u00f1ol,", "tokens": [50776, 38603, 8526, 368, 1750, 28760, 279, 631, 10368, 465, 417, 2982, 369, 6805, 68, 416, 8057, 31702, 465, 31177, 11, 50934], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 676, "seek": 360736, "start": 3618.76, "end": 3621.92, "text": " lo que grupo de palabra, si cada uno de las palabras de espa\u00f1ol con qu\u00e9 grupo de caracteres", "tokens": [50934, 450, 631, 20190, 368, 31702, 11, 1511, 8411, 8526, 368, 2439, 35240, 368, 31177, 416, 8057, 20190, 368, 28760, 279, 51092], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 677, "seek": 360736, "start": 3621.92, "end": 3627.7200000000003, "text": " se corresponde en chino. Esto es el ideal, pero claro, o sea, si ya es dif\u00edcil conseguir", "tokens": [51092, 369, 6805, 68, 465, 417, 2982, 13, 20880, 785, 806, 7157, 11, 4768, 16742, 11, 277, 4158, 11, 1511, 2478, 785, 17258, 21229, 51382], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 678, "seek": 360736, "start": 3627.7200000000003, "end": 3632.28, "text": " cosas que est\u00e9n alineadas a nivel de documentos, si imaginan que nadie va a ir a mano al", "tokens": [51382, 12218, 631, 871, 3516, 419, 533, 6872, 257, 24423, 368, 4166, 329, 11, 1511, 23427, 282, 631, 28060, 2773, 257, 3418, 257, 18384, 419, 51610], "temperature": 0.0, "avg_logprob": -0.18846453962654902, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.01395230833441019}, {"id": 679, "seek": 363228, "start": 3632.28, "end": 3638.4, "text": " linear a nivel de palabra cada uno de las palabras de los idiomas. Entonces, en la pr\u00e1ctica", "tokens": [50364, 1622, 289, 257, 24423, 368, 31702, 8411, 8526, 368, 2439, 35240, 368, 1750, 18014, 7092, 13, 15097, 11, 465, 635, 27300, 29041, 50670], "temperature": 0.0, "avg_logprob": -0.20475380761282785, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.01720494031906128}, {"id": 680, "seek": 363228, "start": 3638.4, "end": 3643.36, "text": " nunca vamos a encontrar un corpus alineado a nivel de palabra, pero vamos a ver que, como", "tokens": [50670, 13768, 5295, 257, 17525, 517, 1181, 31624, 419, 533, 1573, 257, 24423, 368, 31702, 11, 4768, 5295, 257, 1306, 631, 11, 2617, 50918], "temperature": 0.0, "avg_logprob": -0.20475380761282785, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.01720494031906128}, {"id": 681, "seek": 363228, "start": 3643.36, "end": 3647.88, "text": " resultado de la construcci\u00f3n de los modelos de lenguaje, se produce tambi\u00e9n como un producto", "tokens": [50918, 28047, 368, 635, 12946, 14735, 368, 1750, 2316, 329, 368, 35044, 84, 11153, 11, 369, 5258, 6407, 2617, 517, 47583, 51144], "temperature": 0.0, "avg_logprob": -0.20475380761282785, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.01720494031906128}, {"id": 682, "seek": 363228, "start": 3647.88, "end": 3652.84, "text": " secundario, se produce la alineaci\u00f3n de los corpus. Entonces, obtenes las dos cosas a", "tokens": [51144, 907, 997, 4912, 11, 369, 5258, 635, 419, 533, 3482, 368, 1750, 1181, 31624, 13, 15097, 11, 28326, 279, 2439, 4491, 12218, 257, 51392], "temperature": 0.0, "avg_logprob": -0.20475380761282785, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.01720494031906128}, {"id": 683, "seek": 363228, "start": 3652.84, "end": 3657.96, "text": " la vez. Bueno, yo otra cosa es que, a diferencia", "tokens": [51392, 635, 5715, 13, 16046, 11, 5290, 13623, 10163, 785, 631, 11, 257, 38844, 51648], "temperature": 0.0, "avg_logprob": -0.20475380761282785, "compression_ratio": 1.764957264957265, "no_speech_prob": 0.01720494031906128}, {"id": 684, "seek": 365796, "start": 3657.96, "end": 3664.08, "text": " de el texto monol\u00edngue que yo usaba para los modelos de lenguaje, es muy raro que", "tokens": [50364, 368, 806, 35503, 1108, 401, 870, 872, 622, 631, 5290, 505, 5509, 1690, 1750, 2316, 329, 368, 35044, 84, 11153, 11, 785, 5323, 367, 9708, 631, 50670], "temperature": 0.0, "avg_logprob": -0.17634007213561514, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.015692848712205887}, {"id": 685, "seek": 365796, "start": 3664.08, "end": 3671.48, "text": " naturalmente se produzcan textos en dos idiomas a la vez. O sea, hay que buscarlos bastante,", "tokens": [50670, 3303, 4082, 369, 28093, 7035, 2487, 329, 465, 4491, 18014, 7092, 257, 635, 5715, 13, 422, 4158, 11, 4842, 631, 1255, 6166, 9389, 14651, 11, 51040], "temperature": 0.0, "avg_logprob": -0.17634007213561514, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.015692848712205887}, {"id": 686, "seek": 365796, "start": 3671.48, "end": 3676.32, "text": " digamos, bastante cuidadosamente. Existen algunos contextos en donde eso se produce. Por", "tokens": [51040, 36430, 11, 14651, 20770, 4181, 3439, 13, 2111, 4821, 21078, 4319, 329, 465, 10488, 7287, 369, 5258, 13, 5269, 51282], "temperature": 0.0, "avg_logprob": -0.17634007213561514, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.015692848712205887}, {"id": 687, "seek": 365796, "start": 3676.32, "end": 3680.28, "text": " ejemplo, en algunos portales de noticias, puede pasar que tengan versiones en distintos", "tokens": [51282, 13358, 11, 465, 21078, 2436, 4229, 368, 406, 48042, 11, 8919, 25344, 631, 46874, 3037, 279, 465, 49337, 51480], "temperature": 0.0, "avg_logprob": -0.17634007213561514, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.015692848712205887}, {"id": 688, "seek": 365796, "start": 3680.28, "end": 3684.08, "text": " idiomas y lo que hagan sea traducir las noticias en distintos idiomas. Entonces, si yo", "tokens": [51480, 18014, 7092, 288, 450, 631, 324, 1275, 4158, 2479, 1311, 347, 2439, 406, 48042, 465, 49337, 18014, 7092, 13, 15097, 11, 1511, 5290, 51670], "temperature": 0.0, "avg_logprob": -0.17634007213561514, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.015692848712205887}, {"id": 689, "seek": 368408, "start": 3684.08, "end": 3688.04, "text": " puedo encontrar uno de esos, es una buena fuente para construirme un corpus paralelo", "tokens": [50364, 21612, 17525, 8526, 368, 22411, 11, 785, 2002, 25710, 8536, 1576, 1690, 38445, 1398, 517, 1181, 31624, 26009, 10590, 50562], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 690, "seek": 368408, "start": 3688.04, "end": 3692.0, "text": " anineado a nivel de documentos. O sea, esta noticia se corresponde con esta otra en el", "tokens": [50562, 364, 533, 1573, 257, 24423, 368, 4166, 329, 13, 422, 4158, 11, 5283, 406, 15341, 369, 6805, 68, 416, 5283, 13623, 465, 806, 50760], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 691, "seek": 368408, "start": 3692.0, "end": 3695.7999999999997, "text": " otro idioma. Pero un lugar en donde se producen naturalmente", "tokens": [50760, 11921, 18014, 6440, 13, 9377, 517, 11467, 465, 10488, 369, 1082, 13037, 3303, 4082, 50950], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 692, "seek": 368408, "start": 3695.7999999999997, "end": 3702.16, "text": " este tipo de textos es en los pa\u00edses que son bil\u00edng\u00fces, o multil\u00edng\u00fces. Por ejemplo,", "tokens": [50950, 4065, 9746, 368, 2487, 329, 785, 465, 1750, 23070, 631, 1872, 8588, 870, 872, 774, 279, 11, 277, 2120, 388, 870, 872, 774, 279, 13, 5269, 13358, 11, 51268], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 693, "seek": 368408, "start": 3702.16, "end": 3706.7999999999997, "text": " en Canad\u00e1, que hablan ingl\u00e9s y franc\u00e9s, las discusiones del Parlamento Canad\u00edense", "tokens": [51268, 465, 10380, 842, 11, 631, 3025, 8658, 49766, 288, 30514, 2191, 11, 2439, 717, 1149, 5411, 1103, 29666, 8824, 10380, 870, 1288, 51500], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 694, "seek": 368408, "start": 3706.7999999999997, "end": 3711.88, "text": " siempre, por ley, tienen que transcribirse en los dos idiomas, tienen que traducirse", "tokens": [51500, 12758, 11, 1515, 27786, 11, 12536, 631, 1145, 1142, 10119, 405, 465, 1750, 4491, 18014, 7092, 11, 12536, 631, 2479, 1311, 36097, 51754], "temperature": 0.0, "avg_logprob": -0.20999489367847712, "compression_ratio": 1.65993265993266, "no_speech_prob": 0.07347670197486877}, {"id": 695, "seek": 371188, "start": 3711.88, "end": 3718.0, "text": " si est\u00e1 en ingl\u00e9s, se daus en franc\u00e9s, se daus en ingl\u00e9s. Y guardan una correspondencia", "tokens": [50364, 1511, 3192, 465, 49766, 11, 369, 1120, 301, 465, 30514, 2191, 11, 369, 1120, 301, 465, 49766, 13, 398, 6290, 282, 2002, 6805, 10974, 50670], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 696, "seek": 371188, "start": 3718.0, "end": 3720.48, "text": " entre eso. Guardan el documento de todas las discusiones del Parlamento en los dos", "tokens": [50670, 3962, 7287, 13, 11549, 282, 806, 4166, 78, 368, 10906, 2439, 717, 1149, 5411, 1103, 29666, 8824, 465, 1750, 4491, 50794], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 697, "seek": 371188, "start": 3720.48, "end": 3725.6, "text": " idiomas. Entonces, ah\u00ed, naturalmente se produce un corpus paralelo anineado de documentos", "tokens": [50794, 18014, 7092, 13, 15097, 11, 12571, 11, 3303, 4082, 369, 5258, 517, 1181, 31624, 26009, 10590, 364, 533, 1573, 368, 4166, 329, 51050], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 698, "seek": 371188, "start": 3725.6, "end": 3731.12, "text": " para el ingl\u00e9s y el franc\u00e9s, que se se conoce como el corpus Hansard. Eso tambi\u00e9n ocurre", "tokens": [51050, 1690, 806, 49766, 288, 806, 30514, 2191, 11, 631, 369, 369, 33029, 384, 2617, 806, 1181, 31624, 17926, 515, 13, 27795, 6407, 26430, 265, 51326], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 699, "seek": 371188, "start": 3731.12, "end": 3735.6, "text": " en concon, en conconciable ingl\u00e9s y chinos, son los dos idiomas oficiales. Entonces,", "tokens": [51326, 465, 416, 1671, 11, 465, 416, 1671, 537, 712, 49766, 288, 14210, 329, 11, 1872, 1750, 4491, 18014, 7092, 37189, 279, 13, 15097, 11, 51550], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 700, "seek": 371188, "start": 3735.6, "end": 3739.4, "text": " el corpus m\u00e1s grande que se tiene para ingl\u00e9s y chinos, est\u00e1 hecho como una compilaci\u00f3n", "tokens": [51550, 806, 1181, 31624, 3573, 8883, 631, 369, 7066, 1690, 49766, 288, 14210, 329, 11, 3192, 13064, 2617, 2002, 715, 388, 3482, 51740], "temperature": 0.0, "avg_logprob": -0.26837662562427905, "compression_ratio": 1.8904593639575973, "no_speech_prob": 0.019600946456193924}, {"id": 701, "seek": 373940, "start": 3739.4, "end": 3742.88, "text": " de lo que son las discusiones del Parlamento de Hong Kong. Y tambi\u00e9n pasa en la N\u00faneo", "tokens": [50364, 368, 450, 631, 1872, 2439, 717, 1149, 5411, 1103, 29666, 8824, 368, 8868, 9832, 13, 398, 6407, 20260, 465, 635, 426, 2481, 716, 78, 50538], "temperature": 0.0, "avg_logprob": -0.20899765193462372, "compression_ratio": 1.796, "no_speech_prob": 0.04422525689005852}, {"id": 702, "seek": 373940, "start": 3742.88, "end": 3748.92, "text": " Europea, en el Parlamento Europeo, tambi\u00e9n tienen la costumbre de traducir todas las discusiones", "tokens": [50538, 3315, 64, 11, 465, 806, 29666, 8824, 3315, 78, 11, 6407, 12536, 635, 2063, 449, 2672, 368, 2479, 1311, 347, 10906, 2439, 717, 1149, 5411, 50840], "temperature": 0.0, "avg_logprob": -0.20899765193462372, "compression_ratio": 1.796, "no_speech_prob": 0.04422525689005852}, {"id": 703, "seek": 373940, "start": 3748.92, "end": 3752.92, "text": " a todos los idiomas o a muchos de los idiomas que se usan en la Uni\u00f3n Europea. Entonces,", "tokens": [50840, 257, 6321, 1750, 18014, 7092, 277, 257, 17061, 368, 1750, 18014, 7092, 631, 369, 505, 282, 465, 635, 1156, 2560, 3315, 64, 13, 15097, 11, 51040], "temperature": 0.0, "avg_logprob": -0.20899765193462372, "compression_ratio": 1.796, "no_speech_prob": 0.04422525689005852}, {"id": 704, "seek": 373940, "start": 3752.92, "end": 3758.2000000000003, "text": " hay corpus paralelo para casi todos los idiomas de la Uni\u00f3n Europea. Pero claro, todos", "tokens": [51040, 4842, 1181, 31624, 26009, 10590, 1690, 22567, 6321, 1750, 18014, 7092, 368, 635, 1156, 2560, 3315, 64, 13, 9377, 16742, 11, 6321, 51304], "temperature": 0.0, "avg_logprob": -0.20899765193462372, "compression_ratio": 1.796, "no_speech_prob": 0.04422525689005852}, {"id": 705, "seek": 373940, "start": 3758.2000000000003, "end": 3762.56, "text": " estos est\u00e1n alineados a nivel de documento. Yo s\u00e9 qu\u00e9 documento se corresponde con", "tokens": [51304, 12585, 10368, 419, 533, 4181, 257, 24423, 368, 4166, 78, 13, 7616, 7910, 8057, 4166, 78, 369, 6805, 68, 416, 51522], "temperature": 0.0, "avg_logprob": -0.20899765193462372, "compression_ratio": 1.796, "no_speech_prob": 0.04422525689005852}, {"id": 706, "seek": 376256, "start": 3762.56, "end": 3770.32, "text": " cual otro en el otro idioma, pero no anivel de oraciones y mucho menos anivel de palabras.", "tokens": [50364, 10911, 11921, 465, 806, 11921, 18014, 6440, 11, 4768, 572, 364, 592, 338, 368, 420, 9188, 288, 9824, 8902, 364, 592, 338, 368, 35240, 13, 50752], "temperature": 0.0, "avg_logprob": -0.26249029976981025, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.04191821068525314}, {"id": 707, "seek": 376256, "start": 3770.32, "end": 3776.24, "text": " Pero bueno, partiendo de un corpus alineado a nivel de documentos, yo puedo llegar a construir", "tokens": [50752, 9377, 11974, 11, 644, 7304, 368, 517, 1181, 31624, 419, 533, 1573, 257, 24423, 368, 4166, 329, 11, 5290, 21612, 24892, 257, 38445, 51048], "temperature": 0.0, "avg_logprob": -0.26249029976981025, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.04191821068525314}, {"id": 708, "seek": 376256, "start": 3776.24, "end": 3780.96, "text": " me, por lo menos, una alineaci\u00f3n a nivel de oraciones, siendo un proceso relativamente", "tokens": [51048, 385, 11, 1515, 450, 8902, 11, 2002, 419, 533, 3482, 257, 24423, 368, 420, 9188, 11, 31423, 517, 29314, 21960, 3439, 51284], "temperature": 0.0, "avg_logprob": -0.26249029976981025, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.04191821068525314}, {"id": 709, "seek": 376256, "start": 3780.96, "end": 3790.12, "text": " sencillo. Esto se conoce como el algoritmo de que \u00e9l y Church, que es un algoritmo relativamente", "tokens": [51284, 46749, 78, 13, 20880, 369, 33029, 384, 2617, 806, 3501, 50017, 3280, 368, 631, 11810, 288, 7882, 11, 631, 785, 517, 3501, 50017, 3280, 21960, 3439, 51742], "temperature": 0.0, "avg_logprob": -0.26249029976981025, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.04191821068525314}, {"id": 710, "seek": 379012, "start": 3790.12, "end": 3796.88, "text": " f\u00e1cil para alinear corpus, o sea, para pasar corpus que est\u00e1n alineados a nivel de documento,", "tokens": [50364, 17474, 1690, 419, 533, 289, 1181, 31624, 11, 277, 4158, 11, 1690, 25344, 1181, 31624, 631, 10368, 419, 533, 4181, 257, 24423, 368, 4166, 78, 11, 50702], "temperature": 0.0, "avg_logprob": -0.23660119974388266, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.03476536646485329}, {"id": 711, "seek": 379012, "start": 3796.88, "end": 3802.68, "text": " pasarlos a que est\u00e9n alineados a nivel de oraci\u00f3n. Y bueno, esto es un algoritmo que funciona,", "tokens": [50702, 1736, 39734, 257, 631, 871, 3516, 419, 533, 4181, 257, 24423, 368, 420, 3482, 13, 398, 11974, 11, 7433, 785, 517, 3501, 50017, 3280, 631, 26210, 11, 50992], "temperature": 0.0, "avg_logprob": -0.23660119974388266, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.03476536646485329}, {"id": 712, "seek": 379012, "start": 3802.68, "end": 3806.74, "text": " est\u00e1 un poco basado en lo que era el algoritmo de distancia de edici\u00f3n del EventTime, que", "tokens": [50992, 3192, 517, 10639, 987, 1573, 465, 450, 631, 4249, 806, 3501, 50017, 3280, 368, 1483, 22862, 368, 1257, 15534, 1103, 13222, 22233, 11, 631, 51195], "temperature": 0.0, "avg_logprob": -0.23660119974388266, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.03476536646485329}, {"id": 713, "seek": 379012, "start": 3806.74, "end": 3816.2, "text": " vimos hace bastante tiempo en el curso. Bueno, es como muy parecido, tambi\u00e9n es un", "tokens": [51195, 49266, 10032, 14651, 11772, 465, 806, 31085, 13, 16046, 11, 785, 2617, 5323, 7448, 17994, 11, 6407, 785, 517, 51668], "temperature": 0.0, "avg_logprob": -0.23660119974388266, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.03476536646485329}, {"id": 714, "seek": 381620, "start": 3816.2, "end": 3820.9199999999996, "text": " algoritmo de pronomaci\u00f3n din\u00e1mica, similar a ese. Funciona de la siguiente manera, o", "tokens": [50364, 3501, 50017, 3280, 368, 7569, 298, 3482, 3791, 19524, 2262, 11, 2531, 257, 10167, 13, 11166, 10015, 64, 368, 635, 25666, 13913, 11, 277, 50600], "temperature": 0.0, "avg_logprob": -0.24623002551850817, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.1148994117975235}, {"id": 715, "seek": 381620, "start": 3820.9199999999996, "end": 3825.2799999999997, "text": " sea, no vamos a dar lo mucho en detalle, pero vamos a dar una idea de c\u00f3mo que funcione.", "tokens": [50600, 4158, 11, 572, 5295, 257, 4072, 450, 9824, 465, 1141, 11780, 11, 4768, 5295, 257, 4072, 2002, 1558, 368, 12826, 631, 1019, 66, 5328, 13, 50818], "temperature": 0.0, "avg_logprob": -0.24623002551850817, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.1148994117975235}, {"id": 716, "seek": 381620, "start": 3825.2799999999997, "end": 3829.8799999999997, "text": " En el algoritmo de Gayley Church dice, yo voy a tener un conjunto de oraciones en un idioma", "tokens": [50818, 2193, 806, 3501, 50017, 3280, 368, 23081, 3420, 7882, 10313, 11, 5290, 7552, 257, 11640, 517, 37776, 368, 420, 9188, 465, 517, 18014, 6440, 51048], "temperature": 0.0, "avg_logprob": -0.24623002551850817, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.1148994117975235}, {"id": 717, "seek": 381620, "start": 3829.8799999999997, "end": 3841.3199999999997, "text": " y otro conjunto de oraciones en el otro idioma. Entonces, considero que un traductor para", "tokens": [51048, 288, 11921, 37776, 368, 420, 9188, 465, 806, 11921, 18014, 6440, 13, 15097, 11, 1949, 78, 631, 517, 2479, 84, 1672, 1690, 51620], "temperature": 0.0, "avg_logprob": -0.24623002551850817, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.1148994117975235}, {"id": 718, "seek": 384132, "start": 3841.32, "end": 3846.56, "text": " cada oraci\u00f3n pudo haber tenido tres opciones, digamos, para pasarlas al otro idioma.", "tokens": [50364, 8411, 420, 3482, 280, 6207, 15811, 33104, 15890, 999, 23469, 11, 36430, 11, 1690, 1736, 6843, 296, 419, 11921, 18014, 6440, 13, 50626], "temperature": 0.0, "avg_logprob": -0.2500436176625333, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.07064522057771683}, {"id": 719, "seek": 384132, "start": 3846.56, "end": 3851.1600000000003, "text": " Un traductor, suponga un traductor humano, agarr\u00f3 oraciones que estaban en espa\u00f1ol y", "tokens": [50626, 1156, 2479, 84, 1672, 11, 9331, 556, 64, 517, 2479, 84, 1672, 30985, 11, 623, 2284, 812, 420, 9188, 631, 36713, 465, 31177, 288, 50856], "temperature": 0.0, "avg_logprob": -0.2500436176625333, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.07064522057771683}, {"id": 720, "seek": 384132, "start": 3851.1600000000003, "end": 3856.84, "text": " oraciones que estaban en franc\u00e9s. O sea, no ponerles EIF porque lo que puede confundir", "tokens": [50856, 420, 9188, 631, 36713, 465, 30514, 2191, 13, 422, 4158, 11, 572, 19149, 904, 462, 12775, 4021, 450, 631, 8919, 1497, 997, 347, 51140], "temperature": 0.0, "avg_logprob": -0.2500436176625333, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.07064522057771683}, {"id": 721, "seek": 384132, "start": 3856.84, "end": 3861.36, "text": " con las otras cosas, as\u00ed que vamos a decir el lenguaje de origen era F, franc\u00e9s y el", "tokens": [51140, 416, 2439, 20244, 12218, 11, 8582, 631, 5295, 257, 10235, 806, 35044, 84, 11153, 368, 2349, 268, 4249, 479, 11, 30514, 2191, 288, 806, 51366], "temperature": 0.0, "avg_logprob": -0.2500436176625333, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.07064522057771683}, {"id": 722, "seek": 384132, "start": 3861.36, "end": 3867.7200000000003, "text": " lenguaje de estino era espa\u00f1ol. Bien, entonces, un traductor humano cada vez que se enfrentaba", "tokens": [51366, 35044, 84, 11153, 368, 871, 2982, 4249, 31177, 13, 16956, 11, 13003, 11, 517, 2479, 84, 1672, 30985, 8411, 5715, 631, 369, 33771, 5509, 51684], "temperature": 0.0, "avg_logprob": -0.2500436176625333, "compression_ratio": 1.6908396946564885, "no_speech_prob": 0.07064522057771683}, {"id": 723, "seek": 386772, "start": 3867.72, "end": 3872.8799999999997, "text": " una oraci\u00f3n ten\u00eda tres posibilidades. O bien, traduc\u00eda una oraci\u00f3n por otra oraci\u00f3n,", "tokens": [50364, 2002, 420, 3482, 23718, 15890, 1366, 11607, 10284, 13, 422, 3610, 11, 2479, 1311, 2686, 2002, 420, 3482, 1515, 13623, 420, 3482, 11, 50622], "temperature": 0.0, "avg_logprob": -0.20435737073421478, "compression_ratio": 1.8638297872340426, "no_speech_prob": 0.0063890861347317696}, {"id": 724, "seek": 386772, "start": 3872.8799999999997, "end": 3879.9599999999996, "text": " o bien parte de esta oraci\u00f3n en dos y traduce una oraci\u00f3n por dos, o bien borra esta oraci\u00f3n,", "tokens": [50622, 277, 3610, 6975, 368, 5283, 420, 3482, 465, 4491, 288, 2479, 4176, 2002, 420, 3482, 1515, 4491, 11, 277, 3610, 14828, 424, 5283, 420, 3482, 11, 50976], "temperature": 0.0, "avg_logprob": -0.20435737073421478, "compression_ratio": 1.8638297872340426, "no_speech_prob": 0.0063890861347317696}, {"id": 725, "seek": 386772, "start": 3879.9599999999996, "end": 3884.0, "text": " decide que no es tan importante y abarra y borra la oraci\u00f3n. Entonces, las tres operaciones", "tokens": [50976, 4536, 631, 572, 785, 7603, 9416, 288, 410, 289, 424, 288, 14828, 424, 635, 420, 3482, 13, 15097, 11, 2439, 15890, 2208, 9188, 51178], "temperature": 0.0, "avg_logprob": -0.20435737073421478, "compression_ratio": 1.8638297872340426, "no_speech_prob": 0.0063890861347317696}, {"id": 726, "seek": 386772, "start": 3884.0, "end": 3888.56, "text": " que se hacen a nivel de oraci\u00f3n son la de transformarla en cero, una o dos oraciones", "tokens": [51178, 631, 369, 27434, 257, 24423, 368, 420, 3482, 1872, 635, 368, 4088, 34148, 465, 269, 2032, 11, 2002, 277, 4491, 420, 9188, 51406], "temperature": 0.0, "avg_logprob": -0.20435737073421478, "compression_ratio": 1.8638297872340426, "no_speech_prob": 0.0063890861347317696}, {"id": 727, "seek": 386772, "start": 3888.56, "end": 3897.68, "text": " del otro lado. Eso es una cosa. Lo otro es, el costo relativo de alinear", "tokens": [51406, 1103, 11921, 11631, 13, 27795, 785, 2002, 10163, 13, 6130, 11921, 785, 11, 806, 2063, 78, 1039, 18586, 368, 419, 533, 289, 51862], "temperature": 0.0, "avg_logprob": -0.20435737073421478, "compression_ratio": 1.8638297872340426, "no_speech_prob": 0.0063890861347317696}, {"id": 728, "seek": 389768, "start": 3897.68, "end": 3902.2799999999997, "text": " estas dos oraciones depende del largo relativo de las oraciones. Entonces, si yo tengo dos", "tokens": [50364, 13897, 4491, 420, 9188, 47091, 1103, 31245, 1039, 18586, 368, 2439, 420, 9188, 13, 15097, 11, 1511, 5290, 13989, 4491, 50594], "temperature": 0.0, "avg_logprob": -0.1959007808140346, "compression_ratio": 2.107981220657277, "no_speech_prob": 0.028353985399007797}, {"id": 729, "seek": 389768, "start": 3902.2799999999997, "end": 3908.04, "text": " oraciones que tienen un largo muy parecido, le voy a dar un costo menor para alinearlos,", "tokens": [50594, 420, 9188, 631, 12536, 517, 31245, 5323, 7448, 17994, 11, 476, 7552, 257, 4072, 517, 2063, 78, 26343, 1690, 419, 533, 39734, 11, 50882], "temperature": 0.0, "avg_logprob": -0.1959007808140346, "compression_ratio": 2.107981220657277, "no_speech_prob": 0.028353985399007797}, {"id": 730, "seek": 389768, "start": 3908.04, "end": 3913.2, "text": " era menor o mayor. S\u00ed, menor. Si tiene un largo muy parecido, le voy a dar un valor menor", "tokens": [50882, 4249, 26343, 277, 10120, 13, 12375, 11, 26343, 13, 4909, 7066, 517, 31245, 5323, 7448, 17994, 11, 476, 7552, 257, 4072, 517, 15367, 26343, 51140], "temperature": 0.0, "avg_logprob": -0.1959007808140346, "compression_ratio": 2.107981220657277, "no_speech_prob": 0.028353985399007797}, {"id": 731, "seek": 389768, "start": 3913.2, "end": 3917.24, "text": " para alinear. Si tiene un largo muy distinto, una es muy corta y la otra muy larga, entonces", "tokens": [51140, 1690, 419, 533, 289, 13, 4909, 7066, 517, 31245, 5323, 1483, 17246, 11, 2002, 785, 5323, 11278, 64, 288, 635, 13623, 5323, 1613, 3680, 11, 13003, 51342], "temperature": 0.0, "avg_logprob": -0.1959007808140346, "compression_ratio": 2.107981220657277, "no_speech_prob": 0.028353985399007797}, {"id": 732, "seek": 389768, "start": 3917.24, "end": 3923.52, "text": " le voy a dar un valor mayor para alinear. Entonces, lo que ellos hacen es pensando en", "tokens": [51342, 476, 7552, 257, 4072, 517, 15367, 10120, 1690, 419, 533, 289, 13, 15097, 11, 450, 631, 16353, 27434, 785, 34525, 465, 51656], "temperature": 0.0, "avg_logprob": -0.1959007808140346, "compression_ratio": 2.107981220657277, "no_speech_prob": 0.028353985399007797}, {"id": 733, "seek": 392352, "start": 3923.52, "end": 3927.6, "text": " todo este tipo de operaciones que hay, todas las combinaciones de operaciones posibles,", "tokens": [50364, 5149, 4065, 9746, 368, 2208, 9188, 631, 4842, 11, 10906, 2439, 38514, 9188, 368, 2208, 9188, 1366, 14428, 11, 50568], "temperature": 0.0, "avg_logprob": -0.20078022249283328, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.05769328773021698}, {"id": 734, "seek": 392352, "start": 3927.6, "end": 3936.56, "text": " o sea, partir esta oraci\u00f3n en dos o no partirla o eliminarla o dejarla como est\u00e1. Entonces,", "tokens": [50568, 277, 4158, 11, 13906, 5283, 420, 3482, 465, 4491, 277, 572, 13906, 875, 277, 7892, 34148, 277, 24391, 875, 2617, 3192, 13, 15097, 11, 51016], "temperature": 0.0, "avg_logprob": -0.20078022249283328, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.05769328773021698}, {"id": 735, "seek": 392352, "start": 3936.56, "end": 3941.34, "text": " con programaci\u00f3n din\u00e1mica, ven todas las posibilidades de operar distinto para llegar", "tokens": [51016, 416, 1461, 3482, 3791, 19524, 2262, 11, 6138, 10906, 2439, 1366, 11607, 10284, 368, 2208, 289, 1483, 17246, 1690, 24892, 51255], "temperature": 0.0, "avg_logprob": -0.20078022249283328, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.05769328773021698}, {"id": 736, "seek": 392352, "start": 3941.34, "end": 3946.08, "text": " al otro lado y calculan las que le da un costo menor. O sea, para cada una de las posibilidades", "tokens": [51255, 419, 11921, 11631, 288, 4322, 282, 2439, 631, 476, 1120, 517, 2063, 78, 26343, 13, 422, 4158, 11, 1690, 8411, 2002, 368, 2439, 1366, 11607, 10284, 51492], "temperature": 0.0, "avg_logprob": -0.20078022249283328, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.05769328773021698}, {"id": 737, "seek": 392352, "start": 3946.08, "end": 3952.68, "text": " calculan cu\u00e1l es el costo de cada par de oraciones suman todos los costos del documento.", "tokens": [51492, 4322, 282, 44318, 785, 806, 2063, 78, 368, 8411, 971, 368, 420, 9188, 2408, 282, 6321, 1750, 2063, 329, 1103, 4166, 78, 13, 51822], "temperature": 0.0, "avg_logprob": -0.20078022249283328, "compression_ratio": 1.8273092369477912, "no_speech_prob": 0.05769328773021698}, {"id": 738, "seek": 395268, "start": 3953.2799999999997, "end": 3958.72, "text": " Y se quedan con el caso que les d\u00e9 un costo menor en alineaci\u00f3n. Eso se puede hacer", "tokens": [50394, 398, 369, 13617, 282, 416, 806, 9666, 631, 1512, 2795, 517, 2063, 78, 26343, 465, 419, 533, 3482, 13, 27795, 369, 8919, 6720, 50666], "temperature": 0.0, "avg_logprob": -0.3333634296095515, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.01276328507810831}, {"id": 739, "seek": 395268, "start": 3958.72, "end": 3964.3599999999997, "text": " eficientemente, usando programaci\u00f3n din\u00e1mica lo mismo que hac\u00edamos con la distancia de edici\u00f3n", "tokens": [50666, 49510, 1196, 16288, 11, 29798, 1461, 3482, 3791, 19524, 2262, 450, 12461, 631, 46093, 16275, 416, 635, 1483, 22862, 368, 1257, 15534, 50948], "temperature": 0.0, "avg_logprob": -0.3333634296095515, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.01276328507810831}, {"id": 740, "seek": 395268, "start": 3964.3599999999997, "end": 3964.9199999999996, "text": " de Leberstein.", "tokens": [50948, 368, 1456, 607, 9089, 13, 50976], "temperature": 0.0, "avg_logprob": -0.3333634296095515, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.01276328507810831}, {"id": 741, "seek": 395268, "start": 3973.9199999999996, "end": 3980.3999999999996, "text": " Bueno, y este algoritmo que es relativamente sencillo, digamos, es una soluci\u00f3n bastante simple,", "tokens": [51426, 16046, 11, 288, 4065, 3501, 50017, 3280, 631, 785, 21960, 3439, 46749, 78, 11, 36430, 11, 785, 2002, 24807, 5687, 14651, 2199, 11, 51750], "temperature": 0.0, "avg_logprob": -0.3333634296095515, "compression_ratio": 1.4776119402985075, "no_speech_prob": 0.01276328507810831}, {"id": 742, "seek": 398040, "start": 3980.84, "end": 3986.0, "text": " logra una tasa de error muy buena, que es de un 4%, digamos, que, sobre todo, parede", "tokens": [50386, 3565, 424, 2002, 8023, 64, 368, 6713, 5323, 25710, 11, 631, 785, 368, 517, 1017, 4, 11, 36430, 11, 631, 11, 5473, 5149, 11, 7448, 1479, 50644], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 743, "seek": 398040, "start": 3986.0, "end": 3990.64, "text": " m\u00e1s relacionado, parede m\u00e1s que se parecen como el ingl\u00e9s y el espa\u00f1ol, etc\u00e9tera, logra", "tokens": [50644, 3573, 27189, 1573, 11, 7448, 1479, 3573, 631, 369, 7448, 13037, 2617, 806, 49766, 288, 806, 31177, 11, 5183, 526, 23833, 11, 3565, 424, 50876], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 744, "seek": 398040, "start": 3990.64, "end": 3994.04, "text": " una tasa bastante baja de error de un 4%, hay algunas mejoras que se pueden hacer, pero", "tokens": [50876, 2002, 8023, 64, 14651, 49427, 368, 6713, 368, 517, 1017, 8923, 4842, 27316, 11479, 296, 631, 369, 14714, 6720, 11, 4768, 51046], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 745, "seek": 398040, "start": 3994.04, "end": 4000.64, "text": " en realidad hay un 4% de algo que est\u00e1 bastante bien. Hay un catch que es que para sistemas", "tokens": [51046, 465, 25635, 4842, 517, 1017, 4, 368, 8655, 631, 3192, 14651, 3610, 13, 8721, 517, 3745, 631, 785, 631, 1690, 48720, 51376], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 746, "seek": 398040, "start": 4000.64, "end": 4004.4, "text": " de traducci\u00f3n distintos, traducciones no literales, esto se rompe un poco, por ejemplo,", "tokens": [51376, 368, 2479, 1311, 5687, 49337, 11, 2479, 1311, 23469, 572, 2733, 4229, 11, 7433, 369, 7438, 494, 517, 10639, 11, 1515, 13358, 11, 51564], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 747, "seek": 398040, "start": 4004.4, "end": 4008.96, "text": " para traducir entre ingl\u00e9s y chino, que en chino ni siquiera est\u00e1 claro que les son los l\u00edmites", "tokens": [51564, 1690, 2479, 1311, 347, 3962, 49766, 288, 417, 2982, 11, 631, 465, 417, 2982, 3867, 1511, 35134, 3192, 16742, 631, 1512, 1872, 1750, 287, 14569, 3324, 51792], "temperature": 0.0, "avg_logprob": -0.2656009551017515, "compression_ratio": 1.8079470198675496, "no_speech_prob": 0.08022186905145645}, {"id": 748, "seek": 400896, "start": 4008.96, "end": 4012.68, "text": " de las palabras, eso es m\u00e1s dif\u00edcil de ver. Entonces, bueno, este tipo de algoritmos", "tokens": [50364, 368, 2439, 35240, 11, 7287, 785, 3573, 17258, 368, 1306, 13, 15097, 11, 11974, 11, 4065, 9746, 368, 3501, 50017, 3415, 50550], "temperature": 0.0, "avg_logprob": -0.2882911734385033, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.008442907594144344}, {"id": 749, "seek": 400896, "start": 4012.68, "end": 4016.28, "text": " no funcionan tambi\u00e9n, y bueno, hay variantes que funcionan un poco mejor.", "tokens": [50550, 572, 14186, 282, 6407, 11, 288, 11974, 11, 4842, 3034, 9327, 631, 14186, 282, 517, 10639, 11479, 13, 50730], "temperature": 0.0, "avg_logprob": -0.2882911734385033, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.008442907594144344}, {"id": 750, "seek": 400896, "start": 4016.28, "end": 4024.8, "text": " As\u00ed que bueno, hoy vamos a dejar por ac\u00e1 y vamos a continuar en la pr\u00f3xima con modelos", "tokens": [50730, 17419, 631, 11974, 11, 13775, 5295, 257, 24391, 1515, 23496, 288, 5295, 257, 29980, 465, 635, 24096, 416, 2316, 329, 51156], "temperature": 0.0, "avg_logprob": -0.2882911734385033, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.008442907594144344}, {"id": 751, "seek": 400896, "start": 4024.8, "end": 4025.36, "text": " de traducci\u00f3n.", "tokens": [51156, 368, 2479, 1311, 5687, 13, 51184], "temperature": 0.0, "avg_logprob": -0.2882911734385033, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.008442907594144344}], "language": "es"}