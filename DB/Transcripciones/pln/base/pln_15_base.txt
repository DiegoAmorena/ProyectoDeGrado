Bueno, bienvenidos. En la clase de hoy vamos a ver el tema de redes neuronales que, bueno,
es como digamos, el estado del arte, lo que son las cosas de procesamiento del lenguaje natural
en general hoy en día se rosuelen con redes neuronales. Entonces, es un poco para continuar
con lo que veíamos la vez pasada. Habíamos visto métodos de clasificación, habíamos
visto que había algunos para clasificar cosas en categorías, había algunos secuenciales,
había algunos que llamamos modelos del lenguaje y de los métodos de clasificación, en realidad,
vimos en profundidad, nadie valles, pero vimos que había otro, por ejemplo, algo de la decisión,
regresión logística, Supervector Machines y redes neuronales y para los métodos secuenciales
también aparecian las reneonales, para los modelos del lenguaje también aparecian las reneonales.
Entonces, como que las reneonales son un método muy importante que es muy versátil y se
usa para muchas cosas. Entonces, nos vamos a concentrar un poco, vamos a dar en esta clase una
introducción a lo que son las redes y además ver cómo se usan particularmente para el lenguaje.
O sea, vamos a hablar las técnicas de vectores de palabras y cómo aplicar eso a precisamente
el lenguaje natural. Entonces, ¿cómo empieza esto? Esto empieza inspirado en esto de acá, que es
una neurona biológica, esto lo habrán visto en el hiceo, en biología. Una neurona es un tipo de
célula del sistema nervioso de los animales. ¿Qué tiene distintas partes? ¿Cómo se puede ver ahí?
Sí, puedo apuntar, o puedo apuntar. ¿Aboquela con esto?
Hay, tiene distintas partes, tiene como unos pelitos que entran dentro del cuerpo de neuronas que se
llaman dendritas y después tiene como una especie de cola que sale de la neurona que se llama
acción y, bueno, acá en el centro tenemos lo que sería el cuerpo de la neurona, el soma. Entonces,
en esas por esas dendritas vienen impulsos eléctricos, las dendritas actúan como inhibidores o activadores,
pero vienen impulsos eléctricos, eso se condensan adentro del soma que sea el cuerpo y si se supera
cierto un bral de actividad eléctrica, entonces la neurona dispara un solo punto por el acción,
un solo impulso eléctrico por el acción, lo manda hacia afuera y ese acción está conectado a otras
dendritas que están en otras neuronas. Entonces, esto tiene un montón de entradas, se condensan en el
cuerpo de la célula, de la neurona, dispara un solo pulso eléctrico para afuera y ese pulso eléctrico
viaja a otras neuronas. Entonces, como esas neuronas están conectadas en una especie de red,
cada acción de una neuronas está conectada a las dendritas de otras, entonces la salida de una
es la entrada de otras. Esto conforma una red dentro del cerebro o el sistema nervioso de los animales
y eso es lo que componen una renauronal, en este caso una renauronal natural, una renauronal
biológica. Entonces, en los años 40 se propuso la primera versión matemática de cómo
funciona una neurona, entonces hubo unos científicos que dijieron, bueno, vamos a tratar de simplificar
esto más posible, a estar a verlo y generar una versión en una ecuación que trata de representar
esto. Entonces, ellos diseñaron esta ecuación de acá, en la cual yo dice, bueno, vamos a cambiar
esta neurona biológica que tenía todas estas partes y vamos a crear una especie de neuronar
artificial en la cual yo tengo un conjunto de entradas, un conjunto de pesos de entrada que están
acá, que vendrían a hacer el equivalente a las dendritas. Voy a tener impulso eléctrico de
entrada que son como X1, X2, X3 hasta Xn, que digamos que son los inputs que va a tener esa
neurona. Después, en el centro lo que hago es sumarlos y en realidad lo que estoy sumando es el
producto entre cada impulso de entrada y el peso correspondiente. También le voy a agregar un valor
de sesgo y después la salida le voy a pasar por una función de activación y eso me va a dar
la salida de la neurona. Bien, o sea, esta parte les vamos a estar viendo en detalle. Pero en
definitiva, es como que yo tuviera esta ecuación de abajo, ¿no? Yo tengo la sumatoria de las
entradas multiplicadas por pesos, a eso le subo un sesgo, que se llama B y todo eso se lo aplico
una función sigma que es un poco que son esas funciones sigma. Entonces ven que es una, digamos,
es como una ecuación lineal, ¿no? O sea, la sumatoria ni de XC por WB sub y más B,
todo eso es una, digamos, una fórmula lineal y a eso le agrego un sigma, digamos, se lo aplica un
sigma que esta va a ser una función lineal. Bien, entonces, más adelante para simplificar esta ecuación y
para que después queden más fáciles de calcular las cosas, lo que se hace es decir, bueno, este valor
que veníamos acá, esta B que está sumando, que digamos se usa para que, ahí, esta B que está acá,
que se usa para que, digamos, para poder completar toda la ecuación lineal, lo que se hace
agregarla como un peso más, entonces decimos, bueno, tenemos una entrada más que vale uno y su peso
correspondiente es el sesgo. De eso, en realidad, digamos, después nos olvidamos. Cuando vamos a
trabajar con estas cosas como que no utilizamos mucho el sesgo y nos concentramos en decir, bueno,
vamos a tener un vector que son entradas, que son los X1 hasta XN y un montón de pesos que son
los W1s WBN y adentro la neurona, lo que pasa es que voy a hacer el producto interro entre esos
entre el vector X y el vector W y se lo voy a pasar a la función sigma. Bien, entonces,
esas funciones de activación sigma hay varias, o sea, al principio, digamos, cuando diseñaron
primero esta neurona, lo que se les había ocurrido primero era decir, bueno, yo lo que hago es sumar
todas estas, digamos, todos estos impulsos multiplicados por los pesos, lo sumo y si esa suma supera
cierto umbral, que el umbral lo podrían calcular o mucho que se ha utilizado en uno o en una de esas
cosas, bueno, si supera cierto umbral, entonces mando uno para fuera y si no mando ser. Eso era lo primero
que se le había ocurrido, pero bueno, después empezaron a encontrar otras funciones que eran mejores
para poder entrenar mejores arredes y en definitiva, como que no hay mucho criterio de qué restricciones
que tiene que tener esa función, salvo que tiene que ser derivable, tiene que ser, tiene que ir como
de menos a más, digamos, puede ser de 0 a 1 o de 0 más infinito o de menos infinito más infinito y
tiene que ser no lineal, tiene que tener algún punto de no linealidad. Entonces, estas son algunas muy
usadas, por ejemplo, la función sigma o id o función logística, que es la misma que se usa,
lo que estamos hablando de un rato, digamos, el método de regresión logística utiliza también esta
función, la tangente parólica es otra, la función relu es muy usada y la relu se define como el
máximo entre 0 y 0, relu de 0 es el máximo entre 0 y 0, entonces vale 0 para todos los valores,
excepto para cuando todos los valores menores que 0, pero cuando vale el mayor que 0, vale directamente
el valor. Estas son unas funciones un poco estaña, pues yo les dije que tenían que hacer todas
derivables y esta justo no es derivable en el punto 0, pero después es derivable en todo el
resto de los reales. Bueno, ya hay otras más, pero estas como son como de las más utilizadas.
Bien, lo importante acá es que estas funciones de activación provenan una no linealidad y vamos a
ver, ¿por qué? Ok, bueno, entonces vimos lo que era una neurona, imagínense que en general las
neuronas se ponen como en grupos, digamos, y se distribuyen en capas dentro de una red, ¿no?
Entonces, este es un ejemplo de una de las redes neuronales más simples, más simples que en
realidad son útiles para algo, que se conoce como Perceptron Multi-Capa o Redfield Forward Multi-Capa,
que funcione de la siguiente manera, ¿no? Nosotros tenemos todas las entradas, esas que yo les decía
que la centrada es X1, X2, X3, etcétera, este Xn, sería como una primera capa de entrada y después
yo ubico un montón de neuronas en una segunda capa y las capas que vienen después de la entrada le
voy a llamar capas ocultas, o sea, tengo una primera capa de entrada, esa capa lleva a una capa oculta y
todas las neuronas de la capa oculta están interconectadas con todas las neuronas de la capa de entrada,
o sea, hay pesos que van de todas a todas, después puedo tener otra segunda capa oculta, otra tercera capa
oculta, etcétera, hasta que llevo a una última capa que también está interconectada con la anterior,
que es la capa de salida, bien, pero no hay enlaces que vayan entre la capa inicial y la capa de salida,
digamos, la capa de entrada y la capa de salida, sino que siempre los enlaces van entre una capa y la siguiente,
entonces acá yo digo que tengo una arquitectura en capas donde tengo este, en según esta imagen K,
capas ocultas, tengo la capa oculta 1, capa oculta 2, capa oculta K y después una capa de salida,
bien, entonces esta es como la arquitectura más sencilla, yo tengo un montón de capas, una atrás de
otra y cada capa está completamente interconectada con la anterior, pero nunca saltan entre capas,
bien, entonces analicemos un poco que es lo que pasa dentro de esas capas y para eso vamos a
tratar de mirar la capa, bien, yo tengo entonces en esa imagen es como estamos viendo la frontera
entre una capa y la siguiente, yo tengo la frontera de la capa W1, la capa y y la capa y más 1,
entonces voy a decir que los estados de las neuronas en la capa y que llegan a la capa y son
X1 superí, X2 superí, X3 superí, X4 superí, bien, eso va a ser el estado de la capa y y
quiero calcular cuál va a ser el valor de la capa y más 1 dado que el valor de la capa y era eso,
entonces la capa y yo tenía que valía esto, X1 superí, X2 superí, X3 superí y creo que
llegamos a 4, esta, X4 super, esto es un vector, bien, entonces recuerden como calculábamos
el valor de una neurona, decíamos que por ejemplo para calcular la neurona que está
y arriba que es X1 y más 1 el valor de esta neurona se calculaba como y tenía que hacer las
sumas digamos de los inputs que está donde la de izquierdo por los pesos que llegaban hasta ahí,
entonces en este caso son todas las neuronas que están en la capa y, todos los valores de la
neuronas multiplicados por todos los valores de las flechitas, entonces sería X1 superí por
W y la flechita que está yendo desde la neurona 1 de la capa y hasta la neurona 1 de la capa y
más 1 se llama W1, entonces X1 por W1, más la segunda capa, perdón la segunda neurona de la
capa y por el segundo peso, este era el 2, 1, el peso 2, 1, esto también es de la capa y
más X3 por W3, uno, todo esto es de la capa y, más X4 por W4, uno, bien, entonces la salida
X sub 1 de la capa y más 1 es el producto de todas estas acá, bien, es el producto de la neurona 1 de la
capa anterior por el peso 1, la neurona 2 de la capa anterior por el peso 2, 1, la neurona 3 de la
capa anterior por el peso 3, 1, lo mismo puedo hacer para la otra, puedo decir X2 y sería igual
solo que cambiando acá cambiando los lugares a 2, entonces yo es X1 y por W1, 2 y, más 2
estos, más X4 y por W4, 2 y, bien, sí, decimos, ahí está, cuando estamos en una arquitectura en
capas como ésta es así, cada de todas las neuronas de la capa siguiente están conectadas con
la anterior, pero nunca saltan de capas, nunca cruzan hacia otra, y nunca vuelen hacia atrás,
que es otra cosa que puede pasar en otras arquitecturas de redes, pero esta que es la más
simple es cada capa con la siguiente, bueno, entonces X3 sería lo mismo, X1 y acá el peso 1, 3,
tanda tata, X4, el peso 4, 3, sí, la dimensión es de ahí, los X son vectores de la carrera o de
vez con reales, sí, o sea, no, acá son todos reales, X, todos los X y todos los doles son
todos valores reales, entonces eso quería llegar, yo tengo, X1, X2, X3, X4 son 4 valores reales
que componen un vector, y si yo agarro todos los doles 1, 1, 2, 1, doles 3, 1, doles 4, 1,
doles 1, doles 2, etcétera, esto compone una matriz, en realidad, yo puedo construirme la
matriz de la capa Y, es igual esta matriz que tiene dole 1, 1, hasta dole 4, 3, bien,
W, 1, 3, W, 4, 1, bien, esto es una matriz, entonces al tener eso, en realidad yo puedo expresar la
salida de esta capa, puedo expresar los estados en los cuales digamos los valores en los que quedan
las neuronas de la capa siguiente, los puedo expresar como un producto de matrices, yo digo,
el vector en la capa Y era esto, entonces el vector en la capa Y más 1 va a ser el producto de
XC por WI, digamos esto termina siendo un producto de matrices, si hace el producto de matrices
me daría X1 por W1, X2 por W1, X3 por W3, 1, X4 por W1, que es lo mismo que esté
acá, y si vamos con la segunda columna, me da el mismo de acá, y si vamos con la
tercera columna, me da el mismo de acá, pero es en definitiva la salida de esta capa,
digamos si yo tengo esa neuron ahí, la salida de la capa, a ver dónde les creo,
les pido acá porque esto nos va a tener que quedar para después para poder mirarlo,
pero bueno, tengo X subraí, este es el vector de entrada, y voy a poner acá copiar la matriz
esta, W1 1 hasta W4 1, W4 3, W1 3, la matriz, entonces, digo que el valor de X
y más 1 va a ser el valor en Y por la matriz que representa los pesos de la capa Y,
y a esto lo que me falta agregarle es el sigma, que es la función de activación y el
sigma también puede pertenecer a la capa y digamos yo puedo tener distintas funciones de activación
por capa, bien, entonces, concentremos en esto, decimos que si yo tengo una arquitectura en capa,
donde cada capa está conectada con la anterior, digamos todas las neuronas una capa están conectadas
con todas las neuronas de la anterior, entonces, puedo calcular la activación o los valores que
va a tener la capa Y más 1 en función de la capa Y con esta formula acá, así que supongamos que
tengo, eso creo que es exactamente lo mismo que dice acá, ahí está, tengo esa entrada,
la salida va a ser ese vector, digamos, de tres neuronas y tengo esos pesos,
por lo tanto puedo calcularlo de esta manera, bien, entonces supongamos que tengo una arquitectura
que tiene tres capas, o más, digamos, tiene dos capas ocultas, entonces eso significa que si
tengo dos capas ocultas voy a tener una matriz de pesos, que le voy a llamar W1 y una
matriz de peso que le voy a llamar W2, entonces me va a venir un vector X que va a ser un vector que
tiene un montón de trabajo, X1 hasta Xn, esto es un vector, quiero ver cuál va a ser la salida
de la red suponiendo que tengo una capa de pesos W1 con una función de activación sigma 1 y
una capa de pesos W2 con una función de activación sigma 2, cómo me quedaría la salida de la red,
digamos, de qué, cuál sería la fórmula para la salida de la red,
vamos a llamarle Rn de X a la salida de esta red que es una red que tiene dos capas ocultas y
tiene esa estructura, está estructura en capas, ¿qué les parece? Sí,
ahí está, X por del V1 y esto le aplicamos sigma 1,
y después esto multiplicamos por W2, ahí está, la hacemos W2 y le pasamos sigma 2,
exacto, bien, entonces eso sería, digamos, la ecuación que te queda de una arquitectura con
dos capas ocultas, y bueno, la salida se calcularía de esta manera, tenemos el vector X,
el vector X que le multiplicamos por los pesos de la capa 1, después le pasamos la función
de activación, a esa resultado le multiplicamos por los pesos de la capa 2 y le aplicamos la función
de activación y esa es la salida. Si tuvieramos más capas, si esto fuera un perceptro
multicapa de 30 capas, entonces tendríamos como más añadimiento en esto, pero más o menos
el camino. Bien, entonces ¿qué pasaría si estas funciones de activación fueran la función
identidad o fueran funciones lineales como multiplicar por 4 o algo del estilo, ¿qué
pasaría en ese caso? Ahí está, en ese caso, si esto fuera la identidad o si fuera multiplicado
por una constante, pero supongamos que fuera la función identidad, entonces acá esto
me daría lo mismo que hacer X por W1 por W2, que es lo mismo que hacer X por una cosa que
es un producto entre dos matrices y un producto entre dos matrices vea otra matriz, entonces
si estas funciones fueran una función identidad o fueran una función lineal o fueran una función
de esas, digamos, simples, entonces todo esto sería una ecuación lineal, o sea yo podría
reescribirlo siempre como el producto entre un vector y una matriz, que es un sistema
lineal. Bien, esa es la razón por la cual se necesita que estas cosas acasean no
lineales, que era lo que les decía que bueno, casi que el único requisito que tienen
es tener estas funciones de activación es que sean no lineales, porque si son lineales
cuando yo empiezo a arquitecturar estas cosas en capas, me queda simplemente un producto
de matrices, porque me interesa que sea no lineal y porque, o sea, me molesta que esto sea
un sistema lineal, porque si yo tengo un sistema lineal, digamos, si yo tengo que el
resultado de mi red lo puede expresar como X por una matriz, entonces bueno, hay cierta
clase de problemas, que voy a poder resolver, pero todos los problemas que son no lineales,
todos los problemas que no se pueden capturar por una estructura lineal, entonces no lo
puedo resolver. Bien, sí. Incluso sin la activación, o sea, es una reneural que no tiene
que ir a ninguna, o sea, simplemente es multiplicar un vector por un conjunto de pesos.
Bien, entonces, si yo tengo solamente una función lineal, hay un conjunto de problemas que
puedo modelar, es verdad, pero no son todos, y de hecho no lo vamos a ver, pero hay una
demostración que dice que teniendo funciones de activación no lineales, alcanza incluso
con tener una sola capa oculta y alguna cosita más para modelar cualquier tipo de función
que habiamos interese, digamos, con ciertas propiedades, por lo menos que se ha continuo
en siento intervalo, etcétera, pero asumiendo ciertas propiedades bastante normales, es
posible incluso con una sola capa, con una cantidad ruitada de neuronas, modelar cualquier
función posible. Y eso es un poco el poder que tiene las reneurales, en realidad, son
como suficientemente flexibles como para modelar cualquier cosa, cosa que cuando veíamos,
bueno, no hay valles, era un ejemplo que modelaba ciertos tipos de problemas, si miran
regresión logística, podemos modelarse de dos tipos de problemas, pero algunos no,
las reneurales en calidad son super flexibles y podemos modelar cualquier cosa.
Entonces, sabemos que, para casi cualquier función que aún no le interese modelar, existe
una reneural que podría llegar a cumplirla con suficienta nivel de precisión, que vamos
ahí, teoría y más que les muestran, sin embargo, encontrarla en la práctica no es tan fácil,
o sea, sabemos que existe una, la familia de la reneurales, hay alguna función que me
va a permitir hacer todo lo que quiera, pero bueno, de allá encontrarla no es tan sencillo,
pero bueno, por lo menos sabemos que existe. Igual, con estas cosas que tenemos, o sea,
sabiendo lo más que es arquitecturando en capas y teniendo la función de activación
no lineal en cada una, ya tenés un montón de funciones interesantes que pueden servir
para modelar muchas cosas. Bien, preguntas acá. Bueno, estas otras funciones de activación
interesante que se conoce como la función softmax, se utiliza para los problemas de
clasificación discretos, por ejemplo, hay que tener en el segundo obligatorio que, bueno,
es el problema de clasificar un tweet y lo quiero clasificar en si es positivo, negativo,
neutro o nada, no, tengo esas cuatro clases. Entonces, la función de activación softmax es
como una generalización de la función logística de la sigmoide, que se calcula de esta
manera, dice bueno, yo asumo que los pesos de salida, que son números reales, van a formar
una probabilidad, digamos, lo quiero transformar en una probabilidad, entonces lo calcula de
manera, digo que el valor para y su y su v es e a la y su v sobre la sumatoria de e a la
el resto. Esto solamente para que lo tengan en cuenta, es muy probable que si van a usar
rengebranales en la segunda tarea, tengan que utilizar al final una capa, que se llama
capas softmax, que es una capa que tiene una función de activación especial que sirve
para transformar las salidas en distribución de probabilidad.
Sí, y la mayor, si tiene una distribución de probabilidades, y bueno, la sociedad que
tiene probabilidad mayor, ahí tienes que tener una, sería como una logística independiente
por cada una. Entonces, si es mayor que cero, digo que es valido, si no, o sea, si
voy a decir que puedo tener más de un label a la vez, ahí tendrías que hacer otra
cosa. En softmax, va a intentar que sea una distribución de probabilidades, entonces
probablemente te queda una clase que gane y las demás sea mucho más bajitas.
Bien, bueno, entonces, recuerden que estamos siempre utilizando números, por ahora no hemos
visto nada del lenguaje, eso lo vamos a ver un poco más adelante, ahora son todos
números. En la entrada me vienen números reales, en los pesos tengo números reales,
hago multiplicaciones, le paso funciones de activación, etcétera, y me da otro vector
de números reales, o sea, la salida de esto va a ser un vector de números reales, tener
en cuenta que cada una de estas cosas van a tener sus dimensiones, yo voy a tener, acá
tenía una entrada que tenía cuatro vectores, para cuatro valores, una matriz que tenía
cuatro por tres, entonces al multiplicarlo me devuelve tres, si la siguiente capa es
de tres por ocho, entonces me va a volver ocho y así, o sea, los tamaños de las matrices,
o sea, los tamaños de las capas tienen que coincidir. Pero en definitiva son todos
vectores, ¿no? Por ahora, esto es un cálculo utilizando cálculo numérico vectorial.
Entonces, vamos a hablar un poco de cómo se entrenan estas redes, y vamos a pensar
de la siguiente manera, ¿cómo esto es un método de aprendizaje automático? Yo voy
a tener, como vimos en las clases anteriores, voy a tener un conjunto de entrenamiento,
un conjunto de desarrollo, un conjunto de test, entonces supongamos que yo tengo un
conjunto de entrenamiento que tiene en ejemplos, o sea, en ejemplos significa que voy
a tener en estos vectores y en salidas distintas, que les voy a llamar y, entonces, los vectores
de entrada son estos, los vectores de salidas son estos de acá, y yo tengo que tratar
de ver si la salida se parece al entrada. Entonces, supongamos que la salida es solamente
un valor, ¿no? O sea, para simplificar, vamos a asumir que la entrada de la red es
un vector de cualquier dimensión, y la salida solamente es un valor real, ¿no? Es posible,
¿no? O sea, lo que estoy haciendo es tener una red que tiene muchas capas, lo que sea,
en el final, todo se reduce a una sola salida un valor real, obviamente esto después
se extiende a más valores reales, pero bueno, supongamos que tenemos una sola, ¿no?
Entonces digo que tengo en instancias, o sea, en valores x v, este es mi conjunto de
entrenamiento, supongamos, o el conjunto en el que estoy tratando de medir cosas x v y
me dice que esto es x v, deberían corresponderse con diferentes valores de x v, ¿no?
Este es el conjunto de valores esperados, yo digo que para x v 1 tengo un y v 1, para
x v 2 tengo un y v 2, bien, por ahora son todos números reales, y además tengo que
yo tengo una red neuronal con ciertos pesos, que se la puedo aplicar a x v y con sus
matrices de pesos, entonces mi red neuronal me va a dar cierto valor y le voy a llamar
y subí techo, ¿cómo puedo saber si está bien lo que me da la red neuronal para x v o
no? De qué manera yo puedo llegar a medir si está bien o no, este valor que me dio.
Si, ahí está, o sea, mi salida, en mi conjunto yo decía, bueno, la salida tenía
haber sido y subí, y la salida de medio de la red es y subí techo, ¿cómo puedo saber
si ese está bien o mal? O sea, ¿qué medida me dice si está bien o mal?
Ahí está, lo puedo restar y digo bueno, ¿qué tanto se parecen estos dos? Si esto está
cerca de cero, es un valor muy chiquito, entonces yo puedo decir que estas dos cosas son iguales,
por lo tanto la red me está dando un resultado parecido al que yo esperaba, y si estos dos son
muy diferentes, entonces esto me va a dar un valor bastante alto, entonces yo tengo muchos de
estos, no tengo n ejemplos de este estilo, así que lo que voy a hacer es sumar todos estos,
de igual 1 hasta n, sumo todos los valores, tengo un problema acá que es que a veces yo puedo
le puedo ahorrar por mucho, a veces le puedo ahorrar por poco, pero a veces esto me va a dar
negativo, esto me va a dar positivo, entonces si yo lo sumo todos capaz que me da cero por casualidad,
entonces lo que hago es ponerlos acuadrado, para decir bueno, yo siempre voy a sumar valores
positivos, entonces si mi salida es distinta, el valor esperado siempre esto me va a dar un resultado
positivo, bien, entonces como estoy comparando n ejemplos, a esto lo voy a dividir entre n,
esto de acá me da una métrica condensada que me dice que tanto se equivoco mi red respecto a los
valores, a todos los valores esperados, y de hecho esta es una de las métricas posibles para
medir eso, esta es muy usada, se llama mce, minzcuerderor o error cuadratico medio y es una de las
métricas más conocidas, entonces esto es una métrica que me permite medir la discrepancia que
hay entre los valores esperados de una red acá era isu y, entre los valores esperados de una red y
los valores que la red dio con todos los pesos que tiene hasta el momento, recuerden que este
isu y se calculaba como el resultado de la red para exu y los pesos de red, entonces este tipo
de funciones que miden la diferencia entre los valores esperados y los valores que me dio la
red de verdad se llaman funciones de perdida, bien, o sea el nombre de perdida no se movien de donde
sale, pero se le fue, se le suele llamar funciones de perdida los functions y bueno es uno de los
conceptos que no tiene que aprender cuando aprende de redes neuronales, porque para entrenarlas yo
lo que tengo que hacer es elegir una los function apropiada para problemas, entonces estas de las
más comunes, el error cuadratico medio sirve mucho para problemas donde los valores resultados son
valores reales, no sirve tanto para cuando los valores esperados resultantes son por ejemplo una
distribución de probabilidades o una categoría en muchas como ese problema que tienen en el laboratorio,
para eso utiliza notas, por ejemplo la entropía cruzada o en particular una versión de entropía
cruzada que sirve para decir yo tengo un solo valor correcto de entre muchos que en el laboratorio
les pasa eso digamos que tengo un tweet y es positivo o en negativo o en neutro no puede ser más
de une, entonces para eso se usa la última, es una versión de la entropía cruzada para valores
categoricos, bien y existen unas cuantas más digamos, o sea pero en definitiva siempre tengo que
tener funciones de estilo como pasaba con la función de activación lo que se espera de una
función de perdias es que sea derivable y en el caso de las funciones de perdias lo que se
espera es que cuando la salida de la red se parece muchísimo a los valores esperados,
tiene que estar cercana a cero o tiene que ser un valor mínimo y cuando la salida de la red es
muy diferente tengo que ser un valor más grande, bien, ok entonces ¿por qué es que yo quiero
que todo esto sea derivable? ¿Por qué les parece? Sí, es exacto para minimizar el hecho de
que yo voy a hacer que esto sea derivable digamos que lo que está dentro o sea este es y su
techo y subí techo menos y subí y esto lo calculé con esto que está acá entonces esto
es una sobre n por la sumatoria de 1 esta n de una cosa que tenía la forma sigma de
sigma de sigma de x por w a la 1 por w2, no sé qué menos y subí al cuadrado, bien entonces acá
entonces yo tenía una cosa que era todo derivable y acá afuera tengo otra función que también es
derivable tanto de las funciones de activación como todos los resultados de la red nominal como
la función de perdias como todas estas cosas son todos derivables para que quiero eso porque
efectivamente voy a derivar digamos o sea la técnica se utiliza para entrenar estas cosas se
basa mucho en encontrar derivadas y vamos a dotar de ver por qué bien entonces para entrenar
una de estas redes recordemos que digamos para entrenar estas redes yo recordemos que tengo
conjunto de entrenamiento, un conjunto de desarrollo, un conjunto de test y me interesa tratar
de minimizar esto o sea yo tengo que la red se calcula como dependiendo de el valor de entrada
y el conjunto de pesos que tengo yo voy a multiplicar ese valor de entrada por una matriz y por
otra por la funcional activación etcétera hasta obtener un resultado pero entonces notar que
este valor está en función de la entrada que es que es que es subir y el conjunto de pesos
o leve, no acá yo tengo una función que es que están función de dos cosas estas son las
entradas de conjunto de entrenamiento o del conjunto que estoy mediendo y estos son los pesos que
yo le puedo dar a cada una de las capas entonces una cosa interesante es que yo puedo mirar
este problema desde el punto de vista de que estos valores los dejó fijos digo mi conjunto
de entrenamiento lo conozco entonces los valores están fijos y yo puedo ir cambiando los pesos
hasta encontrar el conjunto de pesos ideales que permita que los valores de entrenamiento multiplicados
por esos pesos me den la salía que yo quiero entonces ahí eso se transforma en un problema como
decían por ahí un problema de demonización, un problema de optimización en el cual lo que
voy a hacer es tomar esto como variable entonces yo lo que quiero encontrar es el argmin para la
familia posible de pesos de las distintas matrices lo leve de esta función acá que es uno sobre
n por sumatoria nn y subitecho menos y subí al cuadrado bien y voy a encontrar el argmin en
w o sea lo que está acá dentro que es rn de xc w le voy variando estos w hasta que hasta
encontrar el ideal bien entonces supongamos que tengo una función así no vamos a ver una función
bastante simple como para ver cómo funciona esto el entrenamiento de una red se da utilizando
una técnica de llama de senso por gradiente hay otras técnicas pero estas por lejos la más
utilizada de todas y la técnica de senso por gradiente funcione la ciente manera si yo tuviera una
función que va solamente en una dimensión y quiero minimizarla y arranco con un punto por acá
digo bueno mi peso inicial me dice que voy a terminar en este lado entonces yo puedo calcular
la derivada en ese lado y decir bueno para aquel lado voy bajando mi función de costo o sea
suponiendo que esta es la función de pérdida o función de costo puedo decir para aquel lado
voy bajando mi función de pérdida y dice bueno lo voy bajando si bajo por esta dimensión si
bajo por esta dirección entonces ahí le digo bueno baja un poquito por ahí y calculame otro
valor que va a estar acá y ahí devuelta voy a calcular la derivada y digo bueno en qué sentido
voy bajando y se voy bajando si voy para allá entonces ahí me encuentro tu valor que este
en esa dirección calculo de vuelta la derivada y así o sea yo puedo ir iterando de esta manera
hasta llegar a un mínimo bien eso me llama de senso por gradiente porque yo tengo quiero encontrar
el mínimo de una función supongamos que esta es mi función de pérdida y empecé teniendo este
valor calculo donde está la dirección en la cual puedo bajar más y voy moviéndome por ahí hasta
llegar al punto bajo esto es un caso ideal en el cual yo tengo una sola variable que estoy tratando
de encontrar en el caso real yo estoy minimizando digamos minimizando esta función respecto a
W que es una cosa que son muchas matrices con muchos pesos con muchas cosas y pueden llegar a
hacer miles de millones de pesos pero bueno en un caso ideal si yo estuviera solamente minimizando
una severía de esta manera cuando yo estoy minimizando millones de variables a la vez lo que pasa
es que esta superficie digamos lo que tengo acá no va a ser una curva tan linda sino que va a ser
una superficie rusa que tiene un montón de de de óptimos locales que no me van a servir pero
cuando yo hago este algoritmo lo que va a hacer es caerse en un óptimo local imagínense que si
esta curva tuviera esta forma entonces este algoritmo llegaría a un óptimo local por acá pero
se perdería el óptimo global que estaba por acá bien eso es algo que puede pasar entonces bueno
no se asusten que cuando uno entra en una rena uronal nunca va a estar seguro de que encontré el
óptimo posible de toda la red de todas las posibles sino que bueno tengo que conformarme con encontrar
una bastante buena probando varias veces bueno entonces decíamos esto sobre entrenamiento
el entrenamiento intenta encontrar los pesos que minimizan esta función de perdiado o sea la
combinación de matricios olv que hace que esta función sea lo menor posible la técnica se utiliza
el senso por gradiente que es lo que está mencionando acá se usa una cosa de llamas de senso por
dancias estocástico que se trata de agarrar cada punto yo agarró cada punto de entrada y
trato de hacer el senso por gradiente consiguiendo solamente ese punto y después agarró otro punto de
entrada y luego varias veces el problema que tiene eso es que es superlento o sea es como que tiene
buena propiedad de convergencia pero es superlento entonces lo que se hace es hacer de senso por gradiente
en lote o en batches que significa bueno en vez de tomar todo el conjunto de entrenamiento que
puede tener 100 mil millones de ejemplos tomo de a 120 o no sé 200 o elijo un batch que digo bueno
tomo este conjunto de ejemplos y hago de senso por ahí después tomo otro conjunto de
senso por la gente por ahí y hasta llegar a un óptimo bien los siguientes backpropagation entonces
yo les dije hasta ahora que todas las cosas tenían que ser derivables y el hecho de que sean
derivables implica que lo vamos a derivar en algún momento no vamos a hacer acá ninguna derivada
digamos porque en realidad los paquetes que se utilizan para trabajar con estas con estas cosas
en realidad son paquetes que permiten hacer derivación automática o sea toda la gracia de construir
redes neuronales utilizando ciertas librerías es que las librerías permiten definir todas estas
cosas como vectores y después ellos hacen las derivadas automáticamente calculan todo automáticamente
pero en definitiva la técnica que se usa para calcular se llama propiedad que implica que cuando
yo voy calculando los pesos de una red para los valores de una red yo digo el lo que tornen
lo multiplico por del V después le paso la función de activación lo multiplico por otra V
le paso la función de activación a medida que voy calculando eso voy dejando como todos los
valores intermedios esos valores se usan de atrás para adelante por el llamado propiedad
y son para calcular las derivadas porque en realidad todos los valores de sumas multiplicaciones
etcétera que yo fui dejando el medio se utilizan como que siempre calculan para después
calcular la derivada y el vaculopadillo es una técnica que me ayuda a hacer eso rápidamente
bien entonces esta es la pregunta que le decía hoy yo puedo encontrar la mejor función posible
puedo contar la mejor reneuronal que explique mi problema 100% bien la verdad que no porque en general
este proceso se cae en óptimos locales y este tipo de funciones que tienen miles de millones
de parámetros lo que pasa que tiene muchísimos últimos locales y bueno el entrenamiento se va a
caer siempre en un óptimo local lo que no hace para evitar eso de alguna manera es por ejemplo
entrenar varias veces una misma red diciendo bueno tengo una misma récola, los mismos parámetros
le entrenó muchas veces y veo cual cual le fue mejor de todos los entrenamientos esa es una de
las formas y el otro problema detiene es el sobre ajuste creo que no lo mencionamos en la
clase anterior sobre ajuste significa que las reneuronales tienen un problema que lo tienen
otro método de clasificación pero las reneuronales es en particular porque como que son muy
versátiles y es que se pueden aprender muy fácil todo el conjunto de entrenamiento yo puedo
entrenar una red que se aprenda muy bien en conjunto de entrenamiento y me diga sí para este X le
corresponde este I y anda bárbaro y el la función de los vea casi cero y sin embargo lo pruebo en
conjunto de test y le va horrible y eso es muy fácil porque como les decía como las reneuronales
pueden modelar cualquier tipo de función entonces es muy fácil que se aprendan todo el conjunto
de entrenamiento y después para el conjunto de tele vaya espantoso ese ese fenómeno se llama
sobre ajuste entonces bueno hay como distintas técnicas para tratar de evitarlo y que la red no
digamos no sea ajustes a los datos sino que se va a generalizar más etcétera bien entonces sí
es una pregunta interesante en realidad hay un conjunto de técnicas que sirven para decir yo
puedo entrenar una red con un conjunto de datos más amplio que capaz que no está el todo correcto y
después una vez que tengo una red de entrenada la entreno de vuelta con un conjunto más chico pero
que tiene mejor calidad y eso da mejor resultado que entrenarla directamente con el conjunto más chico
o con otro tipo de datos entonces de ahí hay variante es cierto que una red una vez que ya
conseguí los pesos de la red lo puedo seguir entrenando usando otros conjuntos y eso es valido
o sea se usa es una técnica que se usa y está buena porque da buenos resultados bien igual en
atare de ustedes no sé no sé si va a la pena hacerlo o sea probablemente si van a entrenar
reneurales lo hacen lo van con los datos que tienen no no creo que sean necesarios a mucha
cosa más pero sí tratar de ver un poco lo que vamos a ver ahora que hasta ahora vieron que
estamos viendo números reales o sea entra a un vector de números reales salían números reales
vectores de números reales sí sí sí sí sí se usan a veces en la práctica da mejor resultado
probar varias veces y o hacer una prueba digamos tipo grid search en el cual digo tengo tantos
parámetros y probar con todos o aleatoriamente probar asampliando distintos parámetros y entrenar es
cierto que también se usan meteorísticas evolutivos y algunas otras para tratar de optimizar la
red pero no sé en la práctica si es que dan tan buenos resultados o simplemente ir probando
con distintas combinaciones andando mejor bueno o general encontrar buenos resultados igual sí
sí sí sí bueno claro pero el problema es que la función de pérdida no va a tener un
óptimo global normalmente no va a tener porque la función de pérdida tiene esta cosa en el medio
no estoy minimizando una cosa que es algo no lineal y que tiene millones de parámetros y yo
puedo ir en la dirección de cualquiera de los millones de parámetros entonces por eso normalmente
digamos eso te genera una superficie super rubosa que tiene un montón de de su día así bajada por
todos lados y justo en boca la el óptimo global es muy difícil o sea nada te garantiza que puedas tener
el óptimo global claro sí sí pero acá queremos esplicitamente que la función de activación sea algo
que me deje la función complicada digamos si vos claro si claro si vos hace que la función
de activación sea tan simple que esto queda como una función convexa entonces pierde
capacidad de generalización la red por eso se dice también que esto es un problema de
optimización no convexa entonces en optimización convexa uno puede asegurar que siempre tenemos un
óptimo global y lo podríamos llegar a encontrar con alguna técnica pero esto es la minimización no
convexa la forma de la gráfica siempre va a tener subidas y bajadas en algún lado
bien más preguntas acá entonces pasemos a la parte del lenguaje bien decíamos hasta el momento
teníamos una reneuronal que a la cual le entraban valores reales y salían valores reales
pero nosotros en realidad nos interesa trabajar con texto nos interesa trabajar con palabras oraciones
documentos tweets en el caso del oriatorio y el problema de este que tenemos una red que le entra
valores reales no es un problema raro digamos un problema que le pasa a la mayoría de los métodos
de prenses automáticos y estuvieron mirando algo de regresión logística etcétera siempre yo
tengo que mandarle valores reales a las cosas salvo en la iglesia es que más o menos uno puede decir bueno
trabajo con palabras o sea como en la extracción esto trabaja en nivel de palabras en el resto
siempre está esperando que yo le mande valores numéricos entonces yo necesito poder tener una
buena representación numérica de los textos y de paso voy a pedir una propiedad más que es
que esa representación numérica tenga algunas propiedades interesantes como por ejemplo una
métrica de distancia que haga que las palabras más cercan las palabras más similares y
este más cerca y la más diferente de este más lejos por ejemplo puedo pedir eso en una
en una representación entonces vamos a ver una técnica de llamar warden bedings o
vectores de palabras que se utiliza para representar las palabras y después eso lo pudo
utilizar como entrada una red y la técnica se basa en la hipótesis distribucional que son hipótesis
que surgió en los 50 con este Firth que era un linguista lógico etcétera y decían lo
siguiente bueno las palabras que aparecen en contextos similares tienden a tener significados
similares y acá tenemos un ejemplito que dice este ejemplito tiene como algunas palabras y
algunas ideas de contexto no la milanesa con queso más rica la uruguayas si es rica la
hamburguesa con queso la milanesa con queso musarelas le decimos una politana no sé qué está
eso como que está hablando de milanesas hamburguesas comida y después el otro dice el
autoño es una de las citaciones del año el verano es mi situación de favoritas el
invierno en invierno hace pila de frío en verano nunca hace frío y está hablando como de otra
cosa no claramente las palabras rojas se parecen más entre sí las palabras azules se
parecen más entre sí entonces idealmente yo quería tener una representación que a las rojas las
deje más o menos cerca y a las azules violetas las deje más o menos en otro lado
bueno una primera idea que surgía es lo que se conoce como matriz término término que
se se realiza contando palabras contando cuando una palabra parece cuánta vez aparece una
palabra en el contexto de otra entonces por ejemplo en este caso yo digo yo tomo alrededor de
una palabra en palabras de contexto alrededor y cuento cuánta vez se aparece otra en ese contexto
entonces como ejemplo tenemos bueno estos son los ejemplos anteriores no la milanesa con queso
más rica la hamburguesa no sé qué el autoño tal cosa y pregunta cómo quedaría la matriz
utilizando un contexto de cuatro palabras y acá no sé si lo llevan a ver todos pero me
aparece que por ejemplo la palabra milanesa tiene las palabras rica y queso en su contexto
de la palabra hamburguesa también pero la palabra toño no la palabra toño tiene en su contexto
bueno acá justo como estoy tomando en igual cuatro no pasa pero las palabras verano y invierno
tienen en su contexto la palabra frío y no tienen ni rica ni queso entonces eso es con
en igual cuatro no contando cuatro palabras alrededor si yo considerara en igual cinco entonces ahí
si aparecería o toño tiene la palabra estaciones en su en su contexto y verano también tiene
estaciones en su contexto entonces es como que me van quedando zonas de la matriz que están
como más acopladas entre sí no como que tienen mayor nivel de proximidad y otras zonas que no
entonces ahí ya tendría como una especie de primera aproximación a lo que sería en
vectores de palabras que es decir bueno yo puedo representar cada palabra con una fila de esta
matriz y esa fila de la matriz va a tener ciertas propiedades cosas de que palabras que están
cerca van a semánticamente similares van a estar cerca en esas en esas filas un problema que tiene
esta representación que dice ahí abajo es que son vectores muy grandes yo tengo vectores de
tamaño básicamente el tamaño del vocabulario si yo tengo considero 10 mil para
ver vocabulario o tener vectores de tamaño de 10 mil donde la mayoría de los de los números
van a ser cero y algunos van a ser valores distintos de cero entonces me va a pasar que los
vectores son dispersos o spars bien entonces ahí como refinaciones esta técnica que se utiliza
bastante o sea esta esta técnica de de construir matriz y determinos términos se puede usar como
base para calcular ciertos tipos de vectores de palabras el algoritmo glob se basa en
comentar comenzar en esta matriz los algoritmos de pca de principal componente análisis se pueden
usar para reducir la dimensionelidad de esta matriz en realidad este tipo de matrices tiene sus
usos pero la que vamos a ver es una técnica un poco posterior a las matrices también
o término que digamos que está como en el inicio de lo que fue las revoluciones que se han dado
en pelea en los últimos años no este este es un trabajo de 2013 un trabajo de bueno un
investigador que ya no es mi collode que propuso en 2013 una técnica que en realidad son dos
acorimos distintos que se llama Word to back o sea ir acorribo para ir de palabras a vectores y
que su idea era construir vectores de ensos o sea vectores que tuviera una dimensión mucho más
chica de vocabulario en vez de tener un vectore tamaño de 10 mil yo voy a tener un vectore tamaño 100 o
250 o 300 y por el hecho de comprimir todo el vocabulario en esos vectores más densos entonces
ganó esas propiedades de que palabras más cercanas son simánticamente similares entonces bueno
obviamente no lo van sólo por comprimir sino por cómo se entrena esto entonces la idea de los
algoritmos de Word to back es decir bueno en vez de contar como la matriz determinó término
de las palabras dentro de un contexto yo lo voy a ver con un problema de clasificación un
problema de probabilístico en el cual voy a predecir qué tan probable es que la palabra C aparezca
en el contexto de la palabra W bien entonces voy a tener una predicción la producción de que es
cierto que aparece la palabra W en el contexto de la palabra C en el contexto de la palabra W
eso sería P de más WS pero a su vez tengo que tener una predicción negativa o sea yo tengo que
saber cuáles son los ejemplos positivos y cuáles son los ejemplos negativos entonces
lo que se hace para esto es decir bueno yo tengo un gran corpus una gran colección de palabras y
yo puedo medir puedo llegar a medir cuáles son los contextos donde aparece la palabra C en el
contexto de la palabra W pero además puedo llegar a medir los casos en los cuales no pasa o sea
yo puedo soltear palabra solatoria si decir bueno una palabra aleatoria no siempre están en
contexto de una palabra W entonces con eso me invento ejemplos negativos tengo ejemplos
positivos que son bueno la palabra queso aparece en el contexto de la palabra burbesa ejemplos
negativos son sortes de una palabra cualquiera y salió yo que se árbol bueno la palabra árbol
no aparece en el contexto de la palabra burbesa bien entonces el algoritmo skip gran que es uno
de los algoritmos de portubec más más utilizados utiliza este ese principio y lo ve como una red
neuronal intenta modelar esto como una renebronal en la cual yo tengo una capa de entrada y la capa
de entrada va a ser una representación one hot esto lo mencionamos la de pasada la representación
one hot es así no en la representación one hot yo voy a tener un vector para la palabra queso y un
vector para la palabra hamburguesa donde voy a tener una columna para cada una de las palabras
posibles entonces voy a tener acá perro acá voy a tener comer acá voy a tener árbol
tan tata y acá va a estar queso en angulado y acá va a estar hamburguesa en otro lado y acá
va a dar más cosas y entonces la representación de la palabra queso es cero en todos lados
y un uno acá y cero en todo el resto la palabra burbesa es cero en todos lados cero acá y
un uno en la burbesa y cero en todo el resto esto es la representación one hot entonces esta red
neuronal en realidad digamos es una renebronal que intenta predecir este problema probabilístico
toma como entrada ese vector de cero y uno es el vector one hot donde la entrada es todo el vocabulario
posible tiene una capa oculta en el medio es una red que tiene una sola capa oculta y como salida
tiene una distribución de probabilidades de todas las palabras en contexto entonces la entrada
es supongamos que esto tiene tamaño 10 mil no tengo 10 mil palabras posibles 10 mil palabras en
el vocabulario entonces la entrada de la red va a ser una cosa de tamaño 10 mil entrada tiene
tamaño 10 mil y la salida va a tener c por 10 mil c es cuántas palabras de contexto estoy contando
o sea si yo estoy contando no sé 10 palabras alrededor de la que estoy mirando entonces va a ser
una salida c por 10 mil esto c por 10 mil representan cuál es la probabilidad de que una palabra
cualquiera por ejemplo hamburguesa esté en un contexto de tres palabras para atrás de la palabra
queso cuál es la probabilidad que la palabra perro esté en un contexto de dos palabras para
adelante la palabra queso y así eso es las c por 10 mil salidas y en el medio tiene una capa
que ahí dice en edim la capa oculta que tiene tamaño 10 mil por dim y dim es la dimensión
de los vectores que eso que les decía que podía hacer dimensión 100 o dimensión 300 o dimensión
150 es un número mucho más chico que vocabulario entonces pensemólo como esto la tano mientras
es un vector o un hot que tiene un uno y un montón de ceros y después lo paso por una
matriz de pesos que tiene este tamaño 10 mil por por ejemplo 300 10 mil por 300 entonces al
multiplicar eso por mi vector acá esto me devuelve una sola fila de esa matriz que tiene dimensión
300 y eso se lo voy a pasar a la función de activación a su vez eso tiene como una especie
de segunda capa en la cual aparece más peso para poder calcular estas salidas pero en realidad al
método después de que se entrena con un montón de valores positivos un montón de valores negativos
dice bueno que eso parece en el contexto de muruesas pero perro no aparece en el contexto de
la muruesa etcétera tengo un montón de valores de este estilo cuando termina de entrenar y
se bueno llegué al mejor cálculo de probabilidades en realidad yo tiro todo el resto de las capas y me
quedo solamente con esta de acá con la capa oculta la capa oculta es una tabla que me dice para
cada una de las palabras hay 300 valores reales que le representan bien entonces me dice bueno para
la palabra que eso esto 300 valores van a ser menos uno tres con cuatro ocho con seis no sé qué
está todo así 300 valores y para las palabras muruesa menos dos tres con uno etcétera etcétera
o sea voy a tener un montón de valores reales que le representan que representan esos números
no lo sé y nadie lo sabe pero sabemos que ahí está codificada la información importante para
poder después trabajar con esos números con esos con esas palabras bien hay eso se le llama
Word in badings esta capa oculta que está acá en esta en esta técnica de Wordback se le llama
capa de badings a la capa oculta que queda entrenada después de esto bien preguntas
ustedes que palabra que esto sí es para ir a la capa oculta y por el producto porque la
matriz doble vez una matriz de 10 mil por dimensión y mi vector one hot es un vector que tiene
tamaño de 10 mil pero hay un solo uno no son todos heros y uno entonces al hacer el producto me
queda exclusivamente la fila que representa la matriz la palabra que eso
bien entonces con esto se logra con esta técnica Wordback y otras técnicas de construcción
de Word in badings sí no el resultado de la capa oculta se lo pasas en esta técnica por lo
menos le pasas el resultado de la capa oculta a otros pesos que van a ir a la salida y esos pesos
son los que calculan la probabilidad de salida pero en realidad después todos esos pesos que aparecen
después no me importa o sea después de que yo termino de entrenar todo la única capa con la
que me voy a quedar es con la del medio que es la que me he interesado entrenar el resto es
como una especie de excusa que se usa para esta tarea para poder encontrar la capa del medio
la salida tiene c por 10 mil que significa yo estoy prediciendo cuál es la probabilidad en todas las
seis palabras de contexto de caparesca alguna palabra
bien entonces les hicimos logramos nuestro objetivo que era decir que hago que puedo
asociar a una palabra a un string un vector de valores reales entonces tengo la palabra perro y
me va a dar un vector de valores reales la palabra comer y me va a dar otro vector de valores reales
además se cumple que los vectores cuanto más cercanos están en ese espacio de dimensión
300 entonces significa las palabras son más similares en algún sentido o si están más
lejanos entonces son más disímiles puedo utilizar por ejemplo la similiaridad coseno para
eso si yo calculo el coseno del ángulo del otro lado vectores eso es una buena medida para
saber qué están parecidos son o incluso para usar la distancia o clídea también para
calcular eso pero la similiaridad coseno es la que más se usa y además de que tiene esa
propiedad de que las palabras más cercanas son más parecidas de alguna manera estas técnicas
descubren cosas interesantes que uno no las entrenó para que las descubran digamos sino que aparecen
como de yapa y aparecen cosas como que por ejemplo yo puedo hacer operaciones entre los vectores
entonces si yo tengo el vector de rey y le resto el vector de hombre y le sumo el vector de
mujer me queda el vector de rey y eso es una propiedad que aparece después de que yo
entren estos vectores suele suceder en alendenar estas colecciones de vectores que agarro el vector de
mujer le resto de hombre y le sumo rey y me queda rey o agarro el vector de Uruguay le resto
donde veo le sumo Francia me da París no entonces ahí en un caso estoy haciendo una transformación
un poco morfológica decir bueno este hombre es la mujer como rey esa rey y el otro estoy
haciendo una transformación más semántica como diciendo la capital de Uruguay y la capital
de Francia es París y de alguna forma yo nunca le dije al sistema que tiene que aprender eso pero
por la forma que hayan creado los vectores suelen tener propiedad de este estilo bien eso fue como
lo lo primero sorprendente que encontraron acerca de estos métodos que es que se pueden como que
derrebo de aprender esas cosas pero no están excesos del problema como por ejemplo si yo tengo
una palabra la palabra vela voy a tener un solo vector que representa la palabra vela y vela
es una palabra que es amigo o sea es polisémica yo puedo tener una vela para aprender una vela
vamos para poner una vela de cumpleaños o sea una pagón o puedo tener un barco a vela y bueno
en los dos casos tengo la misma representación o el gato hidráulico y el gato animal también tengo
la misma representación el banco de sentarse y el banco de financiero también tengo la misma
representación etcétera entonces eso es un problema que tienen estos estas técnicas y es que yo
no tengo digamos no estoy usando por ejemplo wordnet que vieron guarnas en una acción
es clase no no tengo un repositorio significado de wordnet que me ayude a decir cuál es cuál sino
que acá solamente tengo un representante para cada palabra bien y bueno esta esta técnica tiene
ese problema después hay otras tecnicas me permiten crear vectores contextuales que día bueno
es la palabra gato en esta oración donde probablemente sea un gato animal y no un gato hidráulico
bien entonces una vez que construimos esta colección de vectores como los evaluamos cómo sabemos
están bien bueno hay como dos formas de evaluarlos bastante comunes se habla de test intrínsecos y
test en extrínsecos que significan cosas distintas intrínsecos significa yo mido propiedades del
conjunto de vectores que construí entonces una de las que se miden es exactamente lo que decía
no recién me diamos que aparece una propiedad que es que yo puedo hacer dibujar como en
especie para el logramos en el cual digo que hombre es a mujer como rey esa y espero que
es mi colección de vectores haya quedado reina digamos como resultado de su operación o Uruguay
esa montevideo como francia esa y espero que haya quedado parís en ese lugar entonces bueno una
forma de valor estos estos sistemas es construirme una colección grande de estos test se llaman test de
analogías entonces me puedo hacer una colección grande estos test y ver a cuántos le moca mi colección
entonces con yo tengo varias colecciones en vez de distintas veo que este le invoco más veces y
el invoco menos veces otro son los test de similitud o similaridad que esto se hacen con
intervención humana un poco más fuerte que es preguntar un montón de personas por ejemplo
que es más parecido a un durasno una silla una mesa o una manzana a un avestrus o cosas de
estilo entonces tal le dicen a la gente trata de arranquear estas cuatro cinco palabras de cuál es
más parecida menos parecida entonces le preguntar un montón de personas las personas hacen sus
listas y después mirás dentro de tu colección de vectores si las distancias relativas entre esas
palabras son similares o no a la que esperaban los humanos entonces cuanto más similar sea haciendo
el el test de Spirman para eso el descorrelación de Spirman se puede sacar una medida de qué tanto
se parece a la intuición humana lo que el sistema dice eso es llamante es intrínseco porque yo
estoy abarrando la colección de vectores que construí y las estoy testeando sola los test
extrínsecos se refieren a agarro mi colección de vectores y la meto en una tarea de p l n un
poco más grande y veo qué tal le va entonces acá significa bueno yo supongamos que tengo un
sistema de p l n que hace traducción automática o análisis de sentimiento o recuperación de información
o un chatbot o lo que sea si yo tengo un sistema que ya funciona y le cambio su capa de
su colección de vectores por la mía que yo entrené y el sistema mejora en su performance entonces
digo que puedo decir que mi colección de vectores mejora la performance entonces puedo decir que la
colección de vectores es buena eso de llamas test extrínseco o sea no estoy probando directamente
las propiedades de los en vectores sino que estoy probando cómo se comportan en un sistema más grande
bien entonces otra forma de evaluar esto más bien no creo que lleguen a ver nada porque está
muy chiquito pero bueno vamos a mencionarlo es visualizarlos en bedings recuerden que esto tenía
dimensión 100 350 que era una dimensión mucho más chica que el vocabulario pero igual es una
dimensión muy grande o sea lo sumano podemos visualizar dos tres dimensiones de lo sumo y más de
eso ya nos mareamos y estos son vectores de 300 dimensiones pero una forma de visualizarlos es
usar las técnicas de reducción de dimensionalidad por ejemplo p c a y t s n s son de las más comunes
son técnicas que me permiten agarrar 300 dimensiones y bajarlas a dos para poder dibujarlo en un
plano entonces acá no llegan a ver estos son dos trabajos que hicimos en el grupo para distintos
colecciones en bedings en distintos idiomas voy a agarrar esto ahora sí sí queda bien entonces en
este tenemos un trabajo hecho para el español son vectores de palabras en español y
están no van a llegar a verlo lo que están acá porque se ve muy chiquito pero por ejemplo acá
aparece un cláster de años que están todos juntos acá aparecen nombres de personas que
están todos juntos abajo aparecen lugares perú, Uruguay, Bolivia que aparecen como clásterizados
todos juntos entonces uno espera que una colección de vectores que haya quedado bien entrenada aparezcan
como clásters con cosas que son semánticamente similares y el trabajo de la derecha es un trabajo
similar pero que está hecho para el Guarani y bueno acá se ve también más claro que aparecen
cosas como relacionadas con fechas están en héroes las relacionadas con colores están en
en cian las relacionadas con no se bien que dice ahí animales están en verde etcétera países
están en azul etcétera como que no puede estar en esas regiones obviamente esto no es perfecto
van a quedar alguna cosa por fuera etcétera pero si uno logra ver que más o menos clásteriza
entonces tiene como cierta cierta entuición de que andan mejor esos vectores bien preguntas
entonces los guerden beings fueron en definitiva una de las primeras revoluciones que ocurrieron los
últimos años en lo cual es pln y posible que después se empezaron a utilizar arquitecturas de
redes más complejas o sea gracias a que tenemos en bedings y decimos puedo representar una
palabra como un vector de 30 dimensiones ese vector de 30 dimensiones que son números reales
se lo pueden chufar como entrada a una red neuronal y puedo obtener cosas más complicadas a mí me
interesaba de hace un rato dijimos tener representaciones de palabras pero además de oraciones o de
tweets o de documentos enteros y bueno por lo menos yo tengo representación de palabras usando
guerden bedings como que eso está bastante bien resuelto y gracias a que ahora tengo guerden
bedings para usar arquitecturas más complejas como las redes convolucionales las redes
lstm las redes tipo transformers los transformers son lo que más se utiliza bien día pero además
puedo hacer otra cosa con los en bedings algo un poco más simple pero que a su vez me sirve para
resolver otras problemas y es usar la técnica de centróide
que es así esta les va a servir en la tarea salvo que quieran entrenar una red más compleja que
también son bienvenidos si quieren entrenar una lstm un transformer pero el centróide es una
técnica es muy sencilla supongamos que yo tengo mi mi capa en bedings que tiene bueno dice quesos
representas y hamburguesas representas y perro es así gato es así etcétera tengo
vectores para cada palabra y tengo ahora un tweet que le quiero representar utilizando la
colección en bedings yo simplemente puedo agarrar todas las palabras del tweet buscar todos los
vectores correspondientes y hacer el promedio a eso se llama hacer un centróide de todos los
en bedings del tweet y uno dice está apreciado el promedio de perro gato no o sea el tweet dice
este no me gustó la película se hago el promedio no me gustó la película y aún promedio todos
en bedin mediar papa frita pero sin embargo funciona bastante bien es como un poco antintuitivo pero
hacer el promedio de todas esas 300 dimensiones de las distintas palabras después yo utilizo eso
como entrada para otro otro sistema de clasificación no sólo una rena urnal sino que ahí ya
puede utilizar otro tipo de cosas como su proyecto en machines o regresión logística y
anda bastante bien o sea es como extraño pero sobre todo para el problema de análisis de
sentimiento anda bastante bien bueno esa es la técnica del centróide es una técnica fácil de decir
si yo tengo una colección en bedings puedo hacerme en bedings de oraciones o en bedings de textos
un poco más grandes simplemente promediendo los en bedings que tengo bien entonces ahora lo que
vamos a ver en el resto de la clase en unos minutos son ejemplos de cómo funcionan estas
arquitecturas más complejas que puede utilizar gracias a que tengo en bedings no las vamos a
ver en profundidad sino que simplemente vamos a pasar por arriba pero es una idea para ver qué clase
de cosas se pueden hacer y empecemos por las convolutivas las redes tipo CNN se llaman
redes convolutivas o convolucionales y originalmente se utilizaban como para procesar imágenes o sea
también se utilizan todavía en día para procesar imágenes y lo que hacen es ir recorriendo como que
se aumenta una imagen en cuadraditos y lo van recorriendo digamos y después obtienen como
información de cada uno de los cuadraditos bueno pero también se han aplicado al lenguaje y la
forma que se aplica el lenguaje es como decir va tomando de enegramos y va viendo yo que se
por ejemplo tres palabras a la vez y va obteniendo datos de cada una de las tres palabras a la vez y
después con eso después saca un total entonces lo interesante es que digamos puedo pasar a tener
cosas de orden más grande que una palabra o sea ahora en bedes para usar una sola palabra estoy
produciendo toda una variación entonces tenias una pregunta bien entonces un ejemplo
como funciona esto supongamos que estoy tratando de clasificar tweets y digo la película fue
muy aburrida yo me puedo construir una red neuronal de tipo convolutiva que lo que va a ser es decir
bueno a los embeddings de la de a tres palabras los voy tomando de a tres palabras considero
los embeddings de la película fue y a esos tres embeddings se los paso a una red a esa unidad
convolutiva que lo que va a ser es mirar estas tres palabras y tratar de sacar información de
las tres y devolverme una cosa que tenga cierto tamaño fijo y después se va a mover la ventana y en
vez de la película fue va a considerar las palabras películas fue muy y de vuelta lo va a pasar por
esa subred y va tratar de sacar salidas y después fue muy aburrida lo va a pasar por la misma subred
tratar de sacar salidas después voy a tener una capa que dice bueno de todas estas salidas
intermedias que tuve obtengo los máximos y esos máximos los uso para calcular mi salida que
mi salida final sería positivo o negativo en el otro o no no estas redes esta capa convolutiva
que ahí en el medio parece como capa convolutiva es entonces a sus redes que estoy viendo ahí en
realidad son los mismos pesos no es como la misma que se va moviendo y me va dando resultados distintos
bien entonces lo bueno que tiene es que yo agarró todo una entrada que son muchas palabras y me
va a dar una salida única digamos condensa todas las palabras se queda como con las digamos las
dimensiones máximas de cada una que le quede más le interesen y con eso calcula una salida bien esa es
la red tipo convolutiva las redes el STM pertenecen a un grupo más grande de redes que se llama
las redes recurrentes que significa son redes con memoria que van mirando una cada palabra a la
vez y van recordando lo que viene hasta el momento entonces esto me sirve para obtener una salida final
o también para obtener salidas por palabras entonces vamos a ver cómo funciona de estas
esto como una especie de diagrama de cómo sería una una red recurrente similar a la que veíamos
hace un rato digamos en capas pero ahora yo voy a tener una capa que tiene un enlace ese asimismo
digamos todas las neuronas de esa capa van a tener un enlace de vuelto de vuelta a ese asimismo se
llama capa recurrente y bueno después voy a tener una capa de salida entonces cuando yo voy a
ver cómo funciona eso con un tweet que quiero clasificar como la película fue muy aburrida funcionaría
esta manera yo digo bueno primero agarró la palabra a la el embedding de la palabra a la se lo
paso a la red y después voy a agarrar el embedding de la palabra película y se lo paso de vuelta a la
red pero esta vez además de poner el embedding de la palabra película voy a poner también la salida
del paso anterior entonces esto va consumiendo una palabra a la vez y siempre consumiendo la salida de
la etapa anterior entonces va consumiendo la película fue muy aburrida cuando llegó aburrida ya
consumió la salida de todas las capas anteriores y la palabra nueva y ahí es como que la salida de
ese último paso ya medio tiene como una especie de versión condensada de todo lo que era la
elaboración y ahí con esos últimos pesos calculo la salida positivo, negativo, neutro o no
además si yo quisiera podría ir sacando para ir sacando los pesos de cada una de las salidas
entonces ahí tendría como una salida por palabra entonces esto podría servir por ejemplo para
los problemas de clasificación de secuencia que veíamos la despasada bueno con una red de estetilo se
puede hacer clasificación de secuencia sacando una salida por palabra sí tenía una pregunta
el embedding exacto sí sí la entrada en esto caso yo digo bueno asumo que tengo
bordemente yo ya puedo utilizar estas redes más complejas bien y la que es la arquitectura del
estado del arte hoy en día es la arquitectura de tipo transformer que también es una arquitectura que
utiliza secuencias de entrada pero es una arquitectura bastante más compleja acá vamos a
ver solamente una idea muy muy básica como funciona pero es una arquitectura que tiene con muchos
muchos pedazos y hace muchas cosas distintas y bueno se basa en una cosa que se llama capas
autotensionales ahora no vamos a ver qué es el modelo attentional pero lo vamos a ver la clase que
viene normalmente como bueno un ejemplo de cómo funciona el sistema de traducción automática
que utiliza modelos autotensionales bueno una variante de eso es el modelo autotensional que
lo que hace es construir una matriz entre las palabras de una oración y sí misma yo tengo una
oración que tiene en palabras y va a tratar de cruzar las n palabras con las propias n palabras
y tratar de establecer conexiones entre cada uno de los pares entonces termina calculando una
matriz y lo bueno que tiene es que me permite construir en beding contextuales por palabra o
sea en bedings de una palabra vista en contexto y además un embeding total de la oración entonces
funciona más o menos así esto como una especie de representación muy vaga de lo que es un
transformer no o sea de forma de realidad tiene como muchas partes más complejas pero imagínense
que funciona esta manera no yo digo tengo una oración en la película fue muy aburrida entonces
la voy a pasar por una capa autotensional que significa yo cruzo todas las palabras con todas y
calculo la relevancia de cada palabra contra las demás eso me va a dar una serie de salidas y eso
lo que hace es construirme como una colección de en bedings de nivel 1 o sea yo empecé con los
borde en bedings de la película fue una fue muy aburrida y ahora voy a tener una colección de
en beding de nivel 1 que ya mirando algo de contexto eso eso es en beding de nivel 1 a su vez
de los pasos de vuelta a otra capa autotensional que devuelta los cruzos a todos con todos y me
devuelta a dar una salida que son los en beding de nivel 2 y eso lo sigo pasando por varias capas
autotensionales que los cruzan todos con todos hasta que al final me terminan dando o sea lo voy
a pasar en el capas y me terminan dando una salida de nivel 5 digamos entonces al inicio tenía
borde en bedings que miraban solamente una palabra a la vez y lo que tengo al final ya son como
en bedings contextuales en los cuales ya considero varias veces cruzar todas las palabras con todas
entonces como que eso va ganando información en cada paso a su vez a bien después de que yo
tengo estos en beding contextuales en general se utiliza otra red más de tipo de coder puede ser
un transforme puede ser una lstm algo más pero necesito otra cosa que es la que me diga por
ejemplo si es positivo negativa o neutro etcétera pero es otro tipo de red que después decodifica
esa información pero bueno por lo menos atacayo ya construí en bedings de cosas pero bien lo que
tengo acá son tenía la película fue muy aburrida y eso lo transformé en tenía cinco palabras y lo
transformé en cinco en bedings digamos que de distintos niveles pero siempre son cinco en bedings
entonces yo diría que el primero se corresponde con la el segundo con película tercero con fue
es una una versión contextual del en beding porque significa la palabra película en el contexto de
la película fue muy aburrida no es la palabra película en general entonces si yo tuviera una
bración que tiene gato sería gato en el contexto de el gato como pescado que no sería lo mismo que
cuando estoy hablando un gato y un gato y un gato y un gato probablemente o sea los en bedings
que de distintos bien pero además me interesa tener una representación de la oración entera y
para eso lo que se hace es agregar un toque en extra un toque en llamado celse se pone al
principio de la oración y se lo hace jugar con todos los las capas atenciónales del medio entonces
yo tengo una palabra extra que como no es una palabra de la oración no tiene un en beding contextual
sino lo que hace es capturar la información de toda la oración a la vez entonces es en beding que
me queda afuera el en beding que corresponde al toque en celse ese que después yo puedo utilizar
para predecir cosas yo lo utilizo como un en beding que tiene cierto tamaño y se lo paso una
capa de softmax para que me prediga así esa es positiva negativo a neutra o no bien bueno y para
terminar terminar comentarles lo el tipo de herramientas que pueden utilizar para trabajar con
redes neuronales obviamente para el segundo laboratorio van a poder utilizar redes neuronales si
quieren de todo tipo si quieren colecciones en bedings nosotros también les podemos dar o pueden
bajar algunas que estén disponibles en la web pero bueno herramientas habituales para trabajar con
esto son por ejemplo tensorflow y pator que son dos ilotecas el tensorflow de google y pator es
de meta o de facebook y bueno queras en general trabaja contar sonflog y hanginfaces es un
repositorio que tiene un montón de modelos ya aprendrenados para muchos idiomas y para muchas
cosas que ya se pueden utilizar autos de box y funciona muy bien y bueno estas son estas
herramientas y otras más las van a poder utilizar en laboratorio bueno por hoy eso la
próxima vez vamos a ver producción automática
