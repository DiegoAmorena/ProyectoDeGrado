1
00:00:00,000 --> 00:00:26,400
Hoy vamos a tener este, vamos a tener, vamos a terminar de ponernos al día, espero con

2
00:00:26,400 --> 00:00:36,400
luego de las dos clases que suspendimos por razones de fuerza mayor, este va a ser un

3
00:00:36,400 --> 00:00:45,400
poquito larga y vamos a hablar de dos temas bien, bien diferentes, si yo mira que planificar,

4
00:00:45,400 --> 00:00:50,240
bueno de hecho tengo que planificar pero no tengo margen, este no pondría estos dos

5
00:00:50,240 --> 00:00:55,720
temas en la misma clase porque son dos temas bien, bien, bien, bien diferentes y capaz que

6
00:00:55,720 --> 00:01:00,320
es interesante marcar cuando lo veamos y ese puede ser un valor agregado la diferencia entre

7
00:01:00,320 --> 00:01:08,240
los dos desde el punto de vista de los métodos utilizados. Vamos a ver dos temas, uno va a

8
00:01:08,240 --> 00:01:17,400
hacer, se acuerdan que en la clase pasada hablamos de morfología, va, introdujimos un formalismo

9
00:01:17,400 --> 00:01:22,480
que es el de los transportores de Tau finito y su alje, bien dicho, su alje de expresiones

10
00:01:22,480 --> 00:01:29,800
regulares extendida a relaciones, se acuerdan que así como teníamos una alje de expresiones

11
00:01:29,800 --> 00:01:33,320
regulares para los lenguajes ahora teníamos una alje de expresiones regulares para los

12
00:01:33,320 --> 00:01:41,640
transportores o para las relaciones en realidad que eran computadas por los, por los transportores

13
00:01:41,640 --> 00:01:46,840
de Tau finito y después introdujimos un problema que era el de la morfología, es decir encontrar

14
00:01:46,840 --> 00:01:54,200
la estructura interna de las palabras, dar una palabra, analizar su estructura y devolverla,

15
00:01:54,200 --> 00:01:59,960
digamos devolver su estructura interna y viceversa, es una cosa que se llama análisis y la otra

16
00:01:59,960 --> 00:02:04,160
se llama generación, viceversa quiere decir yo te doy la estructura y me das la palabra,

17
00:02:04,160 --> 00:02:10,560
si? Y vimos un poco que la morfología dependía un poco de los lenguajes pero que esencialmente

18
00:02:10,560 --> 00:02:22,400
de lo que se trataba era de tener o que podía modelarse como la existencia de raíces que

19
00:02:22,400 --> 00:02:27,880
eran los morfemas, la palabra estaba dividida en morfemas y que esos morfemas se dividían

20
00:02:27,880 --> 00:02:34,440
en dos, en raíces que son lo que contenían la mayor parte del significado de la palabra,

21
00:02:34,440 --> 00:02:40,560
la porción de la palabra que tiene la mayor parte significado y los afijos, que esencialmente

22
00:02:40,560 --> 00:02:46,360
por lo menos para nuestro idioma son dos, son prefijos y sufijos, prefijo van antes,

23
00:02:46,360 --> 00:02:56,720
sufijo van del. En la clase de hoy lo que vamos a ver en la primera parte es justamente

24
00:02:57,000 --> 00:03:05,040
cómo los transductores o la algebra de estado finito no sirven para modelar los problemas

25
00:03:05,040 --> 00:03:09,760
de morfología, los problemas de análisis y generación y algunas ventajas que ya vimos

26
00:03:09,760 --> 00:03:18,520
que los transductores tienen y cómo se aplican a esto. Este método es un método esencialmente

27
00:03:18,520 --> 00:03:35,320
determinista o orientado a reglas, a un estado de reglas más que determinista, me deciré, van a ver

28
00:03:35,320 --> 00:03:40,600
que mi solución consiste en, bueno, dado una palabra aplico tales reglas y me devuelvo el análisis.

29
00:03:42,160 --> 00:03:46,120
En la segunda parte de la clase vamos a ver un método que no tiene nada que ver desde su

30
00:03:46,120 --> 00:03:51,280
principio, desde su fundamento porque es un método probabilista que esencialmente aprende

31
00:03:51,280 --> 00:04:01,880
de los datos y esos son esencialmente los dos grandes grupos que tenemos de métodos que tenemos

32
00:04:01,880 --> 00:04:06,480
en el análisis del lenguaje natural como una otra cantidad de cosas que involucran datos,

33
00:04:06,480 --> 00:04:13,560
métodos orientados a las reglas donde un experto especifica de alguna forma reglas a aplicar para

34
00:04:13,560 --> 00:04:21,520
resolver el problema y otro conjunto de métodos donde yo aprendo de los datos, los estadísticos son

35
00:04:21,520 --> 00:04:28,720
uno de ellos, hay otro tipo, pero donde yo esencialmente infiero el conocimiento necesario a partir

36
00:04:28,720 --> 00:04:33,160
de los datos. Esos métodos son los que usualmente llamamos métodos de aprendizaje automático.

37
00:04:35,680 --> 00:04:41,280
Van a ver que en muchos de los problemas hay de los dos enfocas.

38
00:04:43,640 --> 00:04:48,520
En algunos andan mejor unos y otros mejor otros hay una vieja guerra en el procesamiento del lenguaje

39
00:04:48,520 --> 00:04:59,080
natural sobre cuáles métodos predominan sobre otros. El siglo XXI ha mostrado una

40
00:04:59,080 --> 00:05:09,800
prevalencia de los métodos basados en datos como vamos a ver acá, pero hay dominios donde los

41
00:05:09,800 --> 00:05:14,440
orientados a reglas funcionan muy bien y cuando funcionan bien, cuando yo puedo describir la

42
00:05:14,440 --> 00:05:19,520
realidad completamente a través de reglas funcionan mejor. Hay veces que las realidades son

43
00:05:19,520 --> 00:05:23,360
demasiado complejas para modelarlas con reglas y ahí donde ganan son los métodos de aprendizaje

44
00:05:23,360 --> 00:05:27,400
automáticos. En general los métodos de aprendizaje en el procesamiento del lenguaje natural son

45
00:05:27,400 --> 00:05:32,360
lo más adecuados porque el lenguaje natural como hemos visto es muy ambiguo, es muy creativo,

46
00:05:32,360 --> 00:05:40,560
es muy cambiante. Bueno, probamos a lo que nos convoca hoy y lo que vamos a hablar es

47
00:05:40,560 --> 00:05:46,000
de morfología de estado finito. Esto es modelar los problemas de morfología que vimos en la clase

48
00:05:46,000 --> 00:05:52,960
pasada con a través de herramientas de estado finito. Esto es un desambigador morfocintáctico

49
00:05:52,960 --> 00:06:11,480
Otro problema de morfología es bueno acá lo que es único que hizo fue separar palabras

50
00:06:11,480 --> 00:06:19,520
por palabras y dice la que puede ser un sustantivo, un pronombre, un artículo, esto es clasificación,

51
00:06:19,520 --> 00:06:38,320
pero además, puedo ver las flexiones ¿no? Vamos con una palabra un poco más. Por ejemplo,

52
00:06:38,320 --> 00:06:53,320
bella, que es un adjetivo, la forma canónica es bella y la flexión es, bueno, qué tanto

53
00:06:53,320 --> 00:07:12,640
bien. Masculino singular es bello. La forma intrusiva es bella. Y se acuerdan que la flexión

54
00:07:12,640 --> 00:07:17,720
es cambiando los morfemas ¿no? Yo cambio el final de la palabra y la flexión. Pensé

55
00:07:17,720 --> 00:07:27,520
que este, la verdad que pensé que este tenía, marcaba los sufijos y prefijos, pero no me

56
00:07:27,520 --> 00:07:33,720
equivoqué de cosa. Pero bueno, lo importante es que nosotros vamos a admitir, flexionar cada palabra,

57
00:07:33,720 --> 00:07:39,640
lavar, por ejemplo, que es un verbo, se flexiona diferente, justamente porque es un verbo.

58
00:07:49,520 --> 00:08:00,280
Lavó, lavas, lavas, lavamos, lavas. Entonces, la morfología es lavamos, yo tengo que decir de

59
00:08:00,280 --> 00:08:06,040
alguna forma que esto es un verbo que está conjugado en la primera persona del plural en el

60
00:08:06,040 --> 00:08:12,040
presente indicativo ¿de acuerdo? Esa es la, las características que tendrían, las marcas que

61
00:08:12,040 --> 00:08:17,040
tendríamos que asociarle a la palabra, en el análisis ¿se entiende? Como lo vimos la que hace

62
00:08:17,040 --> 00:08:33,200
pasadora a mover un poco más en algunos casos. Por ejemplo, yo se ve que en la edición perdí una,

63
00:08:33,200 --> 00:08:46,960
una. Por ejemplo, lo que veíamos la vez pasada que yo quiero llevar a que gatito si es gato que

64
00:08:46,960 --> 00:08:57,920
la forma canónica o lema, lema en realidad, más masculino, más es una marca nada más ¿no?

65
00:08:58,640 --> 00:09:11,520
Es una forma estanda de masculino, singular, diminutivo ¿de acuerdo? Mi problema de ir de acá,

66
00:09:11,520 --> 00:09:26,760
acá se llama análisis. Y ir de acá, acá se llama generación ¿de acuerdo? Esto se llama forma de

67
00:09:26,760 --> 00:09:36,680
superficie y esto se llama forma eléxica ¿tá? ¿cuál de lo, levante la mano el que le parece más

68
00:09:36,680 --> 00:09:43,280
fácil el análisis que la generación? ¿y a quién le parece más fácil la generación que la análisis?

69
00:09:45,280 --> 00:09:51,120
pensé que no iban a votar bien, lo dejamos por ahí, yo también me parece más fácil la generación

70
00:09:51,120 --> 00:09:56,440
que la análisis ¿no? Eso también no, a mí también. Bueno, vamos a dejarlo por ahí,

71
00:09:56,440 --> 00:10:12,880
vamos, después vamos a ver. Bueno, ya en fines de los años 60, las reglas morfológicas son

72
00:10:12,880 --> 00:10:20,120
muy parecidas a las reglas fonéticas, es decir, cómo transformar una palabra en sonidos ¿de acuerdo?

73
00:10:20,120 --> 00:10:26,680
Hay una similitud, yo tengo la forma de superficie y después la mapeo a los fonemas que la producen

74
00:10:26,680 --> 00:10:34,560
y al revés ¿de acuerdo? Es un problema muy similar. De hecho, lo que se llama en alternaciones en

75
00:10:34,560 --> 00:10:41,200
la fonética, ya en los años 60 se describían por reglas de reescritura que decía bueno,

76
00:10:42,200 --> 00:10:56,120
reglas de este tipo ¿no? Si hay una I adelante y una P después, la N se transforma en N ¿de acuerdo?

77
00:10:56,120 --> 00:11:02,480
Entonces la palabra que podría ser pegar IN, con posible en realidad debería ser imposible.

78
00:11:05,600 --> 00:11:10,280
Pero no estaba claro cómo usarlas para analizar, se sabía que había reglas que

79
00:11:10,280 --> 00:11:16,160
uno usaba este tipo de reglas engascadas para generar la palabra, pero no se sabía bien cómo

80
00:11:16,160 --> 00:11:21,840
usarlas para el análisis. ¿Por qué este tipo de reglas, en su formato más genérico, son igual

81
00:11:21,840 --> 00:11:32,920
de expresivas que una máquina de Turing? O sea, que podría expresar lenguajes tan complejos como

82
00:11:32,920 --> 00:11:37,720
se quisiera y cuando uno es muy expresivo en un formalismo, el costo que paga cuál es,

83
00:11:38,720 --> 00:11:45,880
que es computacionalmente muy costoso en el caso general. Los automáticos finitos son muy sencillos,

84
00:11:47,640 --> 00:11:52,960
los automáticos finitos no son muy expresivos, no son tan expresivos, pero son muy eficientes

85
00:11:52,960 --> 00:12:00,080
computacionalmente. En cambio, si yo modelo con máquinas de Turing tengo problemas de

86
00:12:00,080 --> 00:12:07,680
eficiencia, potenciales problemas de eficiencia, así me siento una computadora completa para el poder

87
00:12:07,680 --> 00:12:13,400
computacional igual a la computadora. Bueno, entonces quedaron por ahí, esas reglas quedaron por

88
00:12:13,400 --> 00:12:23,240
ahí por allá por los años 60. En 1972, un señor que se llamaba Johnson dijo, bueno, pero esto,

89
00:12:23,240 --> 00:12:34,640
esto es medio difícil de aplicar sin más contexto, pero los fonologistas siempre asumían que si yo

90
00:12:34,640 --> 00:12:43,720
cambiaba la n por la m, yo estoy analizando esta palabra, ¿no? Y yo cambio la n por la m,

91
00:12:44,600 --> 00:12:52,000
luego sigo avanzando haciendo otros cambios en la palabra, no utilizo esa n como nuevo,

92
00:12:52,000 --> 00:13:00,520
esta m que puse como parte de otra regla. Eso computacionalmente es muy importante,

93
00:13:02,920 --> 00:13:09,440
porque, porque permite, si yo saco esas restricciones, es decir, si yo siempre que digo después que

94
00:13:09,440 --> 00:13:13,840
reemplazo algo me sigo moviendo en la tira original, reemplazo en esta, al hacer esta

95
00:13:13,840 --> 00:13:19,720
transformación, ¿no? ¿Se entienden? Yo estoy, mi idea es ir por el lado de gatito e ir generando

96
00:13:19,720 --> 00:13:24,600
esto, ¿de acuerdo? Analizar esta entrada y ir generando esta salida, ese es nuestro problema.

97
00:13:25,800 --> 00:13:30,960
Si yo aplico una regla y me muevo hacia adelante una regla de este tipo de sustitución,

98
00:13:33,200 --> 00:13:40,600
de esta, pero este beta que yo sustituyo acá, este alfa que sustituyo por un beta, luego no lo

99
00:13:40,600 --> 00:13:48,520
uso con, para otra regla, las propiedades formales de esa transformación hacen que

100
00:13:48,520 --> 00:13:55,520
esas reglas se pueden escribir por transductores. Yo tengo la posibilidad de escribir este tipo

101
00:13:55,520 --> 00:14:02,880
de reglas de reescriptura con transductores, es decir, en el estado finito. Todo esto es un

102
00:14:02,880 --> 00:14:06,720
tema muy, muy, muy largo y como yo le decía en algún momento mismo un curso sobre esto,

103
00:14:06,800 --> 00:14:16,600
pero la idea de esto es que entendieron que ese tipo de sustituciones que yo hago eran

104
00:14:16,600 --> 00:14:20,760
computacionalmente equivalentes a un transductor de estado finito y por lo tanto estaban en el,

105
00:14:20,760 --> 00:14:25,760
en el lado del estado finito. O sea que eran potencialmente eficientes. Nadie se enteró

106
00:14:25,760 --> 00:14:31,400
porque en esa época no había internet. Bueno, voy a parar unos pocos, de los cuales Johnson se ve que

107
00:14:31,400 --> 00:14:41,200
no estaba. Por allá por 1980 aparece en Kaplan y Kei que dicen bueno, redescubren esto de Johnson.

108
00:14:41,200 --> 00:14:45,720
Dicen bueno, pero entonces las reglas de reescriptura, si yo puedo escribir reglas de

109
00:14:45,720 --> 00:14:51,640
reescriptura para modelar la morfología, yo voy a escribir relaciones regulares. ¿Se acuerdan

110
00:14:51,640 --> 00:14:55,320
de las relaciones regulares que vimos en la clase pasada, no? Las relaciones esas que los

111
00:14:55,320 --> 00:15:02,880
transductores representaban, las reglas de reescriptura se pueden ver como relaciones

112
00:15:02,880 --> 00:15:08,160
regulares. Yo puedo modelar las de esa forma y entonces yo podría representar todas estas

113
00:15:08,160 --> 00:15:11,440
sustituciones con transductores. El problema era que en ese momento los transductores los hacían

114
00:15:11,440 --> 00:15:15,520
a mano como tratamos de hacer nosotros los trans, el transductor que hacía el plural, ¿se acuerdan?

115
00:15:15,520 --> 00:15:19,720
Que empezamos a hacer un estado de autómodo y nos armamos un lío de bárbaro porque los hacían

116
00:15:19,720 --> 00:15:28,920
a mano, pero sobre esa base teórica se empezaron a implementar operaciones genéricas que permitían

117
00:15:28,920 --> 00:15:39,280
representar más sencillamente ese tipo de sustitución. Pero además había otro problema y era el siguiente,

118
00:15:39,280 --> 00:16:04,960
que si yo tengo una palabra que dice esto es fonología, ¿no? K-N-PAT. Acá es como es la

119
00:16:04,960 --> 00:16:10,600
estructura de la palabra, yo estoy generándola a la palabra. Acá es lo que dice que hay una regla

120
00:16:10,600 --> 00:16:19,760
que si esta N fonológica se transforma en una M si hay una P después, o sea que suena como una M

121
00:16:19,760 --> 00:16:26,560
después. Esto es una representación abstracta del sonido, ¿tá? Es como que fuera, está acá abajo,

122
00:16:27,560 --> 00:16:34,200
¿de acuerdo? La regla dice esta N grandota que es una marca de fonema, digamos, no sé exactamente

123
00:16:34,200 --> 00:16:42,920
como se dice en coso de fonólogos, se transforma en una M, en una N, perdón, antes de una P.

124
00:16:42,920 --> 00:16:55,560
Sí, en una M, antes de una P, entonces yo acá esto digo K-M-PAT, ¿de acuerdo?

125
00:16:58,840 --> 00:17:10,600
Pero además, pero además, la P, por una cuestión de ortografía, se transforma en una M

126
00:17:10,600 --> 00:17:22,280
si lo que hay antes es una M misma, ¿tá? Entonces esta palabra se debería expresar como K-M-PAT, ¿de acuerdo?

127
00:17:23,600 --> 00:17:30,760
Hay una transformación acá y hay otra transformación acá. Y esta es mi palabra destino. De una

128
00:17:30,760 --> 00:17:39,560
representación fonológica, léxica, pasé una representación de superficie, ¿sí? Pero el problema

129
00:17:39,600 --> 00:17:48,280
es que si yo tengo esta representación de superficie, ¿cuál es el análisis? ¿El análisis lo tengo por acá?

130
00:17:52,800 --> 00:17:56,560
¿De acuerdo? Todas estas palabras,

131
00:17:58,760 --> 00:18:08,960
sí, todas estas análisis de palabras pueden ser válidas para generar esta forma de superficie.

132
00:18:10,560 --> 00:18:16,120
Porque todas darían lo mismo si yo, aunque yo, porque esta regla solo aplica cuando hay una

133
00:18:16,120 --> 00:18:23,360
N grande, si no hay una N grande, no aplica. ¿Se entiende cuál es la situación? Que yo tengo

134
00:18:23,360 --> 00:18:29,760
problemas de no determinismo, que yo para generar, no tengo problemas, pero para volverme pueden

135
00:18:29,760 --> 00:18:38,840
generar muchas, ¿sí? Entonces, ¿no saben qué hacer con esto? Porque decían, bueno, pero entonces

136
00:18:38,840 --> 00:18:46,640
acá ¿qué hago yo con él? ¿Cuál de estas tres es la aposta? ¿Cuál es la buena, digamos?

137
00:18:48,760 --> 00:18:53,120
¿Cómo sé que esta es buena y esta dos no?

138
00:18:53,120 --> 00:19:05,120
Y lo que descubrieron por allá por los años 80 es que yo sé que es la buena,

139
00:19:05,120 --> 00:19:10,840
yo, que esta puede ser buena, porque esta no tienen sentido como forma eléxicas. Son

140
00:19:10,840 --> 00:19:15,720
formas aléxicas que no tienen, que si yo las busco en el dicionario formas eléxicas posibles,

141
00:19:17,200 --> 00:19:22,400
no van a aparecer. Pero acá tengo un problema, que es el de la que hace pasada. Yo no puedo meter

142
00:19:22,400 --> 00:19:28,520
todas las combinaciones en un dicionario posible, porque son demasiadas, pero lo que sí puedo hacer

143
00:19:28,520 --> 00:19:37,600
es meter otro transductor que lo único que haga es decirme cuáles son las posibles combinaciones

144
00:19:37,600 --> 00:19:45,680
que hay de prefijo y sufijo y afijos. Entonces yo, si construyo un transductor que haga estas

145
00:19:45,680 --> 00:19:52,080
reglas y la pego un transductor que identifique las posibles combinaciones, tengo algo que,

146
00:19:52,080 --> 00:19:58,120
daba una palabra, una combinación, me devuelve su forma de superficie y al revés también.

147
00:19:59,160 --> 00:20:05,200
Y eso es justamente lo que hace la morfología de Estado Finito. Yo tengo un repositorio para

148
00:20:05,200 --> 00:20:11,920
palabras que se llama lexicón, que eso en realidad es un repositorio de morfemas,

149
00:20:12,920 --> 00:20:20,560
que generalmente almacena los lemas, los prefijos y los sufijos y lo que llamamos morfotácticas.

150
00:20:20,560 --> 00:20:28,920
Las morfotácticas, lo que son son todas las combinaciones posibles que hay de morfemas en

151
00:20:28,920 --> 00:20:34,800
el lenguaje. ¿Qué morfemas se pegan con las cosas? ¿Se acuerdan de inelefantemente,

152
00:20:34,800 --> 00:20:41,440
que esto puede hacerlo y esto no? Bueno, esos son las morfotácticas. ¿Qué prefijo pueden seguir

153
00:20:41,440 --> 00:20:46,600
a otro? Es decir, yo no puedo tener dos plurales seguidos. Esa es una morfotáctica, es decir,

154
00:20:46,600 --> 00:20:52,880
yo tengo una palabra que termina en A, bueno, si es un sustantivo y además después puede

155
00:20:52,880 --> 00:21:00,320
opcionalmente tener una S para darle el plural, entre otras cosas. Entonces, yo puedo escribir

156
00:21:00,320 --> 00:21:07,680
reglas de ese tipo. Entonces, tengo que tener en cuenta estas cosas. Hay un morfema que es

157
00:21:07,760 --> 00:21:11,920
nocional, lo que acabo de decir, los afijos dependen del arraillo, puedo decir imposible,

158
00:21:11,920 --> 00:21:19,040
pero no inimportante, porque mi idioma no es válido, y en general la derivación es más complicada

159
00:21:19,040 --> 00:21:22,400
que la aflexión, porque la aflexión tiene un comportamiento más regular, principalmente porque

160
00:21:22,400 --> 00:21:26,040
es finito, porque no es creativa la aflexión. ¿Se acuerdan de la aflexión? Era para hacer

161
00:21:26,040 --> 00:21:32,360
los plurales, los que no cambiaban la clase de la palabra o el significado, plurales, género,

162
00:21:33,080 --> 00:21:41,240
verbos, conjugación de verbos. Entonces, bueno, los transductores léxico, que fue lo que en

163
00:21:41,240 --> 00:21:46,320
los años 80 se introdujeron para resolver el problema de la morfología, lo que hacen el

164
00:21:46,320 --> 00:21:50,960
parcin morfológico, y entonces dicen, bueno, yo lo que quiero es una correspondencia entre el nivel

165
00:21:50,960 --> 00:22:00,280
léxico, que es una colección de morfemas, y el nivel de superficie. Si yo veo los automatas

166
00:22:00,280 --> 00:22:08,440
de estado finito como automatas sobre dos cintas, yo podría ver la transformación entre una palabra

167
00:22:08,440 --> 00:22:15,400
y sus marcas como simplemente una transducción que me lleva de la g, la g, la a, la a, y por acá

168
00:22:15,400 --> 00:22:21,560
empieza a cambiar y a generar sobre el alfabeto del lado léxico. ¿De acuerdo? ¿Se tiende más o menos?

169
00:22:23,160 --> 00:22:29,160
¿Sí? Entonces yo voy a tener un transductor de estado finito que de un lado tiene la forma

170
00:22:29,160 --> 00:22:41,080
de superficie y la otra la eléxica. Pero además teníamos el tema de las reglas ortográficas,

171
00:22:41,080 --> 00:22:49,520
o sea, hasta ahora yo tengo, fíjense que yo tengo palabras y cómo pegar, perdón, morfema,

172
00:22:49,520 --> 00:22:55,480
tengo la lista de palabras posibles, de morfemas posibles, la raíz, el sofígráfico, lo tengo

173
00:22:55,480 --> 00:23:04,120
todo junto por un lado. Tengo la s solita, la a solita, la o, y después tengo gát, per, cas,

174
00:23:06,120 --> 00:23:15,120
murciélag, ¿no? Y mente, mente es para decir elefante mente. Y después tengo las morfas

175
00:23:15,120 --> 00:23:20,480
tácticas que dice que elefante mente no se puede. Si siguen luego esta clase lo que hemos introducido al

176
00:23:20,480 --> 00:23:30,480
idioma, entonces vamos a poder también. Pero nos falta la regla ortográfica. Si yo digo tengo

177
00:23:30,480 --> 00:23:36,560
in por un lado, tengo importante por el otro, pero yo no digo, bueno no, dijimos que era importante,

178
00:23:36,560 --> 00:23:45,480
no. Tengo in imposible, yo tengo imposible. La p me da imposible, que no es válido, porque la n

179
00:23:45,480 --> 00:23:50,880
tiene que cambiarse por una m, porque estaba adelante una p, como no se enseñan desde segundo

180
00:23:50,880 --> 00:23:55,480
año de escuela. Entonces nos falta la regla ortográfica. Y bueno, la regla ortográfica también

181
00:23:55,480 --> 00:24:03,720
pueden representarse por un traductor que modifique en una cascada lo que la regla anterior transformó.

182
00:24:07,040 --> 00:24:12,480
Entonces no queda una cosa así, el modelado sea una cosa así. Yo tengo la forma de superficie,

183
00:24:13,480 --> 00:24:21,200
una especie de forma intermedia, una especie de forma intermedia que dice bueno acá apareció

184
00:24:21,200 --> 00:24:28,880
Ito, la marca Ito, y luego el análisis posta. Ito quiere decir masculino singular diminutivo.

185
00:24:31,040 --> 00:24:32,760
Y todo eso lo represento con traduptores.

186
00:24:36,440 --> 00:24:42,080
Este era el modelo que proponía a Koskenyemi, que para la regla ortográfica proponía muchos

187
00:24:42,080 --> 00:24:46,440
traductor en paralelo, pero en realidad esto terminó evolucionando hacia otra cosa, que son

188
00:24:46,440 --> 00:24:52,680
una cascada de reglas, que es lo que vamos a ver ahora, que es lo que introdujeron Lauri Cartioune.

189
00:24:52,680 --> 00:24:55,440
Eran todos finlandeses, ¿sacuerdan del finlandés? Eran medio.

190
00:24:58,160 --> 00:25:04,480
Y este paper, que es muy famoso de los Badenetaria, del año 94, lo que dicen es

191
00:25:04,480 --> 00:25:13,000
Kaplan y Kei propone, muestran que los traduptores eran equivalentes a esa algebra que hablamos

192
00:25:13,000 --> 00:25:18,920
en la clase pasada de relaciones regulares, y es lo que dice la fortaleza de nuestro método surge

193
00:25:18,920 --> 00:25:25,560
de la equivalencia. Mientras razonamos, pero sus relaciones regulares en términos algebraico,

194
00:25:25,560 --> 00:25:30,200
de teoría y conjuntos, describimos los conjuntos de discusión por medio operaciones

195
00:25:30,200 --> 00:25:34,880
constructivas sobre los traduptores de estado finito correspondiente. Al final, por supuesto,

196
00:25:34,880 --> 00:25:38,840
es el traductor el que satisface nuestra necesidad de computacionales. ¿Qué quiere decir esto? Que

197
00:25:38,840 --> 00:25:44,360
yo puedo modelar con expresiones regulares y los traduptores me vienen gratis. Que yo tengo,

198
00:25:44,360 --> 00:25:49,800
al modelarlo a través de unas reglas, yo transformar los traduptores es una cosa automática.

199
00:25:49,800 --> 00:26:01,200
Y eso es justamente lo que vamos a hacer. Vamos a escribir reglas. Yo acá lo voy a mostrar con

200
00:26:01,200 --> 00:26:06,040
un lenguaje de expresiones regulares, que es el de Xerox, que es uno de los más conocidos.

201
00:26:07,560 --> 00:26:17,480
Vamos a ver rápidamente operaciones sobre expresiones regulares y cómo escribirlas

202
00:26:17,640 --> 00:26:22,400
y cómo se transforman esos traduptores. Y después vamos a escribir con eso la morfología

203
00:26:22,400 --> 00:26:30,640
de un lenguaje. Entonces, bueno, ¿qué quiere decir esto? Yo tengo. Voy a tener una expresión

204
00:26:30,640 --> 00:26:42,120
regular. Esto es como se escribe en el lenguaje o relación de acá al lado. Estos son lenguajes.

205
00:26:42,840 --> 00:26:52,480
Atacas uno. El Xero denota a Epsilon en el lenguaje vacío. O sea que yo estoy...

206
00:26:54,800 --> 00:26:58,560
Perdón, acabo de decir una cosa que si me escuchan mis compañeros de teoría del lenguaje,

207
00:26:58,560 --> 00:27:06,440
me matan. Epsilon no es el lenguaje vacío, sino el string vacío. Lo único que tiene es el string vacío.

208
00:27:12,120 --> 00:27:18,200
O la correspondiente relación de identidad, ¿no? En todo esto nosotros estamos denotando

209
00:27:18,200 --> 00:27:23,840
relaciones pares de strings. ¿Se acuerda, no? Es decir, yo tengo una entrada o una salida en el traductor.

210
00:27:23,840 --> 00:27:30,240
A un lenguaje yo lo puedo ver como un caso especial de una relación que es en la cual la entrada

211
00:27:30,240 --> 00:27:39,000
es igual que la salida. El mapeo es uno. Entonces yo acá el Epsilon denota o lenguaje o la relación

212
00:27:39,000 --> 00:27:46,920
correspondiente de identidad. Este símbolo quiere decir cualquier cosa que denota a cualquier

213
00:27:46,920 --> 00:27:54,120
string que tiene un símbolo suelo, excepto de Epsilon. Y si yo pongo A es el string hecho

214
00:27:54,120 --> 00:27:58,920
con solamente la letra A. ¿De acuerdo? Se acuerdan la diferencia entre símbolo y string, ¿no?

215
00:27:58,920 --> 00:28:04,680
El string son símbolos pegados, digamos. Yo tengo un string de un solo símbolo,

216
00:28:04,680 --> 00:28:10,200
pero no es lo mismo un símbolo, un string, así. Pero yo también puedo escribir en mi expresión y

217
00:28:10,200 --> 00:28:15,680
acá viene la novedad respecto a lo... cosas como esto. Especificar que este símbolo A lo leo en

218
00:28:15,680 --> 00:28:24,000
la entrada, pero en la salida no devuelvo la propiedad sino una vez. Y esto, A, 2 puntos A,

219
00:28:24,000 --> 00:28:30,440
es equivalente a A solo. Escribir A solo es lo mismo que escribir A, se mapea A. Por defecto,

220
00:28:30,440 --> 00:28:34,960
yo asumo que si no pongo nada, lo mapeo en la misma salida que la entrada, ¿sí?

221
00:28:37,480 --> 00:28:46,920
Excepto, y esto es una cuestión de notación, acá, ¿sí? ¿Qué quiere decir que cualquier cosa

222
00:28:46,920 --> 00:28:50,200
mapea con cualquier cosa quiere decir que valen todos contra todos, como el producto cartesiano de

223
00:28:50,200 --> 00:28:57,440
símbolos, yo? O sea, que yo escribir esto no es lo mismo que escribir esto, porque acá lo que

224
00:28:57,440 --> 00:29:02,560
estoy diciendo es cualquier símbolo y devuelvo el mismo y acá estoy diciendo cualquier símbolo y

225
00:29:02,560 --> 00:29:10,240
devuelvo cualquier símbolo, o sea que la salida es múltible. Bueno, y pasan más cosas, ¿no?

226
00:29:10,240 --> 00:29:17,200
Yo puedo usar paréntesis, puedo decir una o más veces lo que estaba antes, cero o más veces lo

227
00:29:17,200 --> 00:29:21,800
que estaba antes. ¿Esto qué quiere decir? Cualquier cosa cero o más veces, o sea que esto es

228
00:29:21,800 --> 00:29:29,680
el lenguaje universal, es decir, máster. Y esto es cualquier cosa, siempre y cuando tenga la

229
00:29:29,680 --> 00:29:33,200
misma relación de entrada y salida, el mismo largo de entrada y salida, es decir, mapeo cualquier

230
00:29:33,200 --> 00:29:41,400
símbolo a otro, pero a uno o uno. Y yo puedo definir el complemento que solo está definido

231
00:29:41,400 --> 00:29:45,600
por lenguaje, la negación, hay algunas presiones regulares que son muy interesantes, porque por

232
00:29:45,600 --> 00:29:56,960
ejemplo, contiene a, parece muy sencilla describir, pero en realidad no es tan fácil, es cualquier cosa,

233
00:29:56,960 --> 00:30:01,960
la expresión y cualquier cosa, pero tiene que ser cualquier cosa que no tenga a, esencialmente.

234
00:30:03,960 --> 00:30:08,440
Hay todo, cada uno de estos operadores tiene un paper, digamos, por decirlo de alguna forma.

235
00:30:09,160 --> 00:30:16,400
Esto es, la expresión A sin contar las cosas que también, estas muchas se usan para definir otros

236
00:30:16,400 --> 00:30:28,600
operadores más avanzados que vienen después. Acá tengo la unión, esa OV, la intersección,

237
00:30:28,600 --> 00:30:32,640
ojo que la intersección solo está definida para las expresiones regulares, para cuando son

238
00:30:32,640 --> 00:30:36,400
expresiones, porque las relaciones, si se acuerdan de las clases traductoras, no son en general

239
00:30:36,400 --> 00:30:45,680
cerradas bajo intersección. Y este es el producto cartesiano que es muy importante, es, si yo expreso

240
00:30:45,680 --> 00:30:53,520
acá un conjunto de tiras, cualquiera, tiras que empiezan con A, las mapeo a todas las tiras

241
00:30:53,520 --> 00:31:06,120
de la otra presión. Si yo digo, por ejemplo, Aaster, producto cartesiano Baster, lo que tengo es un

242
00:31:06,160 --> 00:31:12,120
traductor que me devuelve, para cada tira que empieza, cualquier tira que empieza con A me la devuelve

243
00:31:12,120 --> 00:31:19,400
en cualquier tira que empieza con B, si es el producto cartesiano de los dos conjuntos, sencillamente.

244
00:31:19,400 --> 00:31:28,320
Estas son las proyecciones, el reverso, el inverso, y este es muy importante, es la composición,

245
00:31:28,320 --> 00:31:33,800
¿se acuerdan cuál era la composición de traductoria? ¿Quién se acuerda cuál era la composición? Es muy importante.

246
00:31:37,120 --> 00:31:39,120
¿Aguien se acuerda, nadie, ¿se acuerda?

247
00:31:45,120 --> 00:31:53,120
La composición era, yo tenía un traductor por acá, que tomaba una entrada y devolvió una salida,

248
00:31:55,120 --> 00:32:02,120
y tenía otro acá, que también tenía una entrada y devolvió una salida, la composición era la aplicación

249
00:32:02,120 --> 00:32:14,120
cascada de los dos, es decir, yo tomo una entrada, tengo una salida y esa salida la paso por este

250
00:32:14,120 --> 00:32:23,120
traductor, y como los traduptores son cerrados bajo composición, eso quiere decir que si yo luego

251
00:32:23,120 --> 00:32:31,120
puedo modelar esto, una regla con esto, y luego la aplicación de, y luego otra que tiene la segunda,

252
00:32:31,120 --> 00:32:39,120
la aplicación de los dos en cascada se puede modelar por un traductor que hace las dos cosas a la vez,

253
00:32:39,120 --> 00:32:41,120
y nosotros vamos a usar eso.

254
00:32:42,120 --> 00:32:52,120
Bueno, hay toda una área de análisis ahí que son los operadores de reemplazo, que es forma de decir,

255
00:32:52,120 --> 00:32:59,120
bueno, cada vez que aparezca A, reemplazámelo por B en la salida, por ejemplo, cada vez que diga

256
00:32:59,120 --> 00:33:07,120
y pasámelo a masculino, por decir una pagada que no tiene sentido en este caso,

257
00:33:07,120 --> 00:33:11,120
pero ahora vamos a ver cómo combinamos todo esto.

258
00:33:11,120 --> 00:33:16,120
Hay un montón de operadores de reemplazo, dependiendo del contexto en el que aparecen,

259
00:33:16,120 --> 00:33:20,120
si yo reemplazo opcionalmente, etcétera.

260
00:33:25,120 --> 00:33:32,120
Los operadores de reemplazo tienen algún problema, o alguna complejidad, y es la siguiente,

261
00:33:33,120 --> 00:33:41,120
si yo tengo, por ejemplo, esta regla.

262
00:33:53,120 --> 00:33:56,120
¿Cómo leemos esta regla? Alguien me dice cómo leemos esta regla.

263
00:33:56,120 --> 00:34:00,120
¿Como leemos esta regla?

264
00:34:00,120 --> 00:34:03,120
Cómo leemos esta regla.

265
00:34:03,120 --> 00:34:08,120
Cualquier tira que empiece con la B, se supele por C.

266
00:34:08,120 --> 00:34:12,120
Cualquier tira. ¿Está bien?

267
00:34:12,120 --> 00:34:15,120
Cualquier tira.

268
00:34:15,120 --> 00:34:18,120
Bien.

269
00:34:18,120 --> 00:34:23,120
Ya le voy a dar un punto más para el fin de año, pero por hablar con él.

270
00:34:23,120 --> 00:34:26,120
Después me pasan los nombres.

271
00:34:26,120 --> 00:34:31,120
Exacto, es A y cualquier cantidad de B es lo mismo, que empiece con la B.

272
00:34:31,120 --> 00:34:37,120
No, no es cualquiera que empiece con la B, es A y cualquier cantidad de B.

273
00:34:37,120 --> 00:34:40,120
Se reemplaza por C.

274
00:34:40,120 --> 00:34:44,120
La pregunta es ¿cuál es la salida de esto?

275
00:34:44,120 --> 00:34:46,120
C.

276
00:34:46,120 --> 00:34:48,120
¿Cuál es?

277
00:34:48,120 --> 00:34:50,120
C.

278
00:34:50,120 --> 00:34:52,120
¿O?

279
00:34:52,120 --> 00:34:54,120
C.

280
00:34:54,120 --> 00:34:56,120
O, C.

281
00:34:56,120 --> 00:34:58,120
¿O, C.

282
00:34:58,120 --> 00:35:00,120
¿O, C.

283
00:35:00,120 --> 00:35:02,120
¿O, C.

284
00:35:02,120 --> 00:35:04,120
¿O, C.

285
00:35:04,120 --> 00:35:06,120
O, C.

286
00:35:06,120 --> 00:35:08,120
¿O, C.

287
00:35:08,120 --> 00:35:10,120
¿O, C.

288
00:35:10,120 --> 00:35:12,120
¿O, C.

289
00:35:12,120 --> 00:35:14,120
¿Y hay ahora más?

290
00:35:14,120 --> 00:35:16,120
C.

291
00:35:16,120 --> 00:35:18,120
¿Por qué pasa esto?

292
00:35:18,120 --> 00:35:24,120
La definición de transductor o de regla de reemplazo para estas tres es válida porque no es determinista.

293
00:35:24,120 --> 00:35:27,120
Pero muchas veces nosotros queremos decir algo.

294
00:35:27,120 --> 00:35:32,120
Queremos decir bueno, en realidad yo lo que quería decir acá era que hay todas las veces posibles.

295
00:35:32,120 --> 00:35:43,120
Entonces hay también operadores que permiten decir si yo maché o la más tira más larga o la más corta.

296
00:35:43,120 --> 00:35:48,120
Con la impresión regular si ustedes se acuerdan cuando uno busca tiene esa posibilidad.

297
00:35:48,120 --> 00:35:50,120
De decir maché o lo más largo o lo más corte.

298
00:35:50,120 --> 00:35:54,120
Entonces hay un operador especial que se llama...

299
00:35:54,120 --> 00:36:00,120
Bueno, el longest match sería C, ¿verdad?

300
00:36:00,120 --> 00:36:04,120
En lo más largo que puedo machar es A y todas las veces.

301
00:36:04,120 --> 00:36:10,120
Y el shortest match es solo mapear la A en esta presión regular.

302
00:36:10,120 --> 00:36:13,120
A, B, A, A, S.

303
00:36:13,120 --> 00:36:17,120
Hay operadores que permiten escribir eso justamente.

304
00:36:17,120 --> 00:36:21,120
Longest match.

305
00:36:21,120 --> 00:36:25,120
También tengo problemas similares, yo no voy a entrar en detalle acá.

306
00:36:25,120 --> 00:36:32,120
También puedo tener problemas porque muchas veces asumo que reemplazo de izquierda a derecha.

307
00:36:32,120 --> 00:36:53,760
Pero si yo por ejemplo en esta tira reemplazo A B por A, entonces yo lo que voy a hacer

308
00:36:53,760 --> 00:37:08,880
es sustituir esta A por una B y esta nueva A funciona de contexto para la siguiente expresión y eso no

309
00:37:08,880 --> 00:37:12,720
voy a entrar en detrás acá, lo puedo resolver de diferente forma porque yo podría resolverlo, yo

310
00:37:12,720 --> 00:37:15,640
estoy asumiendo que voy de izquierda a derecha pero podría ir de derecha a izquierda sin ningún

311
00:37:15,640 --> 00:37:20,240
problema porque nada me dice que yo analice la tira izquierda a derecha, entonces yo podría venir para

312
00:37:20,240 --> 00:37:28,040
atrás y encontrar, bueno acá no me va a aplicar porque la B no, acá me va a dar lo mismo porque la

313
00:37:28,040 --> 00:37:40,840
B recién encuentra acá, bueno no, está bien, esto me va a devolver A B B acá, en este caso da

314
00:37:40,840 --> 00:37:44,600
lo mismo porque no es amigo pero el caso es que de izquierda a derecha te da diferente que derecha

315
00:37:44,600 --> 00:37:55,680
de izquierda, y lo mismo y con todas sus combinaciones, no nos compliquemos mucho. Bien, entonces bueno

316
00:37:55,680 --> 00:38:00,520
todo esto que es una presentación muy rápida de la esjebra esencialmente lo que nos permite es

317
00:38:00,520 --> 00:38:07,400
como le decía escribir transducciones y el asunto es cómo usamos esto para representar la

318
00:38:07,400 --> 00:38:11,400
morfología en un lenguaje, bueno, entonces hagamos lo siguiente.

319
00:38:11,400 --> 00:38:28,440
No, exactamente no, son todas operaciones algunas muy complejas, muy complejas, el reemplazo por

320
00:38:28,440 --> 00:38:35,920
ejemplo es muy complejo y se construyen unas sobre otras, pero son todas syntactic sugar,

321
00:38:35,920 --> 00:38:41,120
digamos, es decir ninguna introduce nuevas operadores, al final del día son siempre los

322
00:38:41,120 --> 00:38:48,720
mismos operadores, hay algunos, al final del, al final de la presentación hay una bibliografía

323
00:38:48,720 --> 00:38:55,120
ahí y hay algunos artículos, hay un artículo que se llama The Replace Operator, el artículo

324
00:38:55,120 --> 00:39:01,120
muestra cómo definir el operador de reemplazo a partir de las operaciones primitivas, y hay otro

325
00:39:01,120 --> 00:39:06,880
que es el Longest Match y Shortest Match, y hay otro que dice cómo es el reemplazo

326
00:39:06,880 --> 00:39:18,240
opcional, eso fue toda una construcción de esa esja. Bueno, entonces vamos a ver un ejemplo

327
00:39:18,240 --> 00:39:30,160
de cómo funciona esto, que está en el práctico que publicamos y que dice, bueno yo tengo el

328
00:39:30,160 --> 00:39:39,440
uno ¿no? Bambona, sí, nosotros tenemos un lenguaje que se llama Bambona, que tiene sustantivos,

329
00:39:39,440 --> 00:39:48,720
vamos a hablar solo de los sustantivos de Bambona, y tiene la siguiente característica,

330
00:39:48,720 --> 00:39:58,240
hay siete vocales en Bambona, que son esas que están ahí, la I, la E, la E tilde, A, U, O y O,

331
00:39:58,240 --> 00:40:04,400
y no las vocales, ¿sí? Y los sustantivos en Bambona comienzan siempre con una raíz que

332
00:40:04,400 --> 00:40:09,040
usualmente sigue el patrón consonante, vocal, consonante, o consonante, vocal y dos consonante,

333
00:40:10,000 --> 00:40:17,760
por ejemplo, MAV quiere decir libro, COP quiere decir reactor nuclear y LER quiere decir chancho,

334
00:40:17,760 --> 00:40:24,400
por daros uno ejemplo ¿no? Esto es anecdótico lo que quieren decir en nuestro lenguaje,

335
00:40:24,400 --> 00:40:29,760
porque a nosotros lo que nos importa es que las raíces son estas, con lo que comienzan,

336
00:40:29,760 --> 00:40:33,520
pero siempre, ahí ya tenemos un dato, siempre comienzan con una raíz, o sea, no es siempre fijo.

337
00:40:39,520 --> 00:40:47,200
También después de eso, los sustantivos tienen un sufijo opcional, que puede ser ACK, ETH o HIG,

338
00:40:47,200 --> 00:40:57,360
o sea que NUT HIG es un gran circuito integrado, y LERET es un chanchito.

339
00:41:00,400 --> 00:41:05,440
Un máximo de uno de estos tres sufijos puede aparecer una palabra, y yo lo voy a marcar como

340
00:41:05,920 --> 00:41:13,680
PEJ, MADIM o AU, en el lado del éxico. ¿Se entiende lo que estamos haciendo, ¿no? Estamos,

341
00:41:13,680 --> 00:41:18,400
a partir de la palabra, estamos generando su estructura. Luego ha sido, opcionalmente,

342
00:41:18,400 --> 00:41:28,400
un sufijo único que indica la confianza del hablante, ISM, o sea que yo si digo SOBETH, ISM,

343
00:41:29,120 --> 00:41:39,440
estoy diciendo, es un pequeño dentista y lo estoy diciendo, y estoy manifestando lo que es evidente

344
00:41:39,440 --> 00:41:45,040
de la realidad. Hay cosas que nosotros no tenemos forma de expresar en una lenguaje, lo expresamos

345
00:41:45,040 --> 00:41:51,040
con gesto. Luego sigue un sufijo único que indica la confianza, no, ya lo dije, y lo voy a marcar como

346
00:41:51,200 --> 00:41:57,760
obvio, probable y supuesto. Luego sigue una especie de sufijo de plural que quiere decir

347
00:41:57,760 --> 00:42:09,680
IL o EHAC, quiere decir unos pocos, y todas estas cosas que yo no sé qué son, que marcan otras

348
00:42:09,840 --> 00:42:22,800
características. La cuestión que pueden tener, a nosotros que somos computadoras, nos interesa el

349
00:42:22,800 --> 00:42:32,160
mapeo y no quiere decir. Y al final tenemos que el genitivo OSC, puede terminar una palabra,

350
00:42:32,160 --> 00:42:36,880
puede estar seguido de un sufijo ON, que denota posesión inalienable. EMIOT puede estar seguido

351
00:42:36,960 --> 00:42:42,400
por un sufijo EL, que es un intensificador. Hay gente que no está bien. En las palabras de

352
00:42:42,400 --> 00:42:47,680
Bambona, y esto es interesante, las consonantes P, T y K nunca son seguidas de las vocales

353
00:42:47,680 --> 00:42:53,920
frontales I, E o E-contile, sino por sus correspondientes U o O-contile y los pares de símbolo,

354
00:42:53,920 --> 00:43:03,760
blablabla. ¿Qué hacemos con esto? ¿Cuál era la tarea que queremos resolver? ¿Cuál era la tarea

355
00:43:03,760 --> 00:43:06,880
que queremos resolver? Si no me dicen cuál era la tarea que queremos resolver, no vamos a poder

356
00:43:06,880 --> 00:43:14,320
resolverla. Casi que por definición. ¿Qué queremos hacer nosotros? ¿Cuál es nuestro problema a resolver?

357
00:43:18,320 --> 00:43:28,720
¿Cuál es nuestro problema a resolver? ¿Qué quiere decir eso? ¿Qué quiere decir eso? ¿Cómo

358
00:43:28,800 --> 00:43:36,640
modelo eso? ¿Qué quiere decir que modela eso más? ¿Aliciar o generar? Aliciar o generar,

359
00:43:36,640 --> 00:43:40,480
lo que empezamos diciendo en la clase. Es decir, tengo una palabra en Bambona, quiero usar su estructura.

360
00:43:40,480 --> 00:43:46,560
O tengo una estructura, una forma léxica y quiero, o sea, que si yo te digo,

361
00:43:46,560 --> 00:44:11,000
este, si yo digo, como dije hoy, nat, ak, nat, ak, ism, estoy diciendo algo así como nat,

362
00:44:11,000 --> 00:44:28,640
que es casa más pejorativo, más obvio que lo margo como obvio. ¿De acuerdo? Eso es lo que yo

363
00:44:28,640 --> 00:44:35,440
tengo que hacer, es lo mismo que dijimos allá, pasar de la forma de superficie a la forma léxica.

364
00:44:40,440 --> 00:44:46,920
Y entonces, de acuerdo a lo que vimos hasta ahora, ¿qué es lo que yo necesito saber para

365
00:44:46,920 --> 00:44:56,480
hacer esto? ¿Qué cosas necesito tener? Nosotros dijimos que había tres cosas que se necesitaban

366
00:44:56,480 --> 00:45:09,600
para modelar la morfología, ¿cuáles eran? Sí, el lexicón, en realidad son los morfemas,

367
00:45:09,600 --> 00:45:18,520
los lemas malos sufijos, ¿no? Toda la partecita de gombones. ¿Cuáles son los lemas ahí? ¿Cuáles son

368
00:45:18,560 --> 00:45:35,880
los raíces y los afijos? Los morfemas, no sabía la palabra. ¿Cuáles son? ¿Cuáles son? ¿Cuáles son los morfemas? ¿Cómo

369
00:45:35,880 --> 00:45:44,440
formo la palabra en este caso? Es más fácil la pregunta, ¿cuáles son los morfemas? ¿Qué son

370
00:45:44,440 --> 00:45:48,760
los morfemas? Son todas esas palabras. ¿Qué son los morfemas? La hace uno. Son las partes

371
00:45:48,760 --> 00:45:53,560
chiquitas con las que se compone la palabra. ¿De qué estamos hablando? Viñaron las que se pasaron.

372
00:45:54,560 --> 00:46:00,960
Hubo clase con el partido y yo no me... Bueno, son esto, ¿no? Root, milk, so, no sé qué.

373
00:46:03,960 --> 00:46:10,440
Y todas estas, no sé qué, no sé cuánto. ¿De acuerdo? Y además tengo que saber para cada una

374
00:46:10,440 --> 00:46:23,480
de ellas que cuando aparece este acto... Tengo los afijos, ¿no? De acuerdo. Ese es mi... ¿Y cómo

375
00:46:23,480 --> 00:46:33,080
hago para expresar eso con un transductor? ¿Cómo haría un transductor que guarde todas estas palabras?

376
00:46:33,080 --> 00:46:46,440
¿Cómo lo hago? ¿Cómo lo hago? ¿Cómo hago un transductor? Si yo le digo a alguien un transductor

377
00:46:46,440 --> 00:46:57,200
que me guarde todas las palabras y dice, ¿qué hacen ustedes? ¿Qué hacen con esas palabras?

378
00:46:57,200 --> 00:47:04,080
¿Cómo hacen ustedes si yo le digo a cada uno un diccionario? ¿Qué es lo que hacen cuando yo le digo?

379
00:47:04,080 --> 00:47:09,600
No diccionario, Python, un diccionario, así de lo que se buscan. Bueno, ahora vienen en formato

380
00:47:09,600 --> 00:47:15,440
electrónico, pero ¿cómo escribo cada una de las palabras que tengo? Esto es lo mismo. Yo para

381
00:47:15,440 --> 00:47:20,000
empezar a tener mi lexicón tengo que hacer un ordre de todas las palabras que tengo. Un transductor

382
00:47:20,000 --> 00:47:26,720
que me permita recorrer cada palabra posible. O sea, un embole. Tengo que ponerla a todas las

383
00:47:26,720 --> 00:47:33,360
palabras. Y más, yo lo que pueda hacer generando va a depender de acá. No va a haber más sufijo

384
00:47:33,360 --> 00:47:38,280
que estos. Si yo tengo algún otro animal además de chancho, mientras no tenga la raíz, no voy a

385
00:47:38,280 --> 00:47:44,960
poder decirlo. Haga, no descubrimos nada. Toda la información del lexicón está dentro del

386
00:47:44,960 --> 00:47:50,920
transductor. Lo que tiene que es muy sencillo, es un transductor que lo único que hace es recorre

387
00:47:50,920 --> 00:48:07,040
con el morphema correspondiente. ¿Y qué devuelve? ¿Qué devolvería? Devuelve lo mismo, ¿no?

388
00:48:08,040 --> 00:48:14,040
Vamos a suponer que esto es un símbolo de tres. Yo podría hacer tres arco de lo mismo. ¿Tá?

389
00:48:14,040 --> 00:48:23,440
Y con lo sufico pasa lo mismo. ¿Qué operación del álgebra me permite expresar esto? ¿Qué operación

390
00:48:23,440 --> 00:48:34,320
del álgebra me permite expresar esto? ¿Qué operación de las que vimos?

391
00:48:37,040 --> 00:48:42,800
Pues yo puedo escribir el transductor derecho. Pero lo que yo puedo hacer es un transductor que

392
00:48:42,800 --> 00:48:48,080
solo olía mal, porque además acá puede haber combinaciones, ¿no? Porque así hay dos que

393
00:48:48,080 --> 00:48:56,720
empiezan con la misma letra, no es eficiente. Por ejemplo, karg y kusm, la k debería ser común.

394
00:48:56,720 --> 00:48:57,800
Ella es una cosa así, ¿no?

395
00:49:14,800 --> 00:49:21,880
¿De acuerdo? El transductor que le le hago. ¿Sí? ¿Pero cómo hago yo para expresar todas las

396
00:49:21,880 --> 00:49:24,360
palabras? Con una de las operaciones que vimos.

397
00:49:26,720 --> 00:49:40,960
Unión. Simplemente hago un transductor por cada palabra y hago la unión de ellos. Y esa es lo que

398
00:49:40,960 --> 00:49:45,040
yo le decía y lo que realidad es lo que decía el Kaplan y Kei. La gracia es que como yo tengo una

399
00:49:45,040 --> 00:49:49,320
operación definida, dada dos presiones regulares, construir, dada dos transductores, construir

400
00:49:49,320 --> 00:49:55,960
la unión, yo tengo un método constructivo para hacerlo. No tengo que hacer nada. Ya el método

401
00:49:55,960 --> 00:49:58,680
existe, lo único que voy a hacer es decirle a la computadora, así es la unión de todo,

402
00:49:58,680 --> 00:50:04,680
él calcula el automata. Entonces yo modelo de esa forma, modelo con presión regulares

403
00:50:04,680 --> 00:50:14,040
y utilizo las operaciones de transductor. Bien, eso es el lexicon, o sea que así voy

404
00:50:14,040 --> 00:50:20,240
a tener todas mis palabras. ¿Qué otra parte tenía el transductor? Digo, ¿qué otra parte

405
00:50:20,240 --> 00:50:27,760
tenía nuestro analizador? ¿Se acuerdan esa palabra? Morfotácticas. ¿Qué eran las morfotácticas?

406
00:50:27,760 --> 00:50:42,080
¿Qué eran las morfotácticas? Exacto. ¿Cómo se combinan? ¿Cuáles son las versiones autorizadas

407
00:50:42,080 --> 00:50:55,480
de combinación? ¿Cómo serían mis morfotácticas en este caso? Y bueno, es lo que hice acá.

408
00:50:55,480 --> 00:51:06,240
Yo digo, bueno, primero viene una raíz, ¿sí? ¿Qué puede ser una de estas? O sea que yo

409
00:51:06,240 --> 00:51:12,720
la raíla defino como la unión de todas estas. Y después viene un sufijo opcional, o sea

410
00:51:12,720 --> 00:51:18,920
que tengo que definir los sufijos, que es un or de estos tres, que van, además de ser

411
00:51:18,920 --> 00:51:27,000
un or, van a devolver en la salida estas marcas. Van a sustituir esto por esta marca. Y así

412
00:51:27,000 --> 00:51:36,520
papapas sigo pegando cosas, ¿sí? Y la pregunta es, ¿cómo digo ese, cuando yo digo, viene

413
00:51:36,520 --> 00:51:42,120
tal raíz después, después, después? ¿Qué operaciones estoy usando ahí? ¿De las que

414
00:51:42,120 --> 00:51:56,440
vimos? No. No, yo estoy formando una palabra a partir de pedacitos. Es decir, primero viene

415
00:51:56,440 --> 00:52:02,320
la raíz, después viene esto, después viene esto, después viene esto. Con catenacía.

416
00:52:02,320 --> 00:52:11,480
Con catenacía. Muy bien. Yo lo que hago es con catenar las partes para formar una palabra.

417
00:52:11,480 --> 00:52:22,200
Vamos a ver esto como se expresa en… perdón. Vamos a ver, esto está hecho con una herramienta

418
00:52:22,200 --> 00:52:32,520
que se llama XFST. Ustedes pueden bajársela, probarla en el analizador. Acá lo que yo

419
00:52:32,520 --> 00:52:36,280
hice fue, acá lo que hago estoy haciendo es definir expresión irregular. Relación

420
00:52:36,280 --> 00:52:43,680
regular, exactamente con el álgebra que ya las vimos. Entonces yo digo, bueno, la raíz

421
00:52:43,680 --> 00:52:51,200
de un hombre en manbona, un sustantivo en manbona es cualquiera de estas palabras. Esta

422
00:52:51,200 --> 00:52:55,440
ya ve lo que quiere decir que son tres símbolos, una N, una A y una T, y no un símbolo solo,

423
00:52:55,440 --> 00:53:01,560
nada más que eso quiere decir. O sea, una raíz va a ser más NAT, POS, bla, bla. Y va

424
00:53:01,560 --> 00:53:04,600
a devolver lo mismo, o sea, acuerdan que si no poníamos lo que devolvía, devolvía lo

425
00:53:04,600 --> 00:53:10,680
mismo. O sea, esto va a calcular, esto se compila en un traductor que lo único que hace

426
00:53:10,680 --> 00:53:17,440
es tomar la entrada y devolver la salida y que solo acepta esta palabra. ¿De acuerdo?

427
00:53:18,440 --> 00:53:22,800
Y luego empiezo a definir de la misma forma lo sufijo, a hacer los traductores para

428
00:53:22,800 --> 00:53:33,800
lo sufijo. Y digo, bueno, el sufrijo acá me va a devolver como marca peyorativo. Acá

429
00:53:33,800 --> 00:53:37,480
en realidad estoy haciendo el orden para el otro lado, es decir, a partir del análisis

430
00:53:37,480 --> 00:53:43,160
genero la marca. O sea, que si tengo una marca de peyorativo, este porcentaje es para el

431
00:53:43,160 --> 00:53:49,680
escape del más. Si es peyorativo le agregó acá, si es diminutivo este, y etcétera.

432
00:53:49,680 --> 00:54:00,400
Y así defino todos los sufijos que fueron descritos en la letra. ¿Tá? Si ustedes lo

433
00:54:00,400 --> 00:54:05,920
revisan van a ver que se corresponde con la especificación que se vio. Hay algún caso

434
00:54:05,920 --> 00:54:12,200
particular que es, por ejemplo, si no tiene número, yo quiero marcarlo como que no tiene

435
00:54:12,240 --> 00:54:17,360
número, pero no se corresponde nada en el del lado de superficie. No hay marca eléxica.

436
00:54:17,360 --> 00:54:25,360
Es como el masculino en el español, no hay marca de masculino, no es que no tiene marca,

437
00:54:25,360 --> 00:54:34,000
no tiene una marca de superficie, no hay marca ortográfica. Entonces acá simplemente devuelvo

438
00:54:34,000 --> 00:54:44,040
cero que es éxil. O sea, que si no hay nada va a devolver eso. Y entonces la pregunta

439
00:54:44,040 --> 00:54:51,520
es, bueno, yo tengo esto. Tengo la raíz y los sufijos. ¿Cómo voy a definir el sustantivo?

440
00:54:51,520 --> 00:54:59,560
¿Cómo represento al sustantivo? A partir de esto. Este es el lezicón. ¿Cómo dijimos

441
00:54:59,720 --> 00:55:13,200
definir el sustantivo? Exactamente esto que dice. La raíz, esto quiere decir opcional, un sufijo

442
00:55:13,200 --> 00:55:20,560
1 opcional, un sufijo 2 opcional, un sufijo 3 y un sufijo 4. ¿Qué construimos acá? El lezicón,

443
00:55:20,560 --> 00:55:33,400
es decir, yo tengo para cualquier palabra, yo puedo, no solo la reconoce, sino que devuelve

444
00:55:33,400 --> 00:55:41,840
esa estructura eléxica. Y eso quiere decir que construí nada más ni nada menos con

445
00:55:41,840 --> 00:55:55,320
un transductor que de una recibe la palabra y devuelve el análisis. Y además de regalo

446
00:55:55,320 --> 00:56:07,480
viene la inversa. Como los transductores se acuerdan que eran cerrados bajo reverso. Simplemente

447
00:56:07,480 --> 00:56:12,040
devuelta la transidad. Lo que tiene de bueno esto es que el análisis y la generación, y vuelvo a la

448
00:56:12,040 --> 00:56:20,680
pregunta del principio de la clase, es exactamente igual. Es el costo computacional es el mismo,

449
00:56:20,680 --> 00:56:26,920
porque es simplemente leer el transductor de un lado o del otro. Y esa es una de las grandes ventajas

450
00:56:26,920 --> 00:56:31,200
de los transductores tajonitos que después no pasa más en otras cosas. El análisis y la generación

451
00:56:31,200 --> 00:56:42,520
son lo mismo. Pero, ¿qué le falta esto? ¿Qué le falta esto? Las reglas ortográficas. Porque esto

452
00:56:42,520 --> 00:56:50,120
me va a generar cosas, yo le voy a dar el análisis, me va a generar todo muy bien, pero va a tener

453
00:56:50,120 --> 00:56:56,120
problemas porque en las palabras de bambona, las consonantes nunca son seguidas, las vocales,

454
00:56:56,120 --> 00:57:04,340
sino por la verdad. ¿Y cómo vamos a hacer las reglas ortográficas? ¿Qué hacemos con la regla

455
00:57:04,340 --> 00:57:15,920
ortográfica? ¿Cómo hacemos la regla ortográfica? ¿Cómo la representamos? ¿La representamos con un

456
00:57:15,920 --> 00:57:29,500
transductor que haga la sustitución y correspondiente? Ahora vemos eso. Yo acá hice un transductor que

457
00:57:29,500 --> 00:57:34,120
hace las reglas. ¿Qué está utilizando el operador de reemplazo? Simplemente dice la I y la sustituimos,

458
00:57:34,120 --> 00:57:38,680
por eso no sirven los operadores de reemplazo. Porque dice, si hay una I, sustituímelas por una U,

459
00:57:38,680 --> 00:57:49,360
si antes hay una P, una T o una K. ¿O? Y después fíjate que si hay una E la cambió por una O,

460
00:57:49,360 --> 00:57:55,920
si hay una P de una O. Y después fíjate que hay una, y aplicar los dos en cascada. O sea,

461
00:57:55,920 --> 00:58:04,400
empezar con este, aplica este, aplica este. Pero esto lo único que hace es, dado una palabra,

462
00:58:04,400 --> 00:58:12,000
me cambia la cosa. Yo tengo esto que me da la palabra, dada el análisis, me da la palabra y tengo

463
00:58:12,000 --> 00:58:20,200
esto que dada la palabra me corrige la ortografía. ¿Cómo lo junto? ¿Con qué operación? Y ahí sí con

464
00:58:20,200 --> 00:58:29,000
oposición. ¿De acuerdo? Entonces, bambona es simplemente, y acá sí tenemos el transductor

465
00:58:29,400 --> 00:58:36,200
el lexicón compuesto con las reglas ortográficas. Si yo hubiera definido las reglas al revés,

466
00:58:36,200 --> 00:58:44,640
tendría que ser al principio, el autor. Pero como yo la definí de la análisis para el otro lado,

467
00:58:44,640 --> 00:58:51,840
esto queda pegado, digamos, el primer transductor, dado el análisis, te da la palabra con los

468
00:58:51,840 --> 00:58:56,920
errores ortográficos y el segundo transductor te corrige la ortografía. Y devuelve la versión correcta.

469
00:58:56,920 --> 00:59:09,000
¿De acuerdo? Entonces, implementamos exactamente lo que queríamos, es un solo transductor,

470
00:59:09,000 --> 00:59:14,120
porque la composición genera un transductor solo, un transductor muy complejo, construido a partir

471
00:59:14,120 --> 00:59:20,200
de parte muy chiquita, hicimos una especie, no, un poco de ingeniería, fuimos construyendo

472
00:59:20,200 --> 00:59:24,920
de partes y construyendo el gran transductor, que lo que hace es dar a cualquier sustantivo,

473
00:59:24,920 --> 00:59:33,640
me devuelve su estructura. Y, dada la estructura, me dice cómo se pronuncia. Si se fijan,

474
00:59:33,640 --> 00:59:38,600
este es un método que es completamente especificable o que fue completamente especificado por reglas.

475
00:59:40,920 --> 00:59:50,000
O sea, todas las palabras que están acá tengo la generación de su análisis y solo esas.

476
00:59:50,080 --> 00:59:54,000
Si hay una palabra nueva, acá no entra, tengo que modificar el transductor, ¿de acuerdo?

477
01:00:10,000 --> 01:00:15,760
Si, está muy bien la pregunta, no sabes, tenés que tenerlo en cuenta durante tu análisis.

478
01:00:16,720 --> 01:00:20,000
Es decir, vos tenés que tener en cuenta que en la cascada importa el orden.

479
01:00:22,000 --> 01:00:26,640
O sea, que si te pasa eso que vos decís, marchaste, es que tenés que modificar tu análisis,

480
01:00:26,640 --> 01:00:34,640
no hay una iteración, digamos. Sí, totalmente. Exactamente, totalmente.

481
01:00:34,640 --> 01:00:39,960
Pues lo que hace eso es, las reglas ortográficas son, siempre te pasa lo mismo, cuando aplicas

482
01:00:39,960 --> 01:00:45,440
reglas en cascada, tenés que saber que estás haciendo una cascada y que en esa cascada lo

483
01:00:45,440 --> 01:00:49,360
que vos hagas después no puedo estirarlo para atrás, digamos. Que si vos pusiste una marca

484
01:00:49,360 --> 01:00:56,720
de cambio, esa marca, quiero decir, el transductor de la cascada tiene que entender en qué posición

485
01:00:56,720 --> 01:01:02,720
de la cascada está. Porque, por ejemplo, vos podés poner una marca intermedia, porque

486
01:01:02,720 --> 01:01:06,160
va a pasar algo después. Este tipo tiene que saber que le puede venir una marca intermedia

487
01:01:06,160 --> 01:01:13,520
en su alfabeto. De hecho, lo que yo te decía hoy, el paper

488
01:01:13,600 --> 01:01:18,560
dice que hace que el operador de reemplazo hace una cantidad de operaciones sobre la tira,

489
01:01:18,560 --> 01:01:24,720
le mete símbolo, marquitas, coso, todo muy artesanal y las compone en una cascada para

490
01:01:24,720 --> 01:01:31,600
obtener un solo transductor que hace el reemplazo. Bueno, hay otras herramientas para este tipo

491
01:01:31,600 --> 01:01:39,200
de álgebra. En esta, esta es muy potente, en este yo escribí la tesilla de maestría

492
01:01:39,200 --> 01:01:47,520
con la esencia autílitis. Este es muy potente pero muy ineficiente, muy ineficiente. Y ahora

493
01:01:47,520 --> 01:01:57,040
los más populares son OpenFST. Bueno, hay un poco de bibliografía. Este es un libro,

494
01:01:57,040 --> 01:02:01,680
pero este paper resume bastante, de forma bastante interesante, en unas pocas páginas

495
01:02:01,680 --> 01:02:19,040
como ha sido la historia del asunto de Estado Finito. ¿Alguna pregunta? No. Si ustedes quieren

496
01:02:19,040 --> 01:02:29,520
pueden instalarse XFST y hacer pruebas, y efectivamente van a ver que al especificar

497
01:02:29,520 --> 01:02:34,240
estas cosas uno, y les permite aplicarlo al transductor. Es decir, bueno, ¿qué pasa

498
01:02:34,240 --> 01:02:40,080
con esta palabra? Y pronto ni bien se pone uno a probar y empiezan a aparecer las cosas

499
01:02:40,080 --> 01:02:45,640
como el no determinismo o cosas así. Además, esta herramienta permite hacer una cantidad

500
01:02:45,640 --> 01:02:49,560
de análisis internos, es decir, ¿qué tan complicado es el transductor? Uno de los grandes

501
01:02:49,560 --> 01:02:56,520
problemas que tienen los transductores, o el gran problema es que son muy eficientes

502
01:02:56,520 --> 01:03:01,720
para computar cosas, pero claro, toda la información que tenemos ahí está contenida

503
01:03:01,720 --> 01:03:06,360
dentro del transductor, no tiene noción de memoria externa a los transductores, todo

504
01:03:06,360 --> 01:03:14,440
tiene que estar ahí. Eso hace que crezcan muchísimo. Y generalmente los análisis hecho

505
01:03:14,440 --> 01:03:18,880
con transductores son muy eficientes, pero han sido tradicionalmente, necesitan mucha

506
01:03:18,880 --> 01:03:23,520
memoria para ejecutarse porque crecen muy rápido el componerse. Fíjense que yo cuando

507
01:03:23,520 --> 01:03:27,240
los compongo a una especie de producto cartesiano, digamos, en muchos casos, entonces empiezan

508
01:03:27,240 --> 01:03:33,120
a crecer y a crecer y a crecer. Yo creo que de un punto de vista, me estoy

509
01:03:33,120 --> 01:03:38,880
tal vez, me estoy arriesgando lo que estoy diciendo, pero me parece que de un punto

510
01:03:38,880 --> 01:03:43,440
de vista más, industriar los transductores es como que han pasado un poco de moda, porque

511
01:03:43,440 --> 01:03:48,960
las computadoras son tan potentes que tengo modelos más tradicionales, con lenguaje de

512
01:03:48,960 --> 01:03:54,760
programación y más presivo, digamos, y no tengo todo su problema de que me explote

513
01:03:54,760 --> 01:04:01,680
su tamaño. Pero debe haber algunas aplicaciones que trabajan contra autores, pero no en este

514
01:04:01,680 --> 01:04:07,480
marco tan genérico. ¿De acuerdo? Bueno, fin de la parte 1, vamos a pasar a la parte

515
01:04:07,480 --> 01:04:16,480
2. Capaz que están un poco cansados, pero tenemos que ponernos al día. La parte 2,

516
01:04:16,480 --> 01:04:25,120
como les decía, hay que cambiar un poco el chip, porque seguimos dentro de las palabras,

517
01:04:25,120 --> 01:04:35,000
pero vamos a hablar de otra cosa y vamos a usar un método también bastante diferente.

518
01:04:35,000 --> 01:04:52,000
Y es el tema de la detección y la corrección de errores ortográficos. Esto me interesa

519
01:04:52,000 --> 01:05:01,600
por dos motivos. Uno es porque el problema es un problema interesante y otro es porque

520
01:05:01,600 --> 01:05:07,720
es un modelo bastante claro de utilización de un método que se utiliza en muchas cosas,

521
01:05:07,720 --> 01:05:12,600
no solo el procesamiento de un bokeh natural, que se llama modelo del canal ruidoso, que

522
01:05:12,600 --> 01:05:23,520
es el primer modelo proailista que vamos a ver. Y van a ver que la aproximación es completamente

523
01:05:23,520 --> 01:05:32,240
diferente. Y yo me atrevería a decir que es el concepto más importante que podemos

524
01:05:32,240 --> 01:05:39,600
ver en este curso, como concepto general, como concepto nuevo. No digo que el tema valle

525
01:05:39,600 --> 01:05:48,320
sea nuevo, pero desde el punto de vista de los métodos que solemos utilizar los ingenieros,

526
01:05:48,320 --> 01:05:54,560
esto es bastante nuevo. ¿Por qué? Porque utiliza métodos de inferencia en lugar de

527
01:05:54,560 --> 01:06:07,180
métodos deductivos. Esto es, yo tradicionalmente hay dos escuelas filosóficas, si ustedes

528
01:06:07,180 --> 01:06:13,400
quieren que son los racionalistas y los empiricistas. Los racionalistas dicen, bueno, yo puedo construir

529
01:06:13,400 --> 01:06:20,120
un modelo del mundo y sacar conclusiones de ese modelo que construí, en mi cabeza. ¿No?

530
01:06:20,120 --> 01:06:28,840
Aristóteles. Pero los empiricistas, por allá, digamos, Francis Bacon, todas esas

531
01:06:28,840 --> 01:06:34,600
gente decían no, en realidad el mundo es el que hay, yo tengo que inferir los modelos

532
01:06:34,600 --> 01:06:41,120
a partir de los datos que existen. Esas dos corrientes filosóficas han recorrido la humanidad

533
01:06:41,240 --> 01:06:48,320
en esas dos visiones. Y ahora no es menos. Pero ahora, como tenemos muchos datos, ha

534
01:06:48,320 --> 01:06:52,040
tomado bastante importancia todo el tema del empiricismo. El empiricismo es el método

535
01:06:52,040 --> 01:07:00,760
científico, observo, mido y genero realidades, en lugar de construirme realidades teóricas

536
01:07:00,760 --> 01:07:10,640
puras. El método que vamos a ver del canal ruidoso es bien probabilística. Bueno,

537
01:07:10,640 --> 01:07:33,600
pero ¿cómo hacemos? Y bueno, supongamos que yo escucho una palabra. ¿Sí? Yo les digo la palabra.

538
01:07:33,600 --> 01:07:46,480
Vaso. ¿Qué dije? Vaso. Vaso. Vaso. ¿Alguien escuchó otras cosas? ¿Capaz que

539
01:07:46,480 --> 01:07:59,400
se en el fondo escucharon? Paso. ¿Puedo haber dicho perro? ¿Puedo haber dicho perro o no

540
01:07:59,400 --> 01:08:05,600
puedo haber dicho perro? ¿Por qué no? ¿Por qué probablemente no?

541
01:08:10,600 --> 01:08:16,280
Y si hubiera sido por lo que escuchamos, pero ¿que escucharon? Eso no es como una

542
01:08:16,280 --> 01:08:22,000
es. Es decir, no parece que hubiera sido perro. No es probable que el sonido haya llegado tan

543
01:08:22,000 --> 01:08:34,240
cambiado. ¿Puedo haber dicho? ¿Puedo haber dicho eso? ¿Por qué no? Porque no es una palabra.

544
01:08:34,240 --> 01:08:48,960
Entonces, ¿puedo haberlo dicho? No. La idea es que el modelo del canal ruidoso es lo que yo digo,

545
01:08:49,000 --> 01:08:59,080
lo que sucede es que yo recibo de alguna forma una señal y digo bueno modelo el problema digamos,

546
01:08:59,080 --> 01:09:05,480
cuando yo modelo el problema con canal ruidoso es yo tengo una observación ante mí que es eso

547
01:09:05,480 --> 01:09:12,200
que escucharon ustedes que además es diferente para todos porque es una distancia y quiero tratar de

548
01:09:12,200 --> 01:09:18,640
determinar cuán fue la palabra origen porque a mí lo que me interesa saber es que dije yo,

549
01:09:18,640 --> 01:09:22,840
no digo, se trata de la comunicación. A mí lo que me interesa no, a ustedes lo que me interesa es saber

550
01:09:22,840 --> 01:09:36,960
que dije yo. Y en mi definición del problema, yo asumo ya que mi señal pasó por un canal

551
01:09:36,960 --> 01:09:48,920
ruidoso que la tarji versó y que lo único que yo puedo saber es no tener la certeza de cuál

552
01:09:48,920 --> 01:09:55,720
fue la palabra sino lo mejor que puedo aspirar es una distribución de probabilidad. ¿Qué es? ¿Se

553
01:09:55,720 --> 01:09:59,360
acuerdan lo que es una distribución de probabilidad? Fijemos la definición. Yo tengo una serie de

554
01:09:59,360 --> 01:10:06,680
eventos, una distribución de probabilidad es un valor entre 0 y 1 que le doy a cada uno y que

555
01:10:06,720 --> 01:10:11,800
entre todo tiene que sumar uno. Esa es una distribución de probabilidad. Yo puedo hacer una

556
01:10:11,800 --> 01:10:18,800
distribución de probabilidad sobre todas las palabras posibles. Con lo cual descarto ya las

557
01:10:19,320 --> 01:10:22,200
pero

558
01:10:26,800 --> 01:10:27,520
digamos

559
01:10:33,520 --> 01:10:37,640
si supongamos que se llama Luis y yo le digo

560
01:10:37,640 --> 01:10:49,760
yo le hablo y le digo fuiz, ¿no? Él sabe que yo le estoy hablando a él, ¿verdad? Entonces

561
01:10:51,080 --> 01:10:56,960
él le sonó fuiz, o sea que la palabra más cercana le fui probablemente desde el punto de vista de

562
01:10:56,960 --> 01:11:04,760
bueno pero él sabe que le estoy hablando a él, entonces Luis es más probable digamos en su

563
01:11:04,760 --> 01:11:09,080
interpretación. Sigue siendo posible que yo hubiera dicho fuiz porque le voy a decir fui a

564
01:11:09,080 --> 01:11:16,040
tal lado y que se me cortó porque me pasó algo, pero es menos probable. Entonces es lo que arma

565
01:11:17,240 --> 01:11:22,360
cuando me escucha o lo que hacemos todo, cuando escuchamos es bueno o podemos modelar lo que

566
01:11:22,360 --> 01:11:26,040
lo hacemos, no quiere decir que lo hagamos, es generar una distribución de probabilidad sobre

567
01:11:26,040 --> 01:11:30,600
todas las palabras posibles que me dijeron y quedarme con la que es más probable según alguna

568
01:11:30,600 --> 01:11:40,680
regla. Eso se trata el modelado del canal ruidoso. Esto no tiene que ver, porque hoy

569
01:11:40,680 --> 01:11:47,280
día cuando estaba el proceso de mínima discusión. Y tengo entonces dada una palabra, tengo las

570
01:11:47,280 --> 01:11:52,640
originales, cuando tengo un error ortográfico tengo exactamente la misma configuración,

571
01:11:52,640 --> 01:11:57,720
yo tengo una palabra que veo ahí que no sé lo que es y trato de saber cuál es la más,

572
01:11:58,680 --> 01:12:01,600
la más razonable que sea la original.

573
01:12:05,840 --> 01:12:11,240
¿Qué pasa? ¿Cómo hacemos la detección del error? Y bueno, si a mí me aparece en un texto, mate.

574
01:12:15,880 --> 01:12:22,560
Yo puedo detectar que hay, que me equivoqué, ¿por qué? Porque esa palabra no existe,

575
01:12:22,560 --> 01:12:27,600
la detección de palabras inexistentes es muy fácil. Yo pongo un diccionario y no está,

576
01:12:27,600 --> 01:12:30,800
es lo que hacen todos los corretores ortográficos.

577
01:12:34,800 --> 01:12:40,800
Esa es una forma, esto es detección de palabras inexistentes, nada más. Después lo que tengo

578
01:12:40,800 --> 01:12:52,000
es la corrección aislada, que es, bueno, mate, la correjo con tomate. ¿Por qué?

579
01:12:57,280 --> 01:13:01,520
Por la mínima distancia. ¿Por qué es la más parecida? ¿Qué hay? No parece haber otro diccionario

580
01:13:01,520 --> 01:13:06,360
que sea más parecida. Esto, no hay otro candidato de base de tomate.

581
01:13:10,880 --> 01:13:16,960
Mate, puede ser, está bien, es verdad. ¿Verdad? Metí una T y...

582
01:13:20,320 --> 01:13:27,600
Y esto es la más difícil, ¿eh? No, en vez de poner calor, puse el color, está complicado,

583
01:13:27,600 --> 01:13:31,440
porque ahí tengo que conocer el contexto, es mucho más difícil. Con la palabra sola no puedo.

584
01:13:35,280 --> 01:13:39,760
Nunca vas a saber. ¿Es lo que le pasa a los corretores? ¿Cuántas veces dejamos una barbaridad

585
01:13:39,840 --> 01:13:44,240
en nuestros textos? Porque también, justo era una palabra, yo qué sé.

586
01:13:44,240 --> 01:13:48,240
Eso que vamos a hablar en esta clase, después vamos a hablar sobre esto, no se preocupen,

587
01:13:48,240 --> 01:13:52,240
pero vamos a hablar de este tipo de corrección. ¿De cuál es la más probable? Porque esto

588
01:13:52,240 --> 01:13:56,400
no siempre es tan fácil tomando la palabra sola, porque puede haber mucho, bueno, no

589
01:13:56,400 --> 01:13:59,680
siempre es tan fácil, no, ni siquiera era tan fácil. En el caso que el género de Mate

590
01:13:59,680 --> 01:14:05,120
aplica, acá tengo dos candidatas. Entonces, vamos a ver un poco de este caso. ¿Y cómo

591
01:14:05,120 --> 01:14:12,960
modelarlo con el modelo canal ruidoso? Esta clase está basada principalmente en

592
01:14:12,960 --> 01:14:21,120
un artículo que habla de una utilidad que hicieron para IUNE, que creo que se llama

593
01:14:21,120 --> 01:14:25,840
SPEL o correcto. No, SPEL es la clásica que te dice si está viendo mal la palabra,

594
01:14:25,840 --> 01:14:31,520
es correcto eso. ¿Qué te corrige la palabra? Ellos hicieron un análisis y dijeron, bueno,

595
01:14:31,680 --> 01:14:36,880
tomaron un corpo de errores, de errores cometidos, la gallena anotó esto, se cambió por esto,

596
01:14:36,880 --> 01:14:41,840
se cambió por esto, se cambió por esto, y se dio cuenta que entre el 1 y el 3% de

597
01:14:41,840 --> 01:14:48,960
las palabras según el corpus, son errores, eran corpus de transcripciones y mal no recuerdo.

598
01:14:48,960 --> 01:14:58,640
Y que el 80% de esos errores eran por la inserción de una letra o Mate, por el borrado de una

599
01:14:58,720 --> 01:15:06,960
letra, por la sustitución de una letra y por la transposición de dos letras, acá cambiaron

600
01:15:06,960 --> 01:15:14,920
la, de por la o. Sí, es más raro eso, metes dos dedos, eso te puede pasar más con una

601
01:15:14,920 --> 01:15:24,880
máquina a escribir. ¿Por qué les parece haber una pregunta, no? Esta sustitución por una

602
01:15:24,880 --> 01:15:38,640
p, es este, ¿Les parece que es igual para cualquier letra la sustitución acá? Está más

603
01:15:38,640 --> 01:15:43,600
cerca, es más fácil confundir una o con una p o una a en un teclado, por la distribución de la letra,

604
01:15:43,600 --> 01:15:58,960
bueno, eso nos da una pista. Y yo podría llegar a decir bueno, pero entonces lo que voy a hacer es

605
01:15:58,960 --> 01:16:07,080
agarro cualquier error, agarro cualquier error, cualquier palabra que es un error y busco la

606
01:16:07,080 --> 01:16:12,200
candidata más parecida cambiando con una serie de reglas por las que están más cerca en el teclado,

607
01:16:12,640 --> 01:16:18,480
pruebo la o por una p, no, hago todo un paquete de reglas, la pico la palabra y doy un canteón,

608
01:16:18,480 --> 01:16:25,080
algo parecido a lo que hice con la morfología. Bueno, no vamos a hacer eso, nuestra aproximación

609
01:16:25,080 --> 01:16:31,120
va a ser completamente diferente a esa, en lugar de aprender de nuestro modelo, de tomar esa visión

610
01:16:31,120 --> 01:16:37,520
racionalista, en la cual yo supongo una cantidad hipótesis como son demasiadas complicadas a

611
01:16:37,520 --> 01:16:44,720
hipótesis, pero yo qué sé cómo es, no sé si es una o o la p o la... no sé qué letra llama,

612
01:16:47,720 --> 01:16:51,920
no sé, no lo lo voy a dar, o p, no sé qué hay, este

613
01:16:54,960 --> 01:17:05,240
L, no, la L, acá, no, acá, no, después la pico, que pico, que pico,

614
01:17:07,720 --> 01:17:10,400
la I, la I, ¿Quién dijo la I? ¿Quién dijo la I?

615
01:17:10,400 --> 01:17:19,200
Bueno, no sabemos, no es fácil modelar eso, entonces nosotros no vamos a hacer nada, vamos a

616
01:17:19,200 --> 01:17:27,360
aplicar el modelo del canal ruidoso y vamos a decir, bueno, y acá viene el asunto de las

617
01:17:27,360 --> 01:17:32,240
probabilidades condicionales y todo eso, ¿se acuerdan de la probabilidad condicional, ¿no?

618
01:17:32,440 --> 01:17:39,200
Podría condicionales un número entre 0 y 1 bla bla, es una distribución de probabilidad entre

619
01:17:39,200 --> 01:17:48,760
eventos posibles, pero que está condicionada a que haya pasado algo, entonces yo lo que digo es,

620
01:17:49,960 --> 01:17:58,760
yo voy a querer la palabra W, W coso, pechito, gorrito, que maximiza

621
01:18:03,000 --> 01:18:13,480
la probabilidad de, ahora vamos a aplicar un poquito más, ¿se acuerdan, el large max,

622
01:18:13,480 --> 01:18:18,720
lo que quiere decir es, calcula la probabilidad y cuál es la W, que es el argumento para esa,

623
01:18:18,720 --> 01:18:25,960
para esa cuenta, esto es, yo tengo una observación no, que es mi palabra con error,

624
01:18:26,600 --> 01:18:34,280
¿sí? y yo quiero saber exactamente lo que estuvimos conversando ahora, la W, de todas las

625
01:18:34,280 --> 01:18:45,880
W posibles del vocabulario, ¿cuál es aquella para la cual la probabilidad es máxima?

626
01:18:48,280 --> 01:18:52,640
Lo cual solamente me modela el problema, no me lo resuelve, bueno, tengo ni idea,

627
01:18:52,680 --> 01:18:58,280
hasta el momento como calcular la probabilidad, pero mi problema ahora es, ¿cómo calculo

628
01:18:58,280 --> 01:19:06,400
esta probabilidad? Además de la taría titánica de encontrar todas las posibles W y probar con

629
01:19:06,400 --> 01:19:11,800
cada una, que bueno, además tengo que saber esta W, donde saco, donde la estimo, cómo hago,

630
01:19:11,800 --> 01:19:18,520
ese es mi problema en los métodos probabilísticos, ¿cómo calculo las probabilidades? Y la probabilidad

631
01:19:18,520 --> 01:19:22,840
la voy a calcular a partir de qué, ¿cómo podemos aprender esas probabilidades?

632
01:19:27,920 --> 01:19:33,080
Frecuencia, frecuencia de errores, exactamente, así funcionan todos los métodos de aprendizaje

633
01:19:33,080 --> 01:19:41,360
automático, todos los métodos de aprendizaje automático aprenden de corpus o de conjuntos

634
01:19:41,360 --> 01:19:46,640
previamente anotados, porque yo para saber frecuencia de errores, alguna persona me tuvo que anotar

635
01:19:46,640 --> 01:19:53,280
los errores, ese es el gran problema de los métodos de aprendizaje, los métodos de aprendizaje

636
01:19:53,280 --> 01:19:57,960
tienen la gran ventaja de que, esencialmente, no necesitan un experto porque aprenden de los

637
01:19:57,960 --> 01:20:02,880
datos, pero necesitan un experto para que le anote los datos, para que le diga, esto fue un error,

638
01:20:02,880 --> 01:20:08,240
esto fue un error, esto fue un error, esto fue un error, y ahí aprender, bueno, de eso se trata

639
01:20:08,240 --> 01:20:15,560
el modelo canal ruidoso, ¿y qué hace? Bueno, dice, aplica la vieja y querida regla de Valles,

640
01:20:18,360 --> 01:20:27,240
Valles, monje por allá del 1500, descubrió esta regla que es muy muy sencilla, es muy muy difícil

641
01:20:27,240 --> 01:20:33,720
explicar, intuitivamente, que lo que dice es que la probabilidad de un número dado a otro

642
01:20:33,720 --> 01:20:42,880
evento, es igual a la probabilidad, perdón, la probabilidad de un evento, dado a otro evento,

643
01:20:42,880 --> 01:20:48,280
es la probabilidad al revés, con la condición al revés multiplicada por la probabilidad del

644
01:20:48,280 --> 01:21:00,200
X, divida la probabilidad del Y, es decir, esto es bastante obvio porque la probabilidad de que se

645
01:21:00,200 --> 01:21:07,560
den dos eventos, X y Y, al mismo tiempo, es la probabilidad de que se dé X multiplicada por

646
01:21:07,560 --> 01:21:15,400
la probabilidad de que se dé Y, dado que se dio X, ¿sí? La probabilidad de que salga dos veces un 2,

647
01:21:15,400 --> 01:21:20,680
cuando tiene un dado, es la probabilidad de que salga un 2, multiplicado por la probabilidad de que

648
01:21:20,680 --> 01:21:30,180
salga otro 2, dado, el dado es el peor ejemplo porque soy independiente, pero se van a dar

649
01:21:30,180 --> 01:21:42,780
lo mismo, pero la probabilidad de que sea, si la primera palabra de un texto es la, es un artículo,

650
01:21:42,780 --> 01:21:47,580
la probabilidad de que sea un sustantivo, la siguiente seguramente es más alta,

651
01:21:48,580 --> 01:21:59,060
de acuerdo, que si la primera es un verbo, de acuerdo, entonces, pero lo mismo puedo decir al revés,

652
01:21:59,060 --> 01:22:08,860
la probabilidad de X y Y es igual a la probabilidad de Y por la probabilidad de X dado Y, de acuerdo,

653
01:22:09,620 --> 01:22:18,500
igual a estas dos cosas, igual a estas dos, y paso y divido por P su Y, y me da la regla de Valle,

654
01:22:18,500 --> 01:22:23,700
sencillamente, pero es muy interesante lo que dice la regla de Valle, porque dice, si yo condiciono

655
01:22:23,700 --> 01:22:32,060
en un evento, puedo, automáticamente, saber cómo se condiciona en el otro, si yo sé la probabilidad

656
01:22:32,060 --> 01:22:42,220
de que la segunda sea un sustantivo, dado que la primera es un artículo, puedo calcular al revés,

657
01:22:42,220 --> 01:22:46,500
puedo calcular la probabilidad de que sea un artículo, la primera, dado que la segunda es un

658
01:22:46,500 --> 01:22:54,020
sustantivo, hacerla de derecha, de adelante para atrás, digamos, y justamente lo que vamos a hacer

659
01:22:54,020 --> 01:23:00,260
nosotros es decir, bueno, nosotros queríamos calcular esto, la probabilidad, ah, perdón,

660
01:23:00,260 --> 01:23:07,860
nosotros teníamos esta probabilidad que queríamos calcular, P de W dado, si, entonces yo lo que digo

661
01:23:07,860 --> 01:23:13,100
es, aplico Valles y digo, la probabilidad de, de P, ahora vamos a ver por qué hago esto, no,

662
01:23:14,860 --> 01:23:22,380
la probabilidad de O dado W por la probabilidad de W dividido de la probabilidad de O, apliqué

663
01:23:22,380 --> 01:23:27,740
derechito viejo la regla de Valle, quería la probabilidad de la palabra, dada la observación y la

664
01:23:27,780 --> 01:23:30,900
transformo en algo que es la probabilidad de la observación dada la palabra,

665
01:23:33,660 --> 01:23:42,340
¿por qué yo hago esto? Porque yo en mi cuerpo tengo los errores, yo sé la palabra original y veo

666
01:23:42,340 --> 01:23:48,700
la palabra que se, que, en qué se transformó, entonces yo lo que veo fácilmente contando es la,

667
01:23:48,700 --> 01:23:53,420
ahora vamos a ver por qué veo fácilmente contando, la probabilidad de la observación dada la palabra

668
01:23:53,420 --> 01:24:03,780
original, si yo escribí tu mate, perdón, si, si, si yo escribo tu mate, qué tan probable es que

669
01:24:03,780 --> 01:24:10,460
escriba tu mate, te calculan, se entiende, estoy calculando al revés, estoy partiendo la palabra y

670
01:24:10,460 --> 01:24:16,140
viendo cuál es la probabilidad de equivocarme, que vamos a ver ahora que eso es más fácil de

671
01:24:16,140 --> 01:24:23,540
calcular, ahora lo vamos a ver, pero la cuestión es que si yo quiero maximizar esta función,

672
01:24:23,540 --> 01:24:28,460
si se fijan esta función depende, o sea esto es para todas las palabras posible,

673
01:24:29,460 --> 01:24:38,460
la probabilidad de que yo diga tu mate dado que dije perro, que dije caballo, o tomate, o mate,

674
01:24:38,460 --> 01:24:46,380
y si ustedes fijan acá esto varía con la palabra pero no varía con la observación,

675
01:24:46,380 --> 01:24:52,100
entonces si yo maximizar esta función es lo mismo que maximizar esta de arriba, porque esto es

676
01:24:52,100 --> 01:25:02,820
fijo, entonces acá llegó a esto, maximizo la probabilidad de la observación dada la palabra

677
01:25:02,820 --> 01:25:09,540
multiplicada por la probabilidad de la palabra, y miren que interesante ¿no? porque es estoy

678
01:25:09,540 --> 01:25:13,580
dividiendo en dos partes, la regla de bache lo que permite, lo que me permite hacer es dividir en dos

679
01:25:13,580 --> 01:25:26,220
partes bien claras mi estimación de la probabilidad y es la probabilidad a priori de la palabra

680
01:25:26,220 --> 01:25:38,220
¿Qué es? ¿Qué tan probable es en el caso de nuestro es que yo emita siquiera esa palabra? ¿Qué tan

681
01:25:38,220 --> 01:25:49,180
probable es que yo haya querido decir... yo qué sé, no sé, cualquier palabra rara, no se me ocurre

682
01:25:49,180 --> 01:25:52,500
ninguna, me hago, tengo que venir con el ejemplo preparado porque en clases jamás se me ocurre

683
01:25:53,460 --> 01:25:58,100
es un baque tengo, yo dije tomate y quise decir

684
01:26:02,660 --> 01:26:06,620
alguna palabra parecida tomate, pero rara

685
01:26:09,860 --> 01:26:18,900
quise decir mita, que sabemos que es algo, la probabilidad de que yo haya dicho mita es muy

686
01:26:18,900 --> 01:26:23,820
baja porque mita no es una palabra que nadie conozca, supongamos que existe, si no la tradicional

687
01:26:23,820 --> 01:26:33,140
la probabilidad a priori que así se llama es muy baja, es muy baja, ahora si yo hablo claro y digo

688
01:26:33,140 --> 01:26:40,580
mita por más baja que sea, ustedes me escucharon perfecto o sea que la probabilidad de la observación

689
01:26:40,740 --> 01:26:49,460
mita, dado que dije mita es muy alta, por más canal ruidoso que pasó, entonces ni más ni menos

690
01:26:49,460 --> 01:26:55,300
que la probabilidad es que yo estoy queriendo saber es la multiplicación de ambas, yo puedo

691
01:26:55,300 --> 01:26:59,940
tener una palabra que es muy probable que diga, es muy probable que yo haya querido decir este

692
01:27:01,540 --> 01:27:09,980
él o la o cualquier artículo que son las palabras más comunes, pero es muy raro que yo haya dicho él

693
01:27:09,980 --> 01:27:15,900
y que me haya salido tomate, se entiende, entonces esta probabilidad de ser muy alta pero estaba

694
01:27:15,900 --> 01:27:22,460
muy baja, de eso se trata ni más ni menos la regla de base, el canal ruidoso, entonces vamos

695
01:27:22,460 --> 01:27:26,780
a ver un ejemplo en este artículo de cómo corregimos errores basándonos en este algoritmo

696
01:27:26,780 --> 01:27:34,780
vallesiano, la hipótesis de trabajo de los tipos es, los errores son todos por inserción borrado

697
01:27:34,780 --> 01:27:38,540
sustitución y transposición, o sea eliminaron el 20% del corpo porque eran otros errores que

698
01:27:38,540 --> 01:27:45,980
no sabían cómo modelarlo, ellos dicen bueno si yo se me encuentro un error mi única aproximación

699
01:27:45,980 --> 01:27:53,820
es que alguien metió un dedo mal, un solo dedo mal, ¿de acuerdo? se entiende, entonces dicen bueno

700
01:27:55,580 --> 01:27:59,260
tengo la palabra observada que en nuestro caso es esta acrés

701
01:27:59,260 --> 01:28:13,340
si, que no es una palabra, y dice bueno ¿cuáles son? si yo le aplico todas las transformaciones

702
01:28:13,340 --> 01:28:20,180
posibles, una, recuerden una hipótesis que la única que hay es una inserción, o sea ya reduce

703
01:28:20,180 --> 01:28:27,420
mis aspiraciones, o sea ya sé que hay casos que no lo voy a detectar, así de triste es la vida,

704
01:28:27,420 --> 01:28:33,340
digamos, lo modelo probabilita realmente, todos los modelos, todos los modelos y la definición

705
01:28:33,340 --> 01:28:43,380
de modelo simplifican la realidad para poder trabajar, este, él dice bueno podría haber sido

706
01:28:43,380 --> 01:28:50,380
y busca todas las que están a distancia 1, a distancia 1 con estas operaciones y por ejemplo dice

707
01:28:51,340 --> 01:29:02,260
actrice que es que se perdió la T, o crees que es que metimos e insertamos una A

708
01:29:04,580 --> 01:29:11,100
y la posición cero, fíjense que además bueno y así todo ¿no? pero es curioso porque acrés

709
01:29:12,500 --> 01:29:18,540
con una S sola aparece dos veces, porque puede haberla insertado en la posición 4 de la posición

710
01:29:18,580 --> 01:29:23,140
5, tengo que modelar como las dos posibles casos, porque son las dos formas que tengo

711
01:29:23,140 --> 01:29:30,020
que llegar a la misma, y estas son todas las candidatas posibles, según nuestra regla,

712
01:29:30,020 --> 01:29:43,380
porque son la única que está en el dicionario, ¿te entiendes acá? bien, bueno, entonces yo lo que

713
01:29:43,380 --> 01:29:54,380
voy a hacer es esto, calcular la palabra, la palabra correcta como la función que maximiza

714
01:29:54,380 --> 01:30:05,380
la probabilidad del error, el tipo, el error, dada la palabra por la palabra, ¿cómo calculo

715
01:30:05,380 --> 01:30:10,780
la probabilidad de la palabra? ¿cómo calculo la probabilidad a priori de la palabra?

716
01:30:10,780 --> 01:30:26,980
en el corp, ¿no? estamos todos acuerdos que la más razonable aproximación, la que parece más

717
01:30:26,980 --> 01:30:34,180
seguido en el corpus, va a aparecer más seguido en el corpus, esos razonables se

718
01:30:34,180 --> 01:30:40,780
llaman principios de máxima verosimilitud, yo considero que lo que tengo en el corpus es

719
01:30:40,780 --> 01:30:47,780
mi mejor aproximación a la realidad, ¿de acuerdo? es decir, lo que maximice la probabilidad en el

720
01:30:47,780 --> 01:30:56,780
corpus maximiza mi probabilidad, pero tiene un problema, ¿qué pasa si la palabra nunca

721
01:30:56,780 --> 01:31:03,100
apareció en el corpus? porque el corpus de hecho no es infinito, ¿qué pasa si la palabra no apareció

722
01:31:03,100 --> 01:31:14,700
en el corpus? la probabilidad 0, ¿y eso qué hace, qué suceda? que sea imposible que yo le elija, aunque

723
01:31:14,700 --> 01:31:20,420
esté en mi vocabulario, aunque esté recontraparecida nunca le voy a elegir porque nunca apareció en

724
01:31:20,420 --> 01:31:25,620
el corpus, ese es el problema típico del conteo por frecuencias y la corrección típica que le vamos

725
01:31:25,620 --> 01:31:29,740
a ver un poquito más ya que hace que viene es, yo le voy a hacer sacarlo un poco de masa de probabilidad

726
01:31:30,500 --> 01:31:35,500
porque esto es lo que va a hacerme una distribución de probabilidad sobre todas las palabras, ¿no? normalizo

727
01:31:35,500 --> 01:31:42,580
sobre uno y me da una distribución por la frecuencia, ¿qué es esto? 1.343 actres y todas

728
01:31:42,580 --> 01:31:48,220
estas, ¿no? y esta es la probabilidad que es simplemente contar la cantidad de palabras que

729
01:31:48,220 --> 01:31:55,100
aparece sobre el total de palabras que hay, bueno yo lo que hago es sacarlo un poco más a probabilidad

730
01:31:55,100 --> 01:32:00,340
a estos y decir en lugar de dividir en la cuenta generalmente es esta cantidad de veces que aparece

731
01:32:00,340 --> 01:32:05,220
la palabra sobre total de palabra, lo que hago es agregarle un poquitito de masa de probabilidad,

732
01:32:05,220 --> 01:32:15,540
agrego un 0,5 al conteo para que nunca me ve cero, es la solución más ingenieril que se les ocurre,

733
01:32:15,540 --> 01:32:22,220
les saco un poquito más, ni siquiera es muy bueno eso pero funciona, se llama este conteo de las

734
01:32:22,260 --> 01:32:26,420
plazas, vamos a verlo un poquito más la que hace que viene, pero tengo que, ¿por qué le agregó este 0,5

735
01:32:26,420 --> 01:32:34,580
acá? ¿Por qué tengo que agregarle este 0,5B?

736
01:32:34,580 --> 01:32:44,260
es una operación, una cuestión bien operativa

737
01:32:54,460 --> 01:32:58,860
para mantener la probabilidad, prometí que dar 1, esto tiene que ser una distribución de probabilidad,

738
01:32:59,740 --> 01:33:05,220
cuando yo cuento y divido sobre n, lo que me da es una distribución de probabilidad, es decir todo

739
01:33:05,220 --> 01:33:11,060
suma uno, si yo le agrego 0,5 a cada uno deja de sumar uno, entonces yo tengo que normalizarlo y le

740
01:33:11,060 --> 01:33:18,260
agrego esto al total, es como que acá hubiera un poquito más de palabras, entonces yo tengo

741
01:33:18,260 --> 01:33:24,740
que sumarlas acá, y como agrego 0,5 por cada una palabra es como que yo agregar a 0,5 palabras,

742
01:33:25,060 --> 01:33:32,020
0,5 por la cantidad de palabras posibles, ¿no? ¿de acuerdo? esto aparece un montón de veces,

743
01:33:32,020 --> 01:33:35,380
un montón de veces se hace este tipo de cosas, yo siempre que tengo una probabilidad tengo que

744
01:33:35,380 --> 01:33:39,140
buscar la forma de normalizarla y cuando yo empiezo a hacer cuentas, a modificarlo sumando,

745
01:33:39,140 --> 01:33:43,860
puedo romper la probabilidad y yo tengo que asegurarme que sume uno, porque bueno,

746
01:33:43,860 --> 01:33:48,980
porque la base de todo mi teoría probabilística está basada en eso de que son eventos que

747
01:33:49,620 --> 01:33:56,380
son todos menores que uno, los que yo lo mapeo una función menor que uno y que la suma da uno,

748
01:33:56,380 --> 01:34:02,020
y después todo lo que hago es demasiado eso, bueno, pero cuestiono que con esta corrección

749
01:34:02,020 --> 01:34:08,420
llegamos a una distribución de probabilidad de la probabilidad priori, o sea, los más probables

750
01:34:08,420 --> 01:34:17,140
que yo haya querido decir, acces, de acuerdo, dada, si yo no supiera más nada que lo que,

751
01:34:19,140 --> 01:34:25,380
si yo no supiera más nada que las palabras posibles, lo más probable que haya querido decir,

752
01:34:25,380 --> 01:34:30,580
perdón, que quiere decir acros, que es la palabra más común en el corpus, tipo con probabilidad

753
01:34:30,580 --> 01:34:39,820
000019 acros, eso quiere decir que sacró, no, porque nos falta la segunda parte de la probabilidad,

754
01:34:39,820 --> 01:34:46,180
nosotros calculamos esta, la probabilidad a priori, es la probabilidad

755
01:34:49,700 --> 01:34:59,700
que en principio tiene la palabra, sin haber visto los datos, es como mi, si yo lo veo desde un punto de

756
01:34:59,820 --> 01:35:05,220
la probabilidad se pueden ver de dos familias de razonamiento principales, uno de frecuentistas

757
01:35:05,220 --> 01:35:09,060
que es una probabilidad, es la cantidad de veces que pasa algo, la proporción de veces

758
01:35:09,060 --> 01:35:16,780
que pasa algo, si yo lo repito suficientemente, yo tengo un dado un millón de veces, o n veces,

759
01:35:16,780 --> 01:35:20,780
va a atender a la probabilidad a calcular, el defino de eso como la probabilidad, hay

760
01:35:20,780 --> 01:35:26,500
otra visión alternativa de la de prioridad, que es la certeza o la confianza que yo tengo

761
01:35:26,500 --> 01:35:30,940
en algo que no está definida por una frecuencia, esa es la visión vallesiana de la probabilidad,

762
01:35:30,940 --> 01:35:37,740
es lo que yo pienso que, si usted ve en un dado, si yo tiene un dado, ustedes, a priori,

763
01:35:38,740 --> 01:35:45,820
¿cuál es la probabilidad de que salga uno? ¿Por qué?

764
01:35:46,820 --> 01:35:55,060
No tiraron el dado, no? No, no, no, es una pregunta, no tiraron el dado,

765
01:35:55,060 --> 01:35:57,820
¿tenés seis posibles? ¿y qué más?

766
01:36:02,820 --> 01:36:05,500
Sí, pero ¿qué más? ¿qué más estás asumiendo vos?

767
01:36:05,500 --> 01:36:14,900
Que el dado no está cargado, ahora, si yo tiro el dado 100 veces y me cayó 80 veces un 6,

768
01:36:16,820 --> 01:36:24,900
pero mi confianza a priori, antes de ver los datos, es 0, como dijimos, un sexto,

769
01:36:24,900 --> 01:36:32,540
¿por qué? Porque asumo, por algún motivo asumo, por algún motivo, o porque yo lo vi con cara de

770
01:36:32,540 --> 01:36:37,580
dado cargado y pensé que era 0, 8, es válida también, es una prioridad priori, después los

771
01:36:37,580 --> 01:36:43,700
datos me la cambian, de eso se trata la regla de valles. Bueno, perdón, esto es un tema que me gusta

772
01:36:43,700 --> 01:36:50,260
mucho y me entusiasmo. Bueno, pero tenemos que calcular esta. ¿Cómo vamos a hacer para

773
01:36:50,260 --> 01:36:58,100
calcular esta? La probabilidad de que se dé el error dado la clase. ¿Cómo se le ocurre que podríamos

774
01:36:58,100 --> 01:36:58,700
hacer algo así?

775
01:37:06,460 --> 01:37:09,900
Bueno, lo que hicieron estos muchachos fue...

776
01:37:13,740 --> 01:37:19,740
Fue ver qué pasado hacer lo mismo, pero con las sustituciones. ¿Cuántas veces en un

777
01:37:19,740 --> 01:37:26,380
corpo de errores, encontraron un cuerpo de errores, no es menor, cuántas veces se sustituye? Pero

778
01:37:27,540 --> 01:37:32,500
¿no buscaron cuántas veces se sustituye tomate por tomate? ¿Por qué no hicieron ese conteo?

779
01:37:34,700 --> 01:37:38,460
¿Por qué no contaron? Porque yo podía decir, bueno, ¿cuántas veces se cambió actres por

780
01:37:38,460 --> 01:37:43,180
actres, crees, crees, por crees? ¿Por qué no hicieron ese conteo? Igual le decimos con la palabra. ¿Por qué

781
01:37:43,220 --> 01:37:45,180
no aplicaron máxima valor, similitud y ya?

782
01:37:49,180 --> 01:37:57,460
Porque la cantidad de veces que yo casi seguramente es cero. Es decir, mi potencia es muy general,

783
01:37:57,460 --> 01:38:04,980
muy general tener un cuerpo de comunal. Entonces lo que hicieron fue no. Hicieron una matriz de

784
01:38:04,980 --> 01:38:14,180
confusión donde... Perdón, no la tengo acá. Donde contaron cuántas veces

785
01:38:17,180 --> 01:38:25,940
adelante de una O se ponía una A, una B, una C, una D, una E. ¿Cuántas veces después de una O se

786
01:38:25,940 --> 01:38:31,020
borraba la letra? Siguiente. ¿Cuántas veces la O se sustituía por una A, por una B, por una

787
01:38:31,020 --> 01:38:39,420
C, por una D? ¿Y cuántas veces la O se cambiaba por la siguiente? Con eso buscaron capturar esa

788
01:38:39,420 --> 01:38:44,180
intuición de que la O... ¿Por qué qué puede suceder? Y bueno, más probable que la O yo la

789
01:38:44,180 --> 01:38:50,580
sustituya por una P, porque están cerca. Pero no lo hago razonando que están cerca, sino simplemente

790
01:38:50,580 --> 01:38:54,420
contando. ¿Capaz que no es así? ¿Capaz que los datos me dicen otras cosas? ¿Capaz que me dicen

791
01:38:54,420 --> 01:38:59,740
que la O se sustituye por la letra esta que está acá, que no sé cuál es? Por la O,

792
01:38:59,900 --> 01:39:05,380
simplemente porque me confundo, yo qué sé, porque me confundo y le arrode dedo, digamos. Me meto

793
01:39:05,380 --> 01:39:14,260
el mismo dedo de la mano que no es. No importa, lo cuento a partir de los datos. ¿Tá? Y lo que

794
01:39:14,260 --> 01:39:26,580
hicieron fue bueno, dijeron, actres, la probabilidad exista, la probabilidad de que yo, las palabras

795
01:39:26,580 --> 01:39:38,260
acuerdan que era actres, de que yo borre una T antes de una R, es esta y la probabilidad combinada

796
01:39:38,260 --> 01:39:53,420
de ambas es esta. O sea, el producto de las dos, ¿sí? Si se fijan, Cres arranca con muy pocas

797
01:39:53,420 --> 01:39:57,820
expectativas de ganar, porque a priori no apareció nunca, o sea, que le da la probabilidad de esta

798
01:39:57,820 --> 01:40:02,540
residual que le dan métodos para que no de cero, tendría que ser muy alta la probabilidad para

799
01:40:02,540 --> 01:40:09,100
que se igualara. O sea, que insertar una A del antes de una C tendría que ser enorme, la probabilidad

800
01:40:09,100 --> 01:40:13,460
para que cambiara la ecuación acá. Y efectivamente no cambia nada, pero da mucho más chica.

801
01:40:13,900 --> 01:40:27,140
Al revés, la probabilidad más alta es haber insertado una, haber borrado la T. ¿De acuerdo?

802
01:40:30,380 --> 01:40:39,580
Y efectivamente, pero, pero, 5. Esta es bastante más probable, como palabra actres, es una palabra

803
01:40:39,580 --> 01:40:49,860
bastante más probable que actres. Por conteo, parece que una vez en el cuerpo, ¿sí? Y luego,

804
01:40:49,860 --> 01:40:58,940
lo que hicieron fue, bueno, ¿qué hicieron acá? Se quedaron con el porcentaje de aparición de

805
01:40:58,940 --> 01:41:04,060
cada una. ¿Qué hicieron? Volvieron a generar una distribución de probabilidad, porque todo el porcentaje

806
01:41:04,060 --> 01:41:10,380
es lo mismo con una distribución de probabilidad. Esto es 0,37, esto dan 0, 0 y 0. ¿Y cuál gana?

807
01:41:12,300 --> 01:41:19,100
¿Cuál gano? Actres. No, en realidad van no actres, porque puedo llegar de dos formas,

808
01:41:19,100 --> 01:41:25,380
pero sigue siendo la misma palabra. Entonces, estas dos se suman. O sea, que con un 0,4 de

809
01:41:25,380 --> 01:41:30,500
probabilidad, la palabra era actres. La palabra más probable, la corrección más probable,

810
01:41:30,660 --> 01:41:38,780
era actres. ¿Sí? Curiosamente, se ha equivocado, porque en ese contexto era actres.

811
01:41:40,780 --> 01:41:43,820
Pero bueno, ellos no tenían contexto para analizar.

812
01:41:52,020 --> 01:41:59,900
En la versión 3 del libro, me puse muy contento porque hay un capítulo dedicado

813
01:41:59,980 --> 01:42:07,700
especialmente a este tema, lo que muestra que es muy importante. Me puse muy contento

814
01:42:07,700 --> 01:42:13,620
porque piensa igual que yo. Qué bien que está ese tipo, dice lo mismo que yo. Y acá está el

815
01:42:13,620 --> 01:42:19,340
piper, si lo quieren leer. Sobre todo me interesaba más que por la aplicación, por el método,

816
01:42:19,340 --> 01:42:23,180
porque van a ver que este tipo de método se repita. Los métodos vallesianos se repiten

817
01:42:23,180 --> 01:42:29,100
usualmente. Y además porque tienen una cantidad, hay una cantidad de situaciones donde se puede

818
01:42:29,260 --> 01:42:37,460
utilizar este tipo de métodos. El otro día, les voy a contar una cosa. Por ejemplo, el otro día

819
01:42:41,380 --> 01:42:46,620
estaba tratando de argumentar por qué a uno en una institución le conviene publicar sus datos.

820
01:42:48,300 --> 01:42:53,540
Y la regla de valles es una buena forma de convencer a alguien de eso. Porque la regla de

821
01:42:53,540 --> 01:43:02,220
valles lo que dice es, si yo no tengo datos, como con el dado de hoy, me quedo con mi probabilidad

822
01:43:02,220 --> 01:43:11,500
que puedo traducirlos en una visión vallesiana como mi confianza, en algo, a priori. Es decir,

823
01:43:11,500 --> 01:43:19,860
si a mí lo que me preocupa es como institución que al publicar mi datos, mi imagen, en peor,

824
01:43:20,180 --> 01:43:24,980
porque me van a criticar las cosas que publico, pensemos primero cuál era la probabilidad priori,

825
01:43:24,980 --> 01:43:29,900
o decir cuál era tu imagen a priori, cuál era tu confianza a priori. Y muy probablemente,

826
01:43:29,900 --> 01:43:37,140
salvo que vos seas de verdad un desastre, cuando publicar tu dato las cosas mejoran. Eso es

827
01:43:37,140 --> 01:43:44,220
sencillamente aplicar la regla de valles en una situación de todos los días. Bueno, nos vemos en el martes.

